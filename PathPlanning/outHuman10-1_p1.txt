(* /home/sara/Dropbox/Reaching Study/Gilwoo_Automated_v2/csv_only_manual_inspection/2016_12_14_study_4_Part10_1/2016_12_14_study_4_Part10_1_428_680_clean_phase1.csv*)
inPtsRPi = {
{0.5507000,0.2930000,0.2667000},
{0.5499000,0.2930000,0.2665000},
{0.5492000,0.2932000,0.2662000},
{0.5483000,0.2935000,0.2660000},
{0.5474000,0.2940000,0.2657000},
{0.5463000,0.2948000,0.2656000},
{0.5452000,0.2956000,0.2657000},
{0.5441000,0.2968000,0.2658000},
{0.5428000,0.2982000,0.2662000},
{0.5415000,0.2996000,0.2667000},
{0.5403000,0.3012000,0.2673000},
{0.5390000,0.3030000,0.2681000},
{0.5377000,0.3050000,0.2690000},
{0.5364000,0.3072000,0.2700000},
{0.5351000,0.3097000,0.2712000},
{0.5336000,0.3127000,0.2724000},
{0.5320000,0.3159000,0.2736000},
{0.5304000,0.3193000,0.2747000},
{0.5287000,0.3229000,0.2756000},
{0.5269000,0.3266000,0.2762000},
{0.5252000,0.3303000,0.2768000},
{0.5234000,0.3341000,0.2771000},
{0.5217000,0.3380000,0.2774000},
{0.5199000,0.3421000,0.2775000},
{0.5181000,0.3464000,0.2774000},
{0.5162000,0.3509000,0.2772000},
{0.5143000,0.3556000,0.2768000},
{0.5122000,0.3606000,0.2760000},
{0.5102000,0.3656000,0.2750000},
{0.5082000,0.3708000,0.2738000},
{0.5062000,0.3760000,0.2725000},
{0.5044000,0.3817000,0.2709000},
{0.5027000,0.3875000,0.2691000},
{0.5011000,0.3933000,0.2673000},
{0.4998000,0.3989000,0.2647000},
{0.4984000,0.4049000,0.2624000},
{0.4973000,0.4108000,0.2597000},
{0.4965000,0.4166000,0.2567000},
{0.4957000,0.4226000,0.2536000},
{0.4950000,0.4286000,0.2506000},
{0.4945000,0.4347000,0.2476000},
{0.4942000,0.4408000,0.2445000},
{0.4938000,0.4470000,0.2413000},
{0.4933000,0.4534000,0.2382000},
{0.4927000,0.4600000,0.2352000},
{0.4923000,0.4666000,0.2318000},
{0.4916000,0.4734000,0.2285000},
{0.4909000,0.4805000,0.2252000},
{0.4899000,0.4877000,0.2220000},
{0.4886000,0.4951000,0.2188000},
{0.4878000,0.5031000,0.2155000},
{0.4866000,0.5105000,0.2124000},
{0.4853000,0.5179000,0.2095000},
{0.4838000,0.5254000,0.2066000},
{0.4822000,0.5334000,0.2035000},
{0.4812000,0.5417000,0.2003000},
{0.4799000,0.5500000,0.1976000},
{0.4788000,0.5583000,0.1950000},
{0.4778000,0.5667000,0.1924000},
{0.4769000,0.5751000,0.1900000},
{0.4766000,0.5836000,0.1873000},
{0.4759000,0.5917000,0.1852000},
{0.4755000,0.5999000,0.1827000},
{0.4755000,0.6079000,0.1802000},
{0.4753000,0.6160000,0.1775000},
{0.4755000,0.6240000,0.1746000},
{0.4758000,0.6319000,0.1718000},
{0.4762000,0.6397000,0.1689000},
{0.4767000,0.6473000,0.1658000},
{0.4773000,0.6549000,0.1629000},
{0.4781000,0.6622000,0.1600000},
{0.4790000,0.6694000,0.1570000},
{0.4800000,0.6766000,0.1540000},
{0.4811000,0.6835000,0.1508000},
{0.4822000,0.6905000,0.1476000},
{0.4835000,0.6972000,0.1444000},
{0.4849000,0.7039000,0.1413000},
{0.4863000,0.7103000,0.1383000},
{0.4880000,0.7166000,0.1355000},
{0.4896000,0.7227000,0.1330000},
{0.4914000,0.7284000,0.1307000},
{0.4933000,0.7338000,0.1287000},
{0.4954000,0.7389000,0.1269000},
{0.4976000,0.7436000,0.1252000},
{0.4997000,0.7480000,0.1236000},
{0.5020000,0.7521000,0.1222000},
{0.5043000,0.7558000,0.1209000},
{0.5066000,0.7591000,0.1198000},
{0.5089000,0.7621000,0.1187000},
{0.5111000,0.7647000,0.1178000},
{0.5134000,0.7668000,0.1170000},
{0.5156000,0.7685000,0.1163000},
{0.5178000,0.7698000,0.1154000},
{0.5198000,0.7710000,0.1145000},
{0.5218000,0.7719000,0.1134000},
{0.5238000,0.7726000,0.1123000},
{0.5257000,0.7732000,0.1113000},
{0.5275000,0.7736000,0.1102000},
{0.5293000,0.7738000,0.1091000}
};
inPtsRTh = {
{0.6036000,0.2973000,0.2584000},
{0.6029000,0.2973000,0.2585000},
{0.6030000,0.2975000,0.2593000},
{0.6023000,0.2978000,0.2595000},
{0.6013000,0.2983000,0.2598000},
{0.6002000,0.2988000,0.2601000},
{0.5991000,0.2997000,0.2607000},
{0.5978000,0.3006000,0.2616000},
{0.5966000,0.3017000,0.2628000},
{0.5952000,0.3029000,0.2642000},
{0.5938000,0.3043000,0.2658000},
{0.5924000,0.3058000,0.2676000},
{0.5910000,0.3075000,0.2695000},
{0.5895000,0.3094000,0.2716000},
{0.5879000,0.3117000,0.2738000},
{0.5862000,0.3141000,0.2764000},
{0.5846000,0.3170000,0.2788000},
{0.5828000,0.3202000,0.2811000},
{0.5810000,0.3235000,0.2831000},
{0.5791000,0.3268000,0.2849000},
{0.5772000,0.3303000,0.2863000},
{0.5752000,0.3337000,0.2875000},
{0.5733000,0.3373000,0.2885000},
{0.5714000,0.3411000,0.2893000},
{0.5694000,0.3451000,0.2900000},
{0.5673000,0.3494000,0.2907000},
{0.5651000,0.3538000,0.2911000},
{0.5628000,0.3584000,0.2913000},
{0.5605000,0.3631000,0.2915000},
{0.5582000,0.3680000,0.2913000},
{0.5558000,0.3730000,0.2908000},
{0.5537000,0.3782000,0.2900000},
{0.5516000,0.3835000,0.2889000},
{0.5497000,0.3890000,0.2876000},
{0.5480000,0.3944000,0.2860000},
{0.5463000,0.3999000,0.2842000},
{0.5449000,0.4054000,0.2821000},
{0.5436000,0.4109000,0.2798000},
{0.5425000,0.4165000,0.2773000},
{0.5416000,0.4221000,0.2746000},
{0.5409000,0.4279000,0.2718000},
{0.5404000,0.4336000,0.2689000},
{0.5397000,0.4394000,0.2661000},
{0.5391000,0.4453000,0.2631000},
{0.5383000,0.4513000,0.2603000},
{0.5374000,0.4574000,0.2574000},
{0.5363000,0.4636000,0.2547000},
{0.5350000,0.4701000,0.2520000},
{0.5337000,0.4768000,0.2492000},
{0.5322000,0.4834000,0.2465000},
{0.5306000,0.4902000,0.2438000},
{0.5288000,0.4971000,0.2411000},
{0.5269000,0.5040000,0.2384000},
{0.5250000,0.5110000,0.2357000},
{0.5230000,0.5181000,0.2331000},
{0.5211000,0.5254000,0.2307000},
{0.5193000,0.5327000,0.2281000},
{0.5176000,0.5401000,0.2257000},
{0.5160000,0.5476000,0.2233000},
{0.5147000,0.5550000,0.2208000},
{0.5137000,0.5623000,0.2184000},
{0.5127000,0.5696000,0.2158000},
{0.5119000,0.5768000,0.2131000},
{0.5113000,0.5839000,0.2104000},
{0.5108000,0.5910000,0.2075000},
{0.5103000,0.5980000,0.2046000},
{0.5100000,0.6050000,0.2015000},
{0.5099000,0.6119000,0.1983000},
{0.5099000,0.6187000,0.1950000},
{0.5102000,0.6252000,0.1915000},
{0.5106000,0.6316000,0.1878000},
{0.5113000,0.6378000,0.1840000},
{0.5119000,0.6438000,0.1800000},
{0.5125000,0.6498000,0.1761000},
{0.5132000,0.6558000,0.1723000},
{0.5139000,0.6617000,0.1687000},
{0.5146000,0.6677000,0.1653000},
{0.5154000,0.6736000,0.1621000},
{0.5163000,0.6791000,0.1590000},
{0.5174000,0.6845000,0.1561000},
{0.5186000,0.6895000,0.1533000},
{0.5200000,0.6941000,0.1506000},
{0.5216000,0.6985000,0.1483000},
{0.5231000,0.7026000,0.1461000},
{0.5246000,0.7068000,0.1439000},
{0.5263000,0.7101000,0.1423000},
{0.5279000,0.7134000,0.1405000},
{0.5296000,0.7160000,0.1391000},
{0.5312000,0.7186000,0.1374000},
{0.5331000,0.7205000,0.1360000},
{0.5349000,0.7221000,0.1346000},
{0.5369000,0.7234000,0.1331000},
{0.5389000,0.7246000,0.1317000},
{0.5408000,0.7255000,0.1303000},
{0.5426000,0.7261000,0.1289000},
{0.5443000,0.7266000,0.1276000},
{0.5460000,0.7270000,0.1262000},
{0.5476000,0.7271000,0.1248000},
{0.5491000,0.7271000,0.1235000}
};
inPtsRW = {
{0.5634000,0.3512000,0.2962000},
{0.5623000,0.3512000,0.2958000},
{0.5614000,0.3514000,0.2954000},
{0.5603000,0.3517000,0.2950000},
{0.5592000,0.3522000,0.2947000},
{0.5580000,0.3530000,0.2943000},
{0.5568000,0.3541000,0.2940000},
{0.5555000,0.3553000,0.2939000},
{0.5540000,0.3568000,0.2939000},
{0.5525000,0.3584000,0.2940000},
{0.5510000,0.3602000,0.2942000},
{0.5496000,0.3623000,0.2945000},
{0.5482000,0.3645000,0.2949000},
{0.5467000,0.3670000,0.2953000},
{0.5451000,0.3699000,0.2958000},
{0.5436000,0.3731000,0.2963000},
{0.5419000,0.3767000,0.2968000},
{0.5402000,0.3804000,0.2971000},
{0.5385000,0.3842000,0.2974000},
{0.5368000,0.3881000,0.2975000},
{0.5352000,0.3920000,0.2976000},
{0.5336000,0.3960000,0.2975000},
{0.5321000,0.4000000,0.2974000},
{0.5305000,0.4042000,0.2969000},
{0.5289000,0.4085000,0.2964000},
{0.5273000,0.4131000,0.2957000},
{0.5257000,0.4179000,0.2948000},
{0.5239000,0.4229000,0.2937000},
{0.5221000,0.4280000,0.2924000},
{0.5203000,0.4332000,0.2912000},
{0.5188000,0.4386000,0.2896000},
{0.5172000,0.4441000,0.2878000},
{0.5159000,0.4498000,0.2859000},
{0.5148000,0.4556000,0.2838000},
{0.5138000,0.4613000,0.2816000},
{0.5131000,0.4671000,0.2791000},
{0.5122000,0.4728000,0.2766000},
{0.5117000,0.4785000,0.2739000},
{0.5112000,0.4843000,0.2710000},
{0.5110000,0.4901000,0.2682000},
{0.5109000,0.4960000,0.2654000},
{0.5109000,0.5019000,0.2625000},
{0.5110000,0.5080000,0.2597000},
{0.5110000,0.5142000,0.2568000},
{0.5110000,0.5205000,0.2539000},
{0.5109000,0.5269000,0.2509000},
{0.5107000,0.5335000,0.2479000},
{0.5105000,0.5403000,0.2449000},
{0.5102000,0.5473000,0.2418000},
{0.5099000,0.5543000,0.2388000},
{0.5095000,0.5615000,0.2359000},
{0.5091000,0.5687000,0.2330000},
{0.5085000,0.5759000,0.2302000},
{0.5079000,0.5830000,0.2276000},
{0.5076000,0.5907000,0.2249000},
{0.5072000,0.5982000,0.2223000},
{0.5067000,0.6059000,0.2200000},
{0.5064000,0.6137000,0.2177000},
{0.5063000,0.6215000,0.2156000},
{0.5066000,0.6289000,0.2136000},
{0.5068000,0.6366000,0.2116000},
{0.5074000,0.6440000,0.2096000},
{0.5080000,0.6513000,0.2077000},
{0.5088000,0.6584000,0.2057000},
{0.5096000,0.6655000,0.2036000},
{0.5104000,0.6725000,0.2015000},
{0.5113000,0.6795000,0.1991000},
{0.5124000,0.6863000,0.1967000},
{0.5135000,0.6930000,0.1943000},
{0.5148000,0.6994000,0.1919000},
{0.5162000,0.7056000,0.1896000},
{0.5177000,0.7115000,0.1872000},
{0.5193000,0.7172000,0.1847000},
{0.5208000,0.7229000,0.1822000},
{0.5224000,0.7286000,0.1796000},
{0.5241000,0.7343000,0.1769000},
{0.5258000,0.7399000,0.1743000},
{0.5276000,0.7453000,0.1717000},
{0.5294000,0.7506000,0.1693000},
{0.5315000,0.7555000,0.1671000},
{0.5336000,0.7601000,0.1650000},
{0.5358000,0.7644000,0.1632000},
{0.5381000,0.7684000,0.1615000},
{0.5405000,0.7721000,0.1599000},
{0.5429000,0.7755000,0.1584000},
{0.5455000,0.7785000,0.1569000},
{0.5479000,0.7813000,0.1555000},
{0.5504000,0.7836000,0.1541000},
{0.5528000,0.7856000,0.1527000},
{0.5553000,0.7871000,0.1518000},
{0.5575000,0.7884000,0.1508000},
{0.5598000,0.7893000,0.1500000},
{0.5620000,0.7901000,0.1490000},
{0.5641000,0.7907000,0.1481000},
{0.5661000,0.7912000,0.1469000},
{0.5680000,0.7915000,0.1458000},
{0.5698000,0.7917000,0.1446000},
{0.5715000,0.7917000,0.1433000},
{0.5732000,0.7916000,0.1420000}
};
inPtsRLA = {
{0.5446000,0.4597000,0.3042000},
{0.5438000,0.4597000,0.3038000},
{0.5432000,0.4599000,0.3031000},
{0.5425000,0.4603000,0.3023000},
{0.5418000,0.4608000,0.3014000},
{0.5410000,0.4615000,0.3004000},
{0.5405000,0.4625000,0.2991000},
{0.5396000,0.4638000,0.2980000},
{0.5388000,0.4653000,0.2968000},
{0.5380000,0.4670000,0.2957000},
{0.5372000,0.4689000,0.2946000},
{0.5365000,0.4709000,0.2936000},
{0.5357000,0.4731000,0.2925000},
{0.5350000,0.4755000,0.2914000},
{0.5343000,0.4782000,0.2901000},
{0.5336000,0.4811000,0.2887000},
{0.5329000,0.4844000,0.2873000},
{0.5323000,0.4880000,0.2858000},
{0.5319000,0.4917000,0.2843000},
{0.5314000,0.4956000,0.2831000},
{0.5311000,0.4995000,0.2821000},
{0.5308000,0.5032000,0.2810000},
{0.5305000,0.5071000,0.2798000},
{0.5296000,0.5110000,0.2787000},
{0.5291000,0.5151000,0.2773000},
{0.5288000,0.5193000,0.2757000},
{0.5285000,0.5237000,0.2740000},
{0.5283000,0.5284000,0.2722000},
{0.5281000,0.5333000,0.2705000},
{0.5280000,0.5383000,0.2687000},
{0.5280000,0.5433000,0.2667000},
{0.5280000,0.5485000,0.2647000},
{0.5281000,0.5538000,0.2624000},
{0.5283000,0.5593000,0.2602000},
{0.5286000,0.5649000,0.2579000},
{0.5290000,0.5705000,0.2557000},
{0.5295000,0.5761000,0.2535000},
{0.5301000,0.5817000,0.2513000},
{0.5308000,0.5873000,0.2490000},
{0.5315000,0.5929000,0.2467000},
{0.5322000,0.5986000,0.2442000},
{0.5332000,0.6044000,0.2417000},
{0.5343000,0.6102000,0.2393000},
{0.5355000,0.6162000,0.2369000},
{0.5368000,0.6221000,0.2345000},
{0.5381000,0.6281000,0.2321000},
{0.5395000,0.6343000,0.2297000},
{0.5409000,0.6406000,0.2271000},
{0.5423000,0.6470000,0.2245000},
{0.5436000,0.6536000,0.2218000},
{0.5450000,0.6602000,0.2194000},
{0.5465000,0.6668000,0.2170000},
{0.5479000,0.6735000,0.2148000},
{0.5493000,0.6800000,0.2129000},
{0.5507000,0.6866000,0.2109000},
{0.5522000,0.6932000,0.2091000},
{0.5537000,0.6998000,0.2074000},
{0.5553000,0.7066000,0.2057000},
{0.5571000,0.7134000,0.2042000},
{0.5589000,0.7202000,0.2028000},
{0.5608000,0.7269000,0.2016000},
{0.5629000,0.7335000,0.2004000},
{0.5650000,0.7400000,0.1993000},
{0.5672000,0.7463000,0.1982000},
{0.5695000,0.7525000,0.1971000},
{0.5718000,0.7586000,0.1960000},
{0.5742000,0.7646000,0.1948000},
{0.5766000,0.7704000,0.1937000},
{0.5790000,0.7762000,0.1925000},
{0.5814000,0.7817000,0.1913000},
{0.5838000,0.7871000,0.1901000},
{0.5863000,0.7922000,0.1890000},
{0.5888000,0.7972000,0.1879000},
{0.5913000,0.8019000,0.1868000},
{0.5939000,0.8066000,0.1856000},
{0.5965000,0.8112000,0.1843000},
{0.5991000,0.8157000,0.1831000},
{0.6019000,0.8200000,0.1817000},
{0.6047000,0.8241000,0.1804000},
{0.6075000,0.8281000,0.1792000},
{0.6104000,0.8317000,0.1781000},
{0.6133000,0.8351000,0.1770000},
{0.6163000,0.8383000,0.1761000},
{0.6193000,0.8412000,0.1751000},
{0.6223000,0.8438000,0.1742000},
{0.6253000,0.8461000,0.1733000},
{0.6282000,0.8483000,0.1724000},
{0.6310000,0.8501000,0.1715000},
{0.6338000,0.8516000,0.1705000},
{0.6363000,0.8530000,0.1696000},
{0.6388000,0.8540000,0.1688000},
{0.6412000,0.8549000,0.1680000},
{0.6434000,0.8556000,0.1673000},
{0.6455000,0.8562000,0.1665000},
{0.6475000,0.8566000,0.1657000},
{0.6494000,0.8570000,0.1648000},
{0.6511000,0.8572000,0.1638000},
{0.6527000,0.8573000,0.1627000},
{0.6542000,0.8572000,0.1617000}
};
inPtsREl = {
{0.5338000,0.5805000,0.2918000},
{0.5335000,0.5806000,0.2909000},
{0.5333000,0.5808000,0.2900000},
{0.5332000,0.5811000,0.2889000},
{0.5330000,0.5817000,0.2877000},
{0.5328000,0.5823000,0.2862000},
{0.5328000,0.5832000,0.2844000},
{0.5327000,0.5844000,0.2824000},
{0.5328000,0.5858000,0.2804000},
{0.5330000,0.5874000,0.2782000},
{0.5331000,0.5892000,0.2761000},
{0.5334000,0.5911000,0.2740000},
{0.5336000,0.5932000,0.2718000},
{0.5339000,0.5954000,0.2695000},
{0.5341000,0.5978000,0.2670000},
{0.5345000,0.6004000,0.2643000},
{0.5349000,0.6034000,0.2615000},
{0.5355000,0.6065000,0.2586000},
{0.5362000,0.6099000,0.2560000},
{0.5371000,0.6134000,0.2537000},
{0.5381000,0.6169000,0.2516000},
{0.5391000,0.6204000,0.2498000},
{0.5402000,0.6240000,0.2480000},
{0.5413000,0.6275000,0.2461000},
{0.5423000,0.6313000,0.2441000},
{0.5433000,0.6351000,0.2421000},
{0.5444000,0.6393000,0.2399000},
{0.5458000,0.6439000,0.2375000},
{0.5469000,0.6480000,0.2356000},
{0.5483000,0.6526000,0.2334000},
{0.5499000,0.6571000,0.2313000},
{0.5516000,0.6620000,0.2291000},
{0.5533000,0.6669000,0.2269000},
{0.5551000,0.6720000,0.2248000},
{0.5569000,0.6773000,0.2228000},
{0.5587000,0.6828000,0.2211000},
{0.5605000,0.6882000,0.2194000},
{0.5623000,0.6937000,0.2179000},
{0.5642000,0.6991000,0.2164000},
{0.5661000,0.7047000,0.2148000},
{0.5681000,0.7102000,0.2132000},
{0.5703000,0.7157000,0.2115000},
{0.5727000,0.7213000,0.2098000},
{0.5751000,0.7269000,0.2081000},
{0.5777000,0.7329000,0.2062000},
{0.5804000,0.7388000,0.2045000},
{0.5832000,0.7445000,0.2028000},
{0.5863000,0.7503000,0.2009000},
{0.5894000,0.7561000,0.1991000},
{0.5927000,0.7620000,0.1974000},
{0.5961000,0.7678000,0.1957000},
{0.5994000,0.7735000,0.1941000},
{0.6028000,0.7791000,0.1928000},
{0.6062000,0.7847000,0.1916000},
{0.6097000,0.7902000,0.1906000},
{0.6132000,0.7957000,0.1896000},
{0.6169000,0.8011000,0.1888000},
{0.6207000,0.8065000,0.1881000},
{0.6247000,0.8120000,0.1875000},
{0.6286000,0.8175000,0.1870000},
{0.6324000,0.8230000,0.1867000},
{0.6363000,0.8284000,0.1866000},
{0.6402000,0.8337000,0.1865000},
{0.6440000,0.8388000,0.1865000},
{0.6479000,0.8437000,0.1866000},
{0.6518000,0.8485000,0.1868000},
{0.6557000,0.8532000,0.1869000},
{0.6596000,0.8577000,0.1872000},
{0.6634000,0.8621000,0.1875000},
{0.6672000,0.8664000,0.1878000},
{0.6708000,0.8705000,0.1881000},
{0.6745000,0.8745000,0.1884000},
{0.6780000,0.8782000,0.1887000},
{0.6816000,0.8817000,0.1890000},
{0.6852000,0.8851000,0.1893000},
{0.6888000,0.8884000,0.1895000},
{0.6925000,0.8914000,0.1896000},
{0.6963000,0.8943000,0.1897000},
{0.7000000,0.8970000,0.1898000},
{0.7038000,0.8996000,0.1898000},
{0.7075000,0.9019000,0.1897000},
{0.7112000,0.9040000,0.1896000},
{0.7149000,0.9059000,0.1895000},
{0.7186000,0.9077000,0.1893000},
{0.7222000,0.9093000,0.1892000},
{0.7257000,0.9107000,0.1890000},
{0.7291000,0.9119000,0.1887000},
{0.7324000,0.9130000,0.1884000},
{0.7354000,0.9139000,0.1879000},
{0.7383000,0.9146000,0.1874000},
{0.7411000,0.9152000,0.1869000},
{0.7436000,0.9157000,0.1863000},
{0.7460000,0.9161000,0.1859000},
{0.7482000,0.9164000,0.1854000},
{0.7503000,0.9168000,0.1849000},
{0.7521000,0.9170000,0.1843000},
{0.7538000,0.9171000,0.1837000},
{0.7554000,0.9172000,0.1830000},
{0.7568000,0.9172000,0.1822000}
};
inPtsRUA = {
{0.6139000,0.6920000,0.3849000},
{0.6136000,0.6917000,0.3847000},
{0.6132000,0.6915000,0.3843000},
{0.6129000,0.6914000,0.3838000},
{0.6127000,0.6914000,0.3832000},
{0.6124000,0.6915000,0.3825000},
{0.6122000,0.6917000,0.3819000},
{0.6121000,0.6920000,0.3811000},
{0.6120000,0.6926000,0.3804000},
{0.6120000,0.6932000,0.3796000},
{0.6121000,0.6942000,0.3786000},
{0.6121000,0.6951000,0.3777000},
{0.6123000,0.6963000,0.3768000},
{0.6125000,0.6975000,0.3759000},
{0.6126000,0.6988000,0.3749000},
{0.6127000,0.7002000,0.3740000},
{0.6129000,0.7016000,0.3731000},
{0.6132000,0.7033000,0.3722000},
{0.6135000,0.7052000,0.3712000},
{0.6141000,0.7074000,0.3703000},
{0.6150000,0.7097000,0.3694000},
{0.6159000,0.7121000,0.3685000},
{0.6170000,0.7146000,0.3676000},
{0.6180000,0.7170000,0.3669000},
{0.6190000,0.7193000,0.3663000},
{0.6200000,0.7216000,0.3658000},
{0.6208000,0.7240000,0.3652000},
{0.6215000,0.7266000,0.3647000},
{0.6223000,0.7294000,0.3642000},
{0.6232000,0.7324000,0.3636000},
{0.6241000,0.7362000,0.3630000},
{0.6253000,0.7393000,0.3623000},
{0.6267000,0.7425000,0.3617000},
{0.6283000,0.7456000,0.3610000},
{0.6300000,0.7487000,0.3604000},
{0.6318000,0.7519000,0.3598000},
{0.6336000,0.7553000,0.3591000},
{0.6354000,0.7586000,0.3584000},
{0.6373000,0.7621000,0.3576000},
{0.6391000,0.7654000,0.3570000},
{0.6410000,0.7687000,0.3564000},
{0.6427000,0.7718000,0.3559000},
{0.6444000,0.7749000,0.3555000},
{0.6461000,0.7779000,0.3552000},
{0.6478000,0.7811000,0.3548000},
{0.6495000,0.7840000,0.3545000},
{0.6513000,0.7871000,0.3541000},
{0.6531000,0.7901000,0.3535000},
{0.6550000,0.7933000,0.3527000},
{0.6572000,0.7962000,0.3522000},
{0.6595000,0.7993000,0.3515000},
{0.6618000,0.8023000,0.3507000},
{0.6642000,0.8054000,0.3499000},
{0.6668000,0.8084000,0.3491000},
{0.6693000,0.8113000,0.3484000},
{0.6719000,0.8143000,0.3478000},
{0.6745000,0.8172000,0.3473000},
{0.6771000,0.8200000,0.3468000},
{0.6797000,0.8228000,0.3465000},
{0.6822000,0.8255000,0.3463000},
{0.6847000,0.8282000,0.3461000},
{0.6871000,0.8310000,0.3461000},
{0.6895000,0.8338000,0.3462000},
{0.6919000,0.8366000,0.3464000},
{0.6945000,0.8392000,0.3466000},
{0.6970000,0.8419000,0.3468000},
{0.6996000,0.8443000,0.3471000},
{0.7022000,0.8466000,0.3472000},
{0.7048000,0.8488000,0.3473000},
{0.7073000,0.8510000,0.3473000},
{0.7096000,0.8530000,0.3473000},
{0.7119000,0.8551000,0.3473000},
{0.7141000,0.8572000,0.3474000},
{0.7162000,0.8592000,0.3476000},
{0.7183000,0.8611000,0.3477000},
{0.7205000,0.8629000,0.3477000},
{0.7226000,0.8646000,0.3477000},
{0.7247000,0.8663000,0.3476000},
{0.7268000,0.8678000,0.3474000},
{0.7289000,0.8693000,0.3471000},
{0.7310000,0.8707000,0.3469000},
{0.7331000,0.8721000,0.3467000},
{0.7352000,0.8734000,0.3465000},
{0.7375000,0.8745000,0.3462000},
{0.7396000,0.8759000,0.3460000},
{0.7418000,0.8771000,0.3457000},
{0.7442000,0.8781000,0.3454000},
{0.7463000,0.8792000,0.3451000},
{0.7484000,0.8802000,0.3447000},
{0.7503000,0.8813000,0.3444000},
{0.7524000,0.8821000,0.3441000},
{0.7542000,0.8828000,0.3437000},
{0.7557000,0.8836000,0.3433000},
{0.7574000,0.8841000,0.3428000},
{0.7588000,0.8847000,0.3423000},
{0.7601000,0.8851000,0.3417000},
{0.7612000,0.8857000,0.3411000},
{0.7623000,0.8862000,0.3405000},
{0.7632000,0.8867000,0.3399000}
};
inPtsRSh = {
{0.7078000,0.7169000,0.5023000},
{0.7075000,0.7166000,0.5023000},
{0.7070000,0.7161000,0.5023000},
{0.7065000,0.7156000,0.5022000},
{0.7059000,0.7152000,0.5022000},
{0.7054000,0.7147000,0.5021000},
{0.7049000,0.7144000,0.5020000},
{0.7045000,0.7141000,0.5019000},
{0.7041000,0.7139000,0.5018000},
{0.7038000,0.7137000,0.5017000},
{0.7035000,0.7137000,0.5016000},
{0.7032000,0.7137000,0.5015000},
{0.7029000,0.7139000,0.5014000},
{0.7027000,0.7140000,0.5014000},
{0.7024000,0.7142000,0.5014000},
{0.7022000,0.7145000,0.5014000},
{0.7020000,0.7148000,0.5013000},
{0.7018000,0.7151000,0.5012000},
{0.7017000,0.7156000,0.5010000},
{0.7017000,0.7162000,0.5009000},
{0.7017000,0.7171000,0.5008000},
{0.7018000,0.7181000,0.5009000},
{0.7020000,0.7192000,0.5010000},
{0.7023000,0.7203000,0.5012000},
{0.7026000,0.7214000,0.5014000},
{0.7029000,0.7224000,0.5016000},
{0.7032000,0.7236000,0.5017000},
{0.7034000,0.7246000,0.5017000},
{0.7037000,0.7258000,0.5017000},
{0.7040000,0.7270000,0.5017000},
{0.7044000,0.7283000,0.5018000},
{0.7049000,0.7296000,0.5019000},
{0.7055000,0.7309000,0.5020000},
{0.7061000,0.7322000,0.5021000},
{0.7070000,0.7340000,0.5023000},
{0.7077000,0.7353000,0.5023000},
{0.7084000,0.7366000,0.5023000},
{0.7091000,0.7380000,0.5023000},
{0.7098000,0.7395000,0.5024000},
{0.7106000,0.7409000,0.5025000},
{0.7113000,0.7421000,0.5025000},
{0.7121000,0.7433000,0.5025000},
{0.7129000,0.7444000,0.5024000},
{0.7137000,0.7454000,0.5024000},
{0.7145000,0.7465000,0.5023000},
{0.7154000,0.7475000,0.5022000},
{0.7162000,0.7486000,0.5021000},
{0.7169000,0.7497000,0.5019000},
{0.7177000,0.7507000,0.5016000},
{0.7184000,0.7518000,0.5012000},
{0.7191000,0.7528000,0.5008000},
{0.7198000,0.7539000,0.5004000},
{0.7205000,0.7551000,0.4999000},
{0.7212000,0.7562000,0.4996000},
{0.7219000,0.7574000,0.4993000},
{0.7227000,0.7586000,0.4990000},
{0.7234000,0.7598000,0.4988000},
{0.7241000,0.7609000,0.4987000},
{0.7248000,0.7620000,0.4985000},
{0.7255000,0.7631000,0.4984000},
{0.7263000,0.7642000,0.4982000},
{0.7271000,0.7652000,0.4981000},
{0.7279000,0.7663000,0.4980000},
{0.7288000,0.7673000,0.4980000},
{0.7297000,0.7684000,0.4980000},
{0.7306000,0.7694000,0.4979000},
{0.7315000,0.7705000,0.4979000},
{0.7324000,0.7716000,0.4979000},
{0.7333000,0.7726000,0.4979000},
{0.7341000,0.7737000,0.4978000},
{0.7350000,0.7748000,0.4977000},
{0.7359000,0.7759000,0.4977000},
{0.7368000,0.7770000,0.4975000},
{0.7377000,0.7780000,0.4974000},
{0.7386000,0.7791000,0.4973000},
{0.7395000,0.7801000,0.4971000},
{0.7404000,0.7811000,0.4970000},
{0.7412000,0.7821000,0.4967000},
{0.7420000,0.7833000,0.4965000},
{0.7428000,0.7844000,0.4963000},
{0.7436000,0.7855000,0.4961000},
{0.7445000,0.7866000,0.4959000},
{0.7454000,0.7876000,0.4957000},
{0.7463000,0.7887000,0.4955000},
{0.7472000,0.7898000,0.4953000},
{0.7481000,0.7909000,0.4951000},
{0.7491000,0.7920000,0.4948000},
{0.7501000,0.7931000,0.4946000},
{0.7512000,0.7943000,0.4944000},
{0.7523000,0.7955000,0.4942000},
{0.7533000,0.7966000,0.4939000},
{0.7544000,0.7977000,0.4937000},
{0.7554000,0.7987000,0.4935000},
{0.7563000,0.7997000,0.4933000},
{0.7572000,0.8007000,0.4930000},
{0.7580000,0.8018000,0.4927000},
{0.7588000,0.8027000,0.4924000},
{0.7595000,0.8037000,0.4920000},
{0.7602000,0.8046000,0.4916000}
};
inPtsRCh = {
{0.7227000,0.6083000,0.4258000},
{0.7223000,0.6077000,0.4257000},
{0.7219000,0.6072000,0.4256000},
{0.7214000,0.6067000,0.4255000},
{0.7210000,0.6061000,0.4254000},
{0.7206000,0.6056000,0.4252000},
{0.7201000,0.6051000,0.4251000},
{0.7197000,0.6045000,0.4250000},
{0.7197000,0.6045000,0.4250000},
{0.7192000,0.6043000,0.4250000},
{0.7189000,0.6043000,0.4249000},
{0.7186000,0.6044000,0.4247000},
{0.7183000,0.6046000,0.4246000},
{0.7180000,0.6049000,0.4244000},
{0.7177000,0.6053000,0.4242000},
{0.7175000,0.6058000,0.4239000},
{0.7171000,0.6063000,0.4236000},
{0.7167000,0.6066000,0.4233000},
{0.7161000,0.6071000,0.4232000},
{0.7156000,0.6076000,0.4231000},
{0.7150000,0.6083000,0.4231000},
{0.7145000,0.6093000,0.4229000},
{0.7139000,0.6103000,0.4229000},
{0.7133000,0.6115000,0.4229000},
{0.7127000,0.6125000,0.4229000},
{0.7121000,0.6137000,0.4229000},
{0.7115000,0.6148000,0.4229000},
{0.7108000,0.6159000,0.4229000},
{0.7102000,0.6171000,0.4228000},
{0.7095000,0.6184000,0.4227000},
{0.7090000,0.6197000,0.4226000},
{0.7086000,0.6211000,0.4226000},
{0.7080000,0.6225000,0.4226000},
{0.7075000,0.6238000,0.4227000},
{0.7071000,0.6251000,0.4227000},
{0.7068000,0.6264000,0.4227000},
{0.7065000,0.6278000,0.4227000},
{0.7062000,0.6292000,0.4228000},
{0.7060000,0.6307000,0.4227000},
{0.7059000,0.6321000,0.4227000},
{0.7059000,0.6335000,0.4227000},
{0.7058000,0.6349000,0.4226000},
{0.7059000,0.6361000,0.4225000},
{0.7061000,0.6373000,0.4223000},
{0.7063000,0.6387000,0.4221000},
{0.7066000,0.6399000,0.4219000},
{0.7068000,0.6411000,0.4217000},
{0.7072000,0.6423000,0.4215000},
{0.7075000,0.6434000,0.4213000},
{0.7078000,0.6445000,0.4210000},
{0.7081000,0.6456000,0.4207000},
{0.7085000,0.6466000,0.4204000},
{0.7088000,0.6477000,0.4201000},
{0.7091000,0.6487000,0.4198000},
{0.7095000,0.6499000,0.4196000},
{0.7098000,0.6510000,0.4193000},
{0.7102000,0.6522000,0.4191000},
{0.7106000,0.6534000,0.4190000},
{0.7097000,0.6541000,0.4189000},
{0.7103000,0.6555000,0.4188000},
{0.7109000,0.6568000,0.4187000},
{0.7114000,0.6580000,0.4186000},
{0.7118000,0.6593000,0.4185000},
{0.7121000,0.6604000,0.4185000},
{0.7124000,0.6615000,0.4185000},
{0.7127000,0.6627000,0.4186000},
{0.7130000,0.6638000,0.4186000},
{0.7132000,0.6650000,0.4186000},
{0.7135000,0.6661000,0.4187000},
{0.7137000,0.6672000,0.4187000},
{0.7140000,0.6683000,0.4187000},
{0.7143000,0.6694000,0.4187000},
{0.7146000,0.6706000,0.4187000},
{0.7150000,0.6717000,0.4187000},
{0.7154000,0.6728000,0.4186000},
{0.7157000,0.6739000,0.4185000},
{0.7161000,0.6750000,0.4185000},
{0.7165000,0.6761000,0.4184000},
{0.7168000,0.6771000,0.4184000},
{0.7171000,0.6781000,0.4184000},
{0.7176000,0.6790000,0.4184000},
{0.7179000,0.6801000,0.4184000},
{0.7183000,0.6810000,0.4184000},
{0.7186000,0.6821000,0.4183000},
{0.7190000,0.6831000,0.4183000},
{0.7195000,0.6842000,0.4182000},
{0.7199000,0.6853000,0.4181000},
{0.7204000,0.6864000,0.4180000},
{0.7208000,0.6876000,0.4180000},
{0.7212000,0.6886000,0.4179000},
{0.7217000,0.6898000,0.4178000},
{0.7221000,0.6909000,0.4178000},
{0.7226000,0.6920000,0.4178000},
{0.7230000,0.6930000,0.4177000},
{0.7233000,0.6940000,0.4177000},
{0.7238000,0.6949000,0.4177000},
{0.7241000,0.6959000,0.4176000},
{0.7245000,0.6967000,0.4175000},
{0.7248000,0.6976000,0.4175000}
};
inPtsMCh = {
{0.7428000,0.5818000,0.3448000},
{0.7424000,0.5813000,0.3447000},
{0.7420000,0.5808000,0.3446000},
{0.7416000,0.5802000,0.3445000},
{0.7412000,0.5797000,0.3443000},
{0.7408000,0.5792000,0.3442000},
{0.7404000,0.5787000,0.3441000},
{0.7400000,0.5782000,0.3440000},
{0.7396000,0.5777000,0.3439000},
{0.7392000,0.5771000,0.3438000},
{0.7388000,0.5766000,0.3437000},
{0.7384000,0.5761000,0.3436000},
{0.7380000,0.5756000,0.3435000},
{0.7377000,0.5751000,0.3434000},
{0.7373000,0.5745000,0.3432000},
{0.7369000,0.5740000,0.3431000},
{0.7365000,0.5735000,0.3430000},
{0.7361000,0.5730000,0.3429000},
{0.7357000,0.5725000,0.3428000},
{0.7353000,0.5719000,0.3427000},
{0.7349000,0.5714000,0.3426000},
{0.7345000,0.5709000,0.3425000},
{0.7341000,0.5704000,0.3424000},
{0.7337000,0.5699000,0.3423000},
{0.7333000,0.5693000,0.3421000},
{0.7329000,0.5688000,0.3420000},
{0.7329000,0.5688000,0.3420000},
{0.7321000,0.5699000,0.3417000},
{0.7312000,0.5708000,0.3416000},
{0.7303000,0.5717000,0.3414000},
{0.7293000,0.5726000,0.3413000},
{0.7283000,0.5735000,0.3412000},
{0.7273000,0.5746000,0.3412000},
{0.7264000,0.5755000,0.3412000},
{0.7255000,0.5765000,0.3412000},
{0.7246000,0.5774000,0.3412000},
{0.7237000,0.5783000,0.3411000},
{0.7229000,0.5793000,0.3411000},
{0.7221000,0.5802000,0.3411000},
{0.7215000,0.5813000,0.3411000},
{0.7209000,0.5822000,0.3411000},
{0.7204000,0.5832000,0.3411000},
{0.7199000,0.5841000,0.3411000},
{0.7195000,0.5850000,0.3411000},
{0.7191000,0.5858000,0.3411000},
{0.7188000,0.5868000,0.3411000},
{0.7186000,0.5875000,0.3410000},
{0.7185000,0.5885000,0.3409000},
{0.7185000,0.5892000,0.3409000},
{0.7185000,0.5900000,0.3408000},
{0.7186000,0.5908000,0.3407000},
{0.7187000,0.5916000,0.3405000},
{0.7189000,0.5923000,0.3403000},
{0.7189000,0.5930000,0.3401000},
{0.7190000,0.5938000,0.3399000},
{0.7190000,0.5945000,0.3398000},
{0.7191000,0.5953000,0.3397000},
{0.7192000,0.5962000,0.3396000},
{0.7192000,0.5969000,0.3396000},
{0.7191000,0.5978000,0.3397000},
{0.7191000,0.5985000,0.3398000},
{0.7188000,0.5994000,0.3398000},
{0.7188000,0.6002000,0.3399000},
{0.7187000,0.6011000,0.3398000},
{0.7184000,0.6020000,0.3399000},
{0.7183000,0.6030000,0.3400000},
{0.7182000,0.6038000,0.3401000},
{0.7180000,0.6048000,0.3401000},
{0.7177000,0.6058000,0.3403000},
{0.7175000,0.6068000,0.3404000},
{0.7162000,0.6074000,0.3405000},
{0.7162000,0.6085000,0.3405000},
{0.7163000,0.6095000,0.3405000},
{0.7163000,0.6105000,0.3405000},
{0.7164000,0.6114000,0.3405000},
{0.7164000,0.6124000,0.3405000},
{0.7165000,0.6132000,0.3406000},
{0.7166000,0.6142000,0.3407000},
{0.7167000,0.6149000,0.3407000},
{0.7168000,0.6159000,0.3408000},
{0.7170000,0.6167000,0.3409000},
{0.7171000,0.6176000,0.3410000},
{0.7173000,0.6184000,0.3410000},
{0.7174000,0.6193000,0.3410000},
{0.7174000,0.6201000,0.3410000},
{0.7175000,0.6210000,0.3411000},
{0.7176000,0.6219000,0.3411000},
{0.7177000,0.6228000,0.3411000},
{0.7177000,0.6238000,0.3412000},
{0.7178000,0.6247000,0.3413000},
{0.7178000,0.6258000,0.3414000},
{0.7179000,0.6267000,0.3415000},
{0.7179000,0.6277000,0.3416000},
{0.7180000,0.6285000,0.3416000},
{0.7180000,0.6294000,0.3417000},
{0.7182000,0.6302000,0.3418000},
{0.7183000,0.6311000,0.3420000},
{0.7184000,0.6317000,0.3420000},
{0.7185000,0.6325000,0.3420000}
};
inPtsLCh = {
{0.8146000,0.5185000,0.4194000},
{0.8143000,0.5180000,0.4193000},
{0.8140000,0.5176000,0.4191000},
{0.8136000,0.5172000,0.4189000},
{0.8133000,0.5169000,0.4188000},
{0.8130000,0.5164000,0.4187000},
{0.8127000,0.5160000,0.4186000},
{0.8124000,0.5156000,0.4184000},
{0.8120000,0.5152000,0.4183000},
{0.8116000,0.5148000,0.4182000},
{0.8111000,0.5145000,0.4181000},
{0.8106000,0.5142000,0.4179000},
{0.8100000,0.5139000,0.4178000},
{0.8094000,0.5136000,0.4176000},
{0.8088000,0.5134000,0.4175000},
{0.8082000,0.5132000,0.4173000},
{0.8075000,0.5130000,0.4172000},
{0.8068000,0.5127000,0.4171000},
{0.8059000,0.5125000,0.4169000},
{0.8049000,0.5123000,0.4166000},
{0.8038000,0.5122000,0.4164000},
{0.8026000,0.5122000,0.4161000},
{0.8014000,0.5123000,0.4158000},
{0.8002000,0.5125000,0.4155000},
{0.7989000,0.5126000,0.4153000},
{0.7975000,0.5128000,0.4151000},
{0.7961000,0.5130000,0.4149000},
{0.7946000,0.5132000,0.4148000},
{0.7931000,0.5134000,0.4146000},
{0.7916000,0.5137000,0.4145000},
{0.7901000,0.5139000,0.4143000},
{0.7886000,0.5142000,0.4142000},
{0.7871000,0.5145000,0.4141000},
{0.7856000,0.5149000,0.4140000},
{0.7842000,0.5152000,0.4139000},
{0.7828000,0.5154000,0.4139000},
{0.7814000,0.5159000,0.4139000},
{0.7801000,0.5163000,0.4138000},
{0.7787000,0.5167000,0.4138000},
{0.7774000,0.5170000,0.4138000},
{0.7765000,0.5176000,0.4137000},
{0.7769000,0.5187000,0.4131000},
{0.7761000,0.5192000,0.4131000},
{0.7754000,0.5197000,0.4130000},
{0.7747000,0.5203000,0.4130000},
{0.7742000,0.5208000,0.4129000},
{0.7737000,0.5213000,0.4128000},
{0.7733000,0.5219000,0.4127000},
{0.7730000,0.5224000,0.4127000},
{0.7727000,0.5228000,0.4126000},
{0.7724000,0.5233000,0.4125000},
{0.7721000,0.5238000,0.4124000},
{0.7718000,0.5243000,0.4123000},
{0.7716000,0.5248000,0.4122000},
{0.7713000,0.5254000,0.4121000},
{0.7710000,0.5260000,0.4120000},
{0.7707000,0.5266000,0.4121000},
{0.7704000,0.5273000,0.4121000},
{0.7702000,0.5279000,0.4122000},
{0.7698000,0.5286000,0.4123000},
{0.7694000,0.5293000,0.4125000},
{0.7690000,0.5299000,0.4127000},
{0.7687000,0.5306000,0.4127000},
{0.7682000,0.5313000,0.4128000},
{0.7678000,0.5320000,0.4128000},
{0.7674000,0.5327000,0.4129000},
{0.7670000,0.5334000,0.4129000},
{0.7666000,0.5342000,0.4130000},
{0.7662000,0.5349000,0.4130000},
{0.7648000,0.5354000,0.4132000},
{0.7647000,0.5363000,0.4130000},
{0.7646000,0.5371000,0.4129000},
{0.7643000,0.5380000,0.4129000},
{0.7640000,0.5387000,0.4129000},
{0.7638000,0.5395000,0.4130000},
{0.7636000,0.5403000,0.4131000},
{0.7633000,0.5410000,0.4132000},
{0.7632000,0.5418000,0.4133000},
{0.7630000,0.5426000,0.4134000},
{0.7629000,0.5434000,0.4136000},
{0.7628000,0.5441000,0.4137000},
{0.7627000,0.5449000,0.4138000},
{0.7625000,0.5457000,0.4140000},
{0.7624000,0.5464000,0.4141000},
{0.7622000,0.5473000,0.4141000},
{0.7621000,0.5480000,0.4142000},
{0.7619000,0.5489000,0.4144000},
{0.7617000,0.5497000,0.4145000},
{0.7616000,0.5507000,0.4146000},
{0.7614000,0.5515000,0.4148000},
{0.7613000,0.5525000,0.4149000},
{0.7611000,0.5533000,0.4150000},
{0.7609000,0.5542000,0.4152000},
{0.7608000,0.5550000,0.4153000},
{0.7606000,0.5558000,0.4155000},
{0.7605000,0.5566000,0.4156000},
{0.7604000,0.5574000,0.4158000},
{0.7604000,0.5582000,0.4160000},
{0.7603000,0.5589000,0.4161000}
};
inPtsLSh = {
{0.9071000,0.4636000,0.4529000},
{0.9068000,0.4632000,0.4527000},
{0.9064000,0.4628000,0.4526000},
{0.9061000,0.4624000,0.4525000},
{0.9058000,0.4619000,0.4524000},
{0.9056000,0.4614000,0.4523000},
{0.9053000,0.4610000,0.4522000},
{0.9049000,0.4605000,0.4520000},
{0.9046000,0.4600000,0.4518000},
{0.9042000,0.4595000,0.4517000},
{0.9036000,0.4589000,0.4515000},
{0.9031000,0.4584000,0.4514000},
{0.9024000,0.4579000,0.4513000},
{0.9017000,0.4573000,0.4512000},
{0.9009000,0.4568000,0.4511000},
{0.9001000,0.4562000,0.4509000},
{0.8993000,0.4556000,0.4507000},
{0.8984000,0.4549000,0.4505000},
{0.8973000,0.4543000,0.4503000},
{0.8961000,0.4536000,0.4501000},
{0.8947000,0.4530000,0.4497000},
{0.8930000,0.4525000,0.4491000},
{0.8914000,0.4518000,0.4489000},
{0.8897000,0.4512000,0.4485000},
{0.8880000,0.4505000,0.4482000},
{0.8862000,0.4499000,0.4478000},
{0.8845000,0.4493000,0.4474000},
{0.8827000,0.4486000,0.4471000},
{0.8809000,0.4480000,0.4468000},
{0.8790000,0.4474000,0.4465000},
{0.8771000,0.4469000,0.4462000},
{0.8748000,0.4461000,0.4461000},
{0.8728000,0.4454000,0.4459000},
{0.8713000,0.4452000,0.4455000},
{0.8694000,0.4447000,0.4453000},
{0.8676000,0.4443000,0.4451000},
{0.8658000,0.4439000,0.4448000},
{0.8640000,0.4436000,0.4446000},
{0.8623000,0.4433000,0.4445000},
{0.8607000,0.4431000,0.4443000},
{0.8592000,0.4429000,0.4442000},
{0.8578000,0.4427000,0.4441000},
{0.8565000,0.4426000,0.4439000},
{0.8556000,0.4427000,0.4438000},
{0.8543000,0.4425000,0.4438000},
{0.8533000,0.4425000,0.4437000},
{0.8525000,0.4425000,0.4436000},
{0.8518000,0.4426000,0.4435000},
{0.8512000,0.4427000,0.4434000},
{0.8507000,0.4428000,0.4432000},
{0.8502000,0.4430000,0.4432000},
{0.8498000,0.4432000,0.4431000},
{0.8494000,0.4435000,0.4430000},
{0.8490000,0.4437000,0.4429000},
{0.8485000,0.4440000,0.4428000},
{0.8480000,0.4443000,0.4428000},
{0.8475000,0.4446000,0.4427000},
{0.8470000,0.4450000,0.4427000},
{0.8466000,0.4454000,0.4427000},
{0.8452000,0.4451000,0.4430000},
{0.8452000,0.4451000,0.4430000},
{0.8451000,0.4466000,0.4430000},
{0.8445000,0.4470000,0.4431000},
{0.8438000,0.4474000,0.4431000},
{0.8431000,0.4478000,0.4431000},
{0.8425000,0.4481000,0.4430000},
{0.8418000,0.4485000,0.4429000},
{0.8411000,0.4488000,0.4429000},
{0.8404000,0.4492000,0.4427000},
{0.8396000,0.4496000,0.4426000},
{0.8390000,0.4500000,0.4426000},
{0.8383000,0.4504000,0.4425000},
{0.8377000,0.4508000,0.4425000},
{0.8371000,0.4513000,0.4425000},
{0.8365000,0.4518000,0.4425000},
{0.8360000,0.4523000,0.4426000},
{0.8355000,0.4528000,0.4428000},
{0.8351000,0.4533000,0.4430000},
{0.8347000,0.4539000,0.4432000},
{0.8343000,0.4545000,0.4435000},
{0.8340000,0.4550000,0.4438000},
{0.8334000,0.4556000,0.4439000},
{0.8332000,0.4562000,0.4443000},
{0.8328000,0.4568000,0.4445000},
{0.8324000,0.4574000,0.4447000},
{0.8319000,0.4580000,0.4449000},
{0.8314000,0.4585000,0.4451000},
{0.8309000,0.4591000,0.4453000},
{0.8304000,0.4598000,0.4455000},
{0.8300000,0.4604000,0.4457000},
{0.8295000,0.4610000,0.4459000},
{0.8290000,0.4616000,0.4462000},
{0.8286000,0.4622000,0.4465000},
{0.8281000,0.4628000,0.4467000},
{0.8277000,0.4634000,0.4470000},
{0.8273000,0.4640000,0.4472000},
{0.8269000,0.4646000,0.4475000},
{0.8266000,0.4653000,0.4478000},
{0.8262000,0.4658000,0.4481000}
};
inPtsEeWam = {
{0.3609014,0.1146922,0.1117606},
{0.3599198,0.1152315,0.1109659},
{0.3590321,0.1160997,0.1089139},
{0.3579603,0.1169310,0.1075958},
{0.3569122,0.1183809,0.1062099},
{0.3558194,0.1200830,0.1049547},
{0.3548927,0.1220723,0.1038758},
{0.3537041,0.1248768,0.1026763},
{0.3522210,0.1277836,0.1014269},
{0.3507294,0.1311438,0.1003007},
{0.3492026,0.1347198,0.0992515},
{0.3477634,0.1385459,0.0982114},
{0.3464168,0.1426782,0.0974199},
{0.3450019,0.1471332,0.0965472},
{0.3436264,0.1518677,0.0960449},
{0.3424537,0.1573708,0.0951337},
{0.3408871,0.1632613,0.0943615},
{0.3393874,0.1693618,0.0932789},
{0.3375512,0.1757554,0.0920341},
{0.3356067,0.1823143,0.0902473},
{0.3337476,0.1885459,0.0889089},
{0.3318887,0.1948865,0.0872349},
{0.3301288,0.2013082,0.0857829},
{0.3284051,0.2076403,0.0841929},
{0.3267196,0.2146251,0.0824403},
{0.3250231,0.2217326,0.0804819},
{0.3233671,0.2294647,0.0782425},
{0.3214859,0.2380808,0.0750510},
{0.3194960,0.2455761,0.0719354},
{0.3176058,0.2541355,0.0688071},
{0.3160598,0.2625613,0.0655651},
{0.3144661,0.2715568,0.0618592},
{0.3132092,0.2807474,0.0583430},
{0.3120840,0.2900971,0.0546665},
{0.3114345,0.2995559,0.0505942},
{0.3106220,0.3094091,0.0459815},
{0.3097230,0.3189966,0.0413213},
{0.3094146,0.3286145,0.0361525},
{0.3091535,0.3379962,0.0310791},
{0.3092177,0.3478429,0.0265769},
{0.3093291,0.3576035,0.0220902},
{0.3096920,0.3673963,0.0175702},
{0.3102351,0.3777451,0.0128735},
{0.3105384,0.3881480,0.0085725},
{0.3111492,0.3993266,0.0041261},
{0.3117153,0.4105185,-0.0008770},
{0.3121658,0.4215748,-0.0057518},
{0.3128631,0.4331091,-0.0107213},
{0.3130244,0.4447996,-0.0154032},
{0.3133222,0.4569919,-0.0202412},
{0.3137760,0.4693408,-0.0252634},
{0.3139762,0.4814909,-0.0298007},
{0.3136886,0.4936629,-0.0343965},
{0.3135685,0.5061403,-0.0384675},
{0.3136251,0.5188626,-0.0428626},
{0.3141251,0.5315248,-0.0475380},
{0.3139844,0.5444996,-0.0512515},
{0.3142544,0.5575740,-0.0550181},
{0.3149621,0.5711163,-0.0586815},
{0.3162199,0.5844212,-0.0617242},
{0.3174058,0.5977279,-0.0652994},
{0.3186471,0.6109436,-0.0680883},
{0.3202906,0.6240651,-0.0709369},
{0.3222149,0.6366391,-0.0738581},
{0.3240558,0.6492189,-0.0768220},
{0.3262617,0.6617783,-0.0802500},
{0.3284435,0.6739337,-0.0835722},
{0.3308617,0.6858658,-0.0869999},
{0.3334034,0.6976590,-0.0903639},
{0.3361100,0.7091461,-0.0934075},
{0.3387362,0.7201343,-0.0960948},
{0.3417533,0.7308247,-0.0987114},
{0.3446836,0.7411267,-0.1014911},
{0.3478032,0.7513198,-0.1044993},
{0.3510533,0.7613408,-0.1076417},
{0.3545223,0.7711378,-0.1111076},
{0.3581679,0.7806293,-0.1144560},
{0.3621431,0.7899789,-0.1180125},
{0.3660388,0.7987876,-0.1214133},
{0.3703463,0.8071696,-0.1240749},
{0.3745291,0.8148262,-0.1265977},
{0.3786109,0.8219749,-0.1285567},
{0.3828977,0.8285942,-0.1305645},
{0.3874846,0.8346629,-0.1324843},
{0.3920099,0.8403801,-0.1342534},
{0.3967832,0.8451393,-0.1363076},
{0.4011119,0.8495890,-0.1380950},
{0.4056659,0.8531952,-0.1398923},
{0.4097422,0.8561044,-0.1413722},
{0.4137293,0.8582071,-0.1421280},
{0.4174818,0.8600878,-0.1432110},
{0.4207969,0.8611051,-0.1435363},
{0.4241657,0.8620255,-0.1446415},
{0.4273316,0.8625655,-0.1454615},
{0.4305657,0.8630055,-0.1469338},
{0.4335277,0.8628494,-0.1484622},
{0.4361607,0.8626334,-0.1498464},
{0.4388573,0.8621174,-0.1514419},
{0.4413467,0.8612626,-0.1530699}
};
inPtsRPiWam = {
{0.4075560,0.0765855,0.0813590},
{0.4068166,0.0771133,0.0810384},
{0.4061865,0.0777882,0.0802434},
{0.4052825,0.0785511,0.0794839},
{0.4044515,0.0798614,0.0786218},
{0.4034788,0.0812569,0.0780026},
{0.4026798,0.0829468,0.0776416},
{0.4017287,0.0853479,0.0773487},
{0.4004532,0.0878448,0.0772334},
{0.3991812,0.0907356,0.0772851},
{0.3979406,0.0938517,0.0775283},
{0.3966322,0.0970622,0.0778848},
{0.3953787,0.1006279,0.0784882},
{0.3941201,0.1044891,0.0792223},
{0.3929644,0.1087053,0.0803271},
{0.3917135,0.1133877,0.0814505},
{0.3901281,0.1187308,0.0825211},
{0.3885676,0.1243024,0.0833119},
{0.3865735,0.1302200,0.0836990},
{0.3843591,0.1362388,0.0835823},
{0.3822850,0.1420583,0.0834811},
{0.3801044,0.1478829,0.0831076},
{0.3780352,0.1538883,0.0827193},
{0.3759774,0.1598534,0.0823280},
{0.3739144,0.1664633,0.0817229},
{0.3717383,0.1731548,0.0810701},
{0.3696099,0.1804447,0.0800830},
{0.3671676,0.1886509,0.0781661},
{0.3646171,0.1957753,0.0765468},
{0.3622031,0.2039958,0.0744727},
{0.3599832,0.2119199,0.0723413},
{0.3578470,0.2206211,0.0696397},
{0.3559341,0.2293643,0.0669873},
{0.3541757,0.2383150,0.0640928},
{0.3528604,0.2473818,0.0607772},
{0.3511961,0.2567366,0.0568401},
{0.3497860,0.2660572,0.0526611},
{0.3488275,0.2752844,0.0480579},
{0.3479549,0.2843623,0.0434477},
{0.3474047,0.2938330,0.0390943},
{0.3470237,0.3032808,0.0346668},
{0.3469614,0.3127939,0.0302220},
{0.3468335,0.3227065,0.0256619},
{0.3466144,0.3327590,0.0213041},
{0.3465182,0.3435312,0.0169822},
{0.3464201,0.3543266,0.0122770},
{0.3460090,0.3649586,0.0078059},
{0.3457477,0.3760194,0.0032983},
{0.3449980,0.3872957,-0.0010604},
{0.3440619,0.3989840,-0.0056691},
{0.3433595,0.4108357,-0.0103234},
{0.3424380,0.4224642,-0.0144969},
{0.3411942,0.4341553,-0.0187950},
{0.3399709,0.4461445,-0.0228779},
{0.3384706,0.4582578,-0.0271188},
{0.3374303,0.4704667,-0.0314635},
{0.3361640,0.4829575,-0.0353480},
{0.3352426,0.4955812,-0.0390691},
{0.3346363,0.5086390,-0.0428786},
{0.3344356,0.5214543,-0.0464224},
{0.3344256,0.5343909,-0.0502585},
{0.3344760,0.5471190,-0.0535587},
{0.3348744,0.5598111,-0.0571207},
{0.3355985,0.5719916,-0.0605871},
{0.3361905,0.5842423,-0.0643563},
{0.3371430,0.5964864,-0.0684273},
{0.3382999,0.6083541,-0.0723106},
{0.3396175,0.6200304,-0.0764630},
{0.3411254,0.6315887,-0.0806043},
{0.3428740,0.6428798,-0.0847643},
{0.3446835,0.6536074,-0.0887094},
{0.3468884,0.6641646,-0.0927617},
{0.3488744,0.6743348,-0.0970486},
{0.3511528,0.6844127,-0.1013468},
{0.3534430,0.6944289,-0.1057142},
{0.3559760,0.7041805,-0.1099816},
{0.3585991,0.7136733,-0.1140686},
{0.3615325,0.7230534,-0.1182181},
{0.3645337,0.7318886,-0.1222149},
{0.3677561,0.7403973,-0.1256698},
{0.3710224,0.7481529,-0.1289169},
{0.3743291,0.7554167,-0.1317891},
{0.3778100,0.7622175,-0.1345043},
{0.3815232,0.7683998,-0.1370115},
{0.3851748,0.7742096,-0.1394975},
{0.3888762,0.7792616,-0.1418445},
{0.3924114,0.7838407,-0.1440589},
{0.3960287,0.7877268,-0.1460559},
{0.3992601,0.7908290,-0.1479526},
{0.4024621,0.7932977,-0.1494292},
{0.4057470,0.7953792,-0.1510077},
{0.4087141,0.7966138,-0.1521514},
{0.4118396,0.7976504,-0.1537333},
{0.4147245,0.7983957,-0.1551600},
{0.4177202,0.7989726,-0.1568917},
{0.4204136,0.7989407,-0.1586542},
{0.4228815,0.7988495,-0.1603295},
{0.4253835,0.7984886,-0.1621301},
{0.4276380,0.7977246,-0.1638084}
};
inPtsRThWam = {
{0.4502883,0.0871919,0.0785837},
{0.4496276,0.0878163,0.0785166},
{0.4496243,0.0885350,0.0785835},
{0.4488973,0.0893635,0.0781373},
{0.4480625,0.0905822,0.0776791},
{0.4471223,0.0918356,0.0773763},
{0.4463847,0.0934708,0.0772580},
{0.4453641,0.0956131,0.0775426},
{0.4441794,0.0979549,0.0780365},
{0.4428836,0.1006324,0.0787011},
{0.4415363,0.1035362,0.0796412},
{0.4401747,0.1064441,0.0806794},
{0.4388991,0.1097394,0.0819880},
{0.4375006,0.1133342,0.0834957},
{0.4360882,0.1173615,0.0852808},
{0.4347224,0.1216067,0.0874433},
{0.4330527,0.1267533,0.0893775},
{0.4313728,0.1321440,0.0910129},
{0.4293001,0.1378613,0.0922098},
{0.4269817,0.1435981,0.0929867},
{0.4247755,0.1492153,0.0934446},
{0.4224076,0.1547231,0.0937231},
{0.4202136,0.1604826,0.0938411},
{0.4180951,0.1662852,0.0939530},
{0.4159414,0.1726788,0.0939534},
{0.4136916,0.1791409,0.0939507},
{0.4113795,0.1861623,0.0935388},
{0.4088051,0.1940943,0.0923917},
{0.4060086,0.2009849,0.0916815},
{0.4033727,0.2089356,0.0903942},
{0.4008919,0.2164844,0.0888179},
{0.3985591,0.2249673,0.0867774},
{0.3963828,0.2333332,0.0846807},
{0.3944653,0.2419701,0.0821468},
{0.3928236,0.2506508,0.0796144},
{0.3910628,0.2595624,0.0760814},
{0.3894581,0.2686119,0.0724257},
{0.3881682,0.2774475,0.0684110},
{0.3871153,0.2862101,0.0643210},
{0.3864952,0.2952786,0.0602398},
{0.3860539,0.3043821,0.0560132},
{0.3858813,0.3135876,0.0517655},
{0.3855428,0.3230176,0.0475352},
{0.3852831,0.3326733,0.0432753},
{0.3851139,0.3429936,0.0391470},
{0.3846423,0.3533524,0.0348823},
{0.3839267,0.3635059,0.0309062},
{0.3832629,0.3740386,0.0269268},
{0.3823322,0.3848349,0.0228842},
{0.3813267,0.3958568,0.0186907},
{0.3801511,0.4070745,0.0146867},
{0.3788057,0.4180973,0.0108188},
{0.3771318,0.4292610,0.0066671},
{0.3757035,0.4405775,0.0027774},
{0.3738563,0.4518288,-0.0011425},
{0.3722580,0.4632920,-0.0046980},
{0.3706772,0.4750591,-0.0084536},
{0.3693366,0.4870239,-0.0119989},
{0.3683199,0.4992966,-0.0156160},
{0.3680125,0.5111252,-0.0191284},
{0.3675466,0.5233241,-0.0226088},
{0.3674706,0.5352034,-0.0263219},
{0.3676601,0.5469537,-0.0299757},
{0.3680428,0.5583009,-0.0335046},
{0.3685107,0.5695824,-0.0373608},
{0.3690185,0.5809471,-0.0413020},
{0.3698447,0.5920940,-0.0453160},
{0.3709010,0.6029424,-0.0496023},
{0.3720712,0.6136974,-0.0538248},
{0.3737667,0.6240604,-0.0583258},
{0.3753835,0.6339225,-0.0627969},
{0.3776081,0.6435055,-0.0673353},
{0.3795361,0.6526393,-0.0722194},
{0.3815423,0.6618544,-0.0769331},
{0.3836649,0.6709325,-0.0816379},
{0.3858123,0.6799773,-0.0861264},
{0.3879943,0.6887356,-0.0903212},
{0.3905105,0.6974257,-0.0945652},
{0.3930424,0.7056600,-0.0986167},
{0.3959799,0.7133537,-0.1023107},
{0.3989384,0.7204355,-0.1058232},
{0.4020306,0.7270285,-0.1091167},
{0.4053266,0.7331608,-0.1120678},
{0.4086618,0.7387818,-0.1148348},
{0.4119059,0.7440500,-0.1177644},
{0.4153699,0.7483954,-0.1201182},
{0.4185551,0.7525261,-0.1225891},
{0.4219997,0.7558102,-0.1246486},
{0.4249552,0.7584112,-0.1268618},
{0.4280817,0.7601303,-0.1286572},
{0.4312718,0.7617884,-0.1305085},
{0.4342601,0.7625605,-0.1322059},
{0.4373366,0.7633475,-0.1341328},
{0.4402295,0.7637126,-0.1359225},
{0.4432093,0.7640484,-0.1378089},
{0.4457728,0.7637942,-0.1396333},
{0.4482736,0.7634908,-0.1415163},
{0.4508267,0.7628798,-0.1434279},
{0.4530261,0.7619622,-0.1451511}
};
inPtsRWWam = {
{0.4190191,0.1291174,0.1079860},
{0.4180334,0.1297602,0.1075428},
{0.4172360,0.1304997,0.1066897},
{0.4161713,0.1313618,0.1057985},
{0.4151646,0.1327009,0.1049507},
{0.4141252,0.1342157,0.1041180},
{0.4132232,0.1361182,0.1033639},
{0.4121092,0.1386165,0.1029358},
{0.4106694,0.1412977,0.1025004},
{0.4092185,0.1443892,0.1021957},
{0.4077093,0.1477167,0.1020871},
{0.4063022,0.1511591,0.1019684},
{0.4049624,0.1549355,0.1021280},
{0.4035203,0.1590648,0.1023120},
{0.4020834,0.1636017,0.1027599},
{0.4008429,0.1685291,0.1032697},
{0.3991520,0.1741508,0.1036682},
{0.3975023,0.1800079,0.1037342},
{0.3955104,0.1861210,0.1035790},
{0.3933820,0.1922899,0.1029951},
{0.3913931,0.1982555,0.1024261},
{0.3893816,0.2041827,0.1016620},
{0.3874939,0.2102768,0.1009091},
{0.3856258,0.2163785,0.0999864},
{0.3837574,0.2230607,0.0990393},
{0.3818544,0.2298416,0.0979303},
{0.3799983,0.2372165,0.0964858},
{0.3778340,0.2454474,0.0943025},
{0.3754576,0.2526193,0.0923975},
{0.3732196,0.2608084,0.0903147},
{0.3714195,0.2687382,0.0878620},
{0.3695005,0.2774319,0.0850259},
{0.3679593,0.2861196,0.0822921},
{0.3666514,0.2950476,0.0791183},
{0.3655594,0.3039833,0.0761068},
{0.3645478,0.3132314,0.0720083},
{0.3633383,0.3224492,0.0680324},
{0.3626418,0.3315411,0.0636898},
{0.3620557,0.3404925,0.0592770},
{0.3619635,0.3497935,0.0551090},
{0.3619543,0.3590883,0.0508719},
{0.3621780,0.3684667,0.0466231},
{0.3624710,0.3781649,0.0423903},
{0.3627055,0.3880324,0.0382134},
{0.3631759,0.3986019,0.0340041},
{0.3633469,0.4092024,0.0296589},
{0.3633783,0.4196127,0.0254480},
{0.3635817,0.4304312,0.0212233},
{0.3634519,0.4414758,0.0169390},
{0.3634204,0.4527878,0.0125078},
{0.3632204,0.4642861,0.0083477},
{0.3629827,0.4756065,0.0043129},
{0.3623465,0.4870362,0.0000780},
{0.3619214,0.4986071,-0.0037509},
{0.3614814,0.5101678,-0.0077318},
{0.3610768,0.5218525,-0.0114549},
{0.3605590,0.5338410,-0.0149582},
{0.3603618,0.5460015,-0.0184095},
{0.3605527,0.5584714,-0.0217817},
{0.3615057,0.5704902,-0.0249122},
{0.3620213,0.5828205,-0.0280539},
{0.3632218,0.5948461,-0.0312921},
{0.3645317,0.6067153,-0.0343074},
{0.3660345,0.6181483,-0.0372802},
{0.3675457,0.6294926,-0.0404971},
{0.3690990,0.6408952,-0.0437965},
{0.3708910,0.6520537,-0.0472476},
{0.3729155,0.6628947,-0.0508916},
{0.3749748,0.6736245,-0.0543894},
{0.3774792,0.6839446,-0.0580030},
{0.3799098,0.6937339,-0.0613420},
{0.3827941,0.7032247,-0.0647423},
{0.3855424,0.7122159,-0.0684045},
{0.3882882,0.7212675,-0.0719752},
{0.3911505,0.7301667,-0.0756982},
{0.3941083,0.7390255,-0.0794570},
{0.3971228,0.7475817,-0.0829858},
{0.4004885,0.7560670,-0.0867137},
{0.4037484,0.7640939,-0.0901990},
{0.4075345,0.7715364,-0.0932965},
{0.4112472,0.7783692,-0.0962223},
{0.4149908,0.7846931,-0.0987814},
{0.4188838,0.7905940,-0.1012220},
{0.4229706,0.7959349,-0.1034864},
{0.4270383,0.8008588,-0.1057741},
{0.4312534,0.8049802,-0.1080402},
{0.4351398,0.8088309,-0.1101506},
{0.4392610,0.8119092,-0.1122006},
{0.4429454,0.8142141,-0.1141188},
{0.4465923,0.8156623,-0.1154829},
{0.4501327,0.8171191,-0.1169888},
{0.4534010,0.8176430,-0.1180801},
{0.4567006,0.8182540,-0.1196308},
{0.4597848,0.8184338,-0.1209833},
{0.4629257,0.8186670,-0.1227070},
{0.4656752,0.8182947,-0.1243496},
{0.4682871,0.8178972,-0.1260437},
{0.4709331,0.8172260,-0.1278644},
{0.4733073,0.8162420,-0.1295824}
};
inPtsRLAWam = {
{0.3806182,0.4265947,0.1022778},
{0.3806717,0.4273568,0.1011861},
{0.3807705,0.4281927,0.0996821},
{0.3809880,0.4291863,0.0978791},
{0.3811529,0.4306282,0.0958636},
{0.3813728,0.4322366,0.0935904},
{0.3819940,0.4342267,0.0908722},
{0.3824370,0.4367701,0.0879696},
{0.3830623,0.4395070,0.0849204},
{0.3838247,0.4426036,0.0816203},
{0.3844031,0.4458801,0.0785205},
{0.3851981,0.4492218,0.0752626},
{0.3859460,0.4528165,0.0720403},
{0.3868398,0.4567078,0.0686903},
{0.3877341,0.4608939,0.0651907},
{0.3889589,0.4653664,0.0614800},
{0.3900032,0.4704408,0.0575322},
{0.3913559,0.4756890,0.0533860},
{0.3925036,0.4811831,0.0494560},
{0.3937741,0.4867763,0.0457447},
{0.3951827,0.4921472,0.0423149},
{0.3965718,0.4975421,0.0393035},
{0.3980810,0.5030547,0.0363412},
{0.3997582,0.5085795,0.0335117},
{0.4012930,0.5146225,0.0305981},
{0.4028207,0.5207491,0.0276932},
{0.4045100,0.5274244,0.0245237},
{0.4065135,0.5348621,0.0207047},
{0.4080087,0.5413793,0.0178450},
{0.4099639,0.5487259,0.0144640},
{0.4122917,0.5558950,0.0112431},
{0.4147092,0.5637970,0.0078821},
{0.4171565,0.5717001,0.0046816},
{0.4197032,0.5799213,0.0014494},
{0.4222770,0.5882293,-0.0012713},
{0.4245560,0.5970858,-0.0043179},
{0.4268800,0.6058215,-0.0072178},
{0.4292057,0.6146353,-0.0099778},
{0.4318294,0.6232732,-0.0126030},
{0.4344937,0.6322795,-0.0151834},
{0.4372941,0.6412173,-0.0178822},
{0.4404445,0.6501735,-0.0205754},
{0.4438041,0.6593377,-0.0233880},
{0.4472612,0.6686093,-0.0260278},
{0.4510626,0.6784690,-0.0288474},
{0.4548817,0.6882846,-0.0314521},
{0.4589319,0.6977067,-0.0339929},
{0.4635132,0.7072863,-0.0367845},
{0.4679550,0.7169838,-0.0394030},
{0.4726570,0.7268028,-0.0421105},
{0.4775076,0.7365431,-0.0447048},
{0.4822278,0.7460539,-0.0470563},
{0.4869086,0.7554458,-0.0493242},
{0.4916914,0.7648798,-0.0512760},
{0.4965830,0.7741519,-0.0531185},
{0.5014614,0.7834182,-0.0547623},
{0.5066357,0.7925903,-0.0563157},
{0.5120332,0.8018393,-0.0576875},
{0.5176864,0.8112920,-0.0590744},
{0.5233172,0.8206349,-0.0601924},
{0.5286421,0.8300985,-0.0610862},
{0.5342083,0.8394535,-0.0618017},
{0.5398125,0.8485552,-0.0624160},
{0.5453003,0.8573462,-0.0627381},
{0.5509591,0.8658213,-0.0630424},
{0.5565962,0.8742722,-0.0632888},
{0.5623927,0.8824128,-0.0634271},
{0.5681990,0.8902832,-0.0634948},
{0.5738888,0.8980165,-0.0634129},
{0.5796701,0.9055055,-0.0634425},
{0.5850920,0.9125861,-0.0633328},
{0.5907715,0.9194257,-0.0631507},
{0.5961099,0.9258351,-0.0630972},
{0.6016470,0.9319725,-0.0629526},
{0.6072267,0.9378812,-0.0628239},
{0.6128316,0.9436719,-0.0627241},
{0.6186246,0.9488866,-0.0626560},
{0.6246270,0.9540316,-0.0627985},
{0.6304716,0.9586559,-0.0629550},
{0.6364949,0.9630233,-0.0631317},
{0.6423538,0.9668161,-0.0633969},
{0.6481098,0.9702313,-0.0636939},
{0.6538676,0.9733444,-0.0640074},
{0.6596292,0.9761196,-0.0644198},
{0.6652255,0.9786025,-0.0648586},
{0.6706837,0.9806333,-0.0653892},
{0.6758687,0.9823364,-0.0660435},
{0.6809276,0.9837315,-0.0666557},
{0.6854139,0.9845794,-0.0673779},
{0.6896635,0.9850152,-0.0681970},
{0.6938151,0.9854139,-0.0690752},
{0.6973807,0.9854288,-0.0698948},
{0.7009063,0.9854818,-0.0706569},
{0.7041448,0.9852782,-0.0714742},
{0.7072644,0.9852737,-0.0723005},
{0.7099378,0.9848073,-0.0732681},
{0.7124537,0.9843020,-0.0741583},
{0.7148821,0.9837056,-0.0752011},
{0.7169661,0.9829279,-0.0762323}
};
inPtsRElWam = {
{0.4102779,0.4310672,0.1358233},
{0.4102100,0.4317841,0.1348445},
{0.4101613,0.4325884,0.1334736},
{0.4101954,0.4335396,0.1318346},
{0.4101518,0.4349798,0.1299975},
{0.4101446,0.4366111,0.1279132},
{0.4104727,0.4386582,0.1254312},
{0.4106075,0.4413202,0.1227650},
{0.4108945,0.4441501,0.1199747},
{0.4112925,0.4473797,0.1169431},
{0.4115345,0.4508116,0.1140812},
{0.4119748,0.4543257,0.1110671},
{0.4123754,0.4581429,0.1080697},
{0.4129092,0.4622642,0.1049465},
{0.4134326,0.4667436,0.1016649},
{0.4142699,0.4715451,0.0981704},
{0.4149393,0.4769547,0.0944207},
{0.4159085,0.4825148,0.0904749},
{0.4167245,0.4882643,0.0867146},
{0.4176875,0.4940203,0.0831703},
{0.4188050,0.4995296,0.0798979},
{0.4199359,0.5049899,0.0770348},
{0.4211979,0.5105704,0.0742110},
{0.4226336,0.5161205,0.0715229},
{0.4239503,0.5222109,0.0687303},
{0.4252730,0.5283655,0.0659409},
{0.4267547,0.5350589,0.0628888},
{0.4285183,0.5424740,0.0592125},
{0.4298384,0.5488913,0.0564718},
{0.4315910,0.5561751,0.0532168},
{0.4337056,0.5632247,0.0501368},
{0.4359188,0.5709644,0.0469177},
{0.4381870,0.5787193,0.0438409},
{0.4405586,0.5867487,0.0407361},
{0.4429812,0.5948252,0.0381347},
{0.4451290,0.6033648,0.0352084},
{0.4473172,0.6117674,0.0324303},
{0.4495129,0.6202092,0.0297909},
{0.4519757,0.6284456,0.0273015},
{0.4545106,0.6370969,0.0248305},
{0.4571719,0.6456871,0.0222413},
{0.4601679,0.6542919,0.0196617},
{0.4633705,0.6631167,0.0169589},
{0.4666661,0.6720245,0.0144294},
{0.4703018,0.6815371,0.0117166},
{0.4739484,0.6909376,0.0092225},
{0.4777943,0.6999451,0.0068017},
{0.4821417,0.7091364,0.0041369},
{0.4863630,0.7183939,0.0016355},
{0.4908225,0.7277652,-0.0009512},
{0.4954294,0.7370626,-0.0034309},
{0.4999091,0.7461178,-0.0056755},
{0.5043266,0.7549990,-0.0078342},
{0.5088558,0.7639372,-0.0096888},
{0.5134645,0.7726796,-0.0114310},
{0.5180736,0.7814188,-0.0129886},
{0.5229521,0.7900699,-0.0144537},
{0.5280433,0.7987876,-0.0157427},
{0.5333959,0.8077260,-0.0170566},
{0.5387493,0.8165867,-0.0181156},
{0.5438021,0.8255099,-0.0189659},
{0.5490773,0.8343184,-0.0196408},
{0.5543887,0.8428950,-0.0202201},
{0.5595761,0.8511410,-0.0205161},
{0.5648815,0.8590469,-0.0207899},
{0.5701554,0.8669093,-0.0210166},
{0.5755419,0.8744522,-0.0211337},
{0.5809068,0.8817146,-0.0211853},
{0.5861582,0.8888417,-0.0211011},
{0.5914886,0.8957590,-0.0211303},
{0.5964830,0.9022914,-0.0210330},
{0.6017058,0.9085960,-0.0208641},
{0.6065755,0.9144689,-0.0208328},
{0.6116122,0.9200732,-0.0207140},
{0.6166593,0.9254527,-0.0206154},
{0.6217246,0.9307193,-0.0205561},
{0.6269602,0.9354597,-0.0205225},
{0.6323926,0.9401538,-0.0207021},
{0.6376680,0.9443798,-0.0208907},
{0.6431708,0.9484188,-0.0210943},
{0.6485229,0.9519316,-0.0213803},
{0.6538145,0.9551207,-0.0216924},
{0.6591229,0.9580366,-0.0220187},
{0.6644619,0.9606688,-0.0224327},
{0.6696389,0.9630233,-0.0228727},
{0.6746982,0.9649647,-0.0233965},
{0.6795116,0.9666046,-0.0240407},
{0.6842198,0.9679633,-0.0246376},
{0.6883898,0.9688098,-0.0253367},
{0.6924105,0.9693216,-0.0261117},
{0.6963253,0.9697864,-0.0269506},
{0.6997274,0.9699053,-0.0277223},
{0.7030336,0.9700152,-0.0284520},
{0.7060857,0.9698996,-0.0292281},
{0.7089967,0.9699437,-0.0300277},
{0.7114817,0.9695626,-0.0309571},
{0.7138043,0.9691187,-0.0318187},
{0.7160438,0.9685994,-0.0328283},
{0.7179614,0.9679007,-0.0338273}
};
inPtsRUAWam = {
{0.3943094,0.4711522,0.1230485},
{0.3944638,0.4719281,0.1219791},
{0.3946491,0.4728008,0.1205378},
{0.3949865,0.4738310,0.1187849},
{0.3952828,0.4753654,0.1168478},
{0.3956626,0.4771031,0.1146591},
{0.3964672,0.4792671,0.1120234},
{0.3971526,0.4820688,0.1092181},
{0.3980575,0.4850381,0.1062495},
{0.3991412,0.4884166,0.1030393},
{0.4000491,0.4919885,0.1000262},
{0.4011852,0.4956375,0.0968571},
{0.4022899,0.4995843,0.0937208},
{0.4035848,0.5038396,0.0904709},
{0.4049113,0.5084502,0.0870723},
{0.4065970,0.5133772,0.0834664},
{0.4081749,0.5189166,0.0796408},
{0.4100785,0.5245952,0.0756339},
{0.4117993,0.5304489,0.0718419},
{0.4136403,0.5362939,0.0682854},
{0.4155884,0.5418654,0.0649870},
{0.4174953,0.5473774,0.0621237},
{0.4195295,0.5529998,0.0593125},
{0.4217311,0.5585808,0.0566463},
{0.4238220,0.5647070,0.0539292},
{0.4259153,0.5708914,0.0512395},
{0.4281910,0.5776097,0.0483162},
{0.4308590,0.5850438,0.0448133},
{0.4329388,0.5914555,0.0422003},
{0.4355540,0.5987252,0.0391177},
{0.4384762,0.6057513,0.0362182},
{0.4415320,0.6134638,0.0332320},
{0.4445944,0.6211893,0.0304156},
{0.4477272,0.6291931,0.0276181},
{0.4508417,0.6372367,0.0253097},
{0.4536213,0.6457756,0.0227904},
{0.4564617,0.6541537,0.0203978},
{0.4592113,0.6625908,0.0181832},
{0.4622282,0.6708056,0.0160983},
{0.4652904,0.6794453,0.0140878},
{0.4684937,0.6880112,0.0119702},
{0.4720455,0.6965757,0.0098635},
{0.4758397,0.7053409,0.0076508},
{0.4797431,0.7141720,0.0056214},
{0.4840258,0.7235874,0.0034447},
{0.4883326,0.7328668,0.0014743},
{0.4928725,0.7417155,-0.0004708},
{0.4979811,0.7507058,-0.0026528},
{0.5029739,0.7597376,-0.0046717},
{0.5082224,0.7688550,-0.0067710},
{0.5136657,0.7778530,-0.0087774},
{0.5189488,0.7865967,-0.0105694},
{0.5241888,0.7951295,-0.0123105},
{0.5295344,0.8036997,-0.0137304},
{0.5349518,0.8120515,-0.0150574},
{0.5403632,0.8203780,-0.0162056},
{0.5461017,0.8285551,-0.0172795},
{0.5520376,0.8367805,-0.0181527},
{0.5582273,0.8452032,-0.0190237},
{0.5643097,0.8535928,-0.0196046},
{0.5700916,0.8620174,-0.0199995},
{0.5760239,0.8703543,-0.0201843},
{0.5819785,0.8784449,-0.0202957},
{0.5877484,0.8862291,-0.0201316},
{0.5936358,0.8936522,-0.0199753},
{0.5994769,0.9010223,-0.0197701},
{0.6054015,0.9080772,-0.0194700},
{0.6112598,0.9148716,-0.0191090},
{0.6169838,0.9215313,-0.0186172},
{0.6227374,0.9280096,-0.0182300},
{0.6281139,0.9341302,-0.0177505},
{0.6336879,0.9400387,-0.0171895},
{0.6388703,0.9455457,-0.0167977},
{0.6442478,0.9507450,-0.0163372},
{0.6496211,0.9557249,-0.0159119},
{0.6550066,0.9605858,-0.0155263},
{0.6605869,0.9648867,-0.0152034},
{0.6663508,0.9691396,-0.0150751},
{0.6719539,0.9729249,-0.0150036},
{0.6777505,0.9765462,-0.0149224},
{0.6833872,0.9796488,-0.0149584},
{0.6889519,0.9824364,-0.0150428},
{0.6945161,0.9849629,-0.0151412},
{0.7000881,0.9872278,-0.0153338},
{0.7054763,0.9892393,-0.0155650},
{0.7107067,0.9908874,-0.0158861},
{0.7157012,0.9922261,-0.0163693},
{0.7205386,0.9933496,-0.0167963},
{0.7248177,0.9940041,-0.0173834},
{0.7289245,0.9943591,-0.0180584},
{0.7329258,0.9946637,-0.0187945},
{0.7363698,0.9946967,-0.0194931},
{0.7397037,0.9947371,-0.0201371},
{0.7427743,0.9945700,-0.0208427},
{0.7456763,0.9945989,-0.0215585},
{0.7481448,0.9942277,-0.0224451},
{0.7504478,0.9937988,-0.0232661},
{0.7526503,0.9933199,-0.0242338},
{0.7545208,0.9926828,-0.0252100}
};
inPtsRShWam = {
{0.7078000,0.7169000,0.5023000},
{0.7075000,0.7166000,0.5023000},
{0.7070000,0.7161000,0.5023000},
{0.7065000,0.7156000,0.5022000},
{0.7059000,0.7152000,0.5022000},
{0.7054000,0.7147000,0.5021000},
{0.7049000,0.7144000,0.5020000},
{0.7045000,0.7141000,0.5019000},
{0.7041000,0.7139000,0.5018000},
{0.7038000,0.7137000,0.5017000},
{0.7035000,0.7137000,0.5016000},
{0.7032000,0.7137000,0.5015000},
{0.7029000,0.7139000,0.5014000},
{0.7027000,0.7140000,0.5014000},
{0.7024000,0.7142000,0.5014000},
{0.7022000,0.7145000,0.5014000},
{0.7020000,0.7148000,0.5013000},
{0.7018000,0.7151000,0.5012000},
{0.7017000,0.7156000,0.5010000},
{0.7017000,0.7162000,0.5009000},
{0.7017000,0.7171000,0.5008000},
{0.7018000,0.7181000,0.5009000},
{0.7020000,0.7192000,0.5010000},
{0.7023000,0.7203000,0.5012000},
{0.7026000,0.7214000,0.5014000},
{0.7029000,0.7224000,0.5016000},
{0.7032000,0.7236000,0.5017000},
{0.7034000,0.7246000,0.5017000},
{0.7037000,0.7258000,0.5017000},
{0.7040000,0.7270000,0.5017000},
{0.7044000,0.7283000,0.5018000},
{0.7049000,0.7296000,0.5019000},
{0.7055000,0.7309000,0.5020000},
{0.7061000,0.7322000,0.5021000},
{0.7070000,0.7340000,0.5023000},
{0.7077000,0.7353000,0.5023000},
{0.7084000,0.7366000,0.5023000},
{0.7091000,0.7380000,0.5023000},
{0.7098000,0.7395000,0.5024000},
{0.7106000,0.7409000,0.5025000},
{0.7113000,0.7421000,0.5025000},
{0.7121000,0.7433000,0.5025000},
{0.7129000,0.7444000,0.5024000},
{0.7137000,0.7454000,0.5024000},
{0.7145000,0.7465000,0.5023000},
{0.7154000,0.7475000,0.5022000},
{0.7162000,0.7486000,0.5021000},
{0.7169000,0.7497000,0.5019000},
{0.7177000,0.7507000,0.5016000},
{0.7184000,0.7518000,0.5012000},
{0.7191000,0.7528000,0.5008000},
{0.7198000,0.7539000,0.5004000},
{0.7205000,0.7551000,0.4999000},
{0.7212000,0.7562000,0.4996000},
{0.7219000,0.7574000,0.4993000},
{0.7227000,0.7586000,0.4990000},
{0.7234000,0.7598000,0.4988000},
{0.7241000,0.7609000,0.4987000},
{0.7248000,0.7620000,0.4985000},
{0.7255000,0.7631000,0.4984000},
{0.7263000,0.7642000,0.4982000},
{0.7271000,0.7652000,0.4981000},
{0.7279000,0.7663000,0.4980000},
{0.7288000,0.7673000,0.4980000},
{0.7297000,0.7684000,0.4980000},
{0.7306000,0.7694000,0.4979000},
{0.7315000,0.7705000,0.4979000},
{0.7324000,0.7716000,0.4979000},
{0.7333000,0.7726000,0.4979000},
{0.7341000,0.7737000,0.4978000},
{0.7350000,0.7748000,0.4977000},
{0.7359000,0.7759000,0.4977000},
{0.7368000,0.7770000,0.4975000},
{0.7377000,0.7780000,0.4974000},
{0.7386000,0.7791000,0.4973000},
{0.7395000,0.7801000,0.4971000},
{0.7404000,0.7811000,0.4970000},
{0.7412000,0.7821000,0.4967000},
{0.7420000,0.7833000,0.4965000},
{0.7428000,0.7844000,0.4963000},
{0.7436000,0.7855000,0.4961000},
{0.7445000,0.7866000,0.4959000},
{0.7454000,0.7876000,0.4957000},
{0.7463000,0.7887000,0.4955000},
{0.7472000,0.7898000,0.4953000},
{0.7481000,0.7909000,0.4951000},
{0.7491000,0.7920000,0.4948000},
{0.7501000,0.7931000,0.4946000},
{0.7512000,0.7943000,0.4944000},
{0.7523000,0.7955000,0.4942000},
{0.7533000,0.7966000,0.4939000},
{0.7544000,0.7977000,0.4937000},
{0.7554000,0.7987000,0.4935000},
{0.7563000,0.7997000,0.4933000},
{0.7572000,0.8007000,0.4930000},
{0.7580000,0.8018000,0.4927000},
{0.7588000,0.8027000,0.4924000},
{0.7595000,0.8037000,0.4920000},
{0.7602000,0.8046000,0.4916000}
};
shoToUaVsWam = {
{-0.3134906,-0.2457478,-0.3792515},
{-0.3130362,-0.2446719,-0.3803209},
{-0.3123509,-0.2432992,-0.3817622},
{-0.3115135,-0.2417690,-0.3834151},
{-0.3106172,-0.2398346,-0.3853522},
{-0.3097374,-0.2375969,-0.3874409},
{-0.3084328,-0.2351329,-0.3899766},
{-0.3073474,-0.2320312,-0.3926819},
{-0.3060425,-0.2288619,-0.3955505},
{-0.3046588,-0.2252834,-0.3986607},
{-0.3034509,-0.2217115,-0.4015738},
{-0.3020148,-0.2180625,-0.4046429},
{-0.3006101,-0.2143157,-0.4076792},
{-0.2991152,-0.2101604,-0.4109291},
{-0.2974887,-0.2057498,-0.4143277},
{-0.2956030,-0.2011228,-0.4179336},
{-0.2938251,-0.1958834,-0.4216592},
{-0.2917215,-0.1905048,-0.4255661},
{-0.2899007,-0.1851511,-0.4291581},
{-0.2880597,-0.1799061,-0.4326146},
{-0.2861116,-0.1752346,-0.4358130},
{-0.2843047,-0.1707226,-0.4387763},
{-0.2824705,-0.1662002,-0.4416875},
{-0.2805689,-0.1617192,-0.4445537},
{-0.2787780,-0.1566930,-0.4474708},
{-0.2769847,-0.1515086,-0.4503605},
{-0.2750090,-0.1459903,-0.4533838},
{-0.2725410,-0.1395562,-0.4568867},
{-0.2707612,-0.1343445,-0.4594997},
{-0.2684460,-0.1282748,-0.4625823},
{-0.2659238,-0.1225487,-0.4655818},
{-0.2633680,-0.1161362,-0.4686680},
{-0.2609056,-0.1097107,-0.4715844},
{-0.2583728,-0.1030069,-0.4744819},
{-0.2561583,-0.0967633,-0.4769903},
{-0.2540787,-0.0895244,-0.4795096},
{-0.2519383,-0.0824463,-0.4819022},
{-0.2498887,-0.0754092,-0.4841168},
{-0.2475718,-0.0686944,-0.4863017},
{-0.2453096,-0.0614547,-0.4884122},
{-0.2428063,-0.0540888,-0.4905298},
{-0.2400545,-0.0467243,-0.4926365},
{-0.2370603,-0.0390591,-0.4947492},
{-0.2339569,-0.0312280,-0.4967786},
{-0.2304742,-0.0229126,-0.4988553},
{-0.2270674,-0.0146332,-0.5007257},
{-0.2233275,-0.0068845,-0.5025708},
{-0.2189189,0.0010058,-0.5045528},
{-0.2147261,0.0090376,-0.5062717},
{-0.2101776,0.0170550,-0.5079710},
{-0.2054343,0.0250530,-0.5095774},
{-0.2008512,0.0326967,-0.5109694},
{-0.1963112,0.0400295,-0.5122105},
{-0.1916656,0.0474997,-0.5133304},
{-0.1869482,0.0546515,-0.5143574},
{-0.1823368,0.0617780,-0.5152056},
{-0.1772983,0.0687551,-0.5160795},
{-0.1720624,0.0758805,-0.5168527},
{-0.1665727,0.0832032,-0.5175237},
{-0.1611903,0.0904928,-0.5180046},
{-0.1562084,0.0978174,-0.5181995},
{-0.1510761,0.1051543,-0.5182843},
{-0.1459215,0.1121449,-0.5182957},
{-0.1410516,0.1189291,-0.5181316},
{-0.1360642,0.1252522,-0.5179753},
{-0.1311231,0.1316223,-0.5176701},
{-0.1260985,0.1375772,-0.5173700},
{-0.1211402,0.1432716,-0.5170090},
{-0.1163162,0.1489313,-0.5165172},
{-0.1113626,0.1543096,-0.5160300},
{-0.1068861,0.1593302,-0.5154505},
{-0.1022121,0.1641387,-0.5148895},
{-0.0979297,0.1685457,-0.5142977},
{-0.0934522,0.1727450,-0.5137372},
{-0.0889789,0.1766249,-0.5132119},
{-0.0844934,0.1804858,-0.5126263},
{-0.0798131,0.1837867,-0.5122034},
{-0.0748492,0.1870396,-0.5117751},
{-0.0700461,0.1896249,-0.5115036},
{-0.0650495,0.1921462,-0.5112224},
{-0.0602128,0.1941488,-0.5110584},
{-0.0555481,0.1958364,-0.5109428},
{-0.0508839,0.1973629,-0.5108412},
{-0.0462119,0.1985278,-0.5108338},
{-0.0417237,0.1994393,-0.5108650},
{-0.0373933,0.1999874,-0.5109861},
{-0.0333988,0.2002261,-0.5111693},
{-0.0295614,0.2002496,-0.5113963},
{-0.0263823,0.1997041,-0.5117834},
{-0.0233755,0.1988591,-0.5122584},
{-0.0203742,0.1980637,-0.5126945},
{-0.0180302,0.1969967,-0.5131931},
{-0.0156963,0.1960371,-0.5136371},
{-0.0135257,0.1948700,-0.5141427},
{-0.0115237,0.1938989,-0.5145585},
{-0.0098552,0.1924277,-0.5151451},
{-0.0083522,0.1910988,-0.5156661},
{-0.0068497,0.1896199,-0.5162338},
{-0.0056792,0.1880828,-0.5168100}
};
elOffsetVsWam = {
{0.0159684,-0.0400851,0.0127748},
{0.0157462,-0.0401440,0.0128654},
{0.0155122,-0.0402124,0.0129358},
{0.0152089,-0.0402914,0.0130497},
{0.0148691,-0.0403856,0.0131497},
{0.0144820,-0.0404920,0.0132541},
{0.0140055,-0.0406088,0.0134078},
{0.0134549,-0.0407486,0.0135469},
{0.0128370,-0.0408880,0.0137253},
{0.0121513,-0.0410369,0.0139039},
{0.0114854,-0.0411769,0.0140551},
{0.0107895,-0.0413118,0.0142099},
{0.0100855,-0.0414414,0.0143489},
{0.0093244,-0.0415754,0.0144755},
{0.0085214,-0.0417066,0.0145926},
{0.0076728,-0.0418321,0.0147039},
{0.0067644,-0.0419619,0.0147799},
{0.0058300,-0.0420804,0.0148409},
{0.0049251,-0.0421847,0.0148727},
{0.0040473,-0.0422736,0.0148849},
{0.0032166,-0.0423358,0.0149110},
{0.0024405,-0.0423875,0.0149111},
{0.0016684,-0.0424294,0.0148985},
{0.0009025,-0.0424603,0.0148765},
{0.0001283,-0.0424960,0.0148011},
{-0.0006422,-0.0425259,0.0147014},
{-0.0014363,-0.0425508,0.0145727},
{-0.0023407,-0.0425698,0.0143992},
{-0.0031004,-0.0425642,0.0142715},
{-0.0039630,-0.0425501,0.0140990},
{-0.0047706,-0.0425267,0.0139185},
{-0.0056131,-0.0424994,0.0136857},
{-0.0064073,-0.0424701,0.0134252},
{-0.0071687,-0.0424444,0.0131180},
{-0.0078605,-0.0424115,0.0128250},
{-0.0084923,-0.0424108,0.0124179},
{-0.0091446,-0.0423863,0.0120324},
{-0.0096984,-0.0423816,0.0116077},
{-0.0102525,-0.0423601,0.0112032},
{-0.0107798,-0.0423484,0.0107428},
{-0.0113218,-0.0423240,0.0102711},
{-0.0118776,-0.0422838,0.0097982},
{-0.0124692,-0.0422241,0.0093082},
{-0.0130770,-0.0421475,0.0088080},
{-0.0137240,-0.0420503,0.0082720},
{-0.0143842,-0.0419292,0.0077482},
{-0.0150782,-0.0417703,0.0072725},
{-0.0158394,-0.0415694,0.0067897},
{-0.0166109,-0.0413436,0.0063072},
{-0.0173999,-0.0410898,0.0058198},
{-0.0182362,-0.0407904,0.0053464},
{-0.0190397,-0.0404789,0.0048939},
{-0.0198622,-0.0401305,0.0044762},
{-0.0206786,-0.0397625,0.0040416},
{-0.0214873,-0.0393719,0.0036264},
{-0.0222896,-0.0389592,0.0032170},
{-0.0231497,-0.0384852,0.0028258},
{-0.0239944,-0.0379929,0.0024100},
{-0.0248314,-0.0374771,0.0019671},
{-0.0255604,-0.0370060,0.0014890},
{-0.0262895,-0.0365075,0.0010335},
{-0.0269466,-0.0360359,0.0005434},
{-0.0275898,-0.0355499,0.0000757},
{-0.0281723,-0.0350881,-0.0003845},
{-0.0287543,-0.0346053,-0.0008146},
{-0.0293215,-0.0341130,-0.0012466},
{-0.0298596,-0.0336249,-0.0016637},
{-0.0303530,-0.0331570,-0.0020763},
{-0.0308256,-0.0326896,-0.0024839},
{-0.0312488,-0.0322506,-0.0029003},
{-0.0316310,-0.0318388,-0.0032825},
{-0.0319821,-0.0314427,-0.0036746},
{-0.0322947,-0.0310768,-0.0040351},
{-0.0326357,-0.0306718,-0.0043768},
{-0.0329617,-0.0302721,-0.0047035},
{-0.0332820,-0.0298665,-0.0050297},
{-0.0336267,-0.0294270,-0.0053191},
{-0.0339582,-0.0289858,-0.0056270},
{-0.0342859,-0.0285451,-0.0058871},
{-0.0345797,-0.0281274,-0.0061718},
{-0.0348643,-0.0277172,-0.0064219},
{-0.0351374,-0.0273156,-0.0066496},
{-0.0353932,-0.0269263,-0.0068775},
{-0.0356262,-0.0265590,-0.0070989},
{-0.0358374,-0.0262160,-0.0073077},
{-0.0360085,-0.0259226,-0.0075104},
{-0.0361896,-0.0256215,-0.0076714},
{-0.0363187,-0.0253863,-0.0078412},
{-0.0364279,-0.0251943,-0.0079533},
{-0.0365140,-0.0250375,-0.0080533},
{-0.0366005,-0.0248773,-0.0081561},
{-0.0366424,-0.0247914,-0.0082292},
{-0.0366701,-0.0247218,-0.0083148},
{-0.0366887,-0.0246704,-0.0083854},
{-0.0366796,-0.0246552,-0.0084693},
{-0.0366630,-0.0246651,-0.0085120},
{-0.0366435,-0.0246801,-0.0085526},
{-0.0366065,-0.0247204,-0.0085944},
{-0.0365594,-0.0247821,-0.0086172}
};
wOffsetVsWam = {
{-0.0296596,-0.0044724,-0.0335455},
{-0.0295383,-0.0044273,-0.0336584},
{-0.0293908,-0.0043956,-0.0337914},
{-0.0292073,-0.0043533,-0.0339556},
{-0.0289990,-0.0043517,-0.0341339},
{-0.0287718,-0.0043745,-0.0343227},
{-0.0284787,-0.0044315,-0.0345590},
{-0.0281705,-0.0045501,-0.0347954},
{-0.0278322,-0.0046431,-0.0350543},
{-0.0274679,-0.0047761,-0.0353229},
{-0.0271314,-0.0049314,-0.0355608},
{-0.0267767,-0.0051039,-0.0358044},
{-0.0264294,-0.0053264,-0.0360294},
{-0.0260694,-0.0055565,-0.0362562},
{-0.0256986,-0.0058497,-0.0364742},
{-0.0253109,-0.0061787,-0.0366903},
{-0.0249361,-0.0065140,-0.0368885},
{-0.0245525,-0.0068258,-0.0370888},
{-0.0242209,-0.0070811,-0.0372586},
{-0.0239134,-0.0072440,-0.0374256},
{-0.0236222,-0.0073825,-0.0375831},
{-0.0233641,-0.0074478,-0.0377313},
{-0.0231169,-0.0075157,-0.0378698},
{-0.0228754,-0.0075410,-0.0380112},
{-0.0226573,-0.0075884,-0.0381322},
{-0.0224523,-0.0076164,-0.0382477},
{-0.0222447,-0.0076345,-0.0383652},
{-0.0220048,-0.0076119,-0.0385078},
{-0.0218297,-0.0075120,-0.0386269},
{-0.0216272,-0.0074492,-0.0387528},
{-0.0214139,-0.0073297,-0.0388937},
{-0.0212097,-0.0071674,-0.0390356},
{-0.0210305,-0.0070191,-0.0391593},
{-0.0208554,-0.0068274,-0.0392867},
{-0.0207042,-0.0065959,-0.0394060},
{-0.0205730,-0.0062791,-0.0395262},
{-0.0204372,-0.0059459,-0.0396480},
{-0.0203072,-0.0055739,-0.0397687},
{-0.0201464,-0.0051724,-0.0399045},
{-0.0200169,-0.0048174,-0.0400139},
{-0.0198778,-0.0044698,-0.0401235},
{-0.0197234,-0.0041184,-0.0402371},
{-0.0195663,-0.0037790,-0.0403470},
{-0.0194050,-0.0034152,-0.0404572},
{-0.0192391,-0.0030681,-0.0405641},
{-0.0190667,-0.0026530,-0.0406746},
{-0.0188624,-0.0022384,-0.0407946},
{-0.0186284,-0.0018500,-0.0409214},
{-0.0184080,-0.0014101,-0.0410385},
{-0.0181655,-0.0009624,-0.0411593},
{-0.0179219,-0.0005195,-0.0412739},
{-0.0176813,-0.0000639,-0.0413808},
{-0.0174180,0.0004468,-0.0414899},
{-0.0171644,0.0009426,-0.0415872},
{-0.0168815,0.0014723,-0.0416875},
{-0.0166121,0.0019994,-0.0417737},
{-0.0163164,0.0025203,-0.0418620},
{-0.0160100,0.0030518,-0.0419448},
{-0.0157095,0.0035659,-0.0420178},
{-0.0154321,0.0040481,-0.0420769},
{-0.0151600,0.0045885,-0.0421203},
{-0.0148690,0.0051351,-0.0421609},
{-0.0145761,0.0056602,-0.0421960},
{-0.0142758,0.0062052,-0.0422220},
{-0.0139224,0.0067743,-0.0422525},
{-0.0135592,0.0073629,-0.0422722},
{-0.0131491,0.0079606,-0.0422934},
{-0.0127079,0.0085686,-0.0423095},
{-0.0122693,0.0091748,-0.0423118},
{-0.0118185,0.0097465,-0.0423123},
{-0.0113909,0.0102947,-0.0422997},
{-0.0109343,0.0108297,-0.0422866},
{-0.0104656,0.0113661,-0.0422644},
{-0.0099651,0.0118994,-0.0422386},
{-0.0094326,0.0124285,-0.0422085},
{-0.0088930,0.0129526,-0.0421680},
{-0.0083356,0.0134269,-0.0421335},
{-0.0077656,0.0138778,-0.0420963},
{-0.0071964,0.0142761,-0.0420643},
{-0.0066759,0.0146045,-0.0420374},
{-0.0061691,0.0148844,-0.0420166},
{-0.0057047,0.0151106,-0.0420015},
{-0.0052553,0.0153078,-0.0419887},
{-0.0048327,0.0154508,-0.0419871},
{-0.0044134,0.0155791,-0.0419859},
{-0.0040145,0.0156685,-0.0419926},
{-0.0036429,0.0157319,-0.0420028},
{-0.0032922,0.0157682,-0.0420181},
{-0.0029759,0.0157696,-0.0420412},
{-0.0027470,0.0156935,-0.0420852},
{-0.0025102,0.0156275,-0.0421246},
{-0.0023466,0.0155235,-0.0421724},
{-0.0021273,0.0154666,-0.0422050},
{-0.0019409,0.0153786,-0.0422461},
{-0.0017323,0.0153300,-0.0422728},
{-0.0015439,0.0152446,-0.0423110},
{-0.0013506,0.0151833,-0.0423396},
{-0.0011617,0.0151062,-0.0423728},
{-0.0009953,0.0150272,-0.0424051}
};
laToWrVsWam = {
{0.0384009,-0.2974774,0.0057082},
{0.0373617,-0.2975965,0.0063567},
{0.0364655,-0.2976931,0.0070076},
{0.0351833,-0.2978245,0.0079195},
{0.0340117,-0.2979272,0.0090871},
{0.0327524,-0.2980209,0.0105276},
{0.0312292,-0.2981085,0.0124917},
{0.0296722,-0.2981536,0.0149662},
{0.0276071,-0.2982093,0.0175800},
{0.0253938,-0.2982144,0.0205755},
{0.0233062,-0.2981634,0.0235666},
{0.0211041,-0.2980628,0.0267058},
{0.0190165,-0.2978810,0.0300877},
{0.0166805,-0.2976430,0.0336217},
{0.0143493,-0.2972922,0.0375692},
{0.0118839,-0.2968373,0.0417897},
{0.0091488,-0.2962900,0.0461360},
{0.0061464,-0.2956811,0.0503482},
{0.0030068,-0.2950621,0.0541230},
{-0.0003921,-0.2944864,0.0572504},
{-0.0037896,-0.2938916,0.0601112},
{-0.0071902,-0.2933594,0.0623585},
{-0.0105871,-0.2927779,0.0645680},
{-0.0141324,-0.2922009,0.0664747},
{-0.0175356,-0.2915619,0.0684411},
{-0.0209663,-0.2909075,0.0702371},
{-0.0245117,-0.2902079,0.0719621},
{-0.0286796,-0.2894147,0.0735978},
{-0.0325511,-0.2887600,0.0745526},
{-0.0367443,-0.2879176,0.0758507},
{-0.0408722,-0.2871568,0.0766189},
{-0.0452086,-0.2863652,0.0771438},
{-0.0491972,-0.2855805,0.0776106},
{-0.0530518,-0.2848737,0.0776689},
{-0.0567176,-0.2842459,0.0773781},
{-0.0600082,-0.2838544,0.0763262},
{-0.0635417,-0.2833723,0.0752502},
{-0.0665640,-0.2830942,0.0736676},
{-0.0697736,-0.2827807,0.0718800},
{-0.0725302,-0.2824860,0.0702924},
{-0.0753398,-0.2821290,0.0687541},
{-0.0782665,-0.2817068,0.0671985},
{-0.0813331,-0.2811728,0.0657783},
{-0.0845556,-0.2805769,0.0642412},
{-0.0878867,-0.2798671,0.0628515},
{-0.0915347,-0.2790821,0.0611110},
{-0.0955536,-0.2780940,0.0594409},
{-0.0999315,-0.2768552,0.0580078},
{-0.1045031,-0.2755081,0.0563419},
{-0.1092366,-0.2740150,0.0546183},
{-0.1142872,-0.2722570,0.0530525},
{-0.1192451,-0.2704474,0.0513692},
{-0.1245621,-0.2684096,0.0494022},
{-0.1297700,-0.2662726,0.0475251},
{-0.1351016,-0.2639841,0.0453867},
{-0.1403846,-0.2615657,0.0433073},
{-0.1460767,-0.2587492,0.0413575},
{-0.1516715,-0.2558378,0.0392780},
{-0.1571337,-0.2528206,0.0372927},
{-0.1618115,-0.2501447,0.0352802},
{-0.1666208,-0.2472780,0.0330323},
{-0.1709864,-0.2446074,0.0305096},
{-0.1752809,-0.2418399,0.0281086},
{-0.1792659,-0.2391979,0.0254579},
{-0.1834133,-0.2363287,0.0225454},
{-0.1874972,-0.2333770,0.0194923},
{-0.1915017,-0.2303591,0.0161795},
{-0.1952835,-0.2273885,0.0126032},
{-0.1989140,-0.2243920,0.0090235},
{-0.2021909,-0.2215609,0.0054395},
{-0.2051822,-0.2188522,0.0019908},
{-0.2079774,-0.2162010,-0.0015917},
{-0.2105675,-0.2136192,-0.0053073},
{-0.2133588,-0.2107051,-0.0090226},
{-0.2160762,-0.2077145,-0.0128743},
{-0.2187233,-0.2046464,-0.0167329},
{-0.2215018,-0.2013049,-0.0203298},
{-0.2241385,-0.1979646,-0.0239152},
{-0.2267232,-0.1945620,-0.0272440},
{-0.2289604,-0.1914869,-0.0301648},
{-0.2311066,-0.1884469,-0.0328254},
{-0.2331189,-0.1855382,-0.0350875},
{-0.2349838,-0.1827504,-0.0372146},
{-0.2366585,-0.1801847,-0.0390666},
{-0.2381871,-0.1777437,-0.0409156},
{-0.2394303,-0.1756531,-0.0426510},
{-0.2407289,-0.1735055,-0.0441071},
{-0.2416666,-0.1718223,-0.0455449},
{-0.2424685,-0.1703653,-0.0467409},
{-0.2430712,-0.1693529,-0.0472860},
{-0.2436824,-0.1682948,-0.0479136},
{-0.2439797,-0.1677858,-0.0481853},
{-0.2442057,-0.1672278,-0.0489739},
{-0.2443600,-0.1668444,-0.0495091},
{-0.2443387,-0.1666066,-0.0504065},
{-0.2442627,-0.1665126,-0.0510815},
{-0.2441666,-0.1664048,-0.0518854},
{-0.2439490,-0.1664796,-0.0526633},
{-0.2436587,-0.1666859,-0.0533501}
};
elToWrVsWam = {
{0.0087413,-0.3019498,-0.0278373},
{0.0078234,-0.3020239,-0.0273017},
{0.0070747,-0.3020887,-0.0267838},
{0.0059759,-0.3021778,-0.0260361},
{0.0050128,-0.3022789,-0.0250468},
{0.0039806,-0.3023953,-0.0237951},
{0.0027505,-0.3025400,-0.0220673},
{0.0015017,-0.3027037,-0.0198292},
{-0.0002251,-0.3028524,-0.0174743},
{-0.0020741,-0.3029904,-0.0147474},
{-0.0038252,-0.3030949,-0.0119941},
{-0.0056726,-0.3031667,-0.0090986},
{-0.0074130,-0.3032074,-0.0059417},
{-0.0093889,-0.3031995,-0.0026345},
{-0.0113492,-0.3031419,0.0010950},
{-0.0134270,-0.3030160,0.0050993},
{-0.0157873,-0.3028040,0.0092475},
{-0.0184061,-0.3025069,0.0132593},
{-0.0212141,-0.3021433,0.0168644},
{-0.0243056,-0.3017304,0.0198248},
{-0.0274119,-0.3012741,0.0225281},
{-0.0305543,-0.3008071,0.0246272},
{-0.0337039,-0.3002936,0.0266982},
{-0.0370078,-0.2997420,0.0284635},
{-0.0401929,-0.2991503,0.0303090},
{-0.0434186,-0.2985239,0.0319894},
{-0.0467564,-0.2978424,0.0335969},
{-0.0506843,-0.2970266,0.0350900},
{-0.0543808,-0.2962719,0.0359257},
{-0.0583714,-0.2953668,0.0370979},
{-0.0622861,-0.2944864,0.0377252},
{-0.0664183,-0.2935326,0.0381082},
{-0.0702277,-0.2925997,0.0384513},
{-0.0739072,-0.2917011,0.0383823},
{-0.0774218,-0.2908419,0.0379721},
{-0.0805812,-0.2901335,0.0367999},
{-0.0839789,-0.2893182,0.0356022},
{-0.0868712,-0.2886681,0.0338989},
{-0.0899200,-0.2879531,0.0319755},
{-0.0925471,-0.2873034,0.0302785},
{-0.0952176,-0.2865988,0.0286307},
{-0.0979899,-0.2858252,0.0269614},
{-0.1008995,-0.2849518,0.0254314},
{-0.1039606,-0.2839921,0.0237840},
{-0.1071258,-0.2829352,0.0222875},
{-0.1106014,-0.2817351,0.0204364},
{-0.1144160,-0.2803325,0.0186464},
{-0.1185600,-0.2787052,0.0170864},
{-0.1229111,-0.2769182,0.0153034},
{-0.1274021,-0.2749774,0.0134590},
{-0.1322091,-0.2727765,0.0117786},
{-0.1369264,-0.2705113,0.0099884},
{-0.1419801,-0.2679628,0.0079122},
{-0.1469344,-0.2653300,0.0059379},
{-0.1519831,-0.2625118,0.0036992},
{-0.1569967,-0.2595663,0.0015337},
{-0.1623930,-0.2562289,-0.0005045},
{-0.1676815,-0.2527861,-0.0026668},
{-0.1728432,-0.2492547,-0.0047251},
{-0.1772436,-0.2460965,-0.0067966},
{-0.1817808,-0.2426894,-0.0090880},
{-0.1858555,-0.2394723,-0.0116513},
{-0.1898570,-0.2361797,-0.0140874},
{-0.1935416,-0.2329927,-0.0167641},
{-0.1973358,-0.2295544,-0.0197071},
{-0.2010564,-0.2260141,-0.0227799},
{-0.2046509,-0.2223985,-0.0261139},
{-0.2079913,-0.2188199,-0.0297062},
{-0.2111834,-0.2152173,-0.0332883},
{-0.2140095,-0.2118144,-0.0368727},
{-0.2165732,-0.2085575,-0.0403090},
{-0.2189117,-0.2053712,-0.0438783},
{-0.2210331,-0.2022531,-0.0475717},
{-0.2233239,-0.1988057,-0.0512613},
{-0.2255088,-0.1952861,-0.0550828},
{-0.2276163,-0.1916937,-0.0589010},
{-0.2298374,-0.1878779,-0.0624633},
{-0.2319041,-0.1840868,-0.0660115},
{-0.2339196,-0.1802859,-0.0693083},
{-0.2356363,-0.1768824,-0.0722022},
{-0.2372757,-0.1735625,-0.0748420},
{-0.2388236,-0.1704276,-0.0770890},
{-0.2402391,-0.1674426,-0.0792033},
{-0.2414913,-0.1647339,-0.0810537},
{-0.2426005,-0.1621645,-0.0829014},
{-0.2434448,-0.1599846,-0.0846437},
{-0.2443718,-0.1577736,-0.0861099},
{-0.2449588,-0.1560541,-0.0875630},
{-0.2454443,-0.1545956,-0.0887821},
{-0.2458182,-0.1536594,-0.0893712},
{-0.2461926,-0.1526674,-0.0900382},
{-0.2463263,-0.1522623,-0.0903578},
{-0.2463330,-0.1517612,-0.0911788},
{-0.2463009,-0.1514657,-0.0917552},
{-0.2460710,-0.1512766,-0.0926793},
{-0.2458065,-0.1512679,-0.0933925},
{-0.2455172,-0.1512215,-0.0942250},
{-0.2451107,-0.1513734,-0.0950361},
{-0.2446540,-0.1516587,-0.0957552}
};
wrToEeVsWam = {
{-0.0581177,-0.0144252,0.0037745},
{-0.0581137,-0.0145287,0.0034231},
{-0.0582039,-0.0144000,0.0022242},
{-0.0582110,-0.0144308,0.0017973},
{-0.0582525,-0.0143201,0.0012592},
{-0.0583058,-0.0141327,0.0008367},
{-0.0583305,-0.0140459,0.0005120},
{-0.0584051,-0.0137397,-0.0002595},
{-0.0584484,-0.0135140,-0.0010735},
{-0.0584890,-0.0132454,-0.0018951},
{-0.0585068,-0.0129969,-0.0028355},
{-0.0585388,-0.0126131,-0.0037570},
{-0.0585457,-0.0122573,-0.0047081},
{-0.0585184,-0.0119316,-0.0057647},
{-0.0584570,-0.0117341,-0.0067150},
{-0.0583892,-0.0111583,-0.0081360},
{-0.0582649,-0.0108895,-0.0093067},
{-0.0581149,-0.0106461,-0.0104553},
{-0.0579592,-0.0103656,-0.0115449},
{-0.0577753,-0.0099757,-0.0127477},
{-0.0576456,-0.0097096,-0.0135172},
{-0.0574929,-0.0092963,-0.0144271},
{-0.0573652,-0.0089686,-0.0151263},
{-0.0572207,-0.0087382,-0.0157936},
{-0.0570378,-0.0084355,-0.0165990},
{-0.0568313,-0.0081090,-0.0174485},
{-0.0566312,-0.0077518,-0.0182433},
{-0.0563481,-0.0073666,-0.0192515},
{-0.0559615,-0.0070433,-0.0204622},
{-0.0556138,-0.0066729,-0.0215075},
{-0.0553597,-0.0061769,-0.0222968},
{-0.0550344,-0.0058751,-0.0231667},
{-0.0547501,-0.0053721,-0.0239492},
{-0.0545674,-0.0049505,-0.0244519},
{-0.0541249,-0.0044274,-0.0255126},
{-0.0539258,-0.0038223,-0.0260268},
{-0.0536153,-0.0034526,-0.0267111},
{-0.0532272,-0.0029266,-0.0275373},
{-0.0529022,-0.0024963,-0.0281979},
{-0.0527457,-0.0019505,-0.0285321},
{-0.0526252,-0.0014848,-0.0287817},
{-0.0524860,-0.0010704,-0.0290529},
{-0.0522358,-0.0004198,-0.0295168},
{-0.0521671,0.0001156,-0.0296409},
{-0.0520267,0.0007247,-0.0298780},
{-0.0516317,0.0013160,-0.0305359},
{-0.0512125,0.0019621,-0.0311998},
{-0.0507186,0.0026779,-0.0319445},
{-0.0504275,0.0033239,-0.0323422},
{-0.0500982,0.0042041,-0.0327490},
{-0.0494444,0.0050547,-0.0336111},
{-0.0490065,0.0058844,-0.0341136},
{-0.0486579,0.0066267,-0.0344745},
{-0.0483530,0.0075331,-0.0347166},
{-0.0478563,0.0086947,-0.0351308},
{-0.0469517,0.0096723,-0.0360830},
{-0.0465746,0.0106586,-0.0362933},
{-0.0461073,0.0115725,-0.0366086},
{-0.0455907,0.0126450,-0.0368998},
{-0.0452858,0.0139310,-0.0368120},
{-0.0446155,0.0149074,-0.0372454},
{-0.0445747,0.0160975,-0.0367962},
{-0.0442410,0.0173498,-0.0366294},
{-0.0438196,0.0184908,-0.0365778},
{-0.0434899,0.0197263,-0.0363249},
{-0.0428373,0.0208832,-0.0364535},
{-0.0424475,0.0218800,-0.0363246},
{-0.0420538,0.0229711,-0.0361083},
{-0.0415714,0.0240345,-0.0359745},
{-0.0413692,0.0252015,-0.0354045},
{-0.0411735,0.0264005,-0.0347528},
{-0.0410408,0.0275999,-0.0339691},
{-0.0408588,0.0289108,-0.0330866},
{-0.0404850,0.0300523,-0.0325241},
{-0.0400972,0.0311741,-0.0319434},
{-0.0395860,0.0321122,-0.0316505},
{-0.0389549,0.0330476,-0.0314702},
{-0.0383454,0.0339119,-0.0312988},
{-0.0377097,0.0346936,-0.0312143},
{-0.0371882,0.0356332,-0.0307784},
{-0.0367182,0.0364570,-0.0303754},
{-0.0363800,0.0372818,-0.0297753},
{-0.0359862,0.0380002,-0.0293425},
{-0.0354860,0.0387281,-0.0289979},
{-0.0350285,0.0395213,-0.0284793},
{-0.0344702,0.0401591,-0.0282674},
{-0.0340278,0.0407580,-0.0279444},
{-0.0335951,0.0412861,-0.0276917},
{-0.0332033,0.0418903,-0.0272534},
{-0.0328630,0.0425448,-0.0266450},
{-0.0326509,0.0429687,-0.0262223},
{-0.0326042,0.0434621,-0.0254562},
{-0.0325349,0.0437715,-0.0250107},
{-0.0324532,0.0441317,-0.0244782},
{-0.0323600,0.0443384,-0.0242268},
{-0.0321475,0.0445547,-0.0241126},
{-0.0321263,0.0447362,-0.0238027},
{-0.0320759,0.0448914,-0.0235776},
{-0.0319606,0.0450206,-0.0234875}
};
shoToElVsWam = {
{-0.2975221,-0.2858328,-0.3664767},
{-0.2972900,-0.2848159,-0.3674555},
{-0.2968387,-0.2835116,-0.3688264},
{-0.2963046,-0.2820604,-0.3703654},
{-0.2957482,-0.2802202,-0.3722025},
{-0.2952554,-0.2780889,-0.3741868},
{-0.2944273,-0.2757418,-0.3765688},
{-0.2938925,-0.2727798,-0.3791350},
{-0.2932055,-0.2697499,-0.3818253},
{-0.2925075,-0.2663203,-0.3847569},
{-0.2919655,-0.2628884,-0.3875188},
{-0.2912252,-0.2593743,-0.3904329},
{-0.2905246,-0.2557571,-0.3933303},
{-0.2897908,-0.2517358,-0.3964535},
{-0.2889674,-0.2474564,-0.3997351},
{-0.2879301,-0.2429549,-0.4032296},
{-0.2870607,-0.2378453,-0.4068793},
{-0.2858915,-0.2325852,-0.4107251},
{-0.2849755,-0.2273357,-0.4142854},
{-0.2840125,-0.2221797,-0.4177297},
{-0.2828950,-0.2175704,-0.4209021},
{-0.2818641,-0.2131101,-0.4238652},
{-0.2808021,-0.2086296,-0.4267890},
{-0.2796664,-0.2041795,-0.4296771},
{-0.2786497,-0.1991891,-0.4326697},
{-0.2776270,-0.1940345,-0.4356591},
{-0.2764453,-0.1885411,-0.4388112},
{-0.2748817,-0.1821260,-0.4424875},
{-0.2738616,-0.1769087,-0.4452282},
{-0.2724090,-0.1708249,-0.4484832},
{-0.2706944,-0.1650753,-0.4516632},
{-0.2689812,-0.1586356,-0.4549823},
{-0.2673130,-0.1521807,-0.4581591},
{-0.2655414,-0.1454513,-0.4613639},
{-0.2640188,-0.1391748,-0.4641653},
{-0.2625710,-0.1319352,-0.4670916},
{-0.2610828,-0.1248326,-0.4698697},
{-0.2595871,-0.1177908,-0.4725091},
{-0.2578243,-0.1110544,-0.4750985},
{-0.2560894,-0.1038031,-0.4776695},
{-0.2541281,-0.0964129,-0.4802587},
{-0.2519321,-0.0890081,-0.4828383},
{-0.2495295,-0.0812833,-0.4854411},
{-0.2470339,-0.0733755,-0.4879706},
{-0.2441982,-0.0649629,-0.4905834},
{-0.2414516,-0.0565624,-0.4929775},
{-0.2384057,-0.0486549,-0.4952983},
{-0.2347583,-0.0405636,-0.4977631},
{-0.2313370,-0.0323061,-0.4999645},
{-0.2275775,-0.0240348,-0.5021512},
{-0.2236706,-0.0157374,-0.5042309},
{-0.2198909,-0.0077822,-0.5060755},
{-0.2161734,-0.0001010,-0.5077342},
{-0.2123442,0.0077372,-0.5092888},
{-0.2084355,0.0152796,-0.5107310},
{-0.2046264,0.0228188,-0.5119886},
{-0.2004479,0.0302699,-0.5132537},
{-0.1960567,0.0378876,-0.5144427},
{-0.1914041,0.0457260,-0.5155566},
{-0.1867507,0.0534867,-0.5165156},
{-0.1824979,0.0613099,-0.5171659},
{-0.1780227,0.0691184,-0.5177408},
{-0.1735113,0.0765950,-0.5182201},
{-0.1692239,0.0838410,-0.5185161},
{-0.1648185,0.0906469,-0.5187899},
{-0.1604446,0.0975093,-0.5189166},
{-0.1559581,0.1039522,-0.5190337},
{-0.1514932,0.1101146,-0.5190853},
{-0.1471418,0.1162417,-0.5190011},
{-0.1426114,0.1220590,-0.5189303},
{-0.1385170,0.1274914,-0.5187330},
{-0.1341942,0.1326960,-0.5185641},
{-0.1302245,0.1374689,-0.5183328},
{-0.1260878,0.1420732,-0.5181140},
{-0.1219407,0.1463527,-0.5179154},
{-0.1177754,0.1506193,-0.5176561},
{-0.1134398,0.1543597,-0.5175225},
{-0.1088074,0.1580538,-0.5174021},
{-0.1043320,0.1610798,-0.5173907},
{-0.0996292,0.1640188,-0.5173943},
{-0.0950771,0.1664316,-0.5174803},
{-0.0906855,0.1685207,-0.5175924},
{-0.0862771,0.1704366,-0.5177187},
{-0.0818381,0.1719688,-0.5179327},
{-0.0775611,0.1732233,-0.5181727},
{-0.0734018,0.1740647,-0.5184965},
{-0.0695884,0.1746046,-0.5188407},
{-0.0658802,0.1748633,-0.5192376},
{-0.0628102,0.1745098,-0.5197367},
{-0.0598895,0.1738216,-0.5203117},
{-0.0569747,0.1731864,-0.5208506},
{-0.0546726,0.1722053,-0.5214223},
{-0.0523664,0.1713152,-0.5219520},
{-0.0502143,0.1701996,-0.5225281},
{-0.0482033,0.1692437,-0.5230277},
{-0.0465183,0.1677626,-0.5236571},
{-0.0449957,0.1664187,-0.5242187},
{-0.0434562,0.1648994,-0.5248283},
{-0.0422386,0.1633007,-0.5254273}
};
shoToLaVsWam = {
{-0.3271818,-0.2903053,-0.4000222},
{-0.3268283,-0.2892432,-0.4011139},
{-0.3262295,-0.2879073,-0.4026179},
{-0.3255120,-0.2864137,-0.4043209},
{-0.3247471,-0.2845718,-0.4063364},
{-0.3240272,-0.2824634,-0.4085096},
{-0.3229060,-0.2801733,-0.4111278},
{-0.3220630,-0.2773299,-0.4139304},
{-0.3210377,-0.2743930,-0.4168796},
{-0.3199753,-0.2710964,-0.4200797},
{-0.3190969,-0.2678199,-0.4230795},
{-0.3180019,-0.2644782,-0.4262374},
{-0.3169540,-0.2610835,-0.4293597},
{-0.3158602,-0.2572922,-0.4327097},
{-0.3146659,-0.2533061,-0.4362093},
{-0.3132411,-0.2491336,-0.4399200},
{-0.3119968,-0.2443592,-0.4437678},
{-0.3104441,-0.2394110,-0.4478140},
{-0.3091964,-0.2344169,-0.4515440},
{-0.3079259,-0.2294237,-0.4551553},
{-0.3065173,-0.2249528,-0.4584851},
{-0.3052282,-0.2205579,-0.4615965},
{-0.3039190,-0.2161453,-0.4646588},
{-0.3025418,-0.2117205,-0.4676883},
{-0.3013070,-0.2067775,-0.4708019},
{-0.3000793,-0.2016509,-0.4739068},
{-0.2986900,-0.1961756,-0.4771763},
{-0.2968865,-0.1897379,-0.4809953},
{-0.2956913,-0.1844207,-0.4838550},
{-0.2940361,-0.1782741,-0.4872360},
{-0.2921083,-0.1724050,-0.4905569},
{-0.2901908,-0.1658030,-0.4940179},
{-0.2883435,-0.1591999,-0.4973184},
{-0.2863968,-0.1522787,-0.5006506},
{-0.2847230,-0.1457707,-0.5035713},
{-0.2831440,-0.1382142,-0.5066179},
{-0.2815200,-0.1307785,-0.5095178},
{-0.2798943,-0.1233647,-0.5122778},
{-0.2779706,-0.1162268,-0.5150030},
{-0.2761063,-0.1086205,-0.5176834},
{-0.2740059,-0.1008827,-0.5203822},
{-0.2716555,-0.0931265,-0.5230754},
{-0.2690959,-0.0850623,-0.5257880},
{-0.2664388,-0.0767907,-0.5284278},
{-0.2634374,-0.0680310,-0.5311474},
{-0.2605183,-0.0592154,-0.5336521},
{-0.2572681,-0.0508933,-0.5360929},
{-0.2533868,-0.0424137,-0.5386845},
{-0.2497450,-0.0337162,-0.5410030},
{-0.2457430,-0.0249972,-0.5433105},
{-0.2415924,-0.0162569,-0.5455048},
{-0.2375722,-0.0078461,-0.5474563},
{-0.2335914,0.0003458,-0.5492242},
{-0.2295086,0.0086798,-0.5508760},
{-0.2253170,0.0167519,-0.5524185},
{-0.2212386,0.0248182,-0.5537623},
{-0.2167643,0.0327903,-0.5551157},
{-0.2120668,0.0409393,-0.5563875},
{-0.2071136,0.0492920,-0.5575744},
{-0.2021828,0.0575349,-0.5585924},
{-0.1976579,0.0658985,-0.5592862},
{-0.1928917,0.0742535,-0.5599017},
{-0.1880875,0.0822552,-0.5604160},
{-0.1834997,0.0900462,-0.5607381},
{-0.1787409,0.0974213,-0.5610424},
{-0.1740038,0.1048722,-0.5611888},
{-0.1691073,0.1119128,-0.5613271},
{-0.1642010,0.1186832,-0.5613948},
{-0.1594112,0.1254165,-0.5613129},
{-0.1544299,0.1318055,-0.5612425},
{-0.1499080,0.1377861,-0.5610328},
{-0.1451285,0.1435257,-0.5608507},
{-0.1406901,0.1488351,-0.5605972},
{-0.1360530,0.1539725,-0.5603526},
{-0.1313733,0.1587812,-0.5601239},
{-0.1266684,0.1635719,-0.5598241},
{-0.1217754,0.1677866,-0.5596560},
{-0.1165730,0.1719316,-0.5594985},
{-0.1115284,0.1753559,-0.5594550},
{-0.1063051,0.1786233,-0.5594317},
{-0.1012462,0.1813161,-0.5594969},
{-0.0963902,0.1836313,-0.5595939},
{-0.0915324,0.1857444,-0.5597074},
{-0.0866708,0.1874196,-0.5599198},
{-0.0819745,0.1888025,-0.5601586},
{-0.0774163,0.1897333,-0.5604892},
{-0.0732313,0.1903364,-0.5608435},
{-0.0691724,0.1906315,-0.5612557},
{-0.0657861,0.1902794,-0.5617779},
{-0.0626365,0.1895152,-0.5623970},
{-0.0594849,0.1888139,-0.5629752},
{-0.0570193,0.1877288,-0.5635948},
{-0.0544937,0.1867818,-0.5641569},
{-0.0521552,0.1855782,-0.5647742},
{-0.0499356,0.1845737,-0.5653005},
{-0.0480622,0.1830073,-0.5659681},
{-0.0463463,0.1816020,-0.5665583},
{-0.0446179,0.1800056,-0.5672011},
{-0.0432339,0.1783279,-0.5678323}
};
shoToWrVsWam = {
{-0.2887809,-0.5877826,-0.3943140},
{-0.2894666,-0.5868398,-0.3947572},
{-0.2897640,-0.5856003,-0.3956103},
{-0.2903287,-0.5842382,-0.3964015},
{-0.2907354,-0.5824991,-0.3972493},
{-0.2912748,-0.5804843,-0.3979820},
{-0.2916768,-0.5782818,-0.3986361},
{-0.2923908,-0.5754835,-0.3989642},
{-0.2934306,-0.5726023,-0.3992996},
{-0.2945815,-0.5693108,-0.3995043},
{-0.2957907,-0.5659833,-0.3995129},
{-0.2968978,-0.5625409,-0.3995316},
{-0.2979376,-0.5589645,-0.3992720},
{-0.2991797,-0.5549352,-0.3990880},
{-0.3003166,-0.5505983,-0.3986401},
{-0.3013571,-0.5459709,-0.3981303},
{-0.3028480,-0.5406492,-0.3976318},
{-0.3042977,-0.5350921,-0.3974658},
{-0.3061896,-0.5294790,-0.3974210},
{-0.3083180,-0.5239101,-0.3979049},
{-0.3103069,-0.5188445,-0.3983739},
{-0.3124184,-0.5139173,-0.3992380},
{-0.3145061,-0.5089232,-0.4000909},
{-0.3166742,-0.5039215,-0.4012136},
{-0.3188426,-0.4983393,-0.4023607},
{-0.3210456,-0.4925584,-0.4036697},
{-0.3232017,-0.4863835,-0.4052142},
{-0.3255660,-0.4791526,-0.4073975},
{-0.3282424,-0.4731807,-0.4093025},
{-0.3307804,-0.4661916,-0.4113853},
{-0.3329805,-0.4595618,-0.4139380},
{-0.3353995,-0.4521681,-0.4168741},
{-0.3375407,-0.4447804,-0.4197079},
{-0.3394486,-0.4371524,-0.4229817},
{-0.3414406,-0.4300167,-0.4261932},
{-0.3431522,-0.4220686,-0.4302917},
{-0.3450617,-0.4141508,-0.4342676},
{-0.3464582,-0.4064589,-0.4386102},
{-0.3477443,-0.3990075,-0.4431230},
{-0.3486365,-0.3911065,-0.4473910},
{-0.3493457,-0.3830117,-0.4516281},
{-0.3499220,-0.3748333,-0.4558769},
{-0.3504290,-0.3662351,-0.4600097},
{-0.3509945,-0.3573676,-0.4641866},
{-0.3513241,-0.3478981,-0.4682959},
{-0.3520531,-0.3382976,-0.4725411},
{-0.3528217,-0.3289873,-0.4766520},
{-0.3533183,-0.3192688,-0.4806767},
{-0.3542481,-0.3092242,-0.4846610},
{-0.3549796,-0.2990122,-0.4886922},
{-0.3558796,-0.2885139,-0.4924523},
{-0.3568173,-0.2782935,-0.4960871},
{-0.3581535,-0.2680638,-0.4998220},
{-0.3592786,-0.2575929,-0.5033509},
{-0.3604186,-0.2472322,-0.5070318},
{-0.3616232,-0.2367475,-0.5104549},
{-0.3628410,-0.2259590,-0.5137582},
{-0.3637382,-0.2148985,-0.5171095},
{-0.3642473,-0.2035286,-0.5202817},
{-0.3639943,-0.1926098,-0.5233122},
{-0.3642787,-0.1813795,-0.5262539},
{-0.3638782,-0.1703539,-0.5293921},
{-0.3633683,-0.1595847,-0.5323074},
{-0.3627655,-0.1491517,-0.5352802},
{-0.3621543,-0.1389074,-0.5384971},
{-0.3615010,-0.1285048,-0.5416965},
{-0.3606090,-0.1184463,-0.5451476},
{-0.3594845,-0.1087053,-0.5487916},
{-0.3583252,-0.0989755,-0.5522894},
{-0.3566208,-0.0897554,-0.5558030},
{-0.3550902,-0.0810661,-0.5590420},
{-0.3531059,-0.0726753,-0.5624423},
{-0.3512576,-0.0647841,-0.5659045},
{-0.3494118,-0.0567325,-0.5693752},
{-0.3474495,-0.0489333,-0.5729982},
{-0.3453917,-0.0410745,-0.5765570},
{-0.3432772,-0.0335183,-0.5799858},
{-0.3407115,-0.0260330,-0.5834137},
{-0.3382516,-0.0192061,-0.5866990},
{-0.3352655,-0.0128636,-0.5895965},
{-0.3323528,-0.0071308,-0.5923223},
{-0.3295092,-0.0019069,-0.5946814},
{-0.3265162,0.0029940,-0.5969220},
{-0.3233294,0.0072349,-0.5989864},
{-0.3201617,0.0110588,-0.6010741},
{-0.3168466,0.0140802,-0.6031402},
{-0.3139602,0.0168309,-0.6049506},
{-0.3108390,0.0188092,-0.6068006},
{-0.3082546,0.0199141,-0.6085188},
{-0.3057077,0.0201623,-0.6096829},
{-0.3031673,0.0205191,-0.6108888},
{-0.3009990,0.0199430,-0.6117801},
{-0.2986994,0.0195540,-0.6131308},
{-0.2965152,0.0187338,-0.6142833},
{-0.2942743,0.0179670,-0.6157070},
{-0.2923248,0.0164947,-0.6170496},
{-0.2905129,0.0151972,-0.6184437},
{-0.2885669,0.0135260,-0.6198644},
{-0.2868927,0.0116420,-0.6211824}
};
shoToThVsWam = {
{-0.2575117,-0.6297081,-0.4237163},
{-0.2578724,-0.6287837,-0.4237834},
{-0.2573757,-0.6275650,-0.4237165},
{-0.2576027,-0.6262365,-0.4240627},
{-0.2578375,-0.6246178,-0.4245209},
{-0.2582777,-0.6228644,-0.4247237},
{-0.2585153,-0.6209292,-0.4247420},
{-0.2591359,-0.6184869,-0.4243574},
{-0.2599206,-0.6159451,-0.4237635},
{-0.2609164,-0.6130676,-0.4229989},
{-0.2619637,-0.6101638,-0.4219588},
{-0.2630253,-0.6072559,-0.4208206},
{-0.2640009,-0.6041606,-0.4194120},
{-0.2651994,-0.6006658,-0.4179043},
{-0.2663118,-0.5968385,-0.4161192},
{-0.2674776,-0.5928933,-0.4139567},
{-0.2689473,-0.5880467,-0.4119225},
{-0.2704272,-0.5829560,-0.4101871},
{-0.2723999,-0.5777387,-0.4087902},
{-0.2747183,-0.5726019,-0.4079133},
{-0.2769245,-0.5678847,-0.4073554},
{-0.2793924,-0.5633769,-0.4071769},
{-0.2817864,-0.5587174,-0.4071589},
{-0.2842049,-0.5540148,-0.4072470},
{-0.2866586,-0.5487212,-0.4074466},
{-0.2892084,-0.5432591,-0.4076493},
{-0.2918205,-0.5374377,-0.4081612},
{-0.2945949,-0.5305057,-0.4093083},
{-0.2976914,-0.5248151,-0.4100185},
{-0.3006273,-0.5180644,-0.4113058},
{-0.3035081,-0.5118156,-0.4129821},
{-0.3063409,-0.5046327,-0.4151226},
{-0.3091172,-0.4975668,-0.4173193},
{-0.3116347,-0.4902299,-0.4199532},
{-0.3141764,-0.4833492,-0.4226856},
{-0.3166372,-0.4757376,-0.4262186},
{-0.3189419,-0.4679881,-0.4298743},
{-0.3209318,-0.4605525,-0.4338890},
{-0.3226847,-0.4532899,-0.4380790},
{-0.3241048,-0.4456214,-0.4422602},
{-0.3252461,-0.4377179,-0.4464868},
{-0.3262187,-0.4297124,-0.4507345},
{-0.3273572,-0.4213824,-0.4548648},
{-0.3284169,-0.4127267,-0.4591247},
{-0.3293861,-0.4035064,-0.4631530},
{-0.3307577,-0.3941476,-0.4673177},
{-0.3322733,-0.3850941,-0.4711938},
{-0.3336371,-0.3756614,-0.4749732},
{-0.3353678,-0.3658651,-0.4787158},
{-0.3370733,-0.3559432,-0.4825093},
{-0.3389489,-0.3457255,-0.4861133},
{-0.3409943,-0.3358027,-0.4895812},
{-0.3433682,-0.3258390,-0.4932329},
{-0.3454965,-0.3156225,-0.4968226},
{-0.3480437,-0.3055712,-0.5004425},
{-0.3504420,-0.2953080,-0.5036980},
{-0.3527228,-0.2847409,-0.5072536},
{-0.3547634,-0.2738761,-0.5106989},
{-0.3564801,-0.2627034,-0.5141160},
{-0.3574875,-0.2519748,-0.5175284},
{-0.3587534,-0.2408759,-0.5208088},
{-0.3596294,-0.2299966,-0.5244219},
{-0.3602399,-0.2193463,-0.5279757},
{-0.3607572,-0.2089991,-0.5315046},
{-0.3611893,-0.1988176,-0.5353608},
{-0.3615815,-0.1884529,-0.5392020},
{-0.3616553,-0.1784060,-0.5432160},
{-0.3614990,-0.1686576,-0.5475023},
{-0.3612288,-0.1589026,-0.5517248},
{-0.3603333,-0.1496396,-0.5561258},
{-0.3596165,-0.1408775,-0.5604969},
{-0.3582919,-0.1323945,-0.5650353},
{-0.3572639,-0.1243607,-0.5697194},
{-0.3561577,-0.1161456,-0.5743331},
{-0.3549351,-0.1081675,-0.5789379},
{-0.3536877,-0.1001227,-0.5832264},
{-0.3524057,-0.0923644,-0.5873212},
{-0.3506895,-0.0846743,-0.5912652},
{-0.3489576,-0.0776400,-0.5951167},
{-0.3468201,-0.0710463,-0.5986107},
{-0.3446616,-0.0650645,-0.6019232},
{-0.3424694,-0.0595715,-0.6050167},
{-0.3400734,-0.0544392,-0.6077678},
{-0.3376382,-0.0499182,-0.6103348},
{-0.3352941,-0.0457500,-0.6130644},
{-0.3327301,-0.0425046,-0.6152182},
{-0.3305449,-0.0394739,-0.6173891},
{-0.3281003,-0.0372898,-0.6192486},
{-0.3262448,-0.0358888,-0.6212618},
{-0.3242183,-0.0353697,-0.6228572},
{-0.3220282,-0.0348116,-0.6244085},
{-0.3201399,-0.0351395,-0.6259059},
{-0.3180634,-0.0353525,-0.6276328},
{-0.3160705,-0.0359874,-0.6292225},
{-0.3139907,-0.0366516,-0.6308089},
{-0.3122272,-0.0380058,-0.6323333},
{-0.3105264,-0.0392092,-0.6339163},
{-0.3086733,-0.0408202,-0.6354279},
{-0.3071739,-0.0426378,-0.6367511}
};
shoToPiVsWam = {
{-0.3002440,-0.6403145,-0.4209410},
{-0.3006834,-0.6394867,-0.4212616},
{-0.3008135,-0.6383118,-0.4220566},
{-0.3012175,-0.6370489,-0.4227161},
{-0.3014485,-0.6353386,-0.4235782},
{-0.3019212,-0.6334431,-0.4240974},
{-0.3022202,-0.6314532,-0.4243584},
{-0.3027713,-0.6287521,-0.4245513},
{-0.3036468,-0.6260552,-0.4245666},
{-0.3046188,-0.6229644,-0.4244149},
{-0.3055594,-0.6198483,-0.4240717},
{-0.3065678,-0.6166378,-0.4236152},
{-0.3075213,-0.6132721,-0.4229118},
{-0.3085799,-0.6095109,-0.4221777},
{-0.3094356,-0.6054947,-0.4210729},
{-0.3104865,-0.6011123,-0.4199495},
{-0.3118719,-0.5960692,-0.4187789},
{-0.3132324,-0.5907976,-0.4178881},
{-0.3151265,-0.5853800,-0.4173010},
{-0.3173409,-0.5799612,-0.4173177},
{-0.3194150,-0.5750417,-0.4173189},
{-0.3216956,-0.5702171,-0.4177924},
{-0.3239648,-0.5653117,-0.4182807},
{-0.3263226,-0.5604466,-0.4188720},
{-0.3286856,-0.5549367,-0.4196771},
{-0.3311617,-0.5492452,-0.4205299},
{-0.3335901,-0.5431553,-0.4216170},
{-0.3362324,-0.5359491,-0.4235339},
{-0.3390829,-0.5300247,-0.4251532},
{-0.3417969,-0.5230042,-0.4272273},
{-0.3444168,-0.5163801,-0.4294587},
{-0.3470530,-0.5089789,-0.4322603},
{-0.3495659,-0.5015357,-0.4350127},
{-0.3519243,-0.4938850,-0.4380072},
{-0.3541396,-0.4866182,-0.4415228},
{-0.3565039,-0.4785634,-0.4454599},
{-0.3586140,-0.4705428,-0.4496389},
{-0.3602725,-0.4627156,-0.4542421},
{-0.3618451,-0.4551377,-0.4589523},
{-0.3631953,-0.4470670,-0.4634057},
{-0.3642763,-0.4388192,-0.4678332},
{-0.3651386,-0.4305061,-0.4722780},
{-0.3660665,-0.4216935,-0.4767381},
{-0.3670856,-0.4126410,-0.4810959},
{-0.3679818,-0.4029688,-0.4853178},
{-0.3689799,-0.3931734,-0.4899230},
{-0.3701910,-0.3836414,-0.4942941},
{-0.3711523,-0.3736806,-0.4986017},
{-0.3727020,-0.3634043,-0.5026604},
{-0.3743381,-0.3528160,-0.5068691},
{-0.3757405,-0.3419643,-0.5111234},
{-0.3773620,-0.3314358,-0.5148969},
{-0.3793058,-0.3209447,-0.5186950},
{-0.3812291,-0.3100555,-0.5224779},
{-0.3834294,-0.2991422,-0.5264188},
{-0.3852697,-0.2881333,-0.5304635},
{-0.3872360,-0.2768425,-0.5341480},
{-0.3888574,-0.2653188,-0.5377691},
{-0.3901637,-0.2533610,-0.5413786},
{-0.3910644,-0.2416457,-0.5448224},
{-0.3918744,-0.2298091,-0.5484585},
{-0.3926240,-0.2180810,-0.5516587},
{-0.3930256,-0.2064889,-0.5551207},
{-0.3932015,-0.1953084,-0.5585871},
{-0.3935095,-0.1841577,-0.5623563},
{-0.3934570,-0.1729136,-0.5663273},
{-0.3932001,-0.1621459,-0.5702106},
{-0.3927825,-0.1515696,-0.5743630},
{-0.3921746,-0.1410113,-0.5785043},
{-0.3912260,-0.1308202,-0.5825643},
{-0.3903165,-0.1211926,-0.5864094},
{-0.3890116,-0.1117354,-0.5904617},
{-0.3879256,-0.1026652,-0.5945486},
{-0.3865472,-0.0935873,-0.5987468},
{-0.3851570,-0.0846711,-0.6030142},
{-0.3835240,-0.0759195,-0.6070816},
{-0.3818009,-0.0674267,-0.6110686},
{-0.3796675,-0.0590466,-0.6149181},
{-0.3774663,-0.0514114,-0.6187149},
{-0.3750439,-0.0440027,-0.6219698},
{-0.3725776,-0.0373471,-0.6250169},
{-0.3701709,-0.0311833,-0.6276891},
{-0.3675900,-0.0253825,-0.6302043},
{-0.3647768,-0.0203002,-0.6325115},
{-0.3620252,-0.0155904,-0.6347975},
{-0.3592238,-0.0116384,-0.6369445},
{-0.3566886,-0.0081593,-0.6388589},
{-0.3540713,-0.0053732,-0.6406559},
{-0.3519399,-0.0034710,-0.6423526},
{-0.3498379,-0.0022023,-0.6436292},
{-0.3475530,-0.0012208,-0.6449077},
{-0.3456859,-0.0010862,-0.6458514},
{-0.3435604,-0.0010496,-0.6472333},
{-0.3415755,-0.0013043,-0.6484600},
{-0.3394798,-0.0017274,-0.6498917},
{-0.3375864,-0.0028593,-0.6513542},
{-0.3359185,-0.0038505,-0.6527295},
{-0.3341165,-0.0052114,-0.6541301},
{-0.3325620,-0.0068754,-0.6554084}
};
shoToEeVsWam = {
{-0.3468986,-0.6022078,-0.3905394},
{-0.3475802,-0.6013685,-0.3913341},
{-0.3479679,-0.6000003,-0.3933861},
{-0.3485397,-0.5986690,-0.3946042},
{-0.3489878,-0.5968191,-0.3959901},
{-0.3495806,-0.5946170,-0.3971453},
{-0.3500073,-0.5923277,-0.3981242},
{-0.3507959,-0.5892232,-0.3992237},
{-0.3518790,-0.5861164,-0.4003731},
{-0.3530706,-0.5825562,-0.4013993},
{-0.3542974,-0.5789802,-0.4023485},
{-0.3554366,-0.5751541,-0.4032886},
{-0.3564832,-0.5712218,-0.4039801},
{-0.3576981,-0.5668668,-0.4048528},
{-0.3587736,-0.5623323,-0.4053551},
{-0.3597463,-0.5571292,-0.4062663},
{-0.3611129,-0.5515387,-0.4069385},
{-0.3624126,-0.5457382,-0.4079211},
{-0.3641488,-0.5398446,-0.4089659},
{-0.3660933,-0.5338857,-0.4106527},
{-0.3679524,-0.5285541,-0.4118911},
{-0.3699113,-0.5232135,-0.4136651},
{-0.3718712,-0.5178918,-0.4152171},
{-0.3738949,-0.5126597,-0.4170071},
{-0.3758804,-0.5067749,-0.4189597},
{-0.3778769,-0.5006674,-0.4211181},
{-0.3798329,-0.4941353,-0.4234575},
{-0.3819141,-0.4865192,-0.4266490},
{-0.3842040,-0.4802239,-0.4297646},
{-0.3863942,-0.4728645,-0.4328929},
{-0.3883402,-0.4657387,-0.4362349},
{-0.3904339,-0.4580432,-0.4400408},
{-0.3922908,-0.4501526,-0.4436570},
{-0.3940160,-0.4421029,-0.4474335},
{-0.3955655,-0.4344441,-0.4517058},
{-0.3970780,-0.4258909,-0.4563185},
{-0.3986770,-0.4176034,-0.4609787},
{-0.3996854,-0.4093855,-0.4661475},
{-0.4006465,-0.4015038,-0.4713209},
{-0.4013823,-0.3930571,-0.4759231},
{-0.4019709,-0.3844965,-0.4804098},
{-0.4024080,-0.3759037,-0.4849298},
{-0.4026649,-0.3666549,-0.4895265},
{-0.4031616,-0.3572520,-0.4938275},
{-0.4033508,-0.3471734,-0.4981739},
{-0.4036847,-0.3369815,-0.5030770},
{-0.4040342,-0.3270252,-0.5078518},
{-0.4040369,-0.3165909,-0.5126213},
{-0.4046756,-0.3059004,-0.5170032},
{-0.4050778,-0.2948081,-0.5214412},
{-0.4053240,-0.2834592,-0.5260634},
{-0.4058238,-0.2724091,-0.5302007},
{-0.4068114,-0.2614371,-0.5342965},
{-0.4076315,-0.2500597,-0.5380675},
{-0.4082749,-0.2385374,-0.5421626},
{-0.4085749,-0.2270752,-0.5465380},
{-0.4094156,-0.2153004,-0.5500515},
{-0.4098456,-0.2033260,-0.5537181},
{-0.4098379,-0.1908837,-0.5571815},
{-0.4092801,-0.1786788,-0.5601242},
{-0.4088942,-0.1664721,-0.5634994},
{-0.4084529,-0.1542564,-0.5661883},
{-0.4076094,-0.1422349,-0.5689369},
{-0.4065851,-0.1306609,-0.5718581},
{-0.4056442,-0.1191811,-0.5748220},
{-0.4043383,-0.1076217,-0.5781500},
{-0.4030565,-0.0965663,-0.5814722},
{-0.4015383,-0.0857342,-0.5848999},
{-0.3998966,-0.0749410,-0.5882639},
{-0.3979900,-0.0645539,-0.5912075},
{-0.3962638,-0.0546657,-0.5937948},
{-0.3941467,-0.0450753,-0.5964114},
{-0.3921164,-0.0358733,-0.5989911},
{-0.3898968,-0.0266802,-0.6018993},
{-0.3875467,-0.0177592,-0.6049417},
{-0.3849777,-0.0089622,-0.6082076},
{-0.3822321,-0.0004707,-0.6114560},
{-0.3790569,0.0078789,-0.6147125},
{-0.3759612,0.0154876,-0.6179133},
{-0.3724537,0.0227696,-0.6203749},
{-0.3690709,0.0293262,-0.6226977},
{-0.3658891,0.0353749,-0.6244567},
{-0.3625023,0.0409942,-0.6262645},
{-0.3588154,0.0459629,-0.6279843},
{-0.3551901,0.0505801,-0.6295534},
{-0.3513168,0.0542393,-0.6314076},
{-0.3479881,0.0575890,-0.6328950},
{-0.3444341,0.0600952,-0.6344923},
{-0.3414578,0.0618044,-0.6357722},
{-0.3385707,0.0627071,-0.6363280},
{-0.3358182,0.0634878,-0.6371110},
{-0.3336031,0.0634051,-0.6372363},
{-0.3312343,0.0633255,-0.6381415},
{-0.3289684,0.0628655,-0.6387615},
{-0.3266343,0.0623055,-0.6399338},
{-0.3244723,0.0610494,-0.6411622},
{-0.3226393,0.0599334,-0.6422464},
{-0.3206427,0.0584174,-0.6434419},
{-0.3188533,0.0566626,-0.6446699}
};
xyzEulersCh = {
{0.8000343,-0.0617394,0.2611607},
{0.8011124,-0.0612922,0.2617543},
{0.8022847,-0.0617651,0.2621281},
{0.8034593,-0.0622703,0.2613960},
{0.8056790,-0.0622056,0.2615682},
{0.8061841,-0.0624863,0.2615552},
{0.8078134,-0.0622946,0.2612444},
{0.8095151,-0.0620930,0.2620102},
{0.8054810,-0.0682193,0.2615598},
{0.8050810,-0.0706588,0.2595520},
{0.8025480,-0.0748822,0.2574351},
{0.7995003,-0.0798475,0.2550212},
{0.7953788,-0.0851139,0.2518779},
{0.7907072,-0.0902174,0.2478715},
{0.7861051,-0.0977711,0.2428580},
{0.7804454,-0.1058983,0.2384874},
{0.7751734,-0.1123945,0.2328745},
{0.7703644,-0.1173242,0.2281907},
{0.7652812,-0.1217030,0.2222913},
{0.7592747,-0.1272516,0.2162524},
{0.7527461,-0.1321839,0.2091974},
{0.7441271,-0.1395824,0.2006583},
{0.7368098,-0.1461494,0.1921940},
{0.7291138,-0.1538694,0.1827805},
{0.7212203,-0.1601804,0.1731132},
{0.7123124,-0.1665931,0.1628842},
{0.7034204,-0.1645530,0.1540219},
{0.6942316,-0.1594783,0.1543052},
{0.6842721,-0.1586815,0.1540085},
{0.6748035,-0.1577710,0.1525046},
{0.6639892,-0.1590263,0.1525310},
{0.6526999,-0.1614626,0.1521104},
{0.6424814,-0.1613506,0.1524947},
{0.6327707,-0.1620380,0.1519543},
{0.6225333,-0.1628420,0.1523572},
{0.6112438,-0.1646719,0.1522005},
{0.6009089,-0.1675323,0.1509508},
{0.5909510,-0.1689250,0.1510035},
{0.5791188,-0.1718560,0.1490657},
{0.5672421,-0.1715618,0.1488363},
{0.5588888,-0.1756688,0.1481538},
{0.5621138,-0.1844008,0.1508342},
{0.5538768,-0.1875071,0.1504724},
{0.5456686,-0.1908636,0.1501523},
{0.5370640,-0.1958105,0.1477878},
{0.5294989,-0.1989603,0.1482478},
{0.5225771,-0.2020076,0.1462305},
{0.5153385,-0.2040886,0.1460091},
{0.5092318,-0.2062124,0.1439379},
{0.5027362,-0.2074865,0.1427003},
{0.4965583,-0.2078894,0.1408964},
{0.4901060,-0.2083257,0.1395829},
{0.4839165,-0.2079103,0.1367515},
{0.4788515,-0.2097497,0.1352263},
{0.4723036,-0.2108958,0.1331650},
{0.4666428,-0.2130976,0.1308335},
{0.4598159,-0.2142386,0.1280944},
{0.4536120,-0.2149595,0.1264409},
{0.4571255,-0.2078231,0.1245825},
{0.4484561,-0.2127539,0.1225101},
{0.4399193,-0.2171640,0.1188555},
{0.4320605,-0.2223814,0.1178589},
{0.4257324,-0.2255177,0.1155130},
{0.4192479,-0.2261898,0.1143001},
{0.4137265,-0.2302774,0.1143037},
{0.4078128,-0.2316006,0.1139094},
{0.4022336,-0.2339001,0.1126644},
{0.3971258,-0.2357506,0.1118566},
{0.3917952,-0.2394934,0.1128066},
{0.3792226,-0.2360034,0.1108092},
{0.3772261,-0.2550240,0.1122119},
{0.3740527,-0.2561841,0.1132755},
{0.3693275,-0.2560325,0.1119930},
{0.3637485,-0.2570827,0.1119221},
{0.3587146,-0.2581232,0.1101960},
{0.3543451,-0.2591958,0.1093226},
{0.3485972,-0.2601272,0.1073434},
{0.3442505,-0.2615223,0.1064994},
{0.3403043,-0.2622239,0.1041379},
{0.3368120,-0.2623540,0.1036239},
{0.3322092,-0.2632335,0.1026607},
{0.3287094,-0.2641397,0.1014334},
{0.3240924,-0.2635290,0.0995844},
{0.3201799,-0.2641159,0.0982393},
{0.3160375,-0.2664870,0.0969037},
{0.3108558,-0.2687623,0.0956409},
{0.3058713,-0.2696880,0.0932467},
{0.3002186,-0.2712666,0.0914934},
{0.2963392,-0.2741170,0.0902175},
{0.2913436,-0.2749848,0.0884977},
{0.2865986,-0.2783552,0.0875393},
{0.2818028,-0.2793604,0.0861040},
{0.2763609,-0.2818740,0.0849076},
{0.2722396,-0.2833505,0.0830130},
{0.2681116,-0.2844880,0.0817872},
{0.2636932,-0.2854064,0.0804777},
{0.2600310,-0.2864225,0.0789112},
{0.2567351,-0.2884786,0.0762713},
{0.2534732,-0.2887044,0.0753846}
};
xzxEulersWr = {
{0.8186659,-0.6180858,-1.9335182},
{0.8198673,-0.6244615,-1.9351117},
{0.8256957,-0.6346301,-1.9263968},
{0.8261288,-0.6401406,-1.9273990},
{0.8233794,-0.6430202,-1.9232107},
{0.8259318,-0.6449147,-1.9247268},
{0.8292692,-0.6477382,-1.9308448},
{0.8273271,-0.6494928,-1.9243846},
{0.8285599,-0.6545112,-1.9219240},
{0.8292420,-0.6587106,-1.9190442},
{0.8305135,-0.6640700,-1.9139017},
{0.8354508,-0.6676493,-1.9113164},
{0.8381276,-0.6708390,-1.9059875},
{0.8430500,-0.6759269,-1.9014439},
{0.8468386,-0.6815169,-1.8981783},
{0.8546873,-0.6843169,-1.8886432},
{0.8579648,-0.6899185,-1.8810774},
{0.8622741,-0.6961064,-1.8752246},
{0.8631632,-0.7013121,-1.8665751},
{0.8663951,-0.7066267,-1.8574576},
{0.8664403,-0.7110176,-1.8531622},
{0.8697528,-0.7147599,-1.8479644},
{0.8701132,-0.7182326,-1.8440160},
{0.8747254,-0.7245274,-1.8443252},
{0.8760285,-0.7292136,-1.8386650},
{0.8819169,-0.7346482,-1.8353017},
{0.8875653,-0.7393858,-1.8326710},
{0.8889147,-0.7450091,-1.8244842},
{0.8950144,-0.7535728,-1.8148258},
{0.8907445,-0.7589104,-1.8008421},
{0.8970251,-0.7629970,-1.7989779},
{0.8968302,-0.7704790,-1.7914061},
{0.8983749,-0.7737076,-1.7851129},
{0.9042686,-0.7782356,-1.7869563},
{0.9020036,-0.7815601,-1.7719725},
{0.9143234,-0.7842800,-1.7764720},
{0.9133558,-0.7902242,-1.7690195},
{0.9174436,-0.7939828,-1.7616392},
{0.9212689,-0.7994520,-1.7580068},
{0.9253326,-0.8009292,-1.7591149},
{0.9267475,-0.8032062,-1.7602269},
{0.9266891,-0.8064571,-1.7603240},
{0.9273527,-0.8064994,-1.7567966},
{0.9276349,-0.8082933,-1.7597692},
{0.9312437,-0.8096593,-1.7627437},
{0.9303856,-0.8132287,-1.7548514},
{0.9324879,-0.8169493,-1.7494378},
{0.9334359,-0.8198057,-1.7420772},
{0.9370440,-0.8246901,-1.7429845},
{0.9428864,-0.8263754,-1.7450364},
{0.9401372,-0.8288790,-1.7321040},
{0.9439109,-0.8319719,-1.7303161},
{0.9459128,-0.8376660,-1.7306954},
{0.9462181,-0.8399752,-1.7313915},
{0.9534877,-0.8397375,-1.7328993},
{0.9530198,-0.8419713,-1.7176529},
{0.9487603,-0.8439529,-1.7157159},
{0.9478342,-0.8476489,-1.7137417},
{0.9455251,-0.8480587,-1.7103664},
{0.9489814,-0.8433510,-1.7171233},
{0.9427627,-0.8441628,-1.7064490},
{0.9512726,-0.8422652,-1.7237015},
{0.9509731,-0.8378497,-1.7284072},
{0.9526050,-0.8352186,-1.7317396},
{0.9539266,-0.8317850,-1.7394510},
{0.9512509,-0.8292141,-1.7359985},
{0.9524153,-0.8302671,-1.7418760},
{0.9548450,-0.8295753,-1.7500130},
{0.9539955,-0.8285925,-1.7535695},
{0.9554416,-0.8250034,-1.7674267},
{0.9541362,-0.8192928,-1.7798652},
{0.9529981,-0.8128181,-1.7951517},
{0.9553817,-0.8040380,-1.8135259},
{0.9528112,-0.7980138,-1.8228335},
{0.9540683,-0.7927661,-1.8352900},
{0.9575120,-0.7914171,-1.8441472},
{0.9594531,-0.7896436,-1.8499835},
{0.9645932,-0.7893630,-1.8583628},
{0.9648623,-0.7889884,-1.8622228},
{0.9714958,-0.7843771,-1.8756765},
{0.9757119,-0.7807092,-1.8876177},
{0.9774270,-0.7750518,-1.9012896},
{0.9804966,-0.7710601,-1.9130231},
{0.9853548,-0.7656493,-1.9236889},
{0.9919546,-0.7583447,-1.9382768},
{1.0049835,-0.7545915,-1.9523203},
{1.0121798,-0.7499578,-1.9646555},
{1.0266625,-0.7471871,-1.9811194},
{1.0396587,-0.7409205,-1.9991119},
{1.0493216,-0.7297476,-2.0167463},
{1.0543963,-0.7232151,-2.0298423},
{1.0595745,-0.7123993,-2.0481318},
{1.0647270,-0.7070562,-2.0621791},
{1.0698755,-0.6991613,-2.0770226},
{1.0771184,-0.6961859,-2.0892555},
{1.0828310,-0.6914058,-2.0973891},
{1.0897615,-0.6883595,-2.1107133},
{1.0979484,-0.6856975,-2.1235895},
{1.1073931,-0.6838338,-2.1345519}
};
xyzEulersWr = {
{1.9536563,2.8012111,-2.7028578},
{1.9512654,2.7971524,-2.6961449},
{1.9643755,2.7885749,-2.6976435},
{1.9620841,2.7848252,-2.6923553},
{1.9634141,2.7823538,-2.6943781},
{1.9636499,2.7812979,-2.6912169},
{1.9590046,2.7802057,-2.6824902},
{1.9641276,2.7782603,-2.6877206},
{1.9667953,2.7744407,-2.6863414},
{1.9696467,2.7712391,-2.6859504},
{1.9754356,2.7669893,-2.6870472},
{1.9823913,2.7642546,-2.6868948},
{1.9904843,2.7613349,-2.6902449},
{1.9993475,2.7573103,-2.6911327},
{2.0054062,2.7532059,-2.6900938},
{2.0239521,2.7500043,-2.6988919},
{2.0347841,2.7449970,-2.7034798},
{2.0444379,2.7397969,-2.7057103},
{2.0544481,2.7348493,-2.7123764},
{2.0674330,2.7297558,-2.7198073},
{2.0715638,2.7260362,-2.7219202},
{2.0803030,2.7227186,-2.7257216},
{2.0846284,2.7196913,-2.7282501},
{2.0870365,2.7149823,-2.7232144},
{2.0941487,2.7106927,-2.7273285},
{2.1027417,2.7060591,-2.7279541},
{2.1103735,2.7021837,-2.7279940},
{2.1206201,2.6967537,-2.7353251},
{2.1367856,2.6889015,-2.7428899},
{2.1493344,2.6830271,-2.7595482},
{2.1569389,2.6797093,-2.7593853},
{2.1647202,2.6728486,-2.7657014},
{2.1737920,2.6696479,-2.7730918},
{2.1759674,2.6662617,-2.7671445},
{2.1930285,2.6619381,-2.7884687},
{2.1985212,2.6601368,-2.7795996},
{2.2061050,2.6544353,-2.7876898},
{2.2193219,2.6506511,-2.7972575},
{2.2267340,2.6456615,-2.7998829},
{2.2288773,2.6444731,-2.7971585},
{2.2281489,2.6426479,-2.7938860},
{2.2270870,2.6399617,-2.7916239},
{2.2326503,2.6396018,-2.7975016},
{2.2283118,2.6383945,-2.7913532},
{2.2274036,2.6375138,-2.7855007},
{2.2366161,2.6338255,-2.7964697},
{2.2453481,2.6301196,-2.8034445},
{2.2559667,2.6270285,-2.8144816},
{2.2570271,2.6228896,-2.8099273},
{2.2595040,2.6213327,-2.8054812},
{2.2746151,2.6178971,-2.8271044},
{2.2801928,2.6152446,-2.8283986},
{2.2802203,2.6106667,-2.8241074},
{2.2789287,2.6086824,-2.8214696},
{2.2840709,2.6089953,-2.8188632},
{2.3052575,2.6054164,-2.8460878},
{2.3033657,2.6035766,-2.8485949},
{2.3044704,2.6002958,-2.8502047},
{2.3070411,2.5997031,-2.8564132},
{2.3016668,2.6041899,-2.8462932},
{2.3109305,2.6024844,-2.8662207},
{2.2946031,2.6058481,-2.8344732},
{2.2885518,2.6100602,-2.8283701},
{2.2860202,2.6127230,-2.8237689},
{2.2771151,2.6161853,-2.8120446},
{2.2800557,2.6179783,-2.8198811},
{2.2725233,2.6177361,-2.8086328},
{2.2635047,2.6190930,-2.7946645},
{2.2578570,2.6202637,-2.7890788},
{2.2406892,2.6246325,-2.7676677},
{2.2236317,2.6310153,-2.7506051},
{2.2032939,2.6380473,-2.7305341},
{2.1833785,2.6475166,-2.7083814},
{2.1702297,2.6536762,-2.6988725},
{2.1565915,2.6593836,-2.6847824},
{2.1487421,2.6617421,-2.6730222},
{2.1435936,2.6639416,-2.6662018},
{2.1378105,2.6653285,-2.6547280},
{2.1331540,2.6661933,-2.6496888},
{2.1239486,2.6716962,-2.6354390},
{2.1141216,2.6763911,-2.6228150},
{2.1005084,2.6829617,-2.6101558},
{2.0902611,2.6877667,-2.5992289},
{2.0838375,2.6937425,-2.5909756},
{2.0751768,2.7019811,-2.5799994},
{2.0724334,2.7068919,-2.5677655},
{2.0664621,2.7126426,-2.5581565},
{2.0622139,2.7174490,-2.5433122},
{2.0563228,2.7254634,-2.5303995},
{2.0498056,2.7364720,-2.5238144},
{2.0423113,2.7435355,-2.5175277},
{2.0308417,2.7546034,-2.5109066},
{2.0221791,2.7611580,-2.5033390},
{2.0137812,2.7694023,-2.4981969},
{2.0085574,2.7738786,-2.4908403},
{2.0071533,2.7786705,-2.4888498},
{2.0006069,2.7834695,-2.4811103},
{1.9957609,2.7878565,-2.4737907},
{1.9940268,2.7914550,-2.4672252}
};
xyzEulersWrInDeg = {
{111.9362615,160.4975756,-154.8623472},
{111.7992739,160.2650257,-154.4777245},
{112.5504275,159.7735733,-154.5635844},
{112.4191388,159.5587306,-154.2605976},
{112.4953441,159.4171298,-154.3764933},
{112.5088536,159.3566328,-154.1953714},
{112.2426967,159.2940499,-153.6953649},
{112.5362234,159.1825883,-153.9950485},
{112.6890692,158.9637399,-153.9160267},
{112.8524456,158.7803025,-153.8936210},
{113.1841224,158.5368064,-153.9564624},
{113.5826568,158.3801243,-153.9477347},
{114.0463496,158.2128338,-154.1396783},
{114.5541742,157.9822402,-154.1905431},
{114.9013101,157.7470802,-154.1310206},
{115.9639109,157.5636381,-154.6351158},
{116.5845386,157.2767427,-154.8979811},
{117.1376617,156.9788009,-155.0257791},
{117.7112069,156.6953238,-155.4077184},
{118.4551867,156.4034842,-155.8334766},
{118.6918630,156.1903696,-155.9545417},
{119.1925801,156.0002866,-156.1723436},
{119.4404086,155.8268316,-156.3172156},
{119.5783840,155.5570263,-156.0286940},
{119.9858839,155.3112496,-156.2644139},
{120.4782238,155.0457682,-156.3002556},
{120.9154923,154.8237196,-156.3025406},
{121.5025804,154.5126053,-156.7225833},
{122.4287986,154.0627056,-157.1560123},
{123.1477911,153.7261297,-158.1104629},
{123.5834934,153.5360355,-158.1011333},
{124.0293289,153.1429435,-158.4630153},
{124.5491092,152.9595590,-158.8864535},
{124.6737461,152.7655443,-158.5457023},
{125.6512754,152.5178211,-159.7674898},
{125.9659868,152.4146138,-159.2593277},
{126.4005066,152.0879403,-159.7228616},
{127.1577805,151.8711224,-160.2710495},
{127.5824583,151.5852383,-160.4214749},
{127.7052635,151.5171494,-160.2653739},
{127.6635272,151.4125727,-160.0778783},
{127.6026877,151.2586660,-159.9482673},
{127.9214398,151.2380414,-160.2850356},
{127.6728591,151.1688703,-159.9327591},
{127.6208232,151.1184117,-159.5974324},
{128.1486606,150.9070865,-160.2259101},
{128.6489684,150.6947502,-160.6255361},
{129.2573711,150.5176453,-161.2579189},
{129.3181275,150.2805015,-160.9969730},
{129.4600411,150.1912994,-160.7422309},
{130.3258448,149.9944532,-161.9811495},
{130.6454257,149.8424798,-162.0553001},
{130.6470002,149.5801808,-161.8094332},
{130.5729954,149.4664893,-161.6583001},
{130.8676246,149.4844200,-161.5089651},
{132.0815250,149.2793617,-163.0688214},
{131.9731338,149.1739487,-163.2124658},
{132.0364304,148.9859772,-163.3047024},
{132.1837155,148.9520171,-163.6604211},
{131.8757946,149.2090885,-163.0805880},
{132.4065645,149.1113712,-164.2223482},
{131.4710706,149.3041010,-162.4033489},
{131.1243591,149.5454324,-162.0536692},
{130.9793087,149.6980000,-161.7900385},
{130.4690851,149.8963782,-161.1182880},
{130.6375671,149.9991058,-161.5672853},
{130.2059919,149.9852296,-160.9228047},
{129.6892690,150.0629743,-160.1224784},
{129.3656749,150.1300493,-159.8024454},
{128.3820316,150.3803662,-158.5756762},
{127.4047110,150.7460711,-157.5980635},
{126.2394397,151.1489788,-156.4480772},
{125.0983745,151.6915293,-155.1788259},
{124.3450046,152.0444465,-154.6340059},
{123.5635932,152.3714553,-153.8266986},
{123.1138520,152.5065880,-153.1528888},
{122.8188636,152.6326117,-152.7621095},
{122.4875210,152.7120763,-152.1047098},
{122.2207210,152.7616224,-151.8159877},
{121.6932885,153.0769187,-150.9995326},
{121.1302442,153.3459130,-150.2762296},
{120.3502653,153.7223810,-149.5509139},
{119.7631416,153.9976891,-148.9248438},
{119.3950929,154.3400740,-148.4519686},
{118.8988729,154.8121112,-147.8230773},
{118.7416886,155.0934795,-147.1221232},
{118.3995581,155.4229751,-146.5715706},
{118.1561525,155.6983614,-145.7210555},
{117.8186180,156.1575503,-144.9812132},
{117.4452121,156.7882957,-144.6039132},
{117.0158172,157.1930067,-144.2437099},
{116.3586588,157.8271519,-143.8643515},
{115.8623296,158.2026988,-143.4307600},
{115.3811621,158.6750654,-143.1361373},
{115.0818636,158.9315343,-142.7146373},
{115.0014121,159.2060916,-142.6005883},
{114.6263347,159.4810534,-142.1571505},
{114.3486754,159.7324111,-141.7377655},
{114.2493223,159.9385883,-141.3615919}
};
inPtsRPi = {
{0.3522150,0.5762683,-0.0640925},
{0.3518262,0.5756544,-0.0640436},
{0.3518067,0.5749639,-0.0640147},
{0.3517128,0.5741911,-0.0642949},
{0.3514594,0.5735427,-0.0648403},
{0.3511496,0.5731840,-0.0636252},
{0.3509495,0.5727440,-0.0633849},
{0.3507364,0.5725852,-0.0625689},
{0.3527323,0.5715629,-0.0575618},
{0.3535349,0.5709614,-0.0559238},
{0.3549441,0.5703871,-0.0526126},
{0.3567763,0.5696978,-0.0486079},
{0.3585709,0.5691879,-0.0442635},
{0.3602337,0.5688984,-0.0397885},
{0.3633448,0.5679254,-0.0351691},
{0.3665274,0.5670413,-0.0288761},
{0.3688889,0.5666078,-0.0234593},
{0.3704821,0.5667043,-0.0180559},
{0.3715090,0.5670441,-0.0136175},
{0.3727690,0.5670491,-0.0087263},
{0.3737521,0.5673109,-0.0043667},
{0.3755431,0.5668518,0.0010546},
{0.3773023,0.5665532,0.0051056},
{0.3795912,0.5658294,0.0090674},
{0.3810872,0.5656685,0.0127674},
{0.3825948,0.5654801,0.0169262},
{0.3794131,0.5684872,0.0210268},
{0.3737948,0.5726065,0.0309261},
{0.3702782,0.5751177,0.0415463},
{0.3666151,0.5776483,0.0514013},
{0.3637827,0.5792616,0.0631572},
{0.3613246,0.5807606,0.0752515},
{0.3572293,0.5831765,0.0870103},
{0.3538686,0.5852098,0.0976829},
{0.3495816,0.5872733,0.1090419},
{0.3459792,0.5888440,0.1214968},
{0.3430606,0.5901476,0.1324510},
{0.3389440,0.5920787,0.1432567},
{0.3355871,0.5932701,0.1550293},
{0.3300918,0.5954739,0.1672530},
{0.3279509,0.5964845,0.1773544},
{0.3294840,0.5971902,0.1819965},
{0.3263201,0.5986264,0.1924442},
{0.3232928,0.5998548,0.2032526},
{0.3217903,0.6003301,0.2138390},
{0.3181289,0.6017181,0.2248008},
{0.3154645,0.6029578,0.2343382},
{0.3114679,0.6045275,0.2451783},
{0.3082845,0.6059431,0.2548154},
{0.3040385,0.6073234,0.2654173},
{0.2995947,0.6096919,0.2757127},
{0.2951080,0.6112140,0.2860636},
{0.2910324,0.6128460,0.2955446},
{0.2878501,0.6137341,0.3053915},
{0.2842130,0.6145839,0.3161553},
{0.2813826,0.6158632,0.3265713},
{0.2782319,0.6167134,0.3377890},
{0.2748862,0.6179036,0.3487206},
{0.2683022,0.6245610,0.3526996},
{0.2673735,0.6236615,0.3658298},
{0.2669277,0.6234350,0.3780162},
{0.2659128,0.6223474,0.3909769},
{0.2647938,0.6227139,0.4018348},
{0.2617260,0.6240005,0.4125985},
{0.2599116,0.6243065,0.4237449},
{0.2565035,0.6256453,0.4344369},
{0.2545405,0.6267220,0.4445528},
{0.2518256,0.6281157,0.4544934},
{0.2490792,0.6287894,0.4650949},
{0.2421808,0.6287319,0.4788428},
{0.2499884,0.6257737,0.4884685},
{0.2461878,0.6281552,0.4969899},
{0.2430647,0.6303252,0.5054832},
{0.2392550,0.6316865,0.5148779},
{0.2365043,0.6332555,0.5235896},
{0.2332009,0.6351357,0.5319130},
{0.2309046,0.6364086,0.5405886},
{0.2279400,0.6380142,0.5487458},
{0.2268899,0.6401702,0.5556284},
{0.2236512,0.6424502,0.5629656},
{0.2216665,0.6438940,0.5704274},
{0.2204924,0.6457657,0.5768369},
{0.2188913,0.6475192,0.5833553},
{0.2176131,0.6491722,0.5894419},
{0.2184224,0.6499122,0.5953040},
{0.2181730,0.6501224,0.6019408},
{0.2183049,0.6506623,0.6075776},
{0.2185054,0.6504224,0.6135426},
{0.2198421,0.6506547,0.6182097},
{0.2195451,0.6505815,0.6232253},
{0.2205988,0.6497788,0.6279924},
{0.2210503,0.6494188,0.6319440},
{0.2216396,0.6481493,0.6362425},
{0.2226019,0.6477278,0.6392499},
{0.2223997,0.6473715,0.6421938},
{0.2224833,0.6468501,0.6449609},
{0.2222672,0.6465846,0.6473887},
{0.2242668,0.6460950,0.6489399},
{0.2236951,0.6461329,0.6506155}
};
inPtsRTh = {
{0.3598631,0.6166435,-0.0986922},
{0.3598093,0.6160405,-0.0986373},
{0.3610979,0.6157986,-0.0987528},
{0.3614263,0.6150998,-0.0990636},
{0.3617134,0.6142652,-0.0994098},
{0.3618783,0.6136482,-0.0982518},
{0.3621233,0.6131899,-0.0978275},
{0.3626928,0.6125650,-0.0968388},
{0.3656570,0.6114969,-0.0915688},
{0.3672877,0.6106350,-0.0896536},
{0.3696287,0.6097940,-0.0858626},
{0.3724652,0.6088436,-0.0814882},
{0.3752195,0.6081000,-0.0767607},
{0.3778666,0.6075074,-0.0718109},
{0.3818618,0.6062107,-0.0666326},
{0.3864619,0.6047662,-0.0599272},
{0.3899673,0.6041247,-0.0541708},
{0.3926163,0.6039243,-0.0482599},
{0.3945413,0.6039853,-0.0435635},
{0.3968198,0.6036380,-0.0384481},
{0.3983133,0.6036781,-0.0338357},
{0.4007650,0.6028742,-0.0282338},
{0.4029326,0.6022798,-0.0240999},
{0.4056535,0.6013157,-0.0201554},
{0.4075857,0.6008446,-0.0164321},
{0.4095982,0.6004144,-0.0121619},
{0.4065951,0.6032146,-0.0080166},
{0.4017153,0.6071820,0.0022160},
{0.3992263,0.6094368,0.0133897},
{0.3963524,0.6117278,0.0236818},
{0.3942132,0.6131073,0.0360924},
{0.3925069,0.6142488,0.0485354},
{0.3890082,0.6162714,0.0606649},
{0.3860272,0.6181024,0.0716745},
{0.3826310,0.6198706,0.0836976},
{0.3795038,0.6211361,0.0964375},
{0.3771301,0.6221139,0.1076699},
{0.3735898,0.6236201,0.1189808},
{0.3707724,0.6245199,0.1310589},
{0.3655123,0.6266602,0.1435335},
{0.3636109,0.6274395,0.1537961},
{0.3656510,0.6273724,0.1582768},
{0.3629026,0.6284293,0.1689259},
{0.3600760,0.6294417,0.1796968},
{0.3588271,0.6295121,0.1901377},
{0.3556699,0.6302592,0.2013468},
{0.3535364,0.6308558,0.2108263},
{0.3500571,0.6316529,0.2218054},
{0.3472182,0.6326050,0.2313548},
{0.3434782,0.6334865,0.2416447},
{0.3394584,0.6346583,0.2514908},
{0.3352178,0.6355342,0.2619013},
{0.3311197,0.6365834,0.2712850},
{0.3280729,0.6369501,0.2810040},
{0.3248381,0.6371096,0.2913140},
{0.3225964,0.6370946,0.3014215},
{0.3194407,0.6372275,0.3120419},
{0.3161593,0.6376366,0.3225231},
{0.3094931,0.6434769,0.3257856},
{0.3084847,0.6419339,0.3383074},
{0.3081975,0.6406554,0.3497749},
{0.3067862,0.6391674,0.3622462},
{0.3054168,0.6389290,0.3723463},
{0.3020375,0.6395734,0.3825627},
{0.3001045,0.6393205,0.3930145},
{0.2966003,0.6398160,0.4031563},
{0.2942394,0.6402079,0.4126551},
{0.2911817,0.6410116,0.4219714},
{0.2882768,0.6410622,0.4321440},
{0.2807499,0.6410699,0.4450395},
{0.2880075,0.6370916,0.4539446},
{0.2835376,0.6392294,0.4615893},
{0.2793770,0.6410657,0.4689386},
{0.2748653,0.6420390,0.4776426},
{0.2714716,0.6432370,0.4854734},
{0.2676975,0.6445603,0.4932341},
{0.2649060,0.6452611,0.5014215},
{0.2616518,0.6463571,0.5093244},
{0.2600266,0.6477548,0.5155806},
{0.2563500,0.6496070,0.5224038},
{0.2537628,0.6505910,0.5293325},
{0.2518075,0.6520706,0.5350254},
{0.2495715,0.6535022,0.5409350},
{0.2476497,0.6546241,0.5465917},
{0.2476694,0.6550447,0.5523178},
{0.2471320,0.6547044,0.5583646},
{0.2465488,0.6548252,0.5637161},
{0.2463116,0.6541389,0.5691343},
{0.2468717,0.6538957,0.5735093},
{0.2460547,0.6537018,0.5778779},
{0.2464610,0.6526221,0.5822413},
{0.2460912,0.6523975,0.5857486},
{0.2461764,0.6512672,0.5899589},
{0.2466030,0.6509839,0.5926212},
{0.2460805,0.6506266,0.5952987},
{0.2458701,0.6500285,0.5979153},
{0.2452374,0.6497988,0.6001597},
{0.2468051,0.6492596,0.6013854},
{0.2459580,0.6491809,0.6029148}
};
inPtsRW = {
{0.3706926,0.6249511,-0.0227725},
{0.3699933,0.6241895,-0.0226456},
{0.3698531,0.6233880,-0.0225641},
{0.3696120,0.6225099,-0.0228564},
{0.3693524,0.6217956,-0.0233797},
{0.3687303,0.6213935,-0.0222177},
{0.3681008,0.6211837,-0.0219466},
{0.3676369,0.6209602,-0.0211437},
{0.3694226,0.6195775,-0.0158159},
{0.3699760,0.6189209,-0.0140514},
{0.3711391,0.6180987,-0.0104175},
{0.3726990,0.6173405,-0.0061527},
{0.3742914,0.6166465,-0.0015803},
{0.3756276,0.6161700,0.0032307},
{0.3784498,0.6149508,0.0083010},
{0.3814174,0.6138404,0.0147989},
{0.3834987,0.6133145,0.0205626},
{0.3846247,0.6133242,0.0261886},
{0.3855291,0.6135638,0.0307484},
{0.3868658,0.6134628,0.0357821},
{0.3879701,0.6136169,0.0402778},
{0.3901527,0.6129635,0.0459109},
{0.3923632,0.6124764,0.0500099},
{0.3950323,0.6115507,0.0539703},
{0.3970719,0.6111249,0.0576256},
{0.3990739,0.6107874,0.0617592},
{0.3959109,0.6138683,0.0657886},
{0.3897044,0.6180270,0.0758186},
{0.3857683,0.6204215,0.0867763},
{0.3820597,0.6227450,0.0969061},
{0.3789294,0.6244428,0.1089739},
{0.3763109,0.6254850,0.1212770},
{0.3720223,0.6277527,0.1331828},
{0.3684467,0.6298111,0.1439368},
{0.3644530,0.6316603,0.1557752},
{0.3607379,0.6331947,0.1681767},
{0.3581284,0.6340108,0.1793615},
{0.3543061,0.6356263,0.1904383},
{0.3512721,0.6363462,0.2024458},
{0.3459011,0.6383246,0.2148123},
{0.3441707,0.6390680,0.2249679},
{0.3462769,0.6397933,0.2293153},
{0.3436204,0.6410914,0.2399081},
{0.3409161,0.6421627,0.2507431},
{0.3398731,0.6424762,0.2611840},
{0.3366073,0.6435360,0.2723052},
{0.3345069,0.6446666,0.2817823},
{0.3308980,0.6460949,0.2925377},
{0.3280940,0.6476776,0.3019546},
{0.3243063,0.6493798,0.3120949},
{0.3203989,0.6513727,0.3218376},
{0.3162902,0.6531791,0.3319775},
{0.3125493,0.6550705,0.3412048},
{0.3099791,0.6562402,0.3505922},
{0.3071640,0.6577127,0.3608719},
{0.3052455,0.6587492,0.3706576},
{0.3028004,0.6596587,0.3813423},
{0.3000181,0.6610177,0.3917993},
{0.2940145,0.6684643,0.3947104},
{0.2940266,0.6676384,0.4069288},
{0.2946842,0.6669228,0.4186353},
{0.2942650,0.6662277,0.4308963},
{0.2942119,0.6666631,0.4409020},
{0.2918951,0.6679566,0.4509010},
{0.2910811,0.6683011,0.4611732},
{0.2886562,0.6693749,0.4711492},
{0.2873874,0.6702986,0.4805175},
{0.2854426,0.6716067,0.4896114},
{0.2836267,0.6720220,0.4996259},
{0.2772246,0.6718384,0.5126253},
{0.2865880,0.6680512,0.5213990},
{0.2835735,0.6702320,0.5288331},
{0.2811951,0.6721843,0.5359664},
{0.2782141,0.6731429,0.5445085},
{0.2762955,0.6744138,0.5521256},
{0.2736458,0.6760544,0.5596779},
{0.2720230,0.6769508,0.5674850},
{0.2696258,0.6783441,0.5748617},
{0.2691239,0.6800604,0.5808764},
{0.2663501,0.6822676,0.5871655},
{0.2647205,0.6834698,0.5937154},
{0.2639228,0.6851237,0.5991440},
{0.2625208,0.6866559,0.6046974},
{0.2614608,0.6880803,0.6099430},
{0.2626134,0.6886044,0.6148898},
{0.2624734,0.6886217,0.6206110},
{0.2626265,0.6889184,0.6254783},
{0.2626977,0.6885229,0.6305887},
{0.2639352,0.6884762,0.6343589},
{0.2637977,0.6882886,0.6384335},
{0.2647671,0.6870355,0.6426523},
{0.2652208,0.6864970,0.6459492},
{0.2658030,0.6849683,0.6499771},
{0.2668786,0.6843870,0.6524869},
{0.2666236,0.6838768,0.6551875},
{0.2667187,0.6830912,0.6577244},
{0.2663210,0.6826206,0.6599032},
{0.2682083,0.6818836,0.6610863},
{0.2674266,0.6817833,0.6625763}
};
inPtsRLA = {
{0.3485557,0.6890722,0.0643373},
{0.3478801,0.6886202,0.0641771},
{0.3475927,0.6881435,0.0638881},
{0.3472580,0.6877371,0.0632238},
{0.3466549,0.6875326,0.0620901},
{0.3456001,0.6874135,0.0626635},
{0.3443447,0.6878206,0.0619428},
{0.3430361,0.6881558,0.0620513},
{0.3442948,0.6869386,0.0669052},
{0.3443224,0.6868697,0.0679972},
{0.3449088,0.6864566,0.0711022},
{0.3459656,0.6859288,0.0747630},
{0.3469104,0.6854057,0.0789084},
{0.3477180,0.6851393,0.0831595},
{0.3500619,0.6841801,0.0875440},
{0.3523290,0.6831402,0.0933683},
{0.3537823,0.6828891,0.0983242},
{0.3541807,0.6834336,0.1031671},
{0.3546054,0.6843482,0.1069371},
{0.3559932,0.6848093,0.1116065},
{0.3574369,0.6855445,0.1158256},
{0.3603153,0.6851228,0.1212414},
{0.3631407,0.6850635,0.1252421},
{0.3669661,0.6839873,0.1294919},
{0.3699209,0.6838066,0.1331809},
{0.3729472,0.6836732,0.1371630},
{0.3701166,0.6868923,0.1408637},
{0.3630586,0.6914218,0.1500821},
{0.3588769,0.6941978,0.1605165},
{0.3548775,0.6970629,0.1700465},
{0.3515743,0.6989317,0.1815978},
{0.3491387,0.7002480,0.1935389},
{0.3445163,0.7026743,0.2049272},
{0.3411072,0.7048851,0.2154165},
{0.3370969,0.7069766,0.2271389},
{0.3337885,0.7084127,0.2396464},
{0.3319109,0.7095197,0.2508797},
{0.3287307,0.7111675,0.2621250},
{0.3266568,0.7118111,0.2743924},
{0.3216638,0.7134551,0.2870501},
{0.3206168,0.7141200,0.2973716},
{0.3239100,0.7158598,0.3010773},
{0.3219160,0.7171771,0.3116283},
{0.3200189,0.7184754,0.3224365},
{0.3201453,0.7189816,0.3327542},
{0.3177580,0.7203718,0.3435491},
{0.3169091,0.7220547,0.3526534},
{0.3140797,0.7240102,0.3628756},
{0.3123949,0.7262279,0.3716195},
{0.3093064,0.7285977,0.3812665},
{0.3063741,0.7313272,0.3902829},
{0.3032252,0.7339513,0.3996792},
{0.3006599,0.7368047,0.4082379},
{0.2994387,0.7389534,0.4168228},
{0.2979312,0.7408365,0.4261069},
{0.2975503,0.7425934,0.4349629},
{0.2963893,0.7442115,0.4445459},
{0.2947929,0.7462938,0.4539789},
{0.2895316,0.7551089,0.4549502},
{0.2908774,0.7546776,0.4669445},
{0.2932458,0.7543408,0.4780164},
{0.2942916,0.7539701,0.4898574},
{0.2957476,0.7548434,0.4992898},
{0.2947094,0.7564925,0.5087516},
{0.2955220,0.7572360,0.5183582},
{0.2945114,0.7587327,0.5276674},
{0.2950352,0.7600063,0.5362933},
{0.2948323,0.7615011,0.5446957},
{0.2947012,0.7621209,0.5541720},
{0.2892860,0.7617548,0.5672035},
{0.3016146,0.7577885,0.5755624},
{0.3001192,0.7600732,0.5824661},
{0.2993571,0.7620125,0.5892725},
{0.2980097,0.7628780,0.5973114},
{0.2978372,0.7640896,0.6043412},
{0.2968519,0.7655829,0.6112169},
{0.2969683,0.7662816,0.6184134},
{0.2960948,0.7676745,0.6250618},
{0.2971549,0.7694320,0.6300955},
{0.2955038,0.7715767,0.6358187},
{0.2951385,0.7727079,0.6417542},
{0.2953294,0.7743594,0.6465339},
{0.2948860,0.7759135,0.6516012},
{0.2946254,0.7773081,0.6563520},
{0.2967995,0.7777259,0.6607979},
{0.2975026,0.7774495,0.6663202},
{0.2983945,0.7776668,0.6709433},
{0.2991493,0.7769868,0.6760507},
{0.3011475,0.7767886,0.6796359},
{0.3010271,0.7763448,0.6840485},
{0.3024947,0.7749025,0.6884025},
{0.3030330,0.7742269,0.6920687},
{0.3040398,0.7722656,0.6965414},
{0.3053407,0.7714285,0.6993826},
{0.3055161,0.7705659,0.7023990},
{0.3058502,0.7695309,0.7054121},
{0.3056469,0.7687170,0.7079602},
{0.3079371,0.7676267,0.7094899},
{0.3073677,0.7671107,0.7113246}
};
inPtsREl = {
{0.3072970,0.7688219,0.1468040},
{0.3062253,0.7689149,0.1460731},
{0.3059291,0.7688389,0.1453671},
{0.3057065,0.7689059,0.1441175},
{0.3050569,0.7693376,0.1424610},
{0.3037342,0.7696401,0.1423351},
{0.3022589,0.7704948,0.1409215},
{0.3003758,0.7715135,0.1399418},
{0.3016239,0.7706077,0.1443899},
{0.3013730,0.7712267,0.1445912},
{0.3017988,0.7712684,0.1471261},
{0.3026750,0.7712479,0.1501844},
{0.3035243,0.7711571,0.1538834},
{0.3041907,0.7712263,0.1576662},
{0.3066943,0.7705199,0.1617228},
{0.3089885,0.7698240,0.1670988},
{0.3103588,0.7699578,0.1715640},
{0.3105312,0.7708539,0.1755877},
{0.3111099,0.7721383,0.1789903},
{0.3128782,0.7730787,0.1831837},
{0.3147182,0.7741883,0.1870955},
{0.3185911,0.7741214,0.1927712},
{0.3226106,0.7745129,0.1968455},
{0.3278228,0.7743024,0.2007863},
{0.3321120,0.7746330,0.2045949},
{0.3366546,0.7747047,0.2088914},
{0.3343398,0.7782038,0.2127052},
{0.3263916,0.7831697,0.2214154},
{0.3220715,0.7856893,0.2312428},
{0.3178842,0.7887845,0.2403411},
{0.3147163,0.7908129,0.2514731},
{0.3124911,0.7925120,0.2631872},
{0.3080342,0.7951782,0.2742018},
{0.3050434,0.7977000,0.2843911},
{0.3014498,0.8000269,0.2959692},
{0.2988031,0.8016536,0.3087311},
{0.2978438,0.8029105,0.3202181},
{0.2955135,0.8046542,0.3317904},
{0.2945999,0.8052136,0.3445771},
{0.2901911,0.8068430,0.3577762},
{0.2905751,0.8077716,0.3683030},
{0.2956831,0.8105710,0.3711429},
{0.2947390,0.8121756,0.3818045},
{0.2938906,0.8135824,0.3926081},
{0.2952036,0.8145618,0.4034131},
{0.2937987,0.8164258,0.4142959},
{0.2942807,0.8184335,0.4231972},
{0.2925572,0.8209455,0.4330327},
{0.2922955,0.8237414,0.4412866},
{0.2907098,0.8268356,0.4502608},
{0.2889993,0.8303371,0.4584432},
{0.2870788,0.8334910,0.4670502},
{0.2859940,0.8369680,0.4745825},
{0.2861609,0.8399660,0.4821951},
{0.2863537,0.8425502,0.4904990},
{0.2875720,0.8450340,0.4983179},
{0.2880407,0.8474344,0.5068134},
{0.2881161,0.8502513,0.5149312},
{0.2838650,0.8604912,0.5135425},
{0.2871044,0.8606412,0.5246723},
{0.2913945,0.8607768,0.5350404},
{0.2943780,0.8607874,0.5461963},
{0.2976772,0.8621759,0.5547387},
{0.2981815,0.8641735,0.5633787},
{0.3009304,0.8652198,0.5720658},
{0.3016849,0.8670255,0.5804677},
{0.3041397,0.8685308,0.5881987},
{0.3058698,0.8702738,0.5956781},
{0.3078360,0.8709497,0.6042812},
{0.3036988,0.8705545,0.6172321},
{0.3198194,0.8662863,0.6248105},
{0.3200400,0.8687374,0.6309238},
{0.3209407,0.8705704,0.6368918},
{0.3212801,0.8713950,0.6443169},
{0.3229696,0.8724476,0.6505854},
{0.3237982,0.8738160,0.6566662},
{0.3256361,0.8744265,0.6629011},
{0.3266116,0.8756690,0.6686711},
{0.3294871,0.8772596,0.6726715},
{0.3292708,0.8794274,0.6773675},
{0.3301930,0.8804245,0.6824890},
{0.3317171,0.8819855,0.6863198},
{0.3322318,0.8834470,0.6905001},
{0.3330099,0.8847905,0.6945430},
{0.3364284,0.8850155,0.6983978},
{0.3381435,0.8844871,0.7036175},
{0.3398866,0.8845221,0.7077103},
{0.3415018,0.8837020,0.7126855},
{0.3443382,0.8831357,0.7161253},
{0.3447746,0.8825716,0.7203448},
{0.3468977,0.8809141,0.7248477},
{0.3477358,0.8799808,0.7286074},
{0.3492753,0.8777597,0.7333885},
{0.3510457,0.8766595,0.7363426},
{0.3515932,0.8756267,0.7398112},
{0.3522490,0.8741862,0.7431212},
{0.3524786,0.8730724,0.7460133},
{0.3554047,0.8716623,0.7478412},
{0.3549737,0.8709086,0.7501406}
};
inPtsRUA = {
{0.3937291,0.8986110,0.2033738},
{0.3933475,0.8984414,0.2025557},
{0.3936412,0.8978836,0.2018034},
{0.3941923,0.8974583,0.2004090},
{0.3943520,0.8974697,0.1982731},
{0.3938708,0.8972731,0.1981892},
{0.3936726,0.8974596,0.1966559},
{0.3931177,0.8978046,0.1953793},
{0.3962603,0.8953715,0.2005755},
{0.3978842,0.8947620,0.2006380},
{0.4000192,0.8936385,0.2032559},
{0.4026996,0.8919919,0.2065699},
{0.4055715,0.8904828,0.2104172},
{0.4083402,0.8889808,0.2143240},
{0.4134109,0.8863179,0.2183626},
{0.4184264,0.8833118,0.2241359},
{0.4226213,0.8810955,0.2283738},
{0.4254208,0.8798829,0.2323817},
{0.4283357,0.8790179,0.2352335},
{0.4323700,0.8778664,0.2388775},
{0.4363370,0.8771843,0.2418949},
{0.4422765,0.8750645,0.2467085},
{0.4484029,0.8735963,0.2494720},
{0.4561316,0.8712339,0.2520400},
{0.4630523,0.8693696,0.2539847},
{0.4703006,0.8671917,0.2563437},
{0.4698270,0.8692029,0.2582414},
{0.4629678,0.8726502,0.2671297},
{0.4597076,0.8738675,0.2773947},
{0.4568306,0.8753210,0.2865519},
{0.4548173,0.8757868,0.2989966},
{0.4540099,0.8752239,0.3109405},
{0.4508536,0.8762340,0.3222284},
{0.4492160,0.8769370,0.3319453},
{0.4469116,0.8774020,0.3431845},
{0.4453793,0.8770901,0.3554308},
{0.4456151,0.8764726,0.3662007},
{0.4441372,0.8765163,0.3769867},
{0.4441026,0.8753174,0.3891245},
{0.4405470,0.8753656,0.4017318},
{0.4422111,0.8741436,0.4112469},
{0.4490434,0.8737084,0.4127917},
{0.4493848,0.8726258,0.4227045},
{0.4499278,0.8712517,0.4326962},
{0.4528784,0.8689185,0.4421843},
{0.4527474,0.8676194,0.4521425},
{0.4545369,0.8667182,0.4596745},
{0.4538916,0.8661430,0.4685495},
{0.4545349,0.8661053,0.4754017},
{0.4540084,0.8663787,0.4828618},
{0.4531495,0.8674071,0.4895237},
{0.4519014,0.8682304,0.4966047},
{0.4512334,0.8696922,0.5022795},
{0.4518080,0.8704580,0.5081102},
{0.4522557,0.8708027,0.5145096},
{0.4538701,0.8709934,0.5204530},
{0.4545460,0.8711555,0.5271236},
{0.4546917,0.8717086,0.5333987},
{0.4504625,0.8806398,0.5297275},
{0.4538959,0.8776059,0.5390336},
{0.4582164,0.8748037,0.5470565},
{0.4611014,0.8716669,0.5568079},
{0.4643908,0.8702679,0.5634378},
{0.4648592,0.8700778,0.5705161},
{0.4675073,0.8684808,0.5778377},
{0.4680135,0.8681374,0.5849578},
{0.4704570,0.8673077,0.5909387},
{0.4717776,0.8669258,0.5968499},
{0.4733496,0.8652807,0.6041947},
{0.4687412,0.8639358,0.6156201},
{0.4841826,0.8547929,0.6218157},
{0.4838306,0.8552941,0.6268931},
{0.4842729,0.8556152,0.6315218},
{0.4841822,0.8546008,0.6381362},
{0.4853327,0.8538332,0.6432452},
{0.4856583,0.8534540,0.6483550},
{0.4870051,0.8522541,0.6535046},
{0.4873623,0.8515400,0.6586723},
{0.4895284,0.8513915,0.6614349},
{0.4886217,0.8518391,0.6656388},
{0.4890330,0.8511455,0.6702366},
{0.4900189,0.8510378,0.6736550},
{0.4900330,0.8511368,0.6773793},
{0.4903503,0.8510612,0.6810009},
{0.4931657,0.8496632,0.6846788},
{0.4943675,0.8477469,0.6899320},
{0.4958016,0.8468410,0.6937114},
{0.4970263,0.8448765,0.6987123},
{0.4995858,0.8431858,0.7022281},
{0.4998851,0.8417978,0.7069247},
{0.5018767,0.8391445,0.7117354},
{0.5026613,0.8375719,0.7156033},
{0.5038359,0.8344237,0.7208140},
{0.5053895,0.8328236,0.7237304},
{0.5056888,0.8311548,0.7273935},
{0.5061595,0.8293033,0.7307335},
{0.5061568,0.8277189,0.7341157},
{0.5089021,0.8257061,0.7359484},
{0.5084887,0.8246170,0.7387078}
};
inPtsRSh = {
{0.5258723,0.9744899,0.2026314},
{0.5256754,0.9743089,0.2019027},
{0.5264408,0.9733252,0.2011262},
{0.5274547,0.9723279,0.1995003},
{0.5281901,0.9716332,0.1973699},
{0.5283663,0.9707686,0.1972997},
{0.5286774,0.9702970,0.1956511},
{0.5288403,0.9698963,0.1944009},
{0.5329140,0.9660764,0.1997806},
{0.5354069,0.9643465,0.1994501},
{0.5386612,0.9617540,0.2018809},
{0.5424053,0.9587115,0.2050097},
{0.5462807,0.9556053,0.2086133},
{0.5501635,0.9525387,0.2120739},
{0.5565713,0.9479649,0.2155002},
{0.5628588,0.9430931,0.2208222},
{0.5680964,0.9391389,0.2243419},
{0.5718712,0.9360910,0.2275732},
{0.5757272,0.9335493,0.2291095},
{0.5806895,0.9303267,0.2313399},
{0.5853885,0.9276036,0.2329973},
{0.5923272,0.9232484,0.2363314},
{0.5993554,0.9195084,0.2373415},
{0.6079231,0.9149484,0.2378187},
{0.6154621,0.9111705,0.2375741},
{0.6231765,0.9070629,0.2375303},
{0.6228952,0.9085796,0.2372230},
{0.6162491,0.9117760,0.2458073},
{0.6133599,0.9121760,0.2557476},
{0.6109090,0.9125988,0.2641997},
{0.6096217,0.9114413,0.2757526},
{0.6095570,0.9093825,0.2873458},
{0.6069935,0.9091031,0.2983950},
{0.6059647,0.9082682,0.3076592},
{0.6043427,0.9076661,0.3190963},
{0.6032926,0.9056489,0.3311324},
{0.6041021,0.9030021,0.3411206},
{0.6031836,0.9013397,0.3514661},
{0.6038766,0.8981531,0.3629547},
{0.6008934,0.8969717,0.3751805},
{0.6030556,0.8934089,0.3838109},
{0.6105154,0.8896218,0.3846186},
{0.6111344,0.8867183,0.3937119},
{0.6119637,0.8834999,0.4028934},
{0.6151338,0.8790715,0.4110007},
{0.6152451,0.8761077,0.4203179},
{0.6171829,0.8732935,0.4264887},
{0.6168359,0.8709309,0.4346174},
{0.6178069,0.8688744,0.4400207},
{0.6171373,0.8672277,0.4467225},
{0.6162852,0.8661902,0.4522391},
{0.6151493,0.8650449,0.4584389},
{0.6143814,0.8645941,0.4628268},
{0.6150547,0.8628203,0.4677787},
{0.6154716,0.8610397,0.4731810},
{0.6169518,0.8588667,0.4780049},
{0.6174671,0.8568745,0.4836379},
{0.6175760,0.8552793,0.4889668},
{0.6130749,0.8626183,0.4842625},
{0.6161613,0.8571832,0.4926019},
{0.6199477,0.8521718,0.4991840},
{0.6224169,0.8466977,0.5079460},
{0.6250562,0.8432396,0.5131372},
{0.6250403,0.8414333,0.5188617},
{0.6271101,0.8375916,0.5254313},
{0.6270347,0.8354896,0.5314526},
{0.6287233,0.8328069,0.5364761},
{0.6295399,0.8306005,0.5417224},
{0.6306584,0.8268790,0.5487123},
{0.6258054,0.8251289,0.5593294},
{0.6401433,0.8118293,0.5651505},
{0.6395479,0.8108009,0.5699607},
{0.6393727,0.8100750,0.5736642},
{0.6387846,0.8080056,0.5796320},
{0.6394001,0.8061894,0.5840035},
{0.6392356,0.8046167,0.5886379},
{0.6401031,0.8024578,0.5929990},
{0.6399579,0.8005433,0.5977902},
{0.6415928,0.7993393,0.6000421},
{0.6405198,0.7987158,0.6042651},
{0.6405653,0.7969945,0.6087218},
{0.6411663,0.7958563,0.6119274},
{0.6408482,0.7952273,0.6152889},
{0.6408507,0.7940807,0.6190944},
{0.6431416,0.7914990,0.6223441},
{0.6440060,0.7884384,0.6276318},
{0.6449268,0.7865503,0.6313873},
{0.6458472,0.7837838,0.6362791},
{0.6481076,0.7810924,0.6399191},
{0.6482525,0.7792468,0.6446335},
{0.6497766,0.7755736,0.6498043},
{0.6504628,0.7736476,0.6538745},
{0.6515799,0.7701161,0.6591342},
{0.6530219,0.7679411,0.6623319},
{0.6533073,0.7660196,0.6662769},
{0.6538169,0.7640106,0.6700834},
{0.6539708,0.7622777,0.6736597},
{0.6565129,0.7599259,0.6755304},
{0.6562141,0.7589065,0.6785277}
};
inPtsRCh = {
{0.4834035,0.9118117,0.0924676},
{0.4832358,0.9112235,0.0916080},
{0.4839080,0.9102523,0.0907773},
{0.4847163,0.9091947,0.0892654},
{0.4853663,0.9083041,0.0869859},
{0.4855198,0.9074939,0.0868101},
{0.4858037,0.9067220,0.0851468},
{0.4860707,0.9059414,0.0837784},
{0.4899409,0.9033817,0.0887282},
{0.4920013,0.9017397,0.0886135},
{0.4947616,0.8997110,0.0909218},
{0.4978705,0.8974186,0.0939164},
{0.5010924,0.8951036,0.0973503},
{0.5040006,0.8929550,0.1007875},
{0.5091578,0.8895699,0.1041667},
{0.5142708,0.8860437,0.1092847},
{0.5182900,0.8831180,0.1129035},
{0.5210905,0.8807896,0.1161025},
{0.5238542,0.8786964,0.1180563},
{0.5275209,0.8760455,0.1205849},
{0.5308599,0.8737345,0.1226507},
{0.5357959,0.8703760,0.1263702},
{0.5408444,0.8672085,0.1280638},
{0.5470786,0.8634282,0.1295000},
{0.5523322,0.8601926,0.1301528},
{0.5576886,0.8569187,0.1312716},
{0.5558470,0.8583078,0.1318995},
{0.5494578,0.8612415,0.1406166},
{0.5464883,0.8617699,0.1505309},
{0.5437457,0.8622478,0.1592280},
{0.5422591,0.8614784,0.1706158},
{0.5419379,0.8599935,0.1821658},
{0.5393172,0.8597264,0.1933091},
{0.5380578,0.8589259,0.2027265},
{0.5362481,0.8579923,0.2137824},
{0.5351708,0.8563198,0.2256705},
{0.5356407,0.8540767,0.2357804},
{0.5347085,0.8525763,0.2461124},
{0.5349179,0.8499816,0.2574645},
{0.5319524,0.8490886,0.2694359},
{0.5338094,0.8461491,0.2781575},
{0.5407221,0.8422368,0.2794625},
{0.5412501,0.8397973,0.2884669},
{0.5418283,0.8372330,0.2975378},
{0.5444689,0.8336662,0.3058106},
{0.5445698,0.8312572,0.3149768},
{0.5460412,0.8288810,0.3212501},
{0.5457667,0.8271295,0.3291488},
{0.5465618,0.8253978,0.3346674},
{0.5459646,0.8240688,0.3412262},
{0.5450949,0.8232885,0.3467866},
{0.5440470,0.8224203,0.3527573},
{0.5432078,0.8220408,0.3571707},
{0.5437138,0.8204860,0.3620007},
{0.5439909,0.8191036,0.3673794},
{0.5451430,0.8171489,0.3721778},
{0.5454234,0.8156010,0.3777592},
{0.5453622,0.8144005,0.3831147},
{0.5405983,0.8191850,0.3790614},
{0.5434438,0.8150020,0.3873504},
{0.5468415,0.8110307,0.3940409},
{0.5492287,0.8065417,0.4026390},
{0.5514816,0.8036544,0.4080265},
{0.5512793,0.8019895,0.4138367},
{0.5532062,0.7984730,0.4202880},
{0.5532167,0.7965108,0.4264509},
{0.5546103,0.7939937,0.4315169},
{0.5552236,0.7918176,0.4368717},
{0.5564243,0.7883826,0.4437634},
{0.5517804,0.7868653,0.4541085},
{0.5655062,0.7749067,0.4598401},
{0.5649518,0.7737244,0.4645540},
{0.5647139,0.7728453,0.4684822},
{0.5642083,0.7709219,0.4744091},
{0.5646065,0.7691928,0.4787952},
{0.5644237,0.7675684,0.4835025},
{0.5650978,0.7655559,0.4880114},
{0.5650965,0.7637699,0.4928117},
{0.5665040,0.7624071,0.4951099},
{0.5656220,0.7615656,0.4991996},
{0.5657870,0.7599439,0.5034080},
{0.5663354,0.7585991,0.5067215},
{0.5659954,0.7577862,0.5100821},
{0.5659175,0.7564661,0.5139239},
{0.5680392,0.7539272,0.5171913},
{0.5688797,0.7511415,0.5223633},
{0.5696693,0.7491787,0.5262203},
{0.5704620,0.7465744,0.5310789},
{0.5725523,0.7437890,0.5348198},
{0.5725983,0.7417422,0.5393418},
{0.5741404,0.7383102,0.5445113},
{0.5747380,0.7362049,0.5486408},
{0.5758701,0.7328976,0.5539010},
{0.5771082,0.7307359,0.5571558},
{0.5774899,0.7286489,0.5611135},
{0.5781364,0.7267084,0.5647114},
{0.5783281,0.7249023,0.5683666},
{0.5807756,0.7226196,0.5701912},
{0.5807332,0.7214312,0.5732128}
};
inPtsMCh = {
{0.4203885,0.9118117,0.0316698},
{0.4202464,0.9112235,0.0308272},
{0.4209317,0.9102523,0.0299829},
{0.4217108,0.9091947,0.0284247},
{0.4222192,0.9083041,0.0262022},
{0.4225025,0.9074939,0.0260251},
{0.4227935,0.9067220,0.0243211},
{0.4230761,0.9059414,0.0229799},
{0.4267743,0.9033817,0.0278887},
{0.4286765,0.9017397,0.0275951},
{0.4313399,0.8997110,0.0298119},
{0.4344635,0.8974186,0.0326817},
{0.4375474,0.8951036,0.0359636},
{0.4404086,0.8929550,0.0391987},
{0.4453297,0.8895699,0.0423624},
{0.4504501,0.8860437,0.0472916},
{0.4544425,0.8831180,0.0506777},
{0.4572511,0.8807896,0.0537004},
{0.4597315,0.8786964,0.0553366},
{0.4630414,0.8760455,0.0575838},
{0.4658554,0.8737345,0.0593082},
{0.4703624,0.8703760,0.0626743},
{0.4747135,0.8672085,0.0639780},
{0.4801465,0.8634282,0.0649774},
{0.4844284,0.8601926,0.0652813},
{0.4888430,0.8569187,0.0660509},
{0.4863512,0.8583078,0.0664083},
{0.4797393,0.8612415,0.0750234},
{0.4767761,0.8617699,0.0848168},
{0.4738643,0.8622478,0.0933507},
{0.4723859,0.8614784,0.1046013},
{0.4719002,0.8599935,0.1160256},
{0.4693515,0.8597264,0.1269943},
{0.4679126,0.8589259,0.1363036},
{0.4661439,0.8579923,0.1472378},
{0.4650719,0.8563198,0.1589904},
{0.4653046,0.8540767,0.1690161},
{0.4642512,0.8525763,0.1791829},
{0.4644277,0.8499816,0.1903887},
{0.4614953,0.8490886,0.2022172},
{0.4632420,0.8461491,0.2108115},
{0.4703295,0.8422368,0.2118371},
{0.4709262,0.8397973,0.2207874},
{0.4716847,0.8372330,0.2298018},
{0.4743360,0.8336662,0.2379532},
{0.4746980,0.8312572,0.2470429},
{0.4761136,0.8288810,0.2531706},
{0.4759361,0.8271295,0.2610153},
{0.4768148,0.8253978,0.2664166},
{0.4764059,0.8240688,0.2728277},
{0.4756768,0.8232885,0.2782708},
{0.4746786,0.8224203,0.2841929},
{0.4737901,0.8220408,0.2884655},
{0.4743142,0.8204860,0.2931943},
{0.4744377,0.8191036,0.2984454},
{0.4756307,0.8171489,0.3031475},
{0.4758520,0.8156010,0.3086144},
{0.4756675,0.8144005,0.3138845},
{0.4710868,0.8191850,0.3096443},
{0.4739431,0.8150020,0.3178293},
{0.4772184,0.8110307,0.3244423},
{0.4796173,0.8065417,0.3329798},
{0.4818655,0.8036544,0.3382170},
{0.4814495,0.8019895,0.3439972},
{0.4834168,0.7984730,0.3504048},
{0.4833872,0.7965108,0.3564706},
{0.4847350,0.7939937,0.3614689},
{0.4852743,0.7918176,0.3667545},
{0.4865901,0.7883826,0.3735960},
{0.4819838,0.7868653,0.3839521},
{0.4954873,0.7749067,0.3896529},
{0.4950051,0.7737244,0.3943037},
{0.4946517,0.7728453,0.3981783},
{0.4941327,0.7709219,0.4040403},
{0.4945097,0.7691928,0.4083892},
{0.4943961,0.7675684,0.4130548},
{0.4950070,0.7655559,0.4174771},
{0.4951841,0.7637699,0.4222344},
{0.4963632,0.7624071,0.4244953},
{0.4956023,0.7615656,0.4285742},
{0.4957878,0.7599439,0.4327821},
{0.4963500,0.7585991,0.4360130},
{0.4958767,0.7577862,0.4394146},
{0.4958484,0.7564661,0.4431362},
{0.4977615,0.7539272,0.4464248},
{0.4987242,0.7511415,0.4515053},
{0.4994405,0.7491787,0.4553559},
{0.5001909,0.7465744,0.4601717},
{0.5022239,0.7437890,0.4638818},
{0.5023830,0.7417422,0.4684041},
{0.5040281,0.7383102,0.4735716},
{0.5046051,0.7362049,0.4776313},
{0.5057191,0.7328976,0.4828950},
{0.5068964,0.7307359,0.4861152},
{0.5072981,0.7286489,0.4900476},
{0.5079163,0.7267084,0.4936664},
{0.5083554,0.7249023,0.4972902},
{0.5106564,0.7226196,0.4991578},
{0.5105526,0.7214312,0.5021310}
};
inPtsLCh = {
{0.5254167,0.9118117,-0.0291280},
{0.5253528,0.9112235,-0.0299536},
{0.5259676,0.9102523,-0.0308114},
{0.5265285,0.9091947,-0.0324160},
{0.5270898,0.9083041,-0.0345815},
{0.5274411,0.9074939,-0.0347599},
{0.5277176,0.9067220,-0.0365045},
{0.5279542,0.9059414,-0.0378186},
{0.5315690,0.9033817,-0.0329508},
{0.5332478,0.9017397,-0.0334233},
{0.5356693,0.8997110,-0.0312980},
{0.5384598,0.8974186,-0.0285531},
{0.5411961,0.8951036,-0.0254231},
{0.5435376,0.8929550,-0.0223901},
{0.5480243,0.8895699,-0.0194419},
{0.5526402,0.8860437,-0.0147016},
{0.5561029,0.8831180,-0.0115481},
{0.5584747,0.8807896,-0.0087017},
{0.5601560,0.8786964,-0.0073831},
{0.5624818,0.8760455,-0.0054173},
{0.5642729,0.8737345,-0.0040344},
{0.5675379,0.8703760,-0.0010217},
{0.5705543,0.8672085,-0.0001079},
{0.5745503,0.8634282,0.0004547},
{0.5775315,0.8601926,0.0004099},
{0.5804892,0.8569187,0.0008302},
{0.5765354,0.8583078,0.0009170},
{0.5700847,0.8612415,0.0094302},
{0.5669816,0.8617699,0.0191027},
{0.5640058,0.8622478,0.0274734},
{0.5624604,0.8614784,0.0385869},
{0.5619393,0.8599935,0.0498854},
{0.5593782,0.8597264,0.0606795},
{0.5577170,0.8589259,0.0698806},
{0.5559242,0.8579923,0.0806933},
{0.5549067,0.8563198,0.0923103},
{0.5551122,0.8540767,0.1022517},
{0.5539539,0.8525763,0.1122534},
{0.5539930,0.8499816,0.1233130},
{0.5510845,0.8490886,0.1349985},
{0.5526836,0.8461491,0.1434655},
{0.5595669,0.8422368,0.1442117},
{0.5602231,0.8397973,0.1531080},
{0.5609615,0.8372330,0.1620658},
{0.5634797,0.8336662,0.1700958},
{0.5639470,0.8312572,0.1791089},
{0.5652139,0.8288810,0.1850912},
{0.5651082,0.8271295,0.1928817},
{0.5658629,0.8253978,0.1981658},
{0.5654584,0.8240688,0.2044291},
{0.5646235,0.8232885,0.2097550},
{0.5636558,0.8224203,0.2156285},
{0.5625933,0.8220408,0.2197604},
{0.5631547,0.8204860,0.2243879},
{0.5631777,0.8191036,0.2295113},
{0.5641966,0.8171489,0.2341173},
{0.5644128,0.8156010,0.2394696},
{0.5641666,0.8144005,0.2446544},
{0.5594838,0.8191850,0.2402273},
{0.5622420,0.8150020,0.2483082},
{0.5653096,0.8110307,0.2548437},
{0.5680045,0.8065417,0.2633205},
{0.5699600,0.8036544,0.2684075},
{0.5696184,0.8019895,0.2741578},
{0.5715707,0.7984730,0.2805216},
{0.5715351,0.7965108,0.2864902},
{0.5726595,0.7939937,0.2914209},
{0.5732760,0.7918176,0.2966373},
{0.5745724,0.7883826,0.3034286},
{0.5698084,0.7868653,0.3137957},
{0.5834501,0.7749067,0.3194657},
{0.5830231,0.7737244,0.3240533},
{0.5824889,0.7728453,0.3278744},
{0.5819992,0.7709219,0.3336714},
{0.5823483,0.7691928,0.3379832},
{0.5823400,0.7675684,0.3426071},
{0.5827495,0.7655559,0.3469428},
{0.5829504,0.7637699,0.3516571},
{0.5839410,0.7624071,0.3538808},
{0.5833141,0.7615656,0.3579489},
{0.5834247,0.7599439,0.3621563},
{0.5838988,0.7585991,0.3653045},
{0.5834178,0.7577862,0.3687472},
{0.5834391,0.7564661,0.3723486},
{0.5851834,0.7539272,0.3756583},
{0.5861366,0.7511415,0.3806474},
{0.5868626,0.7491787,0.3844915},
{0.5875942,0.7465744,0.3892646},
{0.5895519,0.7437890,0.3929437},
{0.5897289,0.7417422,0.3974665},
{0.5914063,0.7383102,0.4026320},
{0.5918616,0.7362049,0.4066218},
{0.5930481,0.7328976,0.4118890},
{0.5941834,0.7307359,0.4150747},
{0.5946354,0.7286489,0.4189818},
{0.5951246,0.7267084,0.4226214},
{0.5955258,0.7249023,0.4262138},
{0.5978143,0.7226196,0.4281244},
{0.5977442,0.7214312,0.4310491}
};
inPtsLSh = {
{0.5969172,0.9347560,-0.1131146},
{0.5968041,0.9341486,-0.1138822},
{0.5975186,0.9329630,-0.1146429},
{0.5981106,0.9318282,-0.1163921},
{0.5986948,0.9305641,-0.1187683},
{0.5991385,0.9297603,-0.1189764},
{0.5993914,0.9288245,-0.1207842},
{0.5996801,0.9277316,-0.1220908},
{0.6032605,0.9253833,-0.1173328},
{0.6047555,0.9236256,-0.1180564},
{0.6069456,0.9214367,-0.1162147},
{0.6097116,0.9191381,-0.1136624},
{0.6121893,0.9168565,-0.1107624},
{0.6143087,0.9147242,-0.1080377},
{0.6183634,0.9111985,-0.1054626},
{0.6226995,0.9075502,-0.1010308},
{0.6256624,0.9046023,-0.0984051},
{0.6275755,0.9021904,-0.0959602},
{0.6286071,0.9000513,-0.0952193},
{0.6303373,0.8973277,-0.0938937},
{0.6310475,0.8949883,-0.0932855},
{0.6329842,0.8916001,-0.0909749},
{0.6349741,0.8881147,-0.0910413},
{0.6375858,0.8839718,-0.0915313},
{0.6391092,0.8805229,-0.0927163},
{0.6404240,0.8771583,-0.0934649},
{0.6348888,0.8788437,-0.0944856},
{0.6282167,0.8821556,-0.0862846},
{0.6250252,0.8830408,-0.0768209},
{0.6216831,0.8837108,-0.0688132},
{0.6201221,0.8833097,-0.0577154},
{0.6195482,0.8816344,-0.0465436},
{0.6170097,0.8814731,-0.0359447},
{0.6150568,0.8813672,-0.0270903},
{0.6132831,0.8806384,-0.0163241},
{0.6121883,0.8794601,-0.0046590},
{0.6120483,0.8774261,0.0049108},
{0.6108085,0.8761496,0.0148625},
{0.6107047,0.8740904,0.0257345},
{0.6076981,0.8739801,0.0375014},
{0.6092693,0.8708567,0.0458068},
{0.6167054,0.8640247,0.0465271},
{0.6172692,0.8616523,0.0553917},
{0.6182000,0.8594620,0.0643964},
{0.6205909,0.8557171,0.0721688},
{0.6213076,0.8533217,0.0813375},
{0.6224486,0.8510654,0.0871138},
{0.6224890,0.8495041,0.0948705},
{0.6230339,0.8479121,0.1000108},
{0.6225805,0.8469288,0.1062718},
{0.6217625,0.8464518,0.1115613},
{0.6208003,0.8460223,0.1173758},
{0.6194734,0.8461319,0.1213878},
{0.6199954,0.8447340,0.1259418},
{0.6198366,0.8436906,0.1309540},
{0.6208037,0.8419224,0.1354540},
{0.6206445,0.8407868,0.1406654},
{0.6202637,0.8399070,0.1457618},
{0.6150669,0.8443428,0.1409748},
{0.6178613,0.8395447,0.1487891},
{0.6206804,0.8364154,0.1545679},
{0.6234579,0.8332417,0.1640219},
{0.6253284,0.8304909,0.1690450},
{0.6248132,0.8292045,0.1747318},
{0.6269233,0.8257271,0.1811681},
{0.6267567,0.8240454,0.1870135},
{0.6276864,0.8216652,0.1918750},
{0.6282178,0.8195191,0.1968804},
{0.6295929,0.8161673,0.2037642},
{0.6246230,0.8166680,0.2141553},
{0.6390330,0.8035215,0.2197858},
{0.6387011,0.8019436,0.2244121},
{0.6379867,0.8011166,0.2279330},
{0.6375641,0.7993944,0.2338696},
{0.6376673,0.7977109,0.2381165},
{0.6376798,0.7961273,0.2427176},
{0.6380114,0.7944033,0.2470319},
{0.6383574,0.7926188,0.2517483},
{0.6391321,0.7913662,0.2538212},
{0.6386334,0.7905189,0.2579656},
{0.6389034,0.7890430,0.2622081},
{0.6392033,0.7875064,0.2653807},
{0.6387738,0.7870818,0.2687256},
{0.6388089,0.7858124,0.2724414},
{0.6406086,0.7832821,0.2755946},
{0.6416416,0.7805181,0.2807938},
{0.6421794,0.7786402,0.2844067},
{0.6429081,0.7761957,0.2892216},
{0.6448630,0.7732152,0.2928146},
{0.6450060,0.7714079,0.2973447},
{0.6468416,0.7678218,0.3024297},
{0.6473664,0.7657829,0.3064365},
{0.6487023,0.7626399,0.3116644},
{0.6497422,0.7603908,0.3148256},
{0.6502720,0.7584160,0.3187276},
{0.6507332,0.7565340,0.3223534},
{0.6511900,0.7547049,0.3259527},
{0.6533085,0.7523423,0.3278196},
{0.6533343,0.7510944,0.3307283}
};
inPtsEeWam = {
{0.1894030,0.3261800,-0.1167376},
{0.1883336,0.3257996,-0.1162714},
{0.1862806,0.3256625,-0.1161416},
{0.1846869,0.3253256,-0.1159281},
{0.1829626,0.3253474,-0.1155621},
{0.1813096,0.3257727,-0.1142007},
{0.1796886,0.3263770,-0.1132727},
{0.1778183,0.3273917,-0.1115283},
{0.1768361,0.3284633,-0.1073152},
{0.1750002,0.3296902,-0.1046393},
{0.1735152,0.3311569,-0.1008479},
{0.1722171,0.3328297,-0.0966719},
{0.1710057,0.3348588,-0.0920810},
{0.1695053,0.3371337,-0.0872047},
{0.1690364,0.3392230,-0.0819876},
{0.1683945,0.3420339,-0.0758063},
{0.1672100,0.3449116,-0.0695637},
{0.1654493,0.3481027,-0.0633971},
{0.1630850,0.3513161,-0.0572828},
{0.1605335,0.3544956,-0.0507620},
{0.1582877,0.3575049,-0.0444643},
{0.1564601,0.3603706,-0.0373364},
{0.1548865,0.3632223,-0.0307973},
{0.1537637,0.3658134,-0.0242925},
{0.1521720,0.3689797,-0.0174269},
{0.1505932,0.3721580,-0.0101408},
{0.1459273,0.3768822,-0.0026905},
{0.1391827,0.3824129,0.0075405},
{0.1340310,0.3863742,0.0176265},
{0.1288262,0.3909028,0.0281341},
{0.1242369,0.3951516,0.0393888},
{0.1195748,0.3994130,0.0512806},
{0.1141440,0.4041633,0.0628188},
{0.1090583,0.4088568,0.0740514},
{0.1035002,0.4138197,0.0855915},
{0.0976477,0.4185639,0.0979974},
{0.0924716,0.4228324,0.1098015},
{0.0862162,0.4276878,0.1211683},
{0.0807362,0.4318740,0.1332282},
{0.0741436,0.4365791,0.1456641},
{0.0700520,0.4410652,0.1568660},
{0.0687243,0.4468693,0.1636543},
{0.0638626,0.4520348,0.1751830},
{0.0593676,0.4567824,0.1870609},
{0.0559816,0.4618298,0.1996794},
{0.0505062,0.4671579,0.2119085},
{0.0460786,0.4722920,0.2236579},
{0.0404511,0.4777724,0.2359639},
{0.0356920,0.4829197,0.2481590},
{0.0299415,0.4883025,0.2609335},
{0.0239377,0.4939354,0.2735493},
{0.0181687,0.4989365,0.2864174},
{0.0125415,0.5035211,0.2993258},
{0.0081267,0.5083078,0.3123140},
{0.0033502,0.5128957,0.3261028},
{-0.0009189,0.5179671,0.3393557},
{-0.0050460,0.5219514,0.3538843},
{-0.0094418,0.5264225,0.3680513},
{-0.0163510,0.5352996,0.3768361},
{-0.0179645,0.5392369,0.3927517},
{-0.0193504,0.5430820,0.4086277},
{-0.0212039,0.5467849,0.4242649},
{-0.0225226,0.5513815,0.4388012},
{-0.0257341,0.5559345,0.4526162},
{-0.0278031,0.5605291,0.4662972},
{-0.0315257,0.5653839,0.4797755},
{-0.0337975,0.5700140,0.4929380},
{-0.0368028,0.5749284,0.5055228},
{-0.0397893,0.5795765,0.5182272},
{-0.0462735,0.5806634,0.5341085},
{-0.0388865,0.5856533,0.5459560},
{-0.0420858,0.5910745,0.5563306},
{-0.0445437,0.5954825,0.5672675},
{-0.0478880,0.5994538,0.5785590},
{-0.0501220,0.6037255,0.5894644},
{-0.0533107,0.6084967,0.5996450},
{-0.0552810,0.6124151,0.6104575},
{-0.0582982,0.6173622,0.6201664},
{-0.0592455,0.6222268,0.6293735},
{-0.0620716,0.6273823,0.6376617},
{-0.0637049,0.6313841,0.6461706},
{-0.0642769,0.6356236,0.6537330},
{-0.0654309,0.6391992,0.6613390},
{-0.0663070,0.6432144,0.6680099},
{-0.0649221,0.6467712,0.6748382},
{-0.0651508,0.6496249,0.6811901},
{-0.0648263,0.6520459,0.6873108},
{-0.0646051,0.6539229,0.6930280},
{-0.0630358,0.6561868,0.6973054},
{-0.0626389,0.6572469,0.7014233},
{-0.0614482,0.6581704,0.7053987},
{-0.0602208,0.6582870,0.7086651},
{-0.0594693,0.6581263,0.7122211},
{-0.0579482,0.6585340,0.7146786},
{-0.0581075,0.6591645,0.7168546},
{-0.0580465,0.6592123,0.7187252},
{-0.0583696,0.6594178,0.7201303},
{-0.0563307,0.6598839,0.7212190},
{-0.0571334,0.6601813,0.7217250}
};
inPtsRPiWam = {
{0.1839514,0.3332123,-0.1836245},
{0.1834501,0.3328849,-0.1831587},
{0.1827029,0.3326538,-0.1828621},
{0.1816096,0.3322925,-0.1825966},
{0.1804431,0.3321952,-0.1822824},
{0.1795265,0.3324198,-0.1809685},
{0.1786511,0.3327467,-0.1800635},
{0.1778247,0.3334673,-0.1784123},
{0.1780025,0.3347129,-0.1741461},
{0.1772395,0.3357539,-0.1714849},
{0.1769703,0.3372470,-0.1676946},
{0.1769710,0.3387579,-0.1634888},
{0.1769495,0.3406976,-0.1588230},
{0.1768057,0.3429108,-0.1538725},
{0.1776088,0.3450573,-0.1485965},
{0.1787022,0.3475152,-0.1422291},
{0.1789402,0.3502230,-0.1357605},
{0.1786875,0.3531578,-0.1293332},
{0.1773627,0.3561100,-0.1230042},
{0.1758186,0.3589557,-0.1162650},
{0.1740597,0.3618307,-0.1098782},
{0.1726815,0.3645439,-0.1026861},
{0.1712347,0.3672473,-0.0961395},
{0.1702592,0.3696978,-0.0895842},
{0.1687145,0.3726895,-0.0826956},
{0.1672665,0.3756172,-0.0753519},
{0.1628137,0.3800914,-0.0678771},
{0.1572483,0.3853574,-0.0573040},
{0.1534743,0.3890856,-0.0468087},
{0.1491204,0.3934676,-0.0360264},
{0.1455682,0.3974188,-0.0244827},
{0.1418049,0.4016452,-0.0122625},
{0.1372142,0.4061483,-0.0004599},
{0.1327389,0.4106119,0.0109792},
{0.1279072,0.4153581,0.0227913},
{0.1226476,0.4197429,0.0354500},
{0.1178008,0.4240113,0.0474055},
{0.1120219,0.4286594,0.0589402},
{0.1068346,0.4328344,0.0711550},
{0.1003829,0.4375817,0.0836763},
{0.0962518,0.4419736,0.0948760},
{0.0950511,0.4469413,0.1017076},
{0.0902764,0.4517897,0.1132598},
{0.0857287,0.4564199,0.1251215},
{0.0822411,0.4611370,0.1377171},
{0.0770987,0.4660968,0.1500483},
{0.0727804,0.4706186,0.1618616},
{0.0674809,0.4753993,0.1743122},
{0.0627607,0.4798686,0.1865741},
{0.0569814,0.4843089,0.1994918},
{0.0510389,0.4890306,0.2122084},
{0.0453763,0.4931554,0.2251413},
{0.0396893,0.4970341,0.2379903},
{0.0349790,0.5009433,0.2509598},
{0.0298852,0.5042747,0.2647866},
{0.0254519,0.5080621,0.2782322},
{0.0208021,0.5113048,0.2926403},
{0.0161096,0.5149110,0.3067929},
{0.0086899,0.5223310,0.3156398},
{0.0061714,0.5253650,0.3314669},
{0.0040280,0.5285392,0.3472319},
{0.0014375,0.5315328,0.3627020},
{-0.0010144,0.5353736,0.3770494},
{-0.0050621,0.5392254,0.3907453},
{-0.0081919,0.5430688,0.4043687},
{-0.0128106,0.5471888,0.4178086},
{-0.0159544,0.5512529,0.4308550},
{-0.0199401,0.5555595,0.4433739},
{-0.0238396,0.5596859,0.4560168},
{-0.0314967,0.5609001,0.4716366},
{-0.0258033,0.5654283,0.4832222},
{-0.0304709,0.5706288,0.4934624},
{-0.0346785,0.5748131,0.5042286},
{-0.0394075,0.5786579,0.5153662},
{-0.0431335,0.5826843,0.5262579},
{-0.0473166,0.5870694,0.5364660},
{-0.0503729,0.5906056,0.5473409},
{-0.0542177,0.5950413,0.5572016},
{-0.0561686,0.5994985,0.5665058},
{-0.0599941,0.6041231,0.5750318},
{-0.0625919,0.6077915,0.5836794},
{-0.0643105,0.6118143,0.5913479},
{-0.0664280,0.6151613,0.5991420},
{-0.0681277,0.6188018,0.6059814},
{-0.0678224,0.6220449,0.6129273},
{-0.0686699,0.6244106,0.6196686},
{-0.0690802,0.6265553,0.6259412},
{-0.0693902,0.6280520,0.6319970},
{-0.0685793,0.6299671,0.6365119},
{-0.0691241,0.6308985,0.6409485},
{-0.0685798,0.6319014,0.6450267},
{-0.0682897,0.6322673,0.6483559},
{-0.0680904,0.6323928,0.6518703},
{-0.0673319,0.6330204,0.6544145},
{-0.0678245,0.6337895,0.6566377},
{-0.0681154,0.6339495,0.6585540},
{-0.0687715,0.6343381,0.6599852},
{-0.0671722,0.6349418,0.6611794},
{-0.0680998,0.6352434,0.6617403}
};
inPtsRThWam = {
{0.1922058,0.3706920,-0.2053819},
{0.1919588,0.3704477,-0.2048459},
{0.1922310,0.3706025,-0.2046384},
{0.1914731,0.3703632,-0.2043751},
{0.1907187,0.3701193,-0.2040522},
{0.1901662,0.3702316,-0.2027425},
{0.1895541,0.3705074,-0.2018872},
{0.1893269,0.3709164,-0.2002006},
{0.1902647,0.3721537,-0.1956557},
{0.1901222,0.3729831,-0.1928829},
{0.1905621,0.3742425,-0.1887998},
{0.1913116,0.3754957,-0.1843804},
{0.1920340,0.3772379,-0.1794761},
{0.1926323,0.3791750,-0.1741897},
{0.1940939,0.3809957,-0.1684913},
{0.1963077,0.3830232,-0.1617857},
{0.1973929,0.3855006,-0.1549669},
{0.1979354,0.3881880,-0.1481877},
{0.1973131,0.3909170,-0.1416278},
{0.1965731,0.3934531,-0.1346625},
{0.1952307,0.3961073,-0.1281221},
{0.1943944,0.3984739,-0.1207511},
{0.1933264,0.4009162,-0.1141549},
{0.1927460,0.4031893,-0.1075586},
{0.1916378,0.4059486,-0.1006634},
{0.1906615,0.4086525,-0.0933288},
{0.1863573,0.4129601,-0.0858715},
{0.1813152,0.4181311,-0.0749776},
{0.1782924,0.4216162,-0.0639924},
{0.1745532,0.4257610,-0.0528532},
{0.1714903,0.4293978,-0.0409515},
{0.1683429,0.4334182,-0.0282709},
{0.1642144,0.4376161,-0.0161337},
{0.1600252,0.4418962,-0.0044904},
{0.1558881,0.4462219,0.0077219},
{0.1510399,0.4503950,0.0205539},
{0.1466838,0.4544040,0.0328076},
{0.1414143,0.4586295,0.0446400},
{0.1367161,0.4625535,0.0571370},
{0.1304903,0.4672214,0.0698083},
{0.1266350,0.4714002,0.0810495},
{0.1259195,0.4757799,0.0877439},
{0.1215060,0.4802179,0.0993494},
{0.1171445,0.4846611,0.1112117},
{0.1139323,0.4890831,0.1237215},
{0.1092336,0.4934838,0.1362575},
{0.1053717,0.4974624,0.1480522},
{0.1005510,0.5016199,0.1605842},
{0.0961335,0.5056982,0.1727054},
{0.0907963,0.5097699,0.1853448},
{0.0853733,0.5137671,0.1979773},
{0.0799205,0.5173014,0.2107800},
{0.0742293,0.5206765,0.2234364},
{0.0697174,0.5241111,0.2360432},
{0.0648796,0.5267905,0.2494024},
{0.0611119,0.5296472,0.2626343},
{0.0565284,0.5323833,0.2766348},
{0.0519169,0.5354138,0.2904866},
{0.0444657,0.5422459,0.2986513},
{0.0420787,0.5447989,0.3138019},
{0.0402119,0.5472431,0.3292078},
{0.0373484,0.5498836,0.3440978},
{0.0348187,0.5532312,0.3577062},
{0.0306599,0.5566002,0.3708560},
{0.0275579,0.5599812,0.3837729},
{0.0230223,0.5634444,0.3967120},
{0.0197158,0.5670410,0.4092551},
{0.0156066,0.5709101,0.4211716},
{0.0116884,0.5744813,0.4333512},
{0.0036870,0.5758468,0.4482652},
{0.0091831,0.5794935,0.4591480},
{0.0041862,0.5845461,0.4685186},
{-0.0005774,0.5886108,0.4782659},
{-0.0056870,0.5921562,0.4887364},
{-0.0097344,0.5959236,0.4987928},
{-0.0141679,0.5998857,0.5085021},
{-0.0174440,0.6029638,0.5188300},
{-0.0214194,0.6069212,0.5282344},
{-0.0235987,0.6108812,0.5370577},
{-0.0276521,0.6151597,0.5449357},
{-0.0305449,0.6185349,0.5530454},
{-0.0326964,0.6223576,0.5600959},
{-0.0350998,0.6255669,0.5672811},
{-0.0371221,0.6288799,0.5736916},
{-0.0373559,0.6317892,0.5801657},
{-0.0382044,0.6338576,0.5863627},
{-0.0389768,0.6357755,0.5922688},
{-0.0393690,0.6371245,0.5978231},
{-0.0389136,0.6388023,0.6019018},
{-0.0397358,0.6397071,0.6056407},
{-0.0394028,0.6406797,0.6093655},
{-0.0396220,0.6412519,0.6121967},
{-0.0397189,0.6415119,0.6154991},
{-0.0393123,0.6422742,0.6176345},
{-0.0399322,0.6431441,0.6196505},
{-0.0403253,0.6432962,0.6213987},
{-0.0411427,0.6438410,0.6226318},
{-0.0396891,0.6445452,0.6235288},
{-0.0406725,0.6448942,0.6239752}
};
inPtsRWWam = {
{0.2006294,0.3771539,-0.1463286},
{0.1998838,0.3767891,-0.1457106},
{0.1990475,0.3765113,-0.1453205},
{0.1978514,0.3761370,-0.1449952},
{0.1966880,0.3760037,-0.1446405},
{0.1955239,0.3762878,-0.1432899},
{0.1942402,0.3767741,-0.1423997},
{0.1932138,0.3775164,-0.1406915},
{0.1932269,0.3785101,-0.1360669},
{0.1922417,0.3795158,-0.1332772},
{0.1917557,0.3808060,-0.1291719},
{0.1914967,0.3822203,-0.1247587},
{0.1912980,0.3840146,-0.1198646},
{0.1908548,0.3860526,-0.1146117},
{0.1913830,0.3879398,-0.1089561},
{0.1922959,0.3902398,-0.1023565},
{0.1922572,0.3927967,-0.0956340},
{0.1915814,0.3956617,-0.0889950},
{0.1901480,0.3985324,-0.0825459},
{0.1886665,0.4012571,-0.0756999},
{0.1870096,0.4040069,-0.0692153},
{0.1859693,0.4064838,-0.0618880},
{0.1849325,0.4090140,-0.0552994},
{0.1843140,0.4113145,-0.0487123},
{0.1832828,0.4141180,-0.0418123},
{0.1822849,0.4169086,-0.0344928},
{0.1778476,0.4214456,-0.0270872},
{0.1717524,0.4267655,-0.0163772},
{0.1675852,0.4303556,-0.0056059},
{0.1631820,0.4345262,0.0054038},
{0.1593159,0.4384271,0.0171024},
{0.1554488,0.4423636,0.0296404},
{0.1506907,0.4467572,0.0416032},
{0.1460143,0.4512275,0.0530997},
{0.1413967,0.4556206,0.0651820},
{0.1360526,0.4600256,0.0778482},
{0.1315057,0.4639070,0.0900729},
{0.1259835,0.4682368,0.1018203},
{0.1211037,0.4720220,0.1142911},
{0.1147682,0.4765727,0.1269518},
{0.1110182,0.4807416,0.1382234},
{0.1103524,0.4857601,0.1448233},
{0.1060051,0.4903969,0.1564117},
{0.1017501,0.4948821,0.1682953},
{0.0987011,0.4995009,0.1808133},
{0.0939150,0.5041530,0.1932795},
{0.0900972,0.5085479,0.2050066},
{0.0851603,0.5132214,0.2174043},
{0.0807687,0.5178078,0.2294265},
{0.0754018,0.5225318,0.2419146},
{0.0700798,0.5271788,0.2544240},
{0.0647178,0.5314737,0.2670652},
{0.0593071,0.5355318,0.2796205},
{0.0551343,0.5396583,0.2921290},
{0.0506774,0.5433465,0.3052969},
{0.0471548,0.5470662,0.3183279},
{0.0431657,0.5503963,0.3322853},
{0.0389825,0.5541498,0.3459994},
{0.0320713,0.5622544,0.3538423},
{0.0304643,0.5654478,0.3689266},
{0.0293910,0.5682770,0.3843484},
{0.0273107,0.5715764,0.3991311},
{0.0258306,0.5754786,0.4126995},
{0.0225123,0.5794010,0.4257535},
{0.0203017,0.5832864,0.4385837},
{0.0166299,0.5872296,0.4514240},
{0.0142011,0.5912588,0.4638727},
{0.0109819,0.5955640,0.4756766},
{0.0079378,0.5994521,0.4877790},
{0.0008419,0.6006789,0.5028112},
{0.0080357,0.6045170,0.5136688},
{0.0042153,0.6096675,0.5230063},
{0.0008983,0.6138689,0.5326704},
{-0.0029652,0.6174362,0.5430826},
{-0.0058095,0.6212908,0.5530247},
{-0.0093299,0.6255011,0.5625433},
{-0.0116434,0.6287923,0.5726746},
{-0.0148977,0.6330823,0.5818354},
{-0.0161639,0.6372831,0.5904211},
{-0.0194572,0.6419243,0.5980064},
{-0.0215531,0.6455150,0.6058774},
{-0.0227586,0.6494699,0.6126902},
{-0.0244600,0.6528075,0.6196713},
{-0.0257647,0.6563925,0.6257883},
{-0.0249986,0.6595401,0.6319072},
{-0.0255130,0.6619161,0.6378568},
{-0.0256446,0.6640466,0.6434841},
{-0.0257708,0.6656587,0.6488220},
{-0.0247018,0.6676037,0.6525822},
{-0.0249415,0.6685460,0.6561327},
{-0.0241255,0.6693994,0.6597816},
{-0.0236325,0.6697539,0.6625154},
{-0.0232665,0.6697625,0.6658103},
{-0.0222953,0.6703088,0.6678787},
{-0.0226966,0.6710409,0.6698970},
{-0.0228175,0.6710610,0.6716241},
{-0.0234134,0.6714409,0.6728703},
{-0.0216831,0.6719908,0.6737536},
{-0.0226057,0.6723306,0.6741831}
};
inPtsRLAWam = {
{0.1183845,0.5638016,0.0736678},
{0.1171587,0.5645388,0.0731651},
{0.1160932,0.5652634,0.0726043},
{0.1148845,0.5661995,0.0717830},
{0.1132223,0.5675365,0.0706469},
{0.1110487,0.5689637,0.0705791},
{0.1085656,0.5710601,0.0695268},
{0.1056793,0.5734483,0.0689472},
{0.1049378,0.5751853,0.0725569},
{0.1029037,0.5778555,0.0733144},
{0.1014730,0.5802366,0.0759536},
{0.1002748,0.5827188,0.0789051},
{0.0991242,0.5852642,0.0826264},
{0.0977607,0.5881166,0.0866434},
{0.0977790,0.5908774,0.0911804},
{0.0977089,0.5939432,0.0965361},
{0.0966657,0.5975247,0.1017202},
{0.0946860,0.6016703,0.1063809},
{0.0928583,0.6058400,0.1112537},
{0.0919583,0.6098888,0.1169665},
{0.0912866,0.6138360,0.1226410},
{0.0924164,0.6171665,0.1301033},
{0.0937628,0.6208030,0.1366213},
{0.0963666,0.6242846,0.1434049},
{0.0982746,0.6280890,0.1505156},
{0.1004910,0.6317049,0.1583084},
{0.0971411,0.6368542,0.1654889},
{0.0888400,0.6430313,0.1742917},
{0.0839803,0.6472771,0.1840129},
{0.0789648,0.6524191,0.1936328},
{0.0749259,0.6570739,0.2043774},
{0.0715766,0.6618712,0.2161394},
{0.0665186,0.6669943,0.2271042},
{0.0625488,0.6722401,0.2379968},
{0.0584874,0.6771831,0.2496707},
{0.0545484,0.6817121,0.2628134},
{0.0521976,0.6861051,0.2753787},
{0.0486422,0.6905918,0.2877681},
{0.0464957,0.6943330,0.3014046},
{0.0414350,0.6983998,0.3151404},
{0.0404259,0.7029460,0.3270141},
{0.0436891,0.7107799,0.3316979},
{0.0415695,0.7159207,0.3434600},
{0.0397178,0.7210054,0.3554323},
{0.0398427,0.7262480,0.3682204},
{0.0375340,0.7318569,0.3802878},
{0.0370798,0.7375694,0.3913888},
{0.0346133,0.7437371,0.4026271},
{0.0335332,0.7501210,0.4132726},
{0.0310784,0.7566462,0.4241944},
{0.0286414,0.7633607,0.4347043},
{0.0261429,0.7695836,0.4454347},
{0.0242298,0.7758026,0.4558008},
{0.0236910,0.7822024,0.4658635},
{0.0231405,0.7879287,0.4768231},
{0.0237483,0.7937787,0.4873992},
{0.0236009,0.7993040,0.4986046},
{0.0231891,0.8052551,0.5093905},
{0.0186015,0.8171015,0.5115494},
{0.0212833,0.8214319,0.5250925},
{0.0250268,0.8254434,0.5387712},
{0.0274607,0.8296607,0.5520771},
{0.0304250,0.8347044,0.5636329},
{0.0308476,0.8395711,0.5748912},
{0.0333637,0.8444397,0.5856493},
{0.0339061,0.8493155,0.5963810},
{0.0364177,0.8541522,0.6066784},
{0.0380818,0.8591265,0.6163905},
{0.0400631,0.8634249,0.6266543},
{0.0359655,0.8643180,0.6415944},
{0.0521398,0.8676109,0.6509146},
{0.0525840,0.8729623,0.6584180},
{0.0536339,0.8770930,0.6665810},
{0.0541772,0.8804887,0.6755142},
{0.0561387,0.8841310,0.6837054},
{0.0572730,0.8881305,0.6913448},
{0.0595947,0.8911872,0.6994583},
{0.0608149,0.8952525,0.7064725},
{0.0640573,0.8993560,0.7124145},
{0.0641547,0.9039196,0.7178710},
{0.0654574,0.9072604,0.7238541},
{0.0673448,0.9111132,0.7285530},
{0.0681924,0.9143614,0.7337112},
{0.0693095,0.9177801,0.7382045},
{0.0730594,0.9204580,0.7428416},
{0.0750293,0.9221609,0.7481469},
{0.0769974,0.9239113,0.7527313},
{0.0788683,0.9248250,0.7578334},
{0.0820627,0.9260855,0.7611570},
{0.0826167,0.9266040,0.7649321},
{0.0848821,0.9267240,0.7688752},
{0.0858995,0.9265881,0.7722375},
{0.0875183,0.9256362,0.7765144},
{0.0894215,0.9255163,0.7791822},
{0.0900143,0.9253944,0.7821491},
{0.0906635,0.9246045,0.7849279},
{0.0909171,0.9241690,0.7871378},
{0.0939855,0.9237381,0.7888366},
{0.0935796,0.9233220,0.7903912}
};
inPtsRElWam = {
{0.1575917,0.5855581,0.0698668},
{0.1564456,0.5861679,0.0694606},
{0.1554843,0.5867214,0.0690133},
{0.1543947,0.5874507,0.0682724},
{0.1528484,0.5885938,0.0672758},
{0.1507858,0.5898497,0.0674584},
{0.1484261,0.5917483,0.0666749},
{0.1456484,0.5939728,0.0664537},
{0.1451041,0.5953728,0.0705239},
{0.1432138,0.5977853,0.0716123},
{0.1419216,0.5999128,0.0746265},
{0.1408691,0.6021165,0.0779912},
{0.1398377,0.6044252,0.0821156},
{0.1385859,0.6070450,0.0865233},
{0.1387401,0.6095085,0.0914460},
{0.1387994,0.6122731,0.0973040},
{0.1378516,0.6156168,0.1029012},
{0.1359505,0.6195488,0.1079942},
{0.1341971,0.6235244,0.1130892},
{0.1334109,0.6272906,0.1189298},
{0.1328473,0.6309750,0.1246323},
{0.1341314,0.6339338,0.1320304},
{0.1356231,0.6372224,0.1383873},
{0.1384002,0.6402815,0.1449137},
{0.1404435,0.6437514,0.1517292},
{0.1427922,0.6470294,0.1591815},
{0.1394481,0.6521764,0.1660804},
{0.1311163,0.6584215,0.1752193},
{0.1262878,0.6625650,0.1851775},
{0.1213035,0.6676037,0.1949982},
{0.1173369,0.6720263,0.2060315},
{0.1140834,0.6765229,0.2180106},
{0.1090729,0.6814730,0.2292236},
{0.1051774,0.6864840,0.2402139},
{0.1011870,0.6911873,0.2520416},
{0.0973441,0.6954074,0.2652569},
{0.0951132,0.6994296,0.2777687},
{0.0916599,0.7035904,0.2901169},
{0.0896430,0.7069110,0.3036647},
{0.0846462,0.7107531,0.3174175},
{0.0837649,0.7148613,0.3291952},
{0.0872279,0.7219656,0.3337605},
{0.0852115,0.7267018,0.3454953},
{0.0834657,0.7313564,0.3574264},
{0.0837099,0.7361101,0.3700653},
{0.0815031,0.7412622,0.3820920},
{0.0811583,0.7464916,0.3929638},
{0.0787828,0.7522089,0.4041375},
{0.0777981,0.7581229,0.4145341},
{0.0754271,0.7641975,0.4252795},
{0.0730629,0.7705022,0.4355589},
{0.0706317,0.7763171,0.4460673},
{0.0687833,0.7821211,0.4560545},
{0.0683136,0.7880185,0.4658199},
{0.0678232,0.7932473,0.4764126},
{0.0684860,0.7985653,0.4866080},
{0.0683805,0.8035985,0.4974453},
{0.0680021,0.8090611,0.5078730},
{0.0634156,0.8206851,0.5095860},
{0.0661263,0.8244243,0.5228238},
{0.0698781,0.8278543,0.5360237},
{0.0723230,0.8314348,0.5490395},
{0.0752744,0.8359294,0.5601637},
{0.0756750,0.8403478,0.5710309},
{0.0781685,0.8445554,0.5814644},
{0.0786727,0.8488852,0.5918235},
{0.0811267,0.8530884,0.6016813},
{0.0827245,0.8574165,0.6109957},
{0.0846344,0.8610007,0.6209518},
{0.0804690,0.8615910,0.6355117},
{0.0964929,0.8635182,0.6445072},
{0.0968376,0.8682654,0.6517434},
{0.0977620,0.8718622,0.6594848},
{0.0981785,0.8746617,0.6681025},
{0.0999843,0.8776775,0.6759008},
{0.1009602,0.8810405,0.6832109},
{0.1031058,0.8834888,0.6909426},
{0.1041555,0.8869055,0.6977023},
{0.1072011,0.8904014,0.7032805},
{0.1071557,0.8944408,0.7085938},
{0.1083071,0.8972713,0.7144135},
{0.1100495,0.9006506,0.7189694},
{0.1107683,0.9035271,0.7239691},
{0.1117692,0.9065529,0.7284002},
{0.1153685,0.9087770,0.7329174},
{0.1172201,0.9100746,0.7382044},
{0.1190765,0.9115027,0.7427126},
{0.1208464,0.9121035,0.7477834},
{0.1239330,0.9130118,0.7511091},
{0.1244548,0.9133704,0.7549597},
{0.1266547,0.9132167,0.7589960},
{0.1276524,0.9129766,0.7624184},
{0.1292129,0.9118088,0.7667490},
{0.1310704,0.9115300,0.7694479},
{0.1316155,0.9112352,0.7724613},
{0.1322289,0.9103094,0.7752861},
{0.1324420,0.9097144,0.7775596},
{0.1354347,0.9090831,0.7792347},
{0.1350062,0.9085601,0.7808562}
};
inPtsRUAWam = {
{0.1320717,0.6039440,0.1020489},
{0.1308719,0.6047931,0.1014619},
{0.1299123,0.6056138,0.1008590},
{0.1288537,0.6066690,0.0999475},
{0.1273283,0.6082064,0.0987253},
{0.1252554,0.6098357,0.0986635},
{0.1228965,0.6122171,0.0975661},
{0.1201210,0.6149927,0.0969744},
{0.1196940,0.6168544,0.1008202},
{0.1179567,0.6198755,0.1015973},
{0.1168530,0.6225343,0.1043727},
{0.1160089,0.6252794,0.1074947},
{0.1152410,0.6280980,0.1114346},
{0.1142973,0.6312513,0.1156630},
{0.1148863,0.6343114,0.1204428},
{0.1153644,0.6376736,0.1261245},
{0.1148961,0.6416544,0.1315384},
{0.1134316,0.6462341,0.1363808},
{0.1122062,0.6508111,0.1413175},
{0.1120039,0.6551334,0.1470637},
{0.1120272,0.6593035,0.1527219},
{0.1139962,0.6626614,0.1602136},
{0.1162142,0.6663752,0.1666435},
{0.1198024,0.6698496,0.1732836},
{0.1226875,0.6737180,0.1802200},
{0.1259196,0.6773561,0.1878277},
{0.1231765,0.6827956,0.1947633},
{0.1149924,0.6893745,0.2036258},
{0.1103651,0.6937596,0.2134329},
{0.1056982,0.6991277,0.2230645},
{0.1020336,0.7038170,0.2339629},
{0.0992004,0.7086000,0.2458415},
{0.0945088,0.7138098,0.2569223},
{0.0910650,0.7190774,0.2678456},
{0.0874305,0.7239707,0.2796279},
{0.0840692,0.7283134,0.2929332},
{0.0824106,0.7325024,0.3055146},
{0.0794556,0.7367578,0.3179733},
{0.0779964,0.7401228,0.3317063},
{0.0734314,0.7439653,0.3456341},
{0.0732215,0.7482044,0.3575161},
{0.0775330,0.7557959,0.3618054},
{0.0761503,0.7606762,0.3735780},
{0.0750562,0.7654792,0.3855319},
{0.0761304,0.7703885,0.3982175},
{0.0745783,0.7757239,0.4101890},
{0.0749803,0.7811751,0.4209618},
{0.0732620,0.7871427,0.4319611},
{0.0730227,0.7933387,0.4421393},
{0.0713318,0.7996898,0.4526387},
{0.0696530,0.8063085,0.4626011},
{0.0678624,0.8124067,0.4728043},
{0.0666658,0.8185166,0.4824340},
{0.0669016,0.8247300,0.4918059},
{0.0670937,0.8302324,0.5020363},
{0.0684764,0.8358328,0.5118297},
{0.0690471,0.8411588,0.5222198},
{0.0693395,0.8469125,0.5321728},
{0.0652488,0.8590787,0.5329862},
{0.0687849,0.8629355,0.5459500},
{0.0733792,0.8664868,0.5588333},
{0.0766147,0.8701406,0.5715882},
{0.0803398,0.8747471,0.5823567},
{0.0813618,0.8792581,0.5929088},
{0.0845506,0.8835477,0.6030020},
{0.0856530,0.8879653,0.6130136},
{0.0887560,0.8922360,0.6225202},
{0.0909485,0.8966175,0.6315055},
{0.0934699,0.9002143,0.6411810},
{0.0896226,0.9007450,0.6557151},
{0.1068386,0.9024943,0.6644779},
{0.1076655,0.9072473,0.6714455},
{0.1090333,0.9108284,0.6789680},
{0.1098810,0.9136006,0.6873851},
{0.1121407,0.9165936,0.6949470},
{0.1135480,0.9199398,0.7020095},
{0.1161244,0.9223752,0.7094728},
{0.1176034,0.9257793,0.7159500},
{0.1210738,0.9292920,0.7211709},
{0.1213763,0.9333376,0.7261953},
{0.1228814,0.9361512,0.7317614},
{0.1249702,0.9395296,0.7360223},
{0.1259756,0.9424065,0.7407657},
{0.1272795,0.9454119,0.7449654},
{0.1312532,0.9475731,0.7492738},
{0.1334164,0.9487766,0.7544781},
{0.1355273,0.9501576,0.7588422},
{0.1375482,0.9506610,0.7638884},
{0.1408837,0.9514808,0.7671656},
{0.1415410,0.9517663,0.7710473},
{0.1439643,0.9514938,0.7751279},
{0.1450710,0.9511670,0.7786384},
{0.1467852,0.9498617,0.7831256},
{0.1487709,0.9494831,0.7859177},
{0.1494138,0.9490746,0.7890866},
{0.1500839,0.9480456,0.7920842},
{0.1503450,0.9473541,0.7945224},
{0.1534635,0.9465993,0.7963371},
{0.1530335,0.9459905,0.7981471}
};
inPtsRShWam = {
{0.5258723,0.9744899,0.2026314},
{0.5256754,0.9743089,0.2019027},
{0.5264408,0.9733252,0.2011262},
{0.5274547,0.9723279,0.1995003},
{0.5281901,0.9716332,0.1973699},
{0.5283663,0.9707686,0.1972997},
{0.5286774,0.9702970,0.1956511},
{0.5288403,0.9698963,0.1944009},
{0.5329140,0.9660764,0.1997806},
{0.5354069,0.9643465,0.1994501},
{0.5386612,0.9617540,0.2018809},
{0.5424053,0.9587115,0.2050097},
{0.5462807,0.9556053,0.2086133},
{0.5501635,0.9525387,0.2120739},
{0.5565713,0.9479649,0.2155002},
{0.5628588,0.9430931,0.2208222},
{0.5680964,0.9391389,0.2243419},
{0.5718712,0.9360910,0.2275732},
{0.5757272,0.9335493,0.2291095},
{0.5806895,0.9303267,0.2313399},
{0.5853885,0.9276036,0.2329973},
{0.5923272,0.9232484,0.2363314},
{0.5993554,0.9195084,0.2373415},
{0.6079231,0.9149484,0.2378187},
{0.6154621,0.9111705,0.2375741},
{0.6231765,0.9070629,0.2375303},
{0.6228952,0.9085796,0.2372230},
{0.6162491,0.9117760,0.2458073},
{0.6133599,0.9121760,0.2557476},
{0.6109090,0.9125988,0.2641997},
{0.6096217,0.9114413,0.2757526},
{0.6095570,0.9093825,0.2873458},
{0.6069935,0.9091031,0.2983950},
{0.6059647,0.9082682,0.3076592},
{0.6043427,0.9076661,0.3190963},
{0.6032926,0.9056489,0.3311324},
{0.6041021,0.9030021,0.3411206},
{0.6031836,0.9013397,0.3514661},
{0.6038766,0.8981531,0.3629547},
{0.6008934,0.8969717,0.3751805},
{0.6030556,0.8934089,0.3838109},
{0.6105154,0.8896218,0.3846186},
{0.6111344,0.8867183,0.3937119},
{0.6119637,0.8834999,0.4028934},
{0.6151338,0.8790715,0.4110007},
{0.6152451,0.8761077,0.4203179},
{0.6171829,0.8732935,0.4264887},
{0.6168359,0.8709309,0.4346174},
{0.6178069,0.8688744,0.4400207},
{0.6171373,0.8672277,0.4467225},
{0.6162852,0.8661902,0.4522391},
{0.6151493,0.8650449,0.4584389},
{0.6143814,0.8645941,0.4628268},
{0.6150547,0.8628203,0.4677787},
{0.6154716,0.8610397,0.4731810},
{0.6169518,0.8588667,0.4780049},
{0.6174671,0.8568745,0.4836379},
{0.6175760,0.8552793,0.4889668},
{0.6130749,0.8626183,0.4842625},
{0.6161613,0.8571832,0.4926019},
{0.6199477,0.8521718,0.4991840},
{0.6224169,0.8466977,0.5079460},
{0.6250562,0.8432396,0.5131372},
{0.6250403,0.8414333,0.5188617},
{0.6271101,0.8375916,0.5254313},
{0.6270347,0.8354896,0.5314526},
{0.6287233,0.8328069,0.5364761},
{0.6295399,0.8306005,0.5417224},
{0.6306584,0.8268790,0.5487123},
{0.6258054,0.8251289,0.5593294},
{0.6401433,0.8118293,0.5651505},
{0.6395479,0.8108009,0.5699607},
{0.6393727,0.8100750,0.5736642},
{0.6387846,0.8080056,0.5796320},
{0.6394001,0.8061894,0.5840035},
{0.6392356,0.8046167,0.5886379},
{0.6401031,0.8024578,0.5929990},
{0.6399579,0.8005433,0.5977902},
{0.6415928,0.7993393,0.6000421},
{0.6405198,0.7987158,0.6042651},
{0.6405653,0.7969945,0.6087218},
{0.6411663,0.7958563,0.6119274},
{0.6408482,0.7952273,0.6152889},
{0.6408507,0.7940807,0.6190944},
{0.6431416,0.7914990,0.6223441},
{0.6440060,0.7884384,0.6276318},
{0.6449268,0.7865503,0.6313873},
{0.6458472,0.7837838,0.6362791},
{0.6481076,0.7810924,0.6399191},
{0.6482525,0.7792468,0.6446335},
{0.6497766,0.7755736,0.6498043},
{0.6504628,0.7736476,0.6538745},
{0.6515799,0.7701161,0.6591342},
{0.6530219,0.7679411,0.6623319},
{0.6533073,0.7660196,0.6662769},
{0.6538169,0.7640106,0.6700834},
{0.6539708,0.7622777,0.6736597},
{0.6565129,0.7599259,0.6755304},
{0.6562141,0.7589065,0.6785277}
};
shoToUaVsWam = {
{-0.3938006,-0.3705459,-0.1005826},
{-0.3948034,-0.3695158,-0.1004407},
{-0.3965285,-0.3677113,-0.1002672},
{-0.3986010,-0.3656589,-0.0995528},
{-0.4008618,-0.3634268,-0.0986446},
{-0.4031109,-0.3609329,-0.0986362},
{-0.4057808,-0.3580799,-0.0980850},
{-0.4087193,-0.3549036,-0.0974265},
{-0.4132201,-0.3492220,-0.0989604},
{-0.4174501,-0.3444710,-0.0978528},
{-0.4218082,-0.3392198,-0.0975082},
{-0.4263963,-0.3334321,-0.0975150},
{-0.4310397,-0.3275073,-0.0971788},
{-0.4358662,-0.3212874,-0.0964109},
{-0.4416850,-0.3136535,-0.0950574},
{-0.4474944,-0.3054195,-0.0946977},
{-0.4532002,-0.2974845,-0.0928035},
{-0.4584396,-0.2898569,-0.0911925},
{-0.4635210,-0.2827381,-0.0877920},
{-0.4686856,-0.2751933,-0.0842762},
{-0.4733612,-0.2683002,-0.0802754},
{-0.4783310,-0.2605870,-0.0761178},
{-0.4831411,-0.2531332,-0.0706980},
{-0.4881207,-0.2450988,-0.0645352},
{-0.4927746,-0.2374525,-0.0573541},
{-0.4972569,-0.2297068,-0.0497027},
{-0.4997187,-0.2257840,-0.0424598},
{-0.5012567,-0.2224015,-0.0421815},
{-0.5029948,-0.2184163,-0.0423147},
{-0.5052108,-0.2134711,-0.0411352},
{-0.5075882,-0.2076244,-0.0417898},
{-0.5103565,-0.2007825,-0.0415042},
{-0.5124847,-0.1952932,-0.0414727},
{-0.5148997,-0.1891908,-0.0398136},
{-0.5169122,-0.1836955,-0.0394684},
{-0.5192234,-0.1773355,-0.0381993},
{-0.5216915,-0.1704997,-0.0356060},
{-0.5237280,-0.1645819,-0.0334928},
{-0.5258802,-0.1580303,-0.0312483},
{-0.5274619,-0.1530063,-0.0295465},
{-0.5298342,-0.1452045,-0.0262948},
{-0.5329823,-0.1338259,-0.0228132},
{-0.5349841,-0.1260421,-0.0201338},
{-0.5369075,-0.1180206,-0.0173615},
{-0.5390034,-0.1086829,-0.0127832},
{-0.5406667,-0.1003838,-0.0101288},
{-0.5422026,-0.0921184,-0.0055269},
{-0.5435738,-0.0837882,-0.0026563},
{-0.5447842,-0.0755357,0.0021186},
{-0.5458055,-0.0675378,0.0059163},
{-0.5466322,-0.0598818,0.0103620},
{-0.5472868,-0.0526381,0.0143655},
{-0.5477156,-0.0460775,0.0196072},
{-0.5481531,-0.0380902,0.0240271},
{-0.5483779,-0.0308073,0.0288552},
{-0.5484755,-0.0230339,0.0338248},
{-0.5484200,-0.0157156,0.0385819},
{-0.5482365,-0.0083667,0.0432060},
{-0.5478261,-0.0035395,0.0487237},
{-0.5473764,0.0057523,0.0533481},
{-0.5465684,0.0143150,0.0596492},
{-0.5458023,0.0234429,0.0636422},
{-0.5447164,0.0315075,0.0692196},
{-0.5436785,0.0378249,0.0740471},
{-0.5425595,0.0459562,0.0775708},
{-0.5413816,0.0524758,0.0815611},
{-0.5399672,0.0594291,0.0860442},
{-0.5385914,0.0660170,0.0897831},
{-0.5371885,0.0733353,0.0924688},
{-0.5361828,0.0756162,0.0963857},
{-0.5333047,0.0906650,0.0993274},
{-0.5318825,0.0964464,0.1014848},
{-0.5303394,0.1007534,0.1053038},
{-0.5289036,0.1055950,0.1077530},
{-0.5272594,0.1104041,0.1109435},
{-0.5256876,0.1153232,0.1133717},
{-0.5239787,0.1199174,0.1164738},
{-0.5223545,0.1252361,0.1181598},
{-0.5205191,0.1299528,0.1211288},
{-0.5191435,0.1346218,0.1219302},
{-0.5176840,0.1391566,0.1230396},
{-0.5161961,0.1436733,0.1240949},
{-0.5148727,0.1471792,0.1254768},
{-0.5135712,0.1513312,0.1258710},
{-0.5118884,0.1560741,0.1269297},
{-0.5105895,0.1603382,0.1268463},
{-0.5093995,0.1636073,0.1274549},
{-0.5082990,0.1668771,0.1276093},
{-0.5072239,0.1703884,0.1272465},
{-0.5067115,0.1725196,0.1264138},
{-0.5058123,0.1759202,0.1253236},
{-0.5053918,0.1775194,0.1247639},
{-0.5047947,0.1797456,0.1239914},
{-0.5042510,0.1815420,0.1235858},
{-0.5038935,0.1830550,0.1228097},
{-0.5037330,0.1840350,0.1220008},
{-0.5036258,0.1850764,0.1208627},
{-0.5030495,0.1866735,0.1208067},
{-0.5031806,0.1870841,0.1196195}
};
elOffsetVsWam = {
{0.0255200,-0.0183859,-0.0321821},
{0.0255737,-0.0186253,-0.0320014},
{0.0255720,-0.0188924,-0.0318457},
{0.0255410,-0.0192182,-0.0316752},
{0.0255202,-0.0196126,-0.0314495},
{0.0255304,-0.0199860,-0.0312051},
{0.0255296,-0.0204688,-0.0308913},
{0.0255274,-0.0210199,-0.0305207},
{0.0254102,-0.0214816,-0.0302963},
{0.0252571,-0.0220902,-0.0299850},
{0.0250686,-0.0226215,-0.0297462},
{0.0248601,-0.0231629,-0.0295035},
{0.0245968,-0.0236727,-0.0293190},
{0.0242885,-0.0242063,-0.0291397},
{0.0238538,-0.0248029,-0.0289967},
{0.0234350,-0.0254004,-0.0288205},
{0.0229555,-0.0260377,-0.0286372},
{0.0225189,-0.0266852,-0.0283866},
{0.0219909,-0.0272868,-0.0282283},
{0.0214070,-0.0278428,-0.0281339},
{0.0208201,-0.0283284,-0.0280896},
{0.0201352,-0.0287277,-0.0281832},
{0.0194088,-0.0291528,-0.0282562},
{0.0185978,-0.0295681,-0.0283699},
{0.0177560,-0.0299666,-0.0284908},
{0.0168727,-0.0303267,-0.0286461},
{0.0162715,-0.0306191,-0.0286829},
{0.0161239,-0.0309530,-0.0284065},
{0.0159227,-0.0311946,-0.0282553},
{0.0156053,-0.0315239,-0.0280663},
{0.0153033,-0.0317907,-0.0279314},
{0.0148829,-0.0320770,-0.0278310},
{0.0145641,-0.0323368,-0.0276987},
{0.0141124,-0.0325934,-0.0276317},
{0.0137566,-0.0327834,-0.0275863},
{0.0132748,-0.0329060,-0.0276763},
{0.0127026,-0.0330728,-0.0277459},
{0.0122043,-0.0331674,-0.0278564},
{0.0116466,-0.0332118,-0.0280416},
{0.0112148,-0.0332122,-0.0282166},
{0.0105434,-0.0333431,-0.0283209},
{0.0096948,-0.0338303,-0.0280449},
{0.0090612,-0.0339743,-0.0280827},
{0.0084095,-0.0341228,-0.0281054},
{0.0075795,-0.0342784,-0.0281521},
{0.0069248,-0.0344617,-0.0280970},
{0.0061780,-0.0346835,-0.0279980},
{0.0055208,-0.0349338,-0.0278236},
{0.0047754,-0.0352157,-0.0276052},
{0.0040952,-0.0354923,-0.0273592},
{0.0034098,-0.0358063,-0.0270423},
{0.0027693,-0.0360896,-0.0267371},
{0.0021175,-0.0363956,-0.0263795},
{0.0014120,-0.0367115,-0.0259860},
{0.0007295,-0.0369851,-0.0256237},
{0.0000097,-0.0372675,-0.0252216},
{-0.0006666,-0.0375603,-0.0247745},
{-0.0013374,-0.0378514,-0.0242998},
{-0.0018332,-0.0383936,-0.0234003},
{-0.0026586,-0.0385112,-0.0231262},
{-0.0035011,-0.0386325,-0.0228095},
{-0.0042917,-0.0387058,-0.0225487},
{-0.0050655,-0.0388177,-0.0221930},
{-0.0056868,-0.0389104,-0.0218779},
{-0.0063820,-0.0389923,-0.0215376},
{-0.0069804,-0.0390801,-0.0211901},
{-0.0076293,-0.0391475,-0.0208390},
{-0.0082240,-0.0392010,-0.0205098},
{-0.0088355,-0.0392137,-0.0202293},
{-0.0091536,-0.0391540,-0.0202034},
{-0.0103457,-0.0389761,-0.0199707},
{-0.0108278,-0.0389819,-0.0197021},
{-0.0112713,-0.0389662,-0.0194832},
{-0.0117025,-0.0389389,-0.0192825},
{-0.0121564,-0.0389161,-0.0190462},
{-0.0125878,-0.0388993,-0.0187987},
{-0.0130185,-0.0388864,-0.0185302},
{-0.0134479,-0.0388739,-0.0182477},
{-0.0138727,-0.0388907,-0.0178904},
{-0.0142206,-0.0388968,-0.0176016},
{-0.0145743,-0.0388798,-0.0173479},
{-0.0149208,-0.0388789,-0.0170529},
{-0.0152073,-0.0388794,-0.0167967},
{-0.0155103,-0.0388590,-0.0165652},
{-0.0158847,-0.0387962,-0.0163565},
{-0.0161963,-0.0387020,-0.0162737},
{-0.0164508,-0.0386549,-0.0161297},
{-0.0167018,-0.0385575,-0.0161050},
{-0.0169507,-0.0384690,-0.0160565},
{-0.0170862,-0.0383960,-0.0160876},
{-0.0173096,-0.0382771,-0.0161320},
{-0.0174186,-0.0381904,-0.0162200},
{-0.0175723,-0.0380529,-0.0163766},
{-0.0177005,-0.0379531,-0.0164698},
{-0.0177983,-0.0378394,-0.0166254},
{-0.0178550,-0.0377362,-0.0167981},
{-0.0179030,-0.0376397,-0.0169628},
{-0.0180288,-0.0375163,-0.0171024},
{-0.0180273,-0.0374305,-0.0172910}
};
wOffsetVsWam = {
{-0.0392072,-0.0217565,0.0038010},
{-0.0392869,-0.0216291,0.0037046},
{-0.0393911,-0.0214580,0.0035910},
{-0.0395102,-0.0212513,0.0035106},
{-0.0396261,-0.0210573,0.0033711},
{-0.0397371,-0.0208860,0.0031207},
{-0.0398606,-0.0206882,0.0028519},
{-0.0399691,-0.0205245,0.0024935},
{-0.0401663,-0.0201875,0.0020330},
{-0.0403101,-0.0199298,0.0017021},
{-0.0404486,-0.0196762,0.0013271},
{-0.0405943,-0.0193977,0.0009138},
{-0.0407135,-0.0191611,0.0005108},
{-0.0408252,-0.0189284,0.0001201},
{-0.0409611,-0.0186311,-0.0002657},
{-0.0410904,-0.0183300,-0.0007680},
{-0.0411860,-0.0180921,-0.0011810},
{-0.0412645,-0.0178785,-0.0016133},
{-0.0413388,-0.0176844,-0.0018355},
{-0.0414527,-0.0174018,-0.0019632},
{-0.0415607,-0.0171390,-0.0019913},
{-0.0417150,-0.0167673,-0.0019271},
{-0.0418603,-0.0164194,-0.0017660},
{-0.0420336,-0.0159969,-0.0015088},
{-0.0421689,-0.0156624,-0.0012136},
{-0.0423013,-0.0153245,-0.0008731},
{-0.0423070,-0.0153223,-0.0005914},
{-0.0422763,-0.0153902,-0.0009276},
{-0.0423075,-0.0152879,-0.0011646},
{-0.0423386,-0.0151847,-0.0013654},
{-0.0424109,-0.0149524,-0.0016540},
{-0.0425068,-0.0146517,-0.0018712},
{-0.0425544,-0.0144787,-0.0021194},
{-0.0426286,-0.0142439,-0.0022171},
{-0.0426997,-0.0140042,-0.0023709},
{-0.0427957,-0.0136953,-0.0024435},
{-0.0429156,-0.0133245,-0.0023900},
{-0.0430177,-0.0129986,-0.0023488},
{-0.0431473,-0.0125780,-0.0022601},
{-0.0432112,-0.0123533,-0.0022770},
{-0.0433390,-0.0119153,-0.0021811},
{-0.0435388,-0.0111857,-0.0020626},
{-0.0436420,-0.0107811,-0.0020353},
{-0.0437479,-0.0103510,-0.0019941},
{-0.0438672,-0.0098621,-0.0018449},
{-0.0439691,-0.0094053,-0.0018042},
{-0.0440785,-0.0089222,-0.0015750},
{-0.0441695,-0.0084718,-0.0015104},
{-0.0442649,-0.0080019,-0.0012615},
{-0.0443486,-0.0075514,-0.0010851},
{-0.0444215,-0.0071415,-0.0008545},
{-0.0444889,-0.0067336,-0.0006325},
{-0.0445535,-0.0063184,-0.0002536},
{-0.0446225,-0.0058161,0.0000436},
{-0.0446827,-0.0053186,0.0004105},
{-0.0447377,-0.0047866,0.0007912},
{-0.0447796,-0.0042945,0.0011593},
{-0.0448131,-0.0038060,0.0015176},
{-0.0448141,-0.0035837,0.0019634},
{-0.0448430,-0.0029924,0.0022687},
{-0.0448513,-0.0024109,0.0027474},
{-0.0448623,-0.0017741,0.0030376},
{-0.0448493,-0.0012250,0.0034692},
{-0.0448274,-0.0007767,0.0038604},
{-0.0448048,-0.0001157,0.0041849},
{-0.0447666,0.0004303,0.0045574},
{-0.0447090,0.0010638,0.0049972},
{-0.0446427,0.0017100,0.0053948},
{-0.0445713,0.0024242,0.0057025},
{-0.0445035,0.0027270,0.0060828},
{-0.0443531,0.0040927,0.0064074},
{-0.0442537,0.0046969,0.0066746},
{-0.0441280,0.0052308,0.0070962},
{-0.0440013,0.0058270,0.0074117},
{-0.0438456,0.0064535,0.0078046},
{-0.0436872,0.0070900,0.0081339},
{-0.0435111,0.0076983,0.0085157},
{-0.0433406,0.0083470,0.0087702},
{-0.0431438,0.0089546,0.0091340},
{-0.0430010,0.0094787,0.0092773},
{-0.0428497,0.0099891,0.0094406},
{-0.0427047,0.0104626,0.0095836},
{-0.0425759,0.0108343,0.0097422},
{-0.0424597,0.0112273,0.0098042},
{-0.0423091,0.0116811,0.0099243},
{-0.0421908,0.0120863,0.0099426},
{-0.0420791,0.0124086,0.0100187},
{-0.0419781,0.0127215,0.0100501},
{-0.0418703,0.0130737,0.0100480},
{-0.0418381,0.0132336,0.0099724},
{-0.0417726,0.0135074,0.0098792},
{-0.0417530,0.0136115,0.0098191},
{-0.0416946,0.0138274,0.0097654},
{-0.0416488,0.0139863,0.0097343},
{-0.0416012,0.0141592,0.0096878},
{-0.0415654,0.0142951,0.0096419},
{-0.0415250,0.0144546,0.0095782},
{-0.0414492,0.0146550,0.0096019},
{-0.0414267,0.0147619,0.0095350}
};
laToWrVsWam = {
{0.0822449,-0.1866477,-0.2199964},
{0.0827251,-0.1877498,-0.2188757},
{0.0829544,-0.1887521,-0.2179248},
{0.0829669,-0.1900624,-0.2167781},
{0.0834657,-0.1915328,-0.2152874},
{0.0844752,-0.1926759,-0.2138690},
{0.0856746,-0.1942859,-0.2119265},
{0.0875345,-0.1959319,-0.2096387},
{0.0882890,-0.1966752,-0.2086239},
{0.0893380,-0.1983396,-0.2065916},
{0.0902827,-0.1994306,-0.2051255},
{0.0912219,-0.2004985,-0.2036637},
{0.0921739,-0.2012496,-0.2024910},
{0.0930941,-0.2020640,-0.2012551},
{0.0936040,-0.2029376,-0.2001365},
{0.0945869,-0.2037033,-0.1988926},
{0.0955916,-0.2047280,-0.1973542},
{0.0968953,-0.2060086,-0.1953759},
{0.0972896,-0.2073076,-0.1937996},
{0.0967082,-0.2086317,-0.1926664},
{0.0957230,-0.2098292,-0.1918563},
{0.0935529,-0.2106827,-0.1919913},
{0.0911697,-0.2117889,-0.1919206},
{0.0879474,-0.2129701,-0.1921172},
{0.0850082,-0.2139710,-0.1923279},
{0.0817939,-0.2147963,-0.1928012},
{0.0807065,-0.2154086,-0.1925762},
{0.0829124,-0.2162658,-0.1906690},
{0.0836049,-0.2169215,-0.1896188},
{0.0842172,-0.2178928,-0.1882291},
{0.0843900,-0.2186467,-0.1872750},
{0.0838722,-0.2195075,-0.1864990},
{0.0841721,-0.2202372,-0.1855011},
{0.0834655,-0.2210126,-0.1848971},
{0.0829093,-0.2215625,-0.1844888},
{0.0815042,-0.2216866,-0.1849652},
{0.0793081,-0.2221981,-0.1853057},
{0.0773413,-0.2223550,-0.1859478},
{0.0746079,-0.2223110,-0.1871135},
{0.0733332,-0.2218271,-0.1881887},
{0.0705923,-0.2222043,-0.1887908},
{0.0666633,-0.2250198,-0.1868746},
{0.0644356,-0.2255238,-0.1870483},
{0.0620323,-0.2261233,-0.1871370},
{0.0588585,-0.2267471,-0.1874071},
{0.0563810,-0.2277039,-0.1870083},
{0.0530174,-0.2290214,-0.1863822},
{0.0505470,-0.2305158,-0.1852228},
{0.0472355,-0.2323132,-0.1838461},
{0.0443233,-0.2341144,-0.1822797},
{0.0414385,-0.2361818,-0.1802803},
{0.0385750,-0.2381098,-0.1783695},
{0.0350772,-0.2402708,-0.1761803},
{0.0314433,-0.2425441,-0.1737345},
{0.0275369,-0.2445822,-0.1715262},
{0.0234064,-0.2467125,-0.1690713},
{0.0195648,-0.2489078,-0.1663194},
{0.0157935,-0.2511053,-0.1633912},
{0.0134698,-0.2548471,-0.1577071},
{0.0091811,-0.2559842,-0.1561660},
{0.0043642,-0.2571664,-0.1544228},
{-0.0001499,-0.2580843,-0.1529459},
{-0.0045944,-0.2592258,-0.1509334},
{-0.0083353,-0.2601701,-0.1491377},
{-0.0130620,-0.2611534,-0.1470657},
{-0.0172762,-0.2620859,-0.1449569},
{-0.0222166,-0.2628934,-0.1428057},
{-0.0270998,-0.2635625,-0.1407139},
{-0.0321252,-0.2639728,-0.1388753},
{-0.0351236,-0.2636391,-0.1387832},
{-0.0441041,-0.2630939,-0.1372458},
{-0.0483687,-0.2632948,-0.1354117},
{-0.0527356,-0.2632241,-0.1339106},
{-0.0571424,-0.2630525,-0.1324316},
{-0.0619482,-0.2628402,-0.1306807},
{-0.0666029,-0.2626294,-0.1288015},
{-0.0712381,-0.2623948,-0.1267837},
{-0.0757126,-0.2621701,-0.1246371},
{-0.0802212,-0.2620728,-0.1219934},
{-0.0836120,-0.2619952,-0.1198647},
{-0.0870105,-0.2617454,-0.1179767},
{-0.0901034,-0.2616433,-0.1158628},
{-0.0926524,-0.2615539,-0.1140399},
{-0.0950742,-0.2613877,-0.1124162},
{-0.0980579,-0.2609180,-0.1109344},
{-0.1005423,-0.2602448,-0.1102901},
{-0.1026420,-0.2598647,-0.1092473},
{-0.1046391,-0.2591663,-0.1090114},
{-0.1067645,-0.2584818,-0.1085748},
{-0.1075582,-0.2580580,-0.1087994},
{-0.1090075,-0.2573246,-0.1090936},
{-0.1095319,-0.2568342,-0.1097222},
{-0.1107848,-0.2558737,-0.1107041},
{-0.1117169,-0.2552075,-0.1113035},
{-0.1127109,-0.2543535,-0.1122521},
{-0.1134809,-0.2535435,-0.1133039},
{-0.1143305,-0.2527281,-0.1142674},
{-0.1156686,-0.2517472,-0.1150830},
{-0.1161852,-0.2509914,-0.1162081}
};
elToWrVsWam = {
{0.0430377,-0.2084042,-0.2161954},
{0.0434382,-0.2093788,-0.2151712},
{0.0435632,-0.2102101,-0.2143338},
{0.0434566,-0.2113137,-0.2132675},
{0.0438396,-0.2125901,-0.2119163},
{0.0447381,-0.2135618,-0.2107483},
{0.0458141,-0.2149742,-0.2090746},
{0.0475654,-0.2164564,-0.2071452},
{0.0481227,-0.2168626,-0.2065909},
{0.0490279,-0.2182695,-0.2048895},
{0.0498341,-0.2191068,-0.2037984},
{0.0506276,-0.2198962,-0.2027499},
{0.0514603,-0.2204106,-0.2019802},
{0.0522689,-0.2209925,-0.2011350},
{0.0526429,-0.2215687,-0.2004021},
{0.0534965,-0.2220333,-0.1996606},
{0.0544056,-0.2228201,-0.1985352},
{0.0556309,-0.2238871,-0.1969893},
{0.0559509,-0.2249920,-0.1956351},
{0.0552555,-0.2260335,-0.1946297},
{0.0541623,-0.2269682,-0.1938476},
{0.0518379,-0.2274500,-0.1939184},
{0.0493094,-0.2282084,-0.1936866},
{0.0459139,-0.2289670,-0.1936260},
{0.0428393,-0.2296334,-0.1935415},
{0.0394927,-0.2301208,-0.1936743},
{0.0383996,-0.2307309,-0.1931676},
{0.0406361,-0.2316559,-0.1915965},
{0.0412974,-0.2322094,-0.1907834},
{0.0418785,-0.2330775,-0.1895945},
{0.0419791,-0.2335992,-0.1889291},
{0.0413655,-0.2341593,-0.1883702},
{0.0416178,-0.2347159,-0.1876204},
{0.0408369,-0.2352565,-0.1871142},
{0.0402096,-0.2355667,-0.1868596},
{0.0387086,-0.2353819,-0.1874087},
{0.0363925,-0.2355226,-0.1876957},
{0.0343236,-0.2353536,-0.1882965},
{0.0314606,-0.2348890,-0.1893736},
{0.0301220,-0.2341804,-0.1904657},
{0.0272533,-0.2341196,-0.1909719},
{0.0231245,-0.2362054,-0.1889372},
{0.0207936,-0.2363049,-0.1890836},
{0.0182844,-0.2364743,-0.1891311},
{0.0149912,-0.2366092,-0.1892520},
{0.0124119,-0.2371092,-0.1888125},
{0.0089389,-0.2379437,-0.1879572},
{0.0063775,-0.2389876,-0.1867332},
{0.0029706,-0.2403151,-0.1851076},
{-0.0000253,-0.2416657,-0.1833649},
{-0.0029830,-0.2433234,-0.1811348},
{-0.0059139,-0.2448434,-0.1790021},
{-0.0094763,-0.2465893,-0.1764340},
{-0.0131792,-0.2483602,-0.1736909},
{-0.0171458,-0.2499009,-0.1711157},
{-0.0213313,-0.2514991,-0.1682801},
{-0.0252148,-0.2532022,-0.1651600},
{-0.0290196,-0.2549114,-0.1618736},
{-0.0313443,-0.2584307,-0.1557437},
{-0.0356620,-0.2589766,-0.1538972},
{-0.0404871,-0.2595773,-0.1516754},
{-0.0450122,-0.2598584,-0.1499083},
{-0.0494438,-0.2604508,-0.1474642},
{-0.0531627,-0.2609468,-0.1452774},
{-0.0578669,-0.2612691,-0.1428807},
{-0.0620428,-0.2616556,-0.1403995},
{-0.0669256,-0.2618297,-0.1378085},
{-0.0717426,-0.2618525,-0.1353191},
{-0.0766966,-0.2615486,-0.1331727},
{-0.0796271,-0.2609121,-0.1327005},
{-0.0884571,-0.2590013,-0.1308384},
{-0.0926223,-0.2585979,-0.1287371},
{-0.0968636,-0.2579933,-0.1268144},
{-0.1011437,-0.2572255,-0.1250199},
{-0.1057938,-0.2563867,-0.1228761},
{-0.1102901,-0.2555395,-0.1206676},
{-0.1147492,-0.2546965,-0.1182680},
{-0.1190532,-0.2538231,-0.1158669},
{-0.1233650,-0.2531182,-0.1128593},
{-0.1266130,-0.2525165,-0.1105874},
{-0.1298602,-0.2517563,-0.1085361},
{-0.1328080,-0.2511807,-0.1062792},
{-0.1352283,-0.2507196,-0.1042977},
{-0.1375339,-0.2501604,-0.1026119},
{-0.1403671,-0.2492369,-0.1010101},
{-0.1427331,-0.2481585,-0.1003475},
{-0.1447211,-0.2474561,-0.0992285},
{-0.1466172,-0.2464448,-0.0989613},
{-0.1486348,-0.2454082,-0.0985268},
{-0.1493963,-0.2448244,-0.0988270},
{-0.1507802,-0.2438172,-0.0992144},
{-0.1512849,-0.2432227,-0.0999030},
{-0.1524794,-0.2420463,-0.1009387},
{-0.1533657,-0.2412212,-0.1015692},
{-0.1543121,-0.2401944,-0.1025643},
{-0.1550464,-0.2392484,-0.1036620},
{-0.1558554,-0.2382735,-0.1046892},
{-0.1571178,-0.2370923,-0.1054811},
{-0.1576119,-0.2362295,-0.1066730}
};
wrToEeVsWam = {
{-0.0112264,-0.0509739,0.0295910},
{-0.0115502,-0.0509895,0.0294392},
{-0.0127669,-0.0508488,0.0291789},
{-0.0131645,-0.0508115,0.0290670},
{-0.0137255,-0.0506563,0.0290784},
{-0.0142143,-0.0505151,0.0290892},
{-0.0145516,-0.0503971,0.0291270},
{-0.0153955,-0.0501247,0.0291632},
{-0.0163908,-0.0500468,0.0287517},
{-0.0172415,-0.0498257,0.0286380},
{-0.0182405,-0.0496492,0.0283239},
{-0.0192796,-0.0493906,0.0280868},
{-0.0202924,-0.0491558,0.0277836},
{-0.0213495,-0.0489189,0.0274070},
{-0.0223466,-0.0487168,0.0269686},
{-0.0239013,-0.0482059,0.0265502},
{-0.0250472,-0.0478851,0.0260703},
{-0.0261321,-0.0475590,0.0255980},
{-0.0270630,-0.0472162,0.0252631},
{-0.0281329,-0.0467615,0.0249379},
{-0.0287220,-0.0465020,0.0247510},
{-0.0295092,-0.0461132,0.0245516},
{-0.0300460,-0.0457918,0.0245021},
{-0.0305503,-0.0455011,0.0244198},
{-0.0311109,-0.0451383,0.0243854},
{-0.0316917,-0.0447506,0.0243520},
{-0.0319203,-0.0445634,0.0243967},
{-0.0325697,-0.0443527,0.0239177},
{-0.0335542,-0.0439815,0.0232324},
{-0.0343559,-0.0436234,0.0227304},
{-0.0350791,-0.0432756,0.0222864},
{-0.0358740,-0.0429507,0.0216402},
{-0.0365467,-0.0425939,0.0212156},
{-0.0369560,-0.0423707,0.0209517},
{-0.0378964,-0.0418009,0.0204096},
{-0.0384050,-0.0414617,0.0201492},
{-0.0390341,-0.0410746,0.0197285},
{-0.0397673,-0.0405490,0.0193480},
{-0.0403674,-0.0401479,0.0189371},
{-0.0406247,-0.0399936,0.0187123},
{-0.0409663,-0.0396764,0.0186426},
{-0.0416281,-0.0388909,0.0188310},
{-0.0421425,-0.0383622,0.0187712},
{-0.0423824,-0.0380997,0.0187655},
{-0.0427196,-0.0376711,0.0188661},
{-0.0434088,-0.0369951,0.0186290},
{-0.0440186,-0.0362559,0.0186513},
{-0.0447092,-0.0354490,0.0185596},
{-0.0450767,-0.0348881,0.0187325},
{-0.0454603,-0.0342293,0.0190189},
{-0.0461422,-0.0332434,0.0191253},
{-0.0465491,-0.0325372,0.0193522},
{-0.0467656,-0.0320107,0.0197053},
{-0.0470076,-0.0313505,0.0201849},
{-0.0473272,-0.0304508,0.0208059},
{-0.0480736,-0.0290991,0.0210277},
{-0.0482117,-0.0284449,0.0215990},
{-0.0484243,-0.0277272,0.0220519},
{-0.0484224,-0.0269548,0.0229938},
{-0.0484289,-0.0262108,0.0238251},
{-0.0487414,-0.0251950,0.0242794},
{-0.0485147,-0.0247915,0.0251338},
{-0.0483532,-0.0240971,0.0261017},
{-0.0482464,-0.0234665,0.0268627},
{-0.0481047,-0.0227573,0.0277136},
{-0.0481556,-0.0218457,0.0283515},
{-0.0479986,-0.0212448,0.0290653},
{-0.0477847,-0.0206356,0.0298461},
{-0.0477271,-0.0198756,0.0304481},
{-0.0471154,-0.0200155,0.0312972},
{-0.0469223,-0.0188636,0.0322872},
{-0.0463011,-0.0185931,0.0333243},
{-0.0454421,-0.0183864,0.0345971},
{-0.0449228,-0.0179824,0.0354764},
{-0.0443126,-0.0175653,0.0364397},
{-0.0439808,-0.0170044,0.0371018},
{-0.0436376,-0.0163773,0.0377829},
{-0.0434006,-0.0157201,0.0383311},
{-0.0430816,-0.0150563,0.0389523},
{-0.0426144,-0.0145421,0.0396553},
{-0.0421518,-0.0141309,0.0402932},
{-0.0415183,-0.0138463,0.0410428},
{-0.0409709,-0.0136083,0.0416677},
{-0.0405423,-0.0131780,0.0422216},
{-0.0399235,-0.0127689,0.0429310},
{-0.0396378,-0.0122912,0.0433333},
{-0.0391816,-0.0120007,0.0438267},
{-0.0388343,-0.0117358,0.0442060},
{-0.0383340,-0.0114169,0.0447232},
{-0.0376974,-0.0112991,0.0452906},
{-0.0373227,-0.0112291,0.0456171},
{-0.0365884,-0.0114669,0.0461498},
{-0.0362028,-0.0116362,0.0464107},
{-0.0356529,-0.0117748,0.0467999},
{-0.0354110,-0.0118763,0.0469576},
{-0.0352291,-0.0118487,0.0471012},
{-0.0349562,-0.0120231,0.0472600},
{-0.0346476,-0.0121069,0.0474654},
{-0.0345277,-0.0121493,0.0475419}
};
shoToElVsWam = {
{-0.3682806,-0.3889318,-0.1327647},
{-0.3692298,-0.3881410,-0.1324421},
{-0.3709565,-0.3866038,-0.1321129},
{-0.3730600,-0.3848772,-0.1312279},
{-0.3753416,-0.3830394,-0.1300941},
{-0.3775805,-0.3809189,-0.1298413},
{-0.3802513,-0.3785487,-0.1289762},
{-0.3831919,-0.3759235,-0.1279472},
{-0.3878099,-0.3707036,-0.1292567},
{-0.3921930,-0.3665612,-0.1278378},
{-0.3967395,-0.3618412,-0.1272543},
{-0.4015362,-0.3565950,-0.1270185},
{-0.4064430,-0.3511801,-0.1264977},
{-0.4115777,-0.3454937,-0.1255506},
{-0.4178311,-0.3384564,-0.1240541},
{-0.4240594,-0.3308200,-0.1235182},
{-0.4302448,-0.3235222,-0.1214407},
{-0.4359208,-0.3165422,-0.1195790},
{-0.4415301,-0.3100249,-0.1160203},
{-0.4472785,-0.3030361,-0.1124102},
{-0.4525412,-0.2966286,-0.1083650},
{-0.4581957,-0.2893147,-0.1043010},
{-0.4637323,-0.2822860,-0.0989543},
{-0.4695229,-0.2746669,-0.0929050},
{-0.4750186,-0.2674191,-0.0858449},
{-0.4803843,-0.2600335,-0.0783488},
{-0.4834471,-0.2564031,-0.0711427},
{-0.4851328,-0.2533545,-0.0705880},
{-0.4870721,-0.2496109,-0.0705700},
{-0.4896055,-0.2449950,-0.0692015},
{-0.4922849,-0.2394150,-0.0697212},
{-0.4954736,-0.2328596,-0.0693352},
{-0.4979206,-0.2276300,-0.0691714},
{-0.5007873,-0.2217842,-0.0674453},
{-0.5031556,-0.2164789,-0.0670547},
{-0.5059485,-0.2102415,-0.0658755},
{-0.5089890,-0.2035725,-0.0633519},
{-0.5115237,-0.1977493,-0.0613493},
{-0.5142335,-0.1912422,-0.0592899},
{-0.5162471,-0.1862185,-0.0577631},
{-0.5192907,-0.1785476,-0.0546156},
{-0.5232875,-0.1676563,-0.0508581},
{-0.5259229,-0.1600164,-0.0482165},
{-0.5284980,-0.1521434,-0.0454669},
{-0.5314239,-0.1429613,-0.0409354},
{-0.5337420,-0.1348454,-0.0382258},
{-0.5360246,-0.1268019,-0.0335249},
{-0.5380530,-0.1187220,-0.0304799},
{-0.5400088,-0.1107515,-0.0254866},
{-0.5417102,-0.1030301,-0.0214430},
{-0.5432224,-0.0956881,-0.0166803},
{-0.5445175,-0.0887277,-0.0123716},
{-0.5455981,-0.0824731,-0.0067724},
{-0.5467411,-0.0748018,-0.0019588},
{-0.5476484,-0.0677923,0.0032316},
{-0.5484658,-0.0603014,0.0086032},
{-0.5490865,-0.0532760,0.0138074},
{-0.5495739,-0.0462182,0.0189061},
{-0.5496593,-0.0419331,0.0253234},
{-0.5500350,-0.0327588,0.0302219},
{-0.5500695,-0.0243175,0.0368397},
{-0.5500940,-0.0152629,0.0410935},
{-0.5497818,-0.0073102,0.0470265},
{-0.5493653,-0.0010855,0.0521692},
{-0.5489415,0.0069639,0.0560331},
{-0.5483620,0.0133957,0.0603710},
{-0.5475965,0.0202815,0.0652052},
{-0.5468154,0.0268160,0.0692734},
{-0.5460240,0.0341216,0.0722395},
{-0.5453364,0.0364622,0.0761823},
{-0.5436504,0.0516889,0.0793567},
{-0.5427103,0.0574645,0.0817827},
{-0.5416107,0.0617872,0.0858206},
{-0.5406061,0.0666561,0.0884705},
{-0.5394158,0.0714880,0.0918972},
{-0.5382753,0.0764238,0.0945730},
{-0.5369972,0.0810310,0.0979436},
{-0.5358023,0.0863622,0.0999121},
{-0.5343917,0.0910621,0.1032384},
{-0.5333641,0.0957250,0.1043287},
{-0.5322582,0.1002768,0.1056917},
{-0.5311169,0.1047944,0.1070420},
{-0.5300800,0.1082997,0.1086802},
{-0.5290815,0.1124722,0.1093058},
{-0.5277731,0.1172779,0.1105733},
{-0.5267859,0.1216362,0.1105726},
{-0.5258503,0.1249524,0.1113253},
{-0.5250008,0.1283197,0.1115043},
{-0.5241746,0.1319194,0.1111900},
{-0.5237977,0.1341236,0.1103262},
{-0.5231219,0.1376431,0.1091917},
{-0.5228103,0.1393290,0.1085439},
{-0.5223670,0.1416927,0.1076148},
{-0.5219515,0.1435889,0.1071160},
{-0.5216918,0.1452157,0.1061844},
{-0.5215880,0.1462988,0.1052027},
{-0.5215288,0.1474367,0.1038998},
{-0.5210783,0.1491572,0.1037043},
{-0.5212079,0.1496536,0.1023285}
};
shoToLaVsWam = {
{-0.4074878,-0.4106883,-0.1289637},
{-0.4085167,-0.4097701,-0.1287376},
{-0.4103476,-0.4080617,-0.1285219},
{-0.4125703,-0.4061284,-0.1277173},
{-0.4149677,-0.4040967,-0.1267230},
{-0.4173176,-0.4018049,-0.1267206},
{-0.4201118,-0.3992369,-0.1261243},
{-0.4231610,-0.3964480,-0.1254537},
{-0.4279762,-0.3908911,-0.1272237},
{-0.4325032,-0.3864910,-0.1261357},
{-0.4371881,-0.3815174,-0.1259272},
{-0.4421305,-0.3759927,-0.1261047},
{-0.4471565,-0.3703411,-0.1259869},
{-0.4524029,-0.3644221,-0.1254305},
{-0.4587922,-0.3570875,-0.1243198},
{-0.4651499,-0.3491499,-0.1242861},
{-0.4714307,-0.3416142,-0.1226217},
{-0.4771852,-0.3344207,-0.1211924},
{-0.4828689,-0.3277093,-0.1178558},
{-0.4887312,-0.3204379,-0.1143734},
{-0.4941018,-0.3137676,-0.1103563},
{-0.4999108,-0.3060820,-0.1062281},
{-0.5055926,-0.2987055,-0.1007203},
{-0.5115565,-0.2906638,-0.0944139},
{-0.5171875,-0.2830814,-0.0870585},
{-0.5226855,-0.2753580,-0.0792219},
{-0.5257541,-0.2717254,-0.0717341},
{-0.5274091,-0.2687447,-0.0715156},
{-0.5293796,-0.2648988,-0.0717347},
{-0.5319442,-0.2601797,-0.0705669},
{-0.5346958,-0.2543675,-0.0713752},
{-0.5379803,-0.2475113,-0.0712064},
{-0.5404749,-0.2421087,-0.0712907},
{-0.5434159,-0.2360280,-0.0696625},
{-0.5458553,-0.2304830,-0.0694256},
{-0.5487442,-0.2239368,-0.0683191},
{-0.5519046,-0.2168969,-0.0657419},
{-0.5545414,-0.2107479,-0.0636980},
{-0.5573808,-0.2038201,-0.0615501},
{-0.5594583,-0.1985719,-0.0600401},
{-0.5626297,-0.1904629,-0.0567967},
{-0.5668263,-0.1788419,-0.0529207},
{-0.5695649,-0.1707975,-0.0502518},
{-0.5722459,-0.1624945,-0.0474610},
{-0.5752911,-0.1528234,-0.0427803},
{-0.5777111,-0.1442507,-0.0400300},
{-0.5801031,-0.1357241,-0.0350999},
{-0.5822226,-0.1271937,-0.0319903},
{-0.5842737,-0.1187534,-0.0267481},
{-0.5860589,-0.1105815,-0.0225281},
{-0.5876439,-0.1028296,-0.0175348},
{-0.5890064,-0.0954613,-0.0130041},
{-0.5901516,-0.0887915,-0.0070260},
{-0.5913637,-0.0806178,-0.0019152},
{-0.5923311,-0.0731109,0.0036421},
{-0.5932035,-0.0650880,0.0093943},
{-0.5938662,-0.0575704,0.0149667},
{-0.5943869,-0.0500242,0.0204237},
{-0.5944734,-0.0455168,0.0272869},
{-0.5948780,-0.0357512,0.0324906},
{-0.5949208,-0.0267284,0.0395871},
{-0.5949563,-0.0170370,0.0441311},
{-0.5946312,-0.0085352,0.0504957},
{-0.5941927,-0.0018622,0.0560295},
{-0.5937464,0.0068482,0.0602181},
{-0.5931286,0.0138260,0.0649284},
{-0.5923055,0.0213453,0.0702023},
{-0.5914581,0.0285260,0.0746681},
{-0.5905953,0.0365458,0.0779421},
{-0.5898399,0.0391891,0.0822651},
{-0.5880035,0.0557816,0.0857641},
{-0.5869639,0.0621614,0.0884573},
{-0.5857387,0.0670180,0.0929168},
{-0.5846074,0.0724831,0.0958822},
{-0.5832614,0.0779416,0.0997019},
{-0.5819626,0.0835138,0.1027069},
{-0.5805084,0.0887293,0.1064592},
{-0.5791430,0.0947092,0.1086823},
{-0.5775355,0.1000167,0.1123724},
{-0.5763651,0.1052037,0.1136060},
{-0.5751079,0.1102659,0.1151323},
{-0.5738216,0.1152569,0.1166256},
{-0.5726559,0.1191341,0.1184223},
{-0.5715412,0.1236994,0.1191101},
{-0.5700822,0.1289590,0.1204975},
{-0.5689767,0.1337225,0.1205152},
{-0.5679294,0.1373610,0.1213440},
{-0.5669789,0.1410412,0.1215543},
{-0.5660449,0.1449931,0.1212379},
{-0.5656357,0.1473572,0.1202986},
{-0.5648946,0.1511505,0.1190709},
{-0.5645633,0.1529405,0.1183630},
{-0.5640616,0.1555201,0.1173802},
{-0.5636004,0.1575752,0.1168503},
{-0.5632930,0.1593748,0.1158722},
{-0.5631534,0.1605939,0.1148446},
{-0.5630537,0.1618913,0.1134780},
{-0.5625274,0.1638122,0.1133062},
{-0.5626346,0.1644156,0.1118635}
};
shoToWrVsWam = {
{-0.3252429,-0.5973360,-0.3489601},
{-0.3257916,-0.5975198,-0.3476133},
{-0.3273932,-0.5968138,-0.3464467},
{-0.3296034,-0.5961909,-0.3444955},
{-0.3315020,-0.5956295,-0.3420104},
{-0.3328423,-0.5944807,-0.3405896},
{-0.3344372,-0.5935228,-0.3380508},
{-0.3356265,-0.5923799,-0.3350925},
{-0.3396872,-0.5875663,-0.3358476},
{-0.3431652,-0.5848307,-0.3327273},
{-0.3469054,-0.5809480,-0.3310527},
{-0.3509086,-0.5764912,-0.3297684},
{-0.3549826,-0.5715907,-0.3284779},
{-0.3593088,-0.5664862,-0.3266856},
{-0.3651883,-0.5600251,-0.3244563},
{-0.3705629,-0.5528533,-0.3231787},
{-0.3758391,-0.5463423,-0.3199759},
{-0.3802899,-0.5404293,-0.3165683},
{-0.3855792,-0.5350169,-0.3116554},
{-0.3920230,-0.5290695,-0.3070398},
{-0.3983788,-0.5235968,-0.3022126},
{-0.4063578,-0.5167647,-0.2982194},
{-0.4144229,-0.5104944,-0.2926409},
{-0.4236090,-0.5036339,-0.2865310},
{-0.4321793,-0.4970525,-0.2793864},
{-0.4408916,-0.4901543,-0.2720231},
{-0.4450476,-0.4871340,-0.2643103},
{-0.4444967,-0.4850105,-0.2621845},
{-0.4457747,-0.4818203,-0.2613535},
{-0.4477270,-0.4780725,-0.2587960},
{-0.4503058,-0.4730142,-0.2586502},
{-0.4541081,-0.4670188,-0.2577054},
{-0.4563028,-0.4623459,-0.2567918},
{-0.4599504,-0.4570406,-0.2545596},
{-0.4629460,-0.4520456,-0.2539143},
{-0.4672400,-0.4456234,-0.2532843},
{-0.4725965,-0.4390951,-0.2510477},
{-0.4772001,-0.4331029,-0.2496458},
{-0.4827729,-0.4261312,-0.2486635},
{-0.4861251,-0.4203990,-0.2482288},
{-0.4920374,-0.4126673,-0.2455875},
{-0.5001630,-0.4038617,-0.2397953},
{-0.5051293,-0.3963213,-0.2373001},
{-0.5102136,-0.3886177,-0.2345980},
{-0.5164327,-0.3795706,-0.2301874},
{-0.5213301,-0.3719546,-0.2270383},
{-0.5270856,-0.3647455,-0.2214821},
{-0.5316756,-0.3577095,-0.2172130},
{-0.5370382,-0.3510666,-0.2105942},
{-0.5417355,-0.3446959,-0.2048078},
{-0.5462054,-0.3390114,-0.1978151},
{-0.5504314,-0.3335711,-0.1913737},
{-0.5550744,-0.3290623,-0.1832063},
{-0.5599204,-0.3231619,-0.1756497},
{-0.5647942,-0.3176932,-0.1678841},
{-0.5697971,-0.3118005,-0.1596769},
{-0.5743013,-0.3064782,-0.1513526},
{-0.5785935,-0.3011295,-0.1429675},
{-0.5810036,-0.3003639,-0.1304202},
{-0.5856970,-0.2917354,-0.1236754},
{-0.5905567,-0.2838948,-0.1148357},
{-0.5951062,-0.2751213,-0.1088149},
{-0.5992256,-0.2677610,-0.1004377},
{-0.6025280,-0.2620322,-0.0931082},
{-0.6068084,-0.2543052,-0.0868476},
{-0.6104048,-0.2482599,-0.0800286},
{-0.6145222,-0.2415482,-0.0726033},
{-0.6185580,-0.2350365,-0.0660457},
{-0.6227205,-0.2274269,-0.0609332},
{-0.6249635,-0.2244499,-0.0565181},
{-0.6321076,-0.2073123,-0.0514817},
{-0.6353326,-0.2011334,-0.0469544},
{-0.6384743,-0.1962061,-0.0409937},
{-0.6417497,-0.1905694,-0.0365494},
{-0.6452096,-0.1848986,-0.0309789},
{-0.6485655,-0.1791156,-0.0260946},
{-0.6517465,-0.1736655,-0.0203244},
{-0.6548556,-0.1674609,-0.0159549},
{-0.6577567,-0.1620561,-0.0096210},
{-0.6599771,-0.1567915,-0.0062587},
{-0.6621184,-0.1514795,-0.0028444},
{-0.6639249,-0.1463863,0.0007628},
{-0.6653082,-0.1424198,0.0043825},
{-0.6666154,-0.1376882,0.0066939},
{-0.6681402,-0.1319590,0.0095631},
{-0.6695190,-0.1265223,0.0102251},
{-0.6705715,-0.1225037,0.0120968},
{-0.6716180,-0.1181251,0.0125429},
{-0.6728094,-0.1134888,0.0126631},
{-0.6731940,-0.1107008,0.0114992},
{-0.6739021,-0.1061741,0.0099773},
{-0.6740952,-0.1038937,0.0086409},
{-0.6748464,-0.1003536,0.0066761},
{-0.6753172,-0.0976323,0.0055468},
{-0.6760039,-0.0949787,0.0036201},
{-0.6766344,-0.0929496,0.0015407},
{-0.6773842,-0.0908368,-0.0007894},
{-0.6781960,-0.0879351,-0.0017769},
{-0.6788198,-0.0865758,-0.0043445}
};
shoToThVsWam = {
{-0.3336665,-0.6037979,-0.4080133},
{-0.3337166,-0.6038612,-0.4067486},
{-0.3342098,-0.6027227,-0.4057647},
{-0.3359816,-0.6019647,-0.4038754},
{-0.3374713,-0.6015139,-0.4014220},
{-0.3382000,-0.6005369,-0.4000423},
{-0.3391233,-0.5997896,-0.3975384},
{-0.3395134,-0.5989800,-0.3946015},
{-0.3426493,-0.5939226,-0.3954364},
{-0.3452846,-0.5913634,-0.3923330},
{-0.3480991,-0.5875115,-0.3906807},
{-0.3510936,-0.5832157,-0.3893901},
{-0.3542467,-0.5783673,-0.3880894},
{-0.3575312,-0.5733637,-0.3862636},
{-0.3624774,-0.5669692,-0.3839914},
{-0.3665511,-0.5600699,-0.3826079},
{-0.3707035,-0.5536383,-0.3793088},
{-0.3739359,-0.5479030,-0.3757609},
{-0.3784141,-0.5426323,-0.3707372},
{-0.3841164,-0.5368736,-0.3660024},
{-0.3901578,-0.5314963,-0.3611194},
{-0.3979328,-0.5247745,-0.3570825},
{-0.4060290,-0.5185922,-0.3514964},
{-0.4151771,-0.5117591,-0.3453773},
{-0.4238243,-0.5052218,-0.3382375},
{-0.4325150,-0.4984104,-0.3308591},
{-0.4365379,-0.4956195,-0.3230945},
{-0.4349339,-0.4936449,-0.3207849},
{-0.4350675,-0.4905598,-0.3197399},
{-0.4363558,-0.4868378,-0.3170529},
{-0.4381314,-0.4820435,-0.3167041},
{-0.4412140,-0.4759643,-0.3156167},
{-0.4427791,-0.4714870,-0.3145287},
{-0.4459395,-0.4663720,-0.3121497},
{-0.4484546,-0.4614443,-0.3113744},
{-0.4522527,-0.4552540,-0.3105785},
{-0.4574184,-0.4485981,-0.3083130},
{-0.4617693,-0.4427102,-0.3068261},
{-0.4671604,-0.4355996,-0.3058177},
{-0.4704030,-0.4297502,-0.3053722},
{-0.4764207,-0.4220087,-0.3027614},
{-0.4845959,-0.4138419,-0.2968747},
{-0.4896284,-0.4065003,-0.2943625},
{-0.4948192,-0.3988387,-0.2916817},
{-0.5012015,-0.3899884,-0.2872793},
{-0.5060115,-0.3826239,-0.2840603},
{-0.5118112,-0.3758311,-0.2784365},
{-0.5162848,-0.3693109,-0.2740332},
{-0.5216735,-0.3631762,-0.2673153},
{-0.5263410,-0.3574578,-0.2613776},
{-0.5309119,-0.3524232,-0.2542618},
{-0.5352288,-0.3477435,-0.2476589},
{-0.5401522,-0.3439177,-0.2393904},
{-0.5453373,-0.3387092,-0.2317355},
{-0.5505919,-0.3342492,-0.2237786},
{-0.5558400,-0.3292195,-0.2153705},
{-0.5609387,-0.3244912,-0.2070031},
{-0.5656591,-0.3198654,-0.1984802},
{-0.5686092,-0.3203723,-0.1856112},
{-0.5740826,-0.3123843,-0.1788000},
{-0.5797358,-0.3049287,-0.1699763},
{-0.5850686,-0.2968141,-0.1638482},
{-0.5902375,-0.2900084,-0.1554310},
{-0.5943803,-0.2848331,-0.1480057},
{-0.5995521,-0.2776104,-0.1416583},
{-0.6040123,-0.2720452,-0.1347405},
{-0.6090075,-0.2657660,-0.1272210},
{-0.6139333,-0.2596903,-0.1205508},
{-0.6189699,-0.2523978,-0.1153611},
{-0.6221184,-0.2492821,-0.1110642},
{-0.6309602,-0.2323358,-0.1060025},
{-0.6353617,-0.2262549,-0.1014421},
{-0.6399500,-0.2214642,-0.0953983},
{-0.6444715,-0.2158495,-0.0908957},
{-0.6491345,-0.2102659,-0.0852108},
{-0.6534034,-0.2047309,-0.0801358},
{-0.6575471,-0.1994940,-0.0741690},
{-0.6613772,-0.1936221,-0.0695558},
{-0.6651916,-0.1884581,-0.0629844},
{-0.6681719,-0.1835561,-0.0593294},
{-0.6711102,-0.1784596,-0.0556764},
{-0.6738627,-0.1734987,-0.0518315},
{-0.6759480,-0.1696605,-0.0480078},
{-0.6779729,-0.1652008,-0.0454028},
{-0.6804975,-0.1597099,-0.0421784},
{-0.6822104,-0.1545809,-0.0412690},
{-0.6839036,-0.1507748,-0.0391185},
{-0.6852162,-0.1466593,-0.0384560},
{-0.6870212,-0.1422901,-0.0380173},
{-0.6879883,-0.1395397,-0.0389929},
{-0.6891794,-0.1348939,-0.0404388},
{-0.6900847,-0.1323957,-0.0416778},
{-0.6912988,-0.1286042,-0.0436352},
{-0.6923342,-0.1256669,-0.0446974},
{-0.6932395,-0.1228754,-0.0466264},
{-0.6941422,-0.1207144,-0.0486847},
{-0.6951135,-0.1184367,-0.0510280},
{-0.6962020,-0.1153807,-0.0520016},
{-0.6968866,-0.1140122,-0.0545524}
};
shoToPiVsWam = {
{-0.3419209,-0.6412776,-0.3862559},
{-0.3422253,-0.6414240,-0.3850614},
{-0.3437378,-0.6406713,-0.3839883},
{-0.3458451,-0.6400354,-0.3820969},
{-0.3477470,-0.6394381,-0.3796523},
{-0.3488398,-0.6383488,-0.3782682},
{-0.3500263,-0.6375503,-0.3757146},
{-0.3510157,-0.6364290,-0.3728132},
{-0.3549115,-0.6313635,-0.3739267},
{-0.3581673,-0.6285926,-0.3709350},
{-0.3616908,-0.6245071,-0.3695754},
{-0.3654343,-0.6199536,-0.3684985},
{-0.3693312,-0.6149077,-0.3674363},
{-0.3733579,-0.6096279,-0.3659464},
{-0.3789625,-0.6029076,-0.3640967},
{-0.3841566,-0.5955779,-0.3630513},
{-0.3891562,-0.5889160,-0.3601025},
{-0.3931838,-0.5829332,-0.3569064},
{-0.3983645,-0.5774393,-0.3521137},
{-0.4048709,-0.5713709,-0.3476049},
{-0.4113288,-0.5657729,-0.3428755},
{-0.4196456,-0.5587045,-0.3390174},
{-0.4281207,-0.5522611,-0.3334810},
{-0.4376639,-0.5452506,-0.3274029},
{-0.4467476,-0.5384809,-0.3202697},
{-0.4559100,-0.5314457,-0.3128823},
{-0.4600815,-0.5284882,-0.3051001},
{-0.4590008,-0.5264186,-0.3031113},
{-0.4598856,-0.5230903,-0.3025562},
{-0.4617887,-0.5191312,-0.3002261},
{-0.4640535,-0.5140225,-0.3002353},
{-0.4677521,-0.5077373,-0.2996083},
{-0.4697793,-0.5029547,-0.2988549},
{-0.4732258,-0.4976562,-0.2966801},
{-0.4764355,-0.4923080,-0.2963050},
{-0.4806450,-0.4859061,-0.2956825},
{-0.4863013,-0.4789908,-0.2937151},
{-0.4911616,-0.4726803,-0.2925259},
{-0.4970420,-0.4653187,-0.2917997},
{-0.5005105,-0.4593899,-0.2915043},
{-0.5068039,-0.4514353,-0.2889348},
{-0.5154643,-0.4426806,-0.2829110},
{-0.5208580,-0.4349285,-0.2804521},
{-0.5262350,-0.4270799,-0.2777718},
{-0.5328927,-0.4179344,-0.2732836},
{-0.5381464,-0.4100108,-0.2702696},
{-0.5444025,-0.4026749,-0.2646271},
{-0.5493550,-0.3955315,-0.2603052},
{-0.5550462,-0.3890057,-0.2534466},
{-0.5601559,-0.3829187,-0.2472307},
{-0.5652463,-0.3771596,-0.2400307},
{-0.5697729,-0.3718894,-0.2332976},
{-0.5746922,-0.3675600,-0.2248365},
{-0.5800757,-0.3618770,-0.2168190},
{-0.5855863,-0.3567650,-0.2083944},
{-0.5914999,-0.3508046,-0.1997726},
{-0.5966650,-0.3455697,-0.1909976},
{-0.6014664,-0.3403683,-0.1821739},
{-0.6043850,-0.3402872,-0.1686227},
{-0.6099899,-0.3318182,-0.1611350},
{-0.6159197,-0.3236326,-0.1519521},
{-0.6209794,-0.3151650,-0.1452440},
{-0.6260706,-0.3078661,-0.1360878},
{-0.6301023,-0.3022079,-0.1281164},
{-0.6353020,-0.2945228,-0.1210626},
{-0.6398452,-0.2883007,-0.1136440},
{-0.6446777,-0.2815541,-0.1056211},
{-0.6494800,-0.2750410,-0.0983485},
{-0.6544980,-0.2671931,-0.0926955},
{-0.6573021,-0.2642288,-0.0876928},
{-0.6659466,-0.2464010,-0.0819283},
{-0.6700189,-0.2401721,-0.0764983},
{-0.6740512,-0.2352619,-0.0694355},
{-0.6781921,-0.2293477,-0.0642658},
{-0.6825336,-0.2235051,-0.0577456},
{-0.6865521,-0.2175473,-0.0521719},
{-0.6904760,-0.2118522,-0.0456581},
{-0.6941755,-0.2055020,-0.0405886},
{-0.6977615,-0.1998408,-0.0335363},
{-0.7005139,-0.1945927,-0.0292333},
{-0.7031572,-0.1892030,-0.0250424},
{-0.7054768,-0.1840420,-0.0205795},
{-0.7072762,-0.1800660,-0.0161468},
{-0.7089784,-0.1752789,-0.0131131},
{-0.7109640,-0.1694541,-0.0094168},
{-0.7126759,-0.1640279,-0.0079632},
{-0.7140070,-0.1599950,-0.0054461},
{-0.7152375,-0.1557318,-0.0042821},
{-0.7166869,-0.1511253,-0.0034072},
{-0.7173766,-0.1483483,-0.0036851},
{-0.7183565,-0.1436722,-0.0047776},
{-0.7187524,-0.1413803,-0.0055186},
{-0.7196703,-0.1377233,-0.0072639},
{-0.7203538,-0.1349207,-0.0079174},
{-0.7211318,-0.1322301,-0.0096392},
{-0.7219323,-0.1300612,-0.0115294},
{-0.7227422,-0.1279396,-0.0136745},
{-0.7236851,-0.1249841,-0.0143511},
{-0.7243139,-0.1236631,-0.0167873}
};
shoToEeVsWam = {
{-0.3364693,-0.6483099,-0.3193691},
{-0.3373417,-0.6485093,-0.3181741},
{-0.3401602,-0.6476626,-0.3172678},
{-0.3427679,-0.6470023,-0.3154284},
{-0.3452275,-0.6462858,-0.3129320},
{-0.3470566,-0.6449958,-0.3115004},
{-0.3489888,-0.6439200,-0.3089239},
{-0.3510220,-0.6425046,-0.3059292},
{-0.3560779,-0.6376131,-0.3070959},
{-0.3604067,-0.6346563,-0.3040894},
{-0.3651459,-0.6305971,-0.3027288},
{-0.3701882,-0.6258818,-0.3016817},
{-0.3752750,-0.6207465,-0.3006943},
{-0.3806583,-0.6154050,-0.2992786},
{-0.3875349,-0.6087419,-0.2974877},
{-0.3944643,-0.6010592,-0.2966285},
{-0.4008863,-0.5942273,-0.2939056},
{-0.4064220,-0.5879883,-0.2909703},
{-0.4126422,-0.5822332,-0.2863923},
{-0.4201560,-0.5758310,-0.2821019},
{-0.4271008,-0.5700988,-0.2774616},
{-0.4358671,-0.5628778,-0.2736678},
{-0.4444689,-0.5562862,-0.2681389},
{-0.4541593,-0.5491350,-0.2621113},
{-0.4632902,-0.5421908,-0.2550010},
{-0.4725833,-0.5349050,-0.2476712},
{-0.4769679,-0.5316974,-0.2399136},
{-0.4770664,-0.5293631,-0.2382668},
{-0.4793289,-0.5258018,-0.2381210},
{-0.4820829,-0.5216960,-0.2360656},
{-0.4853849,-0.5162897,-0.2363638},
{-0.4899821,-0.5099695,-0.2360652},
{-0.4928495,-0.5049398,-0.2355762},
{-0.4969064,-0.4994114,-0.2336079},
{-0.5008424,-0.4938464,-0.2335048},
{-0.5056449,-0.4870850,-0.2331351},
{-0.5116306,-0.4801697,-0.2313191},
{-0.5169674,-0.4736519,-0.2302978},
{-0.5231403,-0.4662791,-0.2297264},
{-0.5267498,-0.4603925,-0.2295164},
{-0.5330037,-0.4523437,-0.2269449},
{-0.5417911,-0.4427526,-0.2209643},
{-0.5472718,-0.4346835,-0.2185289},
{-0.5525961,-0.4267174,-0.2158325},
{-0.5591522,-0.4172417,-0.2113213},
{-0.5647389,-0.4089498,-0.2084094},
{-0.5711042,-0.4010015,-0.2028308},
{-0.5763848,-0.3931585,-0.1986534},
{-0.5821149,-0.3859547,-0.1918617},
{-0.5871958,-0.3789252,-0.1857890},
{-0.5923476,-0.3722549,-0.1786898},
{-0.5969805,-0.3661084,-0.1720215},
{-0.6018400,-0.3610730,-0.1635010},
{-0.6069280,-0.3545124,-0.1554648},
{-0.6121214,-0.3481440,-0.1470782},
{-0.6178707,-0.3408996,-0.1386492},
{-0.6225130,-0.3349231,-0.1297536},
{-0.6270178,-0.3288567,-0.1209155},
{-0.6294259,-0.3273186,-0.1074264},
{-0.6341259,-0.3179462,-0.0998502},
{-0.6392981,-0.3090898,-0.0905563},
{-0.6436209,-0.2999128,-0.0836811},
{-0.6475788,-0.2918581,-0.0743360},
{-0.6507744,-0.2854988,-0.0662455},
{-0.6549131,-0.2770625,-0.0591340},
{-0.6585604,-0.2701056,-0.0516771},
{-0.6625208,-0.2627930,-0.0435381},
{-0.6663427,-0.2556721,-0.0361996},
{-0.6704476,-0.2473025,-0.0304851},
{-0.6720789,-0.2444655,-0.0252209},
{-0.6790298,-0.2261760,-0.0191945},
{-0.6816337,-0.2197265,-0.0136301},
{-0.6839164,-0.2145925,-0.0063966},
{-0.6866725,-0.2085518,-0.0010730},
{-0.6895222,-0.2024640,0.0054609},
{-0.6925463,-0.1961200,0.0110072},
{-0.6953841,-0.1900427,0.0174585},
{-0.6982561,-0.1831810,0.0223762},
{-0.7008383,-0.1771124,0.0293313},
{-0.7025915,-0.1713336,0.0333966},
{-0.7042702,-0.1656104,0.0374488},
{-0.7054432,-0.1602327,0.0418056},
{-0.7062792,-0.1560282,0.0460501},
{-0.7071577,-0.1508662,0.0489155},
{-0.7080636,-0.1447279,0.0524942},
{-0.7091567,-0.1388135,0.0535584},
{-0.7097531,-0.1345044,0.0559235},
{-0.7104523,-0.1298609,0.0567489},
{-0.7111434,-0.1249056,0.0573863},
{-0.7108914,-0.1219999,0.0567897},
{-0.7112249,-0.1174032,0.0555944},
{-0.7106836,-0.1153606,0.0547906},
{-0.7110492,-0.1119898,0.0530868},
{-0.7109701,-0.1094071,0.0523467},
{-0.7114149,-0.1068550,0.0505777},
{-0.7118634,-0.1047983,0.0486419},
{-0.7123404,-0.1028599,0.0464706},
{-0.7128436,-0.1000420,0.0456886},
{-0.7133475,-0.0987251,0.0431973}
};
(* 
WARNING: Logging before InitGoogleLogging() is written to STDERR
W1104 07:47:59.343482  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.706096e+04
Final                            1.749956e-22
Change                           1.706096e+04

Minimizer iterations                      125
Successful steps                          106
Unsuccessful steps                         19
Line search steps                          73

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0108
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7026
    Line search gradient evaluation    0.3771
  Linear solver                        0.0034
  Line search polynomial minimization  0.0005
Minimizer                              0.7207

Postprocessor                          0.0000
Total                                  0.7208

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr0 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe0 = {
{-0.0276754,-0.0136444,0.0735903}
};
rMatsBase0 = {
{-0.3456707,0.7608346,-0.5492198},
{0.7742601,0.5619283,0.2911320},
{0.5301255,-0.3246032,-0.7833261}
};
outThetasWam0 = {
{-0.1158496,-0.2494568,-0.0474730,1.2057666,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.697299e+04
Final                            8.362398e-23
Change                           1.697299e+04

Minimizer iterations                      186
Successful steps                          157
Unsuccessful steps                         29
Line search steps                         101

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0142
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.9615
    Line search gradient evaluation    0.5212
  Linear solver                        0.0039
  Line search polynomial minimization  0.0005
Minimizer                              0.9835

Postprocessor                          0.0000
Total                                  0.9836

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe1 = {
{-0.0280952,-0.0134395,0.0732144}
};
rMatsBase1 = {
{-0.3458777,0.7609778,-0.5488910},
{0.7772576,0.5600688,0.2866942},
{0.5255847,-0.3274686,-0.7851911}
};
outThetasWam1 = {
{-0.1147501,-0.2519346,-0.0475739,1.2070694,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.689945e+04
Final                            3.643123e-23
Change                           1.689945e+04

Minimizer iterations                       89
Successful steps                           72
Unsuccessful steps                         17
Line search steps                          52

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0068
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4525
    Line search gradient evaluation    0.2492
  Linear solver                        0.0018
  Line search polynomial minimization  0.0003
Minimizer                              0.4629

Postprocessor                          0.0000
Total                                  0.4630

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr2 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe2 = {
{-0.0293578,-0.0130984,0.0727638}
};
rMatsBase2 = {
{-0.3462018,0.7599663,-0.5500869},
{0.7797133,0.5591527,0.2817720},
{0.5217198,-0.3313601,-0.7861354}
};
outThetasWam2 = {
{-0.1136078,-0.2544860,-0.0476542,1.2092547,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.682054e+04
Final                            1.677701e-22
Change                           1.682054e+04

Minimizer iterations                       50
Successful steps                           40
Unsuccessful steps                         10
Line search steps                          30

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2509
    Line search gradient evaluation    0.1387
  Linear solver                        0.0011
  Line search polynomial minimization  0.0002
Minimizer                              0.2570

Postprocessor                          0.0000
Total                                  0.2571

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe3 = {
{-0.0297578,-0.0127990,0.0724227}
};
rMatsBase3 = {
{-0.3457800,0.7591221,-0.5515159},
{0.7830660,0.5572874,0.2761129},
{0.5169563,-0.3363990,-0.7871416}
};
outThetasWam3 = {
{-0.1126843,-0.2577024,-0.0481949,1.2115541,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.671329e+04
Final                            1.850509e-22
Change                           1.671329e+04

Minimizer iterations                       68
Successful steps                           51
Unsuccessful steps                         17
Line search steps                          41

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0052
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3343
    Line search gradient evaluation    0.1905
  Linear solver                        0.0016
  Line search polynomial minimization  0.0002
Minimizer                              0.3427

Postprocessor                          0.0000
Total                                  0.3427

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr4 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe4 = {
{-0.0304186,-0.0123497,0.0721359}
};
rMatsBase4 = {
{-0.3450117,0.7585466,-0.5527874},
{0.7872560,0.5545556,0.2696221},
{0.5110723,-0.3421624,-0.7884986}
};
outThetasWam4 = {
{-0.1113500,-0.2615049,-0.0486997,1.2155735,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.659633e+04
Final                            1.217461e-22
Change                           1.659633e+04

Minimizer iterations                       66
Successful steps                           50
Unsuccessful steps                         16
Line search steps                          39

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0050
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3244
    Line search gradient evaluation    0.1843
  Linear solver                        0.0015
  Line search polynomial minimization  0.0002
Minimizer                              0.3323

Postprocessor                          0.0000
Total                                  0.3324

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe5 = {
{-0.0311093,-0.0119799,0.0718630}
};
rMatsBase5 = {
{-0.3455160,0.7571810,-0.5543425},
{0.7904051,0.5532421,0.2630266},
{0.5058443,-0.3472752,-0.7896337}
};
outThetasWam5 = {
{-0.1092408,-0.2647742,-0.0483702,1.2207495,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.644747e+04
Final                            7.127392e-23
Change                           1.644747e+04

Minimizer iterations                      117
Successful steps                          105
Unsuccessful steps                         12
Line search steps                          59

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0089
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6226
    Line search gradient evaluation    0.3279
  Linear solver                        0.0023
  Line search polynomial minimization  0.0003
Minimizer                              0.6363

Postprocessor                          0.0000
Total                                  0.6363

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr6 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe6 = {
{-0.0316865,-0.0115399,0.0715123}
};
rMatsBase6 = {
{-0.3451583,0.7562400,-0.5558479},
{0.7951253,0.5502693,0.2549107},
{0.4986396,-0.3539842,-0.7912356}
};
outThetasWam6 = {
{-0.1069642,-0.2691286,-0.0484169,1.2271541,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.627066e+04
Final                            4.972605e-23
Change                           1.627066e+04

Minimizer iterations                      207
Successful steps                          181
Unsuccessful steps                         26
Line search steps                         120

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0160
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.0962
    Line search gradient evaluation    0.5841
  Linear solver                        0.0043
  Line search polynomial minimization  0.0006
Minimizer                              1.1211

Postprocessor                          0.0000
Total                                  1.1211

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe7 = {
{-0.0329024,-0.0109383,0.0710910}
};
rMatsBase7 = {
{-0.3444079,0.7553020,-0.5575860},
{0.8004845,0.5465698,0.2459388},
{0.4905178,-0.3616357,-0.7928505}
};
outThetasWam7 = {
{-0.1042144,-0.2738180,-0.0483447,1.2361982,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.617500e+04
Final                            5.209390e-22
Change                           1.617500e+04

Minimizer iterations                       51
Successful steps                           35
Unsuccessful steps                         16
Line search steps                          31

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0042
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2465
    Line search gradient evaluation    0.1458
  Linear solver                        0.0016
  Line search polynomial minimization  0.0002
Minimizer                              0.2539

Postprocessor                          0.0000
Total                                  0.2539

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe8 = {
{-0.0340486,-0.0107118,0.0704765}
};
rMatsBase8 = {
{-0.3475513,0.7487137,-0.5644784},
{0.8009017,0.5501015,0.2365265},
{0.4876111,-0.3698867,-0.7908346}
};
outThetasWam8 = {
{-0.1008371,-0.2764620,-0.0465608,1.2447726,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.603661e+04
Final                            4.017512e-22
Change                           1.603661e+04

Minimizer iterations                       39
Successful steps                           25
Unsuccessful steps                         14
Line search steps                          24

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0031
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1828
    Line search gradient evaluation    0.1111
  Linear solver                        0.0009
  Line search polynomial minimization  0.0002
Minimizer                              0.1878

Postprocessor                          0.0000
Total                                  0.1879

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe9 = {
{-0.0351091,-0.0101577,0.0699563}
};
rMatsBase9 = {
{-0.3463546,0.7456691,-0.5692241},
{0.8055419,0.5473743,0.2269000},
{0.4807709,-0.3799460,-0.7902534}
};
outThetasWam9 = {
{-0.0984564,-0.2813438,-0.0466176,1.2550061,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.593461e+04
Final                            5.249734e-22
Change                           1.593461e+04

Minimizer iterations                       34
Successful steps                           25
Unsuccessful steps                          9
Line search steps                          19

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0029
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1825
    Line search gradient evaluation    0.1066
  Linear solver                        0.0011
  Line search polynomial minimization  0.0002
Minimizer                              0.1877

Postprocessor                          0.0000
Total                                  0.1877

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrEl10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrLa10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrWr10 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe10 = {
{-0.0362971,-0.0097630,0.0693490}
};
rMatsBase10 = {
{-0.3463183,0.7408535,-0.5754996},
{0.8080811,0.5471942,0.2181364},
{0.4765171,-0.3895057,-0.7881731}
};
outThetasWam10 = {
{-0.0959758,-0.2848869,-0.0459274,1.2656575,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.583444e+04
Final                            1.020599e-22
Change                           1.583444e+04

Minimizer iterations                      133
Successful steps                          113
Unsuccessful steps                         20
Line search steps                          77

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0110
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7591
    Line search gradient evaluation    0.4106
  Linear solver                        0.0028
  Line search polynomial minimization  0.0004
Minimizer                              0.7759

Postprocessor                          0.0000
Total                                  0.7760

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe11 = {
{-0.0375240,-0.0092909,0.0688195}
};
rMatsBase11 = {
{-0.3274017,0.7257599,-0.6050460},
{0.8250654,0.5316724,0.1912890},
{0.4605162,-0.4365742,-0.7728698}
};
outThetasWam11 = {
{-0.1092565,-0.2572046,-0.0566796,1.2767832,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.576137e+04
Final                            8.758582e-23
Change                           1.576137e+04

Minimizer iterations                      292
Successful steps                          274
Unsuccessful steps                         18
Line search steps                         152

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0241
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.7330
    Line search gradient evaluation    0.8942
  Linear solver                        0.0062
  Line search polynomial minimization  0.0008
Minimizer                              1.7697

Postprocessor                          0.0000
Total                                  1.7698

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA12 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl12 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa12 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr12 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe12 = {
{-0.0387272,-0.0089059,0.0682818}
};
rMatsBase12 = {
{-0.3278060,0.7193423,-0.6124458},
{0.8265516,0.5323348,0.1828446},
{0.4575541,-0.4462805,-0.7690761}
};
outThetasWam12 = {
{-0.1075282,-0.2605678,-0.0553508,1.2891612,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.569316e+04
Final                            2.734148e-22
Change                           1.569316e+04

Minimizer iterations                      123
Successful steps                           98
Unsuccessful steps                         25
Line search steps                          76

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0103
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6872
    Line search gradient evaluation    0.3853
  Linear solver                        0.0030
  Line search polynomial minimization  0.0004
Minimizer                              0.7036

Postprocessor                          0.0000
Total                                  0.7036

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe13 = {
{-0.0399683,-0.0085061,0.0676580}
};
rMatsBase13 = {
{-0.3275823,0.7127145,-0.6202644},
{0.8281687,0.5325922,0.1745913},
{0.4547817,-0.4564905,-0.7647156}
};
outThetasWam13 = {
{-0.1058488,-0.2641651,-0.0540457,1.3024526,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.564851e+04
Final                            2.056250e-22
Change                           1.564851e+04

Minimizer iterations                      162
Successful steps                          149
Unsuccessful steps                         13
Line search steps                          83

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0129
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.9300
    Line search gradient evaluation    0.4855
  Linear solver                        0.0033
  Line search polynomial minimization  0.0004
Minimizer                              0.9496

Postprocessor                          0.0000
Total                                  0.9497

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe14 = {
{-0.0410674,-0.0081293,0.0669959}
};
rMatsBase14 = {
{-0.3270248,0.7043328,-0.6300556},
{0.8292068,0.5336649,0.1661862},
{0.4532890,-0.4680994,-0.7585592}
};
outThetasWam14 = {
{-0.1040886,-0.2685330,-0.0523490,1.3175960,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.559193e+04
Final                            6.738766e-23
Change                           1.559193e+04

Minimizer iterations                       92
Successful steps                           71
Unsuccessful steps                         21
Line search steps                          57

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0068
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4532
    Line search gradient evaluation    0.2568
  Linear solver                        0.0018
  Line search polynomial minimization  0.0003
Minimizer                              0.4638

Postprocessor                          0.0000
Total                                  0.4638

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe15 = {
{-0.0428187,-0.0074653,0.0663288}
};
rMatsBase15 = {
{-0.3275817,0.6945521,-0.6405370},
{0.8299430,0.5355232,0.1562355},
{0.4515361,-0.4804292,-0.7518663}
};
outThetasWam15 = {
{-0.1020572,-0.2719445,-0.0501681,1.3339050,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.553370e+04
Final                            4.329378e-22
Change                           1.553370e+04

Minimizer iterations                       27
Successful steps                           18
Unsuccessful steps                          9
Line search steps                          16

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0020
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1282
    Line search gradient evaluation    0.0777
  Linear solver                        0.0006
  Line search polynomial minimization  0.0001
Minimizer                              0.1314

Postprocessor                          0.0000
Total                                  0.1315

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe16 = {
{-0.0441655,-0.0069394,0.0655411}
};
rMatsBase16 = {
{-0.3257865,0.6861121,-0.6504716},
{0.8318356,0.5350085,0.1477005},
{0.4493469,-0.4929666,-0.7450311}
};
outThetasWam16 = {
{-0.1002775,-0.2763232,-0.0485197,1.3514882,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.544808e+04
Final                            2.708154e-22
Change                           1.544808e+04

Minimizer iterations                       49
Successful steps                           34
Unsuccessful steps                         15
Line search steps                          30

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0036
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2307
    Line search gradient evaluation    0.1367
  Linear solver                        0.0009
  Line search polynomial minimization  0.0001
Minimizer                              0.2362

Postprocessor                          0.0000
Total                                  0.2362

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe17 = {
{-0.0455112,-0.0063573,0.0646732}
};
rMatsBase17 = {
{-0.3238021,0.6782501,-0.6596431},
{0.8346627,0.5330865,0.1384088},
{0.4455226,-0.5057624,-0.7387246}
};
outThetasWam17 = {
{-0.0984159,-0.2803298,-0.0470581,1.3687631,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.540616e+04
Final                            1.204776e-22
Change                           1.540616e+04

Minimizer iterations                      410
Successful steps                          372
Unsuccessful steps                         38
Line search steps                         220

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0305
    Line search cost evaluation        0.0000
  Jacobian evaluation                  2.1737
    Line search gradient evaluation    1.1402
  Linear solver                        0.0070
  Line search polynomial minimization  0.0009
Minimizer                              2.2186

Postprocessor                          0.0000
Total                                  2.2186

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr18 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe18 = {
{-0.0465209,-0.0057547,0.0640230}
};
rMatsBase18 = {
{-0.3198540,0.6718045,-0.6681109},
{0.8372645,0.5304817,0.1325793},
{0.4434880,-0.5169795,-0.7321548}
};
outThetasWam18 = {
{-0.0971172,-0.2856790,-0.0460498,1.3846811,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.539983e+04
Final                            8.590868e-23
Change                           1.539983e+04

Minimizer iterations                       89
Successful steps                           70
Unsuccessful steps                         19
Line search steps                          47

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0071
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4557
    Line search gradient evaluation    0.2554
  Linear solver                        0.0023
  Line search polynomial minimization  0.0003
Minimizer                              0.4677

Postprocessor                          0.0000
Total                                  0.4677

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr19 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe19 = {
{-0.0474746,-0.0050352,0.0634712}
};
rMatsBase19 = {
{-0.3163740,0.6646457,-0.6768704},
{0.8388200,0.5292411,0.1276123},
{0.4430447,-0.5273992,-0.7249562}
};
outThetasWam19 = {
{-0.0959586,-0.2914327,-0.0448068,1.3982720,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.541574e+04
Final                            1.249224e-22
Change                           1.541574e+04

Minimizer iterations                       59
Successful steps                           44
Unsuccessful steps                         15
Line search steps                          34

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0051
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2977
    Line search gradient evaluation    0.1715
  Linear solver                        0.0020
  Line search polynomial minimization  0.0003
Minimizer                              0.3068

Postprocessor                          0.0000
Total                                  0.3070

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe20 = {
{-0.0478666,-0.0045362,0.0631222}
};
rMatsBase20 = {
{-0.3124259,0.6584395,-0.6847244},
{0.8400148,0.5280798,0.1245264},
{0.4435822,-0.5362734,-0.7180848}
};
outThetasWam20 = {
{-0.0951190,-0.2973649,-0.0437888,1.4101856,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.550042e+04
Final                            2.231032e-22
Change                           1.550042e+04

Minimizer iterations                      106
Successful steps                           87
Unsuccessful steps                         19
Line search steps                          58

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0092
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5797
    Line search gradient evaluation    0.3192
  Linear solver                        0.0031
  Line search polynomial minimization  0.0005
Minimizer                              0.5951

Postprocessor                          0.0000
Total                                  0.5952

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe21 = {
{-0.0482198,-0.0039766,0.0629498}
};
rMatsBase21 = {
{-0.3239650,0.6614235,-0.6764359},
{0.8275742,0.5445934,0.1361575},
{0.4584404,-0.5156907,-0.7238063}
};
outThetasWam21 = {
{-0.0777923,-0.3285671,-0.0363258,1.4201309,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.557998e+04
Final                            2.961777e-22
Change                           1.557998e+04

Minimizer iterations                      193
Successful steps                          167
Unsuccessful steps                         26
Line search steps                         105

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0158
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.0911
    Line search gradient evaluation    0.5843
  Linear solver                        0.0041
  Line search polynomial minimization  0.0005
Minimizer                              1.1153

Postprocessor                          0.0000
Total                                  1.1153

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe22 = {
{-0.0482799,-0.0034340,0.0628862}
};
rMatsBase22 = {
{-0.3182489,0.6549574,-0.6853820},
{0.8290805,0.5428817,0.1338092},
{0.4597207,-0.5256522,-0.7157839}
};
outThetasWam22 = {
{-0.0783816,-0.3349911,-0.0374065,1.4301427,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.568772e+04
Final                            1.836490e-22
Change                           1.568772e+04

Minimizer iterations                       90
Successful steps                           72
Unsuccessful steps                         18
Line search steps                          52

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0073
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4891
    Line search gradient evaluation    0.2712
  Linear solver                        0.0018
  Line search polynomial minimization  0.0002
Minimizer                              0.5000

Postprocessor                          0.0000
Total                                  0.5001

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe23 = {
{-0.0481398,-0.0029071,0.0628432}
};
rMatsBase23 = {
{-0.3116361,0.6477249,-0.6952232},
{0.8303802,0.5413100,0.1321065},
{0.4618999,-0.5361305,-0.7065497}
};
outThetasWam23 = {
{-0.0793342,-0.3416001,-0.0387462,1.4390944,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.580036e+04
Final                            3.850925e-22
Change                           1.580036e+04

Minimizer iterations                       66
Successful steps                           50
Unsuccessful steps                         16
Line search steps                          37

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0055
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3507
    Line search gradient evaluation    0.1994
  Linear solver                        0.0015
  Line search polynomial minimization  0.0002
Minimizer                              0.3592

Postprocessor                          0.0000
Total                                  0.3592

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe24 = {
{-0.0481125,-0.0023441,0.0628510}
};
rMatsBase24 = {
{-0.3031867,0.6411710,-0.7049664},
{0.8321201,0.5386497,0.1320330},
{0.4643856,-0.5465860,-0.6968426}
};
outThetasWam24 = {
{-0.0806726,-0.3480265,-0.0404936,1.4495978,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.593472e+04
Final                            1.783759e-22
Change                           1.593472e+04

Minimizer iterations                       90
Successful steps                           77
Unsuccessful steps                         13
Line search steps                          47

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0074
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5048
    Line search gradient evaluation    0.2717
  Linear solver                        0.0018
  Line search polynomial minimization  0.0002
Minimizer                              0.5159

Postprocessor                          0.0000
Total                                  0.5160

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr25 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe25 = {
{-0.0480505,-0.0017914,0.0629122}
};
rMatsBase25 = {
{-0.2938700,0.6339627,-0.7153543},
{0.8334089,0.5364115,0.1330124},
{0.4680492,-0.5570943,-0.6859854}
};
outThetasWam25 = {
{-0.0822526,-0.3537376,-0.0423087,1.4599617,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.599047e+04
Final                            4.546850e-22
Change                           1.599047e+04

Minimizer iterations                       54
Successful steps                           41
Unsuccessful steps                         13
Line search steps                          32

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0047
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2895
    Line search gradient evaluation    0.1650
  Linear solver                        0.0014
  Line search polynomial minimization  0.0002
Minimizer                              0.2972

Postprocessor                          0.0000
Total                                  0.2972

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr26 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe26 = {
{-0.0480616,-0.0014816,0.0629119}
};
rMatsBase26 = {
{-0.2839230,0.6326524,-0.7205128},
{0.8365733,0.5306363,0.1362723},
{0.4685433,-0.5640709,-0.6799200}
};
outThetasWam26 = {
{-0.0839028,-0.3589221,-0.0446828,1.4707385,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.587939e+04
Final                            1.154625e-22
Change                           1.587939e+04

Minimizer iterations                       87
Successful steps                           74
Unsuccessful steps                         13
Line search steps                          43

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0072
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4885
    Line search gradient evaluation    0.2635
  Linear solver                        0.0019
  Line search polynomial minimization  0.0002
Minimizer                              0.4995

Postprocessor                          0.0000
Total                                  0.4996

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe27 = {
{-0.0491522,-0.0010995,0.0620515}
};
rMatsBase27 = {
{-0.2834582,0.6308857,-0.7222428},
{0.8391226,0.5277638,0.1316765},
{0.4642464,-0.5687255,-0.6789894}
};
outThetasWam27 = {
{-0.0820486,-0.3623030,-0.0430934,1.4823164,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.583318e+04
Final                            3.297978e-23
Change                           1.583318e+04

Minimizer iterations                      253
Successful steps                          226
Unsuccessful steps                         27
Line search steps                         137

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0184
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.3137
    Line search gradient evaluation    0.6947
  Linear solver                        0.0041
  Line search polynomial minimization  0.0005
Minimizer                              1.3405

Postprocessor                          0.0000
Total                                  1.3406

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA28 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrEl28 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrLa28 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr28 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe28 = {
{-0.0502752,-0.0005972,0.0611562}
};
rMatsBase28 = {
{-0.2839568,0.6266459,-0.7257296},
{0.8397415,0.5278693,0.1272331},
{0.4628204,-0.5732965,-0.6761127}
};
outThetasWam28 = {
{-0.0805520,-0.3642077,-0.0413478,1.4897986,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.578037e+04
Final                            1.303479e-22
Change                           1.578037e+04

Minimizer iterations                      239
Successful steps                          210
Unsuccessful steps                         29
Line search steps                         128

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0175
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.2412
    Line search gradient evaluation    0.6600
  Linear solver                        0.0040
  Line search polynomial minimization  0.0005
Minimizer                              1.2669

Postprocessor                          0.0000
Total                                  1.2670

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe29 = {
{-0.0511993,-0.0000449,0.0603762}
};
rMatsBase29 = {
{-0.2825743,0.6222812,-0.7300122},
{0.8413988,0.5262538,0.1229022},
{0.4606514,-0.5795024,-0.6722925}
};
outThetasWam29 = {
{-0.0792137,-0.3675140,-0.0398455,1.4997715,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.575492e+04
Final                            4.169647e-22
Change                           1.575492e+04

Minimizer iterations                       48
Successful steps                           31
Unsuccessful steps                         17
Line search steps                          29

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2228
    Line search gradient evaluation    0.1351
  Linear solver                        0.0011
  Line search polynomial minimization  0.0001
Minimizer                              0.2288

Postprocessor                          0.0000
Total                                  0.2288

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe30 = {
{-0.0519571,0.0004538,0.0597414}
};
rMatsBase30 = {
{-0.2841356,0.6146964,-0.7358093},
{0.8408953,0.5284535,0.1167560},
{0.4606104,-0.5855641,-0.6670478}
};
outThetasWam30 = {
{-0.0772886,-0.3689531,-0.0370586,1.5078020,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.575603e+04
Final                            1.833835e-22
Change                           1.575603e+04

Minimizer iterations                       95
Successful steps                           70
Unsuccessful steps                         25
Line search steps                          55

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0075
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4637
    Line search gradient evaluation    0.2673
  Linear solver                        0.0021
  Line search polynomial minimization  0.0003
Minimizer                              0.4754

Postprocessor                          0.0000
Total                                  0.4755

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe31 = {
{-0.0526485,0.0009509,0.0589400}
};
rMatsBase31 = {
{-0.2846267,0.6059354,-0.7428526},
{0.8402637,0.5307063,0.1109403},
{0.4614592,-0.5926155,-0.6601987}
};
outThetasWam31 = {
{-0.0756259,-0.3709337,-0.0344147,1.5161689,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.573226e+04
Final                            6.236852e-23
Change                           1.573226e+04

Minimizer iterations                       75
Successful steps                           54
Unsuccessful steps                         21
Line search steps                          43

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0058
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3623
    Line search gradient evaluation    0.2102
  Linear solver                        0.0019
  Line search polynomial minimization  0.0002
Minimizer                              0.3718

Postprocessor                          0.0000
Total                                  0.3718

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA32 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl32 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa32 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr32 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe32 = {
{-0.0533811,0.0014536,0.0583158}
};
rMatsBase32 = {
{-0.2850653,0.5990951,-0.7482131},
{0.8401596,0.5319172,0.1058103},
{0.4613779,-0.5984556,-0.6549667}
};
outThetasWam32 = {
{-0.0740435,-0.3725590,-0.0318885,1.5249189,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.574834e+04
Final                            7.495677e-23
Change                           1.574834e+04

Minimizer iterations                      154
Successful steps                          131
Unsuccessful steps                         23
Line search steps                          86

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0115
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7921
    Line search gradient evaluation    0.4276
  Linear solver                        0.0028
  Line search polynomial minimization  0.0004
Minimizer                              0.8092

Postprocessor                          0.0000
Total                                  0.8093

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe33 = {
{-0.0536491,0.0018318,0.0579311}
};
rMatsBase33 = {
{-0.2835575,0.5919677,-0.7544331},
{0.8401598,0.5326316,0.1021524},
{0.4623059,-0.6048783,-0.6483792}
};
outThetasWam33 = {
{-0.0731054,-0.3751861,-0.0302268,1.5332201,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.576687e+04
Final                            7.119531e-22
Change                           1.576687e+04

Minimizer iterations                       51
Successful steps                           37
Unsuccessful steps                         14
Line search steps                          32

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0042
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2485
    Line search gradient evaluation    0.1436
  Linear solver                        0.0015
  Line search polynomial minimization  0.0002
Minimizer                              0.2557

Postprocessor                          0.0000
Total                                  0.2557

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe34 = {
{-0.0544783,0.0025116,0.0573073}
};
rMatsBase34 = {
{-0.2838706,0.5844269,-0.7601728},
{0.8391505,0.5350061,0.0979538},
{0.4639439,-0.6100932,-0.6422946}
};
outThetasWam34 = {
{-0.0719135,-0.3763683,-0.0279967,1.5397327,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.585286e+04
Final                            1.925607e-22
Change                           1.585286e+04

Minimizer iterations                       71
Successful steps                           50
Unsuccessful steps                         21
Line search steps                          41

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0057
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3458
    Line search gradient evaluation    0.2024
  Linear solver                        0.0021
  Line search polynomial minimization  0.0003
Minimizer                              0.3558

Postprocessor                          0.0000
Total                                  0.3558

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe35 = {
{-0.0547058,0.0028756,0.0571422}
};
rMatsBase35 = {
{-0.2834435,0.5747859,-0.7676463},
{0.8366838,0.5393940,0.0949441},
{0.4686364,-0.6153659,-0.6338018}
};
outThetasWam35 = {
{-0.0711261,-0.3771877,-0.0261686,1.5461905,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.594154e+04
Final                            5.284607e-22
Change                           1.594154e+04

Minimizer iterations                      103
Successful steps                           72
Unsuccessful steps                         31
Line search steps                          62

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0082
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4956
    Line search gradient evaluation    0.2910
  Linear solver                        0.0027
  Line search polynomial minimization  0.0005
Minimizer                              0.5095

Postprocessor                          0.0000
Total                                  0.5095

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe36 = {
{-0.0548957,0.0033650,0.0567897}
};
rMatsBase36 = {
{-0.2811979,0.5657543,-0.7751451},
{0.8353171,0.5419291,0.0925109},
{0.4724121,-0.6214780,-0.6249735}
};
outThetasWam36 = {
{-0.0706988,-0.3795373,-0.0251040,1.5519567,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.603984e+04
Final                            3.203793e-22
Change                           1.603984e+04

Minimizer iterations                       44
Successful steps                           29
Unsuccessful steps                         15
Line search steps                          27

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0035
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2085
    Line search gradient evaluation    0.1251
  Linear solver                        0.0012
  Line search polynomial minimization  0.0002
Minimizer                              0.2144

Postprocessor                          0.0000
Total                                  0.2145

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe37 = {
{-0.0552355,0.0039220,0.0565375}
};
rMatsBase37 = {
{-0.2795002,0.5570910,-0.7820034},
{0.8333184,0.5453127,0.0906340},
{0.4769278,-0.6263256,-0.6166491}
};
outThetasWam37 = {
{-0.0703631,-0.3807841,-0.0241575,1.5567489,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.617820e+04
Final                            1.079717e-22
Change                           1.617820e+04

Minimizer iterations                      115
Successful steps                           91
Unsuccessful steps                         24
Line search steps                          68

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0087
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5752
    Line search gradient evaluation    0.3209
  Linear solver                        0.0021
  Line search polynomial minimization  0.0003
Minimizer                              0.5883

Postprocessor                          0.0000
Total                                  0.5884

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe38 = {
{-0.0552890,0.0043143,0.0563598}
};
rMatsBase38 = {
{-0.2778194,0.5465770,-0.7899810},
{0.8302513,0.5502786,0.0887486},
{0.4832176,-0.6312267,-0.6066743}
};
outThetasWam38 = {
{-0.0701424,-0.3813363,-0.0232966,1.5602261,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.629436e+04
Final                            2.616842e-22
Change                           1.629436e+04

Minimizer iterations                      201
Successful steps                          173
Unsuccessful steps                         28
Line search steps                         113

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0152
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.0559
    Line search gradient evaluation    0.5663
  Linear solver                        0.0039
  Line search polynomial minimization  0.0005
Minimizer                              1.0792

Postprocessor                          0.0000
Total                                  1.0793

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr39 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe39 = {
{-0.0552913,0.0043719,0.0563501}
};
rMatsBase39 = {
{-0.2764586,0.5377360,-0.7964990},
{0.8272207,0.5550098,0.0875789},
{0.4891591,-0.6346685,-0.5982636}
};
outThetasWam39 = {
{-0.0699058,-0.3809659,-0.0224787,1.5658219,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.641286e+04
Final                            6.176713e-22
Change                           1.641286e+04

Minimizer iterations                       57
Successful steps                           41
Unsuccessful steps                         16
Line search steps                          33

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0043
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2724
    Line search gradient evaluation    0.1578
  Linear solver                        0.0012
  Line search polynomial minimization  0.0002
Minimizer                              0.2791

Postprocessor                          0.0000
Total                                  0.2791

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe40 = {
{-0.0550847,0.0047645,0.0564008}
};
rMatsBase40 = {
{-0.2732007,0.5266614,-0.8049777},
{0.8253770,0.5581403,0.0850426},
{0.4940791,-0.6411764,-0.5871785}
};
outThetasWam40 = {
{-0.0695557,-0.3829474,-0.0215729,1.5718445,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.640747e+04
Final                            1.704301e-22
Change                           1.640747e+04

Minimizer iterations                       65
Successful steps                           47
Unsuccessful steps                         18
Line search steps                          40

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0049
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3113
    Line search gradient evaluation    0.1803
  Linear solver                        0.0013
  Line search polynomial minimization  0.0002
Minimizer                              0.3189

Postprocessor                          0.0000
Total                                  0.3190

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe41 = {
{-0.0549607,0.0061131,0.0562059}
};
rMatsBase41 = {
{-0.2698363,0.5152649,-0.8134436},
{0.8276586,0.5558491,0.0775435},
{0.4921073,-0.6523295,-0.5764517}
};
outThetasWam41 = {
{-0.0678176,-0.3901783,-0.0186108,1.5777883,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.649707e+04
Final                            1.919327e-22
Change                           1.649707e+04

Minimizer iterations                       84
Successful steps                           68
Unsuccessful steps                         16
Line search steps                          45

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0069
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4619
    Line search gradient evaluation    0.2552
  Linear solver                        0.0018
  Line search polynomial minimization  0.0002
Minimizer                              0.4726

Postprocessor                          0.0000
Total                                  0.4726

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe42 = {
{-0.0550296,0.0067426,0.0561809}
};
rMatsBase42 = {
{-0.2672943,0.5043461,-0.8210900},
{0.8261088,0.5586056,0.0741896},
{0.4960827,-0.6584792,-0.5659569}
};
outThetasWam42 = {
{-0.0670357,-0.3922863,-0.0170143,1.5846183,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.658466e+04
Final                            1.843047e-22
Change                           1.658466e+04

Minimizer iterations                      129
Successful steps                           97
Unsuccessful steps                         32
Line search steps                          81

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0110
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6919
    Line search gradient evaluation    0.3944
  Linear solver                        0.0032
  Line search polynomial minimization  0.0005
Minimizer                              0.7094

Postprocessor                          0.0000
Total                                  0.7095

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr43 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe43 = {
{-0.0547889,0.0071250,0.0561929}
};
rMatsBase43 = {
{-0.2646303,0.4932268,-0.8286725},
{0.8247067,0.5611338,0.0706237},
{0.4998297,-0.6647226,-0.5552605}
};
outThetasWam43 = {
{-0.0662026,-0.3946326,-0.0153578,1.5912184,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.670363e+04
Final                            5.755510e-22
Change                           1.670363e+04

Minimizer iterations                      104
Successful steps                           81
Unsuccessful steps                         23
Line search steps                          60

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0085
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5657
    Line search gradient evaluation    0.3170
  Linear solver                        0.0020
  Line search polynomial minimization  0.0003
Minimizer                              0.5784

Postprocessor                          0.0000
Total                                  0.5784

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr44 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe44 = {
{-0.0544912,0.0076783,0.0563475}
};
rMatsBase44 = {
{-0.2595648,0.4808587,-0.8374969},
{0.8236239,0.5630435,0.0680129},
{0.5042518,-0.6721286,-0.5421930}
};
outThetasWam44 = {
{-0.0657359,-0.3980848,-0.0143972,1.5991983,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.676412e+04
Final                            6.236374e-22
Change                           1.676412e+04

Minimizer iterations                       68
Successful steps                           47
Unsuccessful steps                         21
Line search steps                          43

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0057
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3516
    Line search gradient evaluation    0.2086
  Linear solver                        0.0014
  Line search polynomial minimization  0.0002
Minimizer                              0.3602

Postprocessor                          0.0000
Total                                  0.3603

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe45 = {
{-0.0546850,0.0085457,0.0560306}
};
rMatsBase45 = {
{-0.2570875,0.4701199,-0.8443301},
{0.8229572,0.5645163,0.0637408},
{0.5066039,-0.6784605,-0.5320186}
};
outThetasWam45 = {
{-0.0646006,-0.4013331,-0.0123166,1.6055391,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.682017e+04
Final                            3.239664e-22
Change                           1.682017e+04

Minimizer iterations                      208
Successful steps                          197
Unsuccessful steps                         11
Line search steps                         103

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0172
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.2467
    Line search gradient evaluation    0.6382
  Linear solver                        0.0043
  Line search polynomial minimization  0.0005
Minimizer                              1.2728

Postprocessor                          0.0000
Total                                  1.2729

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe46 = {
{-0.0546221,0.0095484,0.0559278}
};
rMatsBase46 = {
{-0.2518323,0.4615552,-0.8506158},
{0.8240984,0.5630918,0.0615593},
{0.5073878,-0.6854885,-0.5221716}
};
outThetasWam46 = {
{-0.0640950,-0.4067987,-0.0114885,1.6109222,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.683568e+04
Final                            1.525387e-22
Change                           1.683568e+04

Minimizer iterations                      165
Successful steps                          146
Unsuccessful steps                         19
Line search steps                          86

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0129
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.9119
    Line search gradient evaluation    0.4832
  Linear solver                        0.0030
  Line search polynomial minimization  0.0004
Minimizer                              0.9309

Postprocessor                          0.0000
Total                                  0.9310

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe47 = {
{-0.0548186,0.0106542,0.0556041}
};
rMatsBase47 = {
{-0.2491290,0.4526469,-0.8561808},
{0.8249166,0.5623458,0.0572699},
{0.5073927,-0.6920101,-0.5134926}
};
outThetasWam47 = {
{-0.0626877,-0.4119606,-0.0090839,1.6172950,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.684675e+04
Final                            2.833666e-22
Change                           1.684675e+04

Minimizer iterations                      114
Successful steps                           96
Unsuccessful steps                         18
Line search steps                          63

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0088
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5797
    Line search gradient evaluation    0.3146
  Linear solver                        0.0028
  Line search polynomial minimization  0.0004
Minimizer                              0.5942

Postprocessor                          0.0000
Total                                  0.5943

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe48 = {
{-0.0545238,0.0115745,0.0555017}
};
rMatsBase48 = {
{-0.2437559,0.4460623,-0.8611686},
{0.8274131,0.5588668,0.0552767},
{0.5059354,-0.6990682,-0.5053049}
};
outThetasWam48 = {
{-0.0618915,-0.4194226,-0.0078826,1.6227877,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.684011e+04
Final                            9.038867e-23
Change                           1.684011e+04

Minimizer iterations                      383
Successful steps                          355
Unsuccessful steps                         28
Line search steps                         201

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0290
    Line search cost evaluation        0.0000
  Jacobian evaluation                  2.0683
    Line search gradient evaluation    1.0706
  Linear solver                        0.0071
  Line search polynomial minimization  0.0011
Minimizer                              2.1121

Postprocessor                          0.0000
Total                                  2.1122

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe49 = {
{-0.0543249,0.0125935,0.0554748}
};
rMatsBase49 = {
{-0.2398189,0.4396440,-0.8655635},
{0.8296153,0.5558635,0.0524799},
{0.5042076,-0.7054991,-0.4980419}
};
outThetasWam49 = {
{-0.0607005,-0.4266209,-0.0059822,1.6281535,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.680656e+04
Final                            2.695365e-22
Change                           1.680656e+04

Minimizer iterations                       51
Successful steps                           35
Unsuccessful steps                         16
Line search steps                          30

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0040
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2434
    Line search gradient evaluation    0.1438
  Linear solver                        0.0013
  Line search polynomial minimization  0.0002
Minimizer                              0.2500

Postprocessor                          0.0000
Total                                  0.2500

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe50 = {
{-0.0544299,0.0139929,0.0551813}
};
rMatsBase50 = {
{-0.2349590,0.4355035,-0.8689827},
{0.8330411,0.5508705,0.0508359},
{0.5008362,-0.7119540,-0.4922242}
};
outThetasWam50 = {
{-0.0596407,-0.4355195,-0.0043971,1.6337268,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.677413e+04
Final                            6.648446e-22
Change                           1.677413e+04

Minimizer iterations                       65
Successful steps                           46
Unsuccessful steps                         19
Line search steps                          40

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0049
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3094
    Line search gradient evaluation    0.1805
  Linear solver                        0.0014
  Line search polynomial minimization  0.0002
Minimizer                              0.3172

Postprocessor                          0.0000
Total                                  0.3172

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe51 = {
{-0.0542641,0.0150847,0.0550261}
};
rMatsBase51 = {
{-0.2307375,0.4316848,-0.8720140},
{0.8361129,0.5463442,0.0492261},
{0.4976699,-0.7177439,-0.4869993}
};
outThetasWam51 = {
{-0.0585556,-0.4440938,-0.0027495,1.6383646,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.672591e+04
Final                            1.152037e-22
Change                           1.672591e+04

Minimizer iterations                      104
Successful steps                           81
Unsuccessful steps                         23
Line search steps                          59

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0080
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5220
    Line search gradient evaluation    0.2934
  Linear solver                        0.0023
  Line search polynomial minimization  0.0003
Minimizer                              0.5346

Postprocessor                          0.0000
Total                                  0.5347

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe52 = {
{-0.0537810,0.0160435,0.0549414}
};
rMatsBase52 = {
{-0.2247485,0.4311203,-0.8738555},
{0.8406117,0.5393361,0.0498853},
{0.4928084,-0.7233615,-0.4836197}
};
outThetasWam52 = {
{-0.0580164,-0.4548385,-0.0021345,1.6411310,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.667333e+04
Final                            2.163752e-22
Change                           1.667333e+04

Minimizer iterations                       52
Successful steps                           37
Unsuccessful steps                         15
Line search steps                          30

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0042
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2505
    Line search gradient evaluation    0.1465
  Linear solver                        0.0013
  Line search polynomial minimization  0.0002
Minimizer                              0.2575

Postprocessor                          0.0000
Total                                  0.2576

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe53 = {
{-0.0532963,0.0171583,0.0549318}
};
rMatsBase53 = {
{-0.2203330,0.4284301,-0.8762996},
{0.8443898,0.5335261,0.0485356},
{0.4883229,-0.7292445,-0.4793155}
};
outThetasWam53 = {
{-0.0567117,-0.4659337,-0.0001874,1.6446302,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.663266e+04
Final                            6.929242e-22
Change                           1.663266e+04

Minimizer iterations                       77
Successful steps                           57
Unsuccessful steps                         20
Line search steps                          49

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0059
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3799
    Line search gradient evaluation    0.2176
  Linear solver                        0.0014
  Line search polynomial minimization  0.0002
Minimizer                              0.3886

Postprocessor                          0.0000
Total                                  0.3886

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe54 = {
{-0.0528345,0.0184656,0.0551112}
};
rMatsBase54 = {
{-0.2154035,0.4270861,-0.8781793},
{0.8480894,0.5276217,0.0485761},
{0.4840926,-0.7343111,-0.4758587}
};
outThetasWam54 = {
{-0.0557825,-0.4773604,0.0010422,1.6467185,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.658372e+04
Final                            3.012655e-22
Change                           1.658372e+04

Minimizer iterations                      104
Successful steps                           82
Unsuccessful steps                         22
Line search steps                          60

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0079
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5313
    Line search gradient evaluation    0.2961
  Linear solver                        0.0020
  Line search polynomial minimization  0.0003
Minimizer                              0.5433

Postprocessor                          0.0000
Total                                  0.5434

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe55 = {
{-0.0527549,0.0202434,0.0548420}
};
rMatsBase55 = {
{-0.2105832,0.4261707,-0.8797916},
{0.8519322,0.5213877,0.0486451},
{0.4794436,-0.7392790,-0.4728640}
};
outThetasWam55 = {
{-0.0546575,-0.4901758,0.0025159,1.6488994,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.651222e+04
Final                            3.963833e-23
Change                           1.651222e+04

Minimizer iterations                       80
Successful steps                           59
Unsuccessful steps                         21
Line search steps                          45

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0061
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3891
    Line search gradient evaluation    0.2232
  Linear solver                        0.0019
  Line search polynomial minimization  0.0002
Minimizer                              0.3989

Postprocessor                          0.0000
Total                                  0.3989

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA56 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe56 = {
{-0.0521247,0.0213367,0.0548629}
};
rMatsBase56 = {
{-0.2060438,0.4270232,-0.8804528},
{0.8561991,0.5143101,0.0490745},
{0.4737817,-0.7437314,-0.4715873}
};
outThetasWam56 = {
{-0.0535011,-0.5039720,0.0040106,1.6510943,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.643070e+04
Final                            1.876691e-22
Change                           1.643070e+04

Minimizer iterations                      170
Successful steps                          148
Unsuccessful steps                         22
Line search steps                          95

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0128
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8899
    Line search gradient evaluation    0.4755
  Linear solver                        0.0033
  Line search polynomial minimization  0.0004
Minimizer                              0.9094

Postprocessor                          0.0000
Total                                  0.9095

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr57 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe57 = {
{-0.0515830,0.0224938,0.0547302}
};
rMatsBase57 = {
{-0.2017596,0.4285985,-0.8806795},
{0.8605360,0.5069709,0.0495817},
{0.4677296,-0.7478528,-0.4711106}
};
outThetasWam57 = {
{-0.0522589,-0.5185754,0.0056497,1.6534181,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.616124e+04
Final                            3.336727e-22
Change                           1.616124e+04

Minimizer iterations                       74
Successful steps                           55
Unsuccessful steps                         19
Line search steps                          44

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0063
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3656
    Line search gradient evaluation    0.2091
  Linear solver                        0.0023
  Line search polynomial minimization  0.0003
Minimizer                              0.3766

Postprocessor                          0.0000
Total                                  0.3766

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr58 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe58 = {
{-0.0511163,0.0240147,0.0545352}
};
rMatsBase58 = {
{-0.1945109,0.4431851,-0.8750728},
{0.8709370,0.4884425,0.0537826},
{0.4512584,-0.7516720,-0.4809937}
};
outThetasWam58 = {
{-0.0519307,-0.5409210,0.0061555,1.6567272,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.618098e+04
Final                            5.757917e-22
Change                           1.618098e+04

Minimizer iterations                       47
Successful steps                           31
Unsuccessful steps                         16
Line search steps                          27

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2219
    Line search gradient evaluation    0.1337
  Linear solver                        0.0012
  Line search polynomial minimization  0.0002
Minimizer                              0.2282

Postprocessor                          0.0000
Total                                  0.2282

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr59 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe59 = {
{-0.0502651,0.0249860,0.0550583}
};
rMatsBase59 = {
{-0.1909293,0.4379276,-0.8785018},
{0.8718100,0.4869400,0.0532615},
{0.4511023,-0.7557175,-0.4747607}
};
outThetasWam59 = {
{-0.0504427,-0.5525069,0.0084702,1.6607914,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.619053e+04
Final                            1.295515e-22
Change                           1.619053e+04

Minimizer iterations                      168
Successful steps                          149
Unsuccessful steps                         19
Line search steps                          89

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0126
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8828
    Line search gradient evaluation    0.4687
  Linear solver                        0.0031
  Line search polynomial minimization  0.0004
Minimizer                              0.9016

Postprocessor                          0.0000
Total                                  0.9016

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr60 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe60 = {
{-0.0496142,0.0262383,0.0551639}
};
rMatsBase60 = {
{-0.1849866,0.4364154,-0.8805235},
{0.8738620,0.4829631,0.0557848},
{0.4496057,-0.7591365,-0.4707085}
};
outThetasWam60 = {
{-0.0498684,-0.5668276,0.0094037,1.6635221,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.621352e+04
Final                            2.830660e-22
Change                           1.621352e+04

Minimizer iterations                       68
Successful steps                           47
Unsuccessful steps                         21
Line search steps                          40

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0059
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3501
    Line search gradient evaluation    0.2068
  Linear solver                        0.0017
  Line search polynomial minimization  0.0003
Minimizer                              0.3596

Postprocessor                          0.0000
Total                                  0.3596

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr61 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe61 = {
{-0.0484847,0.0268254,0.0557230}
};
rMatsBase61 = {
{-0.1845528,0.4343984,-0.8816112},
{0.8739845,0.4828367,0.0549530},
{0.4495457,-0.7603728,-0.4687664}
};
outThetasWam61 = {
{-0.0473025,-0.5826421,0.0116167,1.6661054,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.619985e+04
Final                            1.172064e-22
Change                           1.619985e+04

Minimizer iterations                       58
Successful steps                           39
Unsuccessful steps                         19
Line search steps                          31

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0051
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3011
    Line search gradient evaluation    0.1813
  Linear solver                        0.0014
  Line search polynomial minimization  0.0002
Minimizer                              0.3092

Postprocessor                          0.0000
Total                                  0.3093

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr62 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe62 = {
{-0.0474343,0.0277481,0.0562884}
};
rMatsBase62 = {
{-0.1823632,0.4388204,-0.8798752},
{0.8756972,0.4794128,0.0576004},
{0.4470996,-0.7600000,-0.4717011}
};
outThetasWam62 = {
{-0.0452953,-0.6035374,0.0124802,1.6686032,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.617928e+04
Final                            1.784131e-22
Change                           1.617928e+04

Minimizer iterations                       72
Successful steps                           47
Unsuccessful steps                         25
Line search steps                          42

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0061
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3632
    Line search gradient evaluation    0.2192
  Linear solver                        0.0020
  Line search polynomial minimization  0.0002
Minimizer                              0.3733

Postprocessor                          0.0000
Total                                  0.3734

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA63 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl63 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa63 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr63 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe63 = {
{-0.0465794,0.0285675,0.0566902}
};
rMatsBase63 = {
{-0.1769011,0.4384023,-0.8811977},
{0.8779071,0.4750446,0.0600976},
{0.4449551,-0.7629785,-0.4689124}
};
outThetasWam63 = {
{-0.0453184,-0.6144283,0.0133744,1.6700647,0.0000000,0.0000000,0.0000000}
};
(* 
W1104 07:48:38.119532  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.616188e+04
Final                            1.886768e-22
Change                           1.616188e+04

Minimizer iterations                      146
Successful steps                          103
Unsuccessful steps                         43
Line search steps                          85

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0119
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7555
    Line search gradient evaluation    0.4425
  Linear solver                        0.0033
  Line search polynomial minimization  0.0005
Minimizer                              0.7743

Postprocessor                          0.0000
Total                                  0.7743

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe64 = {
{-0.0454923,0.0294734,0.0571267}
};
rMatsBase64 = {
{-0.1774864,0.4406100,-0.8799781},
{0.8785634,0.4738356,0.0600511},
{0.4434241,-0.7624583,-0.4712031}
};
outThetasWam64 = {
{-0.0424052,-0.6330524,0.0157552,1.6698836,0.0000000,0.0000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.612763e+04
Final                            5.532126e-22
Change                           1.612763e+04

Minimizer iterations                       75
Successful steps                           50
Unsuccessful steps                         25
Line search steps                          40

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0062
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3789
    Line search gradient evaluation    0.2268
  Linear solver                        0.0018
  Line search polynomial minimization  0.0002
Minimizer                              0.3888

Postprocessor                          0.0000
Total                                  0.3888

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr65 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe65 = {
{-0.0447003,0.0305715,0.0573429}
};
rMatsBase65 = {
{-0.1729909,0.4395612,-0.8813967},
{0.8805585,0.4699262,0.0615305},
{0.4412378,-0.7654771,-0.4683524}
};
outThetasWam65 = {
{-0.0419755,-0.6435122,0.0174956,1.6692765,0.0000000,0.0000000,0.0000000}
};
(* 
W1104 07:48:39.243345  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.391538  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.471487  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.524371  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.564649  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.805543  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.805589  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:39.955495  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.089625  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.142952  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.211247  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.286005  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.286047  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.323197  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.503993  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.577908  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.639624  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.639679  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.777732  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.835013  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:40.998740  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.016019  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.044670  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.258994  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.364298  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.364352  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.375643  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.384171  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.564035  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.667613  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.786672  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.810204  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:41.860193  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.009375  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.035959  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.068974  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.176751  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.223465  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.624713  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.667541  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.936532  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.959926  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:42.982940  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:43.344539  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:43.592100  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:43.603960  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:43.714342  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:43.976652  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.104204  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.169504  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.214290  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.313792  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.380769  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.443815  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:44.443861  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.610126e+04
Final                            1.749517e+02
Change                           1.592631e+04

Minimizer iterations                      501
Successful steps                          435
Unsuccessful steps                         66
Line search steps                         989

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0374
    Line search cost evaluation        0.0000
  Jacobian evaluation                  5.3333
    Line search gradient evaluation    4.0767
  Linear solver                        0.0141
  Line search polynomial minimization  0.0110
Minimizer                              5.4121

Postprocessor                          0.0000
Total                                  5.4122

Termination:                   NO_CONVERGENCE (Maximum number of iterations reached. Number of iterations: 500.)

*) 
fitErrUA66 = {
{-0.0162434,0.2268462,0.0996413}
};
fitErrEl66 = {
{-0.0353573,0.2213892,0.1063350}
};
fitErrLa66 = {
{-0.0361940,0.2322617,0.1093308}
};
fitErrWr66 = {
{-0.1022513,0.2028417,0.1497413}
};
fitErrEe66 = {
{-0.1590180,0.2282916,0.2154498}
};
rMatsBase66 = {
{-0.1316566,0.4359414,-0.8902930},
{0.8469660,0.5161365,0.1274823},
{0.5150875,-0.7372640,-0.4371803}
};
outThetasWam66 = {
{-0.0823117,-0.1807315,-0.0184484,1.4577175,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.2482971
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  4.548582e+01    0.00e+00    2.78e+00   0.00e+00   0.00e+00  1.00e+04        0    2.84e-03    2.88e-03
   1  4.852955e+00    4.06e+01    2.82e+00   1.36e-02   1.78e+00  3.00e+04        1    5.79e-03    8.69e-03
   2  7.765076e-05    4.85e+00    2.78e+00   6.65e-04   1.95e+00  9.00e+04        1    5.76e-03    1.45e-02
   3  8.226858e-13    7.77e-05    8.43e-03   1.71e-06   1.80e+00  2.70e+05        1    5.75e-03    2.02e-02
   4  1.306605e-20    8.23e-13    4.52e-06   5.01e-10   1.80e+00  8.10e+05        1    5.74e-03    2.60e-02
   5  2.349542e-21    1.07e-20    3.65e-06   5.23e-14   1.80e+00  2.43e+06        1    6.09e-03    3.21e-02
   6  1.422673e-20   -1.19e-20    6.56e-06   1.23e-15   1.80e+00  7.29e+06        1    5.73e-03    3.79e-02
   7  1.219821e-20    2.03e-21    6.86e-06   8.26e-15   1.80e+00  2.19e+07        1    5.79e-03    4.37e-02
   8  2.991560e-22    1.19e-20    9.40e-07   1.05e-14   1.80e+00  6.56e+07        1    6.04e-03    4.97e-02
   9  2.050028e-21   -1.75e-21    2.11e-06   2.42e-15   1.80e+00  1.97e+08        1    6.05e-03    5.58e-02
  10  1.510673e-21    5.39e-22    1.49e-06   3.14e-15   1.80e+00  5.90e+08        1    5.84e-03    6.17e-02
  11  2.987724e-20   -2.84e-20    1.07e-05   1.93e-15   1.80e+00  1.77e+09        1    5.80e-03    6.75e-02
  12  2.200938e-20    7.87e-21    9.24e-06   1.37e-14   1.80e+00  5.31e+09        1    5.75e-03    7.33e-02
  13  2.684439e-21    1.93e-20    3.22e-06   8.95e-15   1.80e+00  1.59e+10        1    5.79e-03    7.91e-02
  14  1.598998e-22    2.52e-21    5.84e-07   1.41e-15   9.81e-01  4.78e+10        1    5.78e-03    8.49e-02
  15  4.251323e-21   -4.09e-21    5.83e-06   2.26e-15   4.84e-01  4.78e+10        1    5.78e-03    9.07e-02
  16  8.727506e-21   -4.48e-21    4.92e-06   5.62e-15   3.70e-01  4.70e+10        1    5.79e-03    9.65e-02
  17  1.282486e-20   -4.10e-21    6.92e-06   7.47e-15   2.63e-01  4.25e+10        1    5.78e-03    1.02e-01
  18  6.611641e-21    6.21e-21    6.62e-06   9.40e-15   4.89e-01  4.25e+10        1    5.79e-03    1.08e-01
  19  4.156030e-21    2.46e-21    4.07e-06   7.98e-15   3.90e-01  4.20e+10        1    5.71e-03    1.14e-01
  20  3.946870e-21    2.09e-22    5.57e-06   6.45e-15   3.85e-01  4.15e+10        1    5.76e-03    1.20e-01
  21  9.251266e-21   -5.30e-21    8.93e-06   7.35e-15   1.34e-01  2.98e+10        1    5.78e-03    1.25e-01
  22  1.127350e-21    8.12e-21    2.07e-06   8.40e-15   8.85e-01  5.49e+10        1    5.77e-03    1.31e-01
  23  7.598637e-21   -6.47e-21    5.20e-06   2.52e-15   1.42e-01  4.01e+10        1    5.69e-03    1.37e-01
  24  6.950172e-21    6.48e-22    7.01e-06   7.92e-15   1.34e-01  2.88e+10        1    5.77e-03    1.43e-01
  25  1.029582e-20   -3.35e-21    6.80e-06   5.91e-15   4.98e-02  1.66e+10        1    5.77e-03    1.48e-01
  26  9.355537e-21    9.40e-22    5.44e-06   1.00e-14   9.42e-02  1.08e+10        1    5.72e-03    1.54e-01
  27  4.835179e-21    4.52e-21    6.35e-06   7.43e-15   5.05e-01  1.08e+10        1    5.76e-03    1.60e-01
  28  1.009076e-21    3.83e-21    1.80e-06   3.89e-15   8.35e-01  1.55e+10        1    5.75e-03    1.66e-01
  29  8.722523e-21   -7.71e-21    5.33e-06   6.56e-15   5.45e-02  9.07e+09        1    5.76e-03    1.71e-01
  30  1.266312e-20   -3.94e-21    7.09e-06   6.61e-15   1.95e-03  4.56e+09        1    5.74e-03    1.77e-01
  31  9.591467e-21    3.07e-21    8.07e-06   5.40e-15   2.46e-01  4.03e+09        1    5.66e-03    1.83e-01
  32  1.119255e-20   -1.60e-21    6.17e-06   5.70e-15   1.56e-02  2.11e+09        1    5.84e-03    1.89e-01
  33  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  1.06e+09        1    3.08e-03    1.92e-01
  34  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  2.64e+08        1    3.06e-03    1.95e-01
  35  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  3.30e+07        1    3.26e-03    1.98e-01
  36  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  2.06e+06        1    3.24e-03    2.02e-01
  37  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  6.44e+04        1    3.23e-03    2.05e-01
  38  2.892434e-20   -1.77e-20    0.00e+00   1.33e-14  -1.39e-01  1.01e+03        1    3.15e-03    2.08e-01
  39  1.135255e-20   -1.60e-22    9.73e-06   1.33e-14   1.27e-02  5.23e+02        1    6.16e-03    2.14e-01
  40  2.555397e-20   -1.42e-20    0.00e+00   3.64e-15  -1.01e-01  2.61e+02        1    3.17e-03    2.17e-01
  41  2.363265e-21    8.99e-21    4.24e-06   3.58e-15   8.14e-01  3.48e+02        1    6.17e-03    2.24e-01
  42  3.701890e-20   -3.47e-20    0.00e+00   2.66e-15  -1.88e-01  1.74e+02        1    3.19e-03    2.27e-01
  43  3.630039e-20   -3.39e-20    0.00e+00   2.63e-15  -1.82e-01  4.35e+01        1    3.12e-03    2.30e-01
  44  4.191245e-21   -1.83e-21    5.57e-06   2.61e-15   6.71e-02  2.63e+01        1    6.14e-03    2.36e-01
  45  2.673241e-21    1.52e-21    3.14e-06   6.78e-15   3.74e-01  2.59e+01        1    6.22e-03    2.42e-01
  46  1.269552e-21    1.40e-21    3.06e-06   1.87e-15   5.59e-01  2.60e+01        1    6.14e-03    2.48e-01
  47  5.461529e-22    7.23e-22    1.93e-06   1.13e-15   6.97e-01  2.77e+01        1    6.17e-03    2.55e-01
  48  1.857976e-21   -1.31e-21    2.29e-06   2.27e-15   8.02e-02  1.74e+01        1    6.14e-03    2.61e-01
  49  1.502873e-20   -1.32e-20    0.00e+00   5.52e-15  -1.59e-02  8.69e+00        1    3.17e-03    2.64e-01
  50  1.135944e-20   -9.50e-21    6.08e-06   5.07e-15   1.06e-02  4.48e+00        1    6.15e-03    2.70e-01
  51  5.262305e-21    6.10e-21    4.00e-06   6.31e-15   5.98e-01  4.52e+00        1    6.19e-03    2.76e-01
  52  9.265967e-21   -4.00e-21    5.66e-06   1.66e-15   2.31e-02  2.42e+00        1    6.21e-03    2.83e-01
  53  2.668773e-20   -1.74e-20    0.00e+00   9.11e-15  -8.55e-02  1.21e+00        1    3.15e-03    2.86e-01
  54  1.250768e-21    8.02e-21    1.87e-06   7.10e-15   1.03e+00  3.63e+00        1    6.14e-03    2.92e-01
  55  2.035203e-21   -7.84e-22    2.81e-06   2.97e-15   6.63e-02  2.20e+00        1    6.14e-03    2.98e-01
  56  3.688386e-21   -1.65e-21    3.70e-06   4.35e-15   5.56e-02  1.29e+00        1    6.15e-03    3.04e-01
  57  2.430188e-20   -2.06e-20    0.00e+00   5.01e-15  -6.85e-02  6.45e-01        1    3.14e-03    3.07e-01
  58  3.341169e-21    3.47e-22    4.08e-06   3.44e-15   1.24e-01  4.53e-01        1    6.13e-03    3.13e-01
  59  5.817557e-21   -2.48e-21    5.13e-06   2.46e-15   4.13e-02  2.56e-01        1    6.15e-03    3.20e-01
  60  1.461203e-20   -8.79e-21    0.00e+00   1.73e-15  -1.03e-02  1.28e-01        1    3.13e-03    3.23e-01
  61  5.294600e-21    5.23e-22    3.96e-06   1.21e-15   2.43e-01  1.13e-01        1    6.14e-03    3.29e-01
  62  9.203773e-21   -3.91e-21    8.78e-06   8.64e-16   2.08e-02  5.99e-02        1    6.12e-03    3.35e-01
  63  2.498715e-20   -1.58e-20    0.00e+00   6.50e-16  -6.88e-02  2.99e-02        1    3.09e-03    3.38e-01
  64  4.579252e-22    8.75e-21    1.30e-06   4.35e-16   5.08e+00  8.98e-02        1    6.19e-03    3.44e-01
  65  8.497400e-22   -3.92e-22    1.51e-06   4.59e-16   6.81e-02  5.46e-02        1    6.23e-03    3.51e-01
  66  1.841337e-20   -1.76e-20    0.00e+00   2.30e-16  -3.18e-02  2.73e-02        1    3.13e-03    3.54e-01
  67  8.140065e-22    3.57e-23    1.48e-06   2.22e-16   5.57e-01  2.73e-02        1    6.31e-03    3.60e-01
  68  5.753151e-22    2.39e-22    1.17e-06   9.81e-18   3.91e+00  8.20e-02        1    6.29e-03    3.66e-01
  69  2.025820e-21   -1.45e-21    3.83e-06   2.37e-16   6.14e-02  4.90e-02        1    6.24e-03    3.73e-01
  70  4.816166e-21   -2.79e-21    3.62e-06   3.35e-16   4.54e-02  2.80e-02        1    6.15e-03    3.79e-01
  71  8.899360e-21   -4.08e-21    4.96e-06   2.37e-16   2.22e-02  1.49e-02        1    6.19e-03    3.85e-01
  72  9.660554e-21   -7.61e-22    5.75e-06   2.30e-16   1.79e-02  7.87e-03        1    6.19e-03    3.91e-01
  73  9.529941e-21    1.31e-22    5.68e-06   2.11e-17   5.93e-01  7.92e-03        1    6.09e-03    3.97e-01
  74  9.505883e-21    2.41e-23    5.66e-06   1.39e-17   1.12e-01  5.40e-03        1    6.13e-03    4.04e-01
  75  9.408373e-21    9.75e-23    5.64e-06   1.39e-17   6.66e-01  5.60e-03        1    6.16e-03    4.10e-01
  76  5.550932e-21    3.86e-21    4.32e-06   1.39e-17   2.56e+01  1.68e-02        1    6.19e-03    4.16e-01
  77  5.724262e-21   -1.73e-22    3.81e-06   2.26e-16   3.98e-02  9.44e-03        1    6.17e-03    4.22e-01
  78  5.684060e-21    4.02e-23    3.82e-06   9.81e-18   2.41e-01  8.29e-03        1    6.18e-03    4.28e-01
  79  5.593391e-21    9.07e-23    3.79e-06   9.81e-18   6.29e-01  8.43e-03        1    6.17e-03    4.35e-01
  80  5.633448e-21   -4.01e-23    3.77e-06   9.81e-18   4.02e-02  4.74e-03        1    6.17e-03    4.41e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          4.548582e+01
Final                            1.598998e-22
Change                           4.548582e+01

Minimizer iterations                       81
Successful steps                           66
Unsuccessful steps                         15
Line search steps                          44

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0067
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4320
    Line search gradient evaluation    0.2390
  Linear solver                        0.0021
  Line search polynomial minimization  0.0003
Minimizer                              0.4438

Postprocessor                          0.0000
Total                                  0.4439

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.607466e+04
Final                            1.776708e+02
Change                           1.589699e+04

Minimizer iterations                      145
Successful steps                           91
Unsuccessful steps                         54
Line search steps                         245

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0117
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.2102
    Line search gradient evaluation    0.9351
  Linear solver                        0.0028
  Line search polynomial minimization  0.0019
Minimizer                              1.2294

Postprocessor                          0.0000
Total                                  1.2295

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA67 = {
{-0.0221741,0.2539012,0.1124247}
};
fitErrEl67 = {
{-0.0435455,0.2474762,0.1198054}
};
fitErrLa67 = {
{-0.0445209,0.2598648,0.1231670}
};
fitErrWr67 = {
{-0.1193609,0.2269094,0.1683059}
};
fitErrEe67 = {
{-0.1766936,0.2523952,0.2353226}
};
rMatsBase67 = {
{-0.2646136,0.6052074,-0.7508020},
{0.8496725,0.5145489,0.1153085},
{0.4561099,-0.6074236,-0.6503847}
};
outThetasWam67 = {
{-0.0844199,-0.3960417,-0.0405808,1.4316717,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.2785620
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  3.689088e+01    0.00e+00    2.78e+00   0.00e+00   0.00e+00  1.00e+04        0    3.06e-03    3.11e-03
   1  4.782086e+00    3.21e+01    2.82e+00   1.28e-02   1.74e+00  3.00e+04        1    6.38e-03    9.51e-03
   2  1.617313e-04    4.78e+00    2.78e+00   6.40e-04   1.95e+00  9.00e+04        1    6.46e-03    1.60e-02
   3  8.984251e-13    1.62e-04    1.27e-02   1.85e-06   1.76e+00  2.70e+05        1    6.44e-03    2.25e-02
   4  3.640990e-20    8.98e-13    9.78e-06   5.06e-10   1.76e+00  8.10e+05        1    6.26e-03    2.88e-02
   5  2.313760e-20    1.33e-20    1.22e-05   4.89e-14   1.76e+00  2.43e+06        1    6.14e-03    3.50e-02
   6  1.105362e-20    1.21e-20    8.16e-06   9.92e-15   1.76e+00  7.29e+06        1    6.18e-03    4.12e-02
   7  2.197698e-21    8.86e-21    2.28e-06   1.18e-14   1.76e+00  2.19e+07        1    6.16e-03    4.74e-02
   8  1.157030e-20   -9.37e-21    6.26e-06   4.08e-15   1.76e+00  6.56e+07        1    6.21e-03    5.36e-02
   9  9.879437e-21    1.69e-21    9.01e-06   1.33e-14   1.76e+00  1.97e+08        1    6.17e-03    5.98e-02
  10  4.251400e-21    5.63e-21    5.99e-06   2.02e-15   1.76e+00  5.90e+08        1    6.18e-03    6.60e-02
  11  6.615346e-21   -2.36e-21    4.92e-06   3.84e-15   1.76e+00  1.77e+09        1    6.15e-03    7.21e-02
  12  3.626018e-21    2.99e-21    3.19e-06   1.03e-14   1.76e+00  5.31e+09        1    6.14e-03    7.83e-02
  13  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  2.66e+09        1    3.15e-03    8.15e-02
  14  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  6.64e+08        1    3.18e-03    8.47e-02
  15  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  8.30e+07        1    3.14e-03    8.78e-02
  16  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  5.19e+06        1    3.13e-03    9.10e-02
  17  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  1.62e+05        1    3.13e-03    9.41e-02
  18  1.161822e-20   -7.99e-21    0.00e+00   5.43e-15  -1.40e-03  2.53e+03        1    3.15e-03    9.73e-02
  19  1.161655e-20   -7.99e-21    0.00e+00   5.43e-15  -1.35e-03  1.98e+01        1    3.14e-03    1.00e-01
  20  2.515914e-20   -2.15e-20    0.00e+00   5.39e-15  -3.98e-01  7.73e-02        1    3.13e-03    1.04e-01
  21  2.529340e-21    1.10e-21    3.49e-06   9.06e-16   1.56e+00  2.32e-01        1    6.11e-03    1.10e-01
  22  2.710069e-20   -2.46e-20    0.00e+00   1.87e-15  -4.64e-01  1.16e-01        1    3.14e-03    1.13e-01
  23  1.775096e-21    7.54e-22    2.10e-06   1.17e-15   7.71e-01  1.38e-01        1    6.14e-03    1.19e-01
  24  1.858432e-20   -1.68e-20    0.00e+00   1.15e-15  -2.08e-01  6.90e-02        1    3.14e-03    1.22e-01
  25  5.821722e-21   -4.05e-21    4.71e-06   6.88e-16   1.72e-01  5.38e-02        1    6.16e-03    1.28e-01
  26  3.733225e-21    2.09e-21    4.39e-06   9.01e-16   2.17e+00  1.61e-01        1    6.13e-03    1.34e-01
  27  6.704173e-22    3.06e-21    1.37e-06   1.65e-15   1.87e+00  4.84e-01        1    6.12e-03    1.41e-01
  28  5.847382e-21   -5.18e-21    4.73e-06   6.27e-16   1.57e-01  3.66e-01        1    6.15e-03    1.47e-01
  29  3.350015e-21    2.50e-21    3.06e-06   2.40e-15   7.51e-01  4.19e-01        1    6.17e-03    1.53e-01
  30  2.388169e-21    9.62e-22    3.18e-06   4.05e-15   4.10e-01  4.16e-01        1    6.15e-03    1.59e-01
  31  3.250091e-21   -8.62e-22    3.18e-06   2.97e-15   1.90e-01  3.36e-01        1    6.26e-03    1.65e-01
  32  3.461163e-21   -2.11e-22    4.00e-06   3.16e-15   1.77e-01  2.65e-01        1    6.37e-03    1.72e-01
  33  7.483048e-22    2.71e-21    2.30e-06   2.11e-15   1.33e+00  7.94e-01        1    6.22e-03    1.78e-01
  34  4.113162e-21   -3.36e-21    3.52e-06   1.08e-15   1.45e-01  5.84e-01        1    6.17e-03    1.84e-01
  35  3.196608e-21    9.17e-22    3.78e-06   3.50e-15   2.89e-01  5.43e-01        1    6.18e-03    1.90e-01
  36  5.893076e-21   -2.70e-21    0.00e+00   4.09e-15  -2.59e-03  2.72e-01        1    3.15e-03    1.94e-01
  37  8.107493e-22    2.39e-21    2.14e-06   2.95e-15   1.21e+00  8.15e-01        1    6.21e-03    2.00e-01
  38  2.967909e-21   -2.16e-21    3.08e-06   2.29e-15   1.62e-01  6.23e-01        1    6.21e-03    2.06e-01
  39  2.455874e-21    5.12e-22    3.51e-06   3.63e-15   2.43e-01  5.48e-01        1    6.16e-03    2.12e-01
  40  7.965413e-21   -5.51e-21    0.00e+00   2.40e-15  -9.86e-02  2.74e-01        1    3.14e-03    2.15e-01
  41  1.225080e-21    1.23e-21    2.09e-06   1.69e-15   9.38e-01  8.23e-01        1    6.18e-03    2.22e-01
  42  9.780416e-22    2.47e-22    1.96e-06   6.95e-16   4.44e-01  8.22e-01        1    6.15e-03    2.28e-01
  43  1.338103e-21   -3.60e-22    1.71e-06   6.18e-16   2.03e-01  6.80e-01        1    6.18e-03    2.34e-01
  44  6.861292e-21   -5.52e-21    0.00e+00   1.69e-15  -4.41e-02  3.40e-01        1    3.11e-03    2.37e-01
  45  3.529393e-22    9.85e-22    8.91e-07   1.23e-15   1.38e+00  1.02e+00        1    6.09e-03    2.43e-01
  46  5.700467e-22   -2.17e-22    8.85e-07   2.30e-16   2.29e-01  8.79e-01        1    6.16e-03    2.49e-01
  47  1.303102e-21   -7.33e-22    1.85e-06   4.63e-16   1.96e-01  7.18e-01        1    6.15e-03    2.56e-01
  48  1.925208e-22    1.11e-21    1.98e-07   4.68e-15   1.16e+00  2.15e+00        1    6.14e-03    2.62e-01
  49  3.640268e-21   -3.45e-21    3.50e-06   1.83e-15   9.13e-02  1.39e+00        1    6.15e-03    2.68e-01
  50  3.797880e-21   -1.58e-22    5.75e-06   6.96e-15   7.47e-02  8.63e-01        1    6.16e-03    2.74e-01
  51  5.346238e-21   -1.55e-21    3.94e-06   2.01e-15   1.62e-02  4.53e-01        1    6.12e-03    2.80e-01
  52  5.696982e-22    4.78e-21    1.03e-06   3.32e-15   1.16e+00  1.36e+00        1    6.15e-03    2.86e-01
  53  5.387919e-22    3.09e-23    1.13e-06   3.81e-15   1.49e-01  1.01e+00        1    6.15e-03    2.92e-01
  54  7.257388e-21   -6.72e-21    0.00e+00   1.60e-15  -3.87e-01  5.05e-01        1    3.13e-03    2.96e-01
  55  1.622611e-21   -1.08e-21    2.87e-06   7.27e-16   7.66e-01  5.94e-01        1    6.15e-03    3.02e-01
  56  1.205904e-20   -1.04e-20    0.00e+00   1.26e-15  -1.09e+00  2.97e-01        1    3.14e-03    3.05e-01
  57  7.973227e-22    8.25e-22    1.52e-06   9.20e-16   7.59e-01  3.45e-01        1    6.26e-03    3.11e-01
  58  5.792947e-21   -5.00e-21    0.00e+00   2.02e-15  -6.89e-02  1.73e-01        1    3.26e-03    3.15e-01
  59  2.616707e-21   -1.82e-21    3.03e-06   1.12e-15   4.31e-01  1.72e-01        1    6.23e-03    3.21e-01
  60  3.424523e-22    2.27e-21    4.82e-07   1.80e-15   2.15e+00  5.16e-01        1    6.13e-03    3.27e-01
  61  5.119058e-22   -1.69e-22    1.19e-06   2.67e-15   6.37e-01  5.27e-01        1    6.18e-03    3.33e-01
  62  3.372883e-21   -2.86e-21    3.77e-06   1.79e-15   2.50e-01  4.69e-01        1    6.16e-03    3.39e-01
  63  4.959888e-22    2.88e-21    1.22e-06   2.38e-15   1.30e+00  1.41e+00        1    6.16e-03    3.45e-01
  64  4.471181e-22    4.89e-23    7.58e-07   5.61e-16   4.70e-01  1.41e+00        1    6.15e-03    3.52e-01
  65  2.356657e-22    2.11e-22    6.42e-07   1.00e-15   2.03e+00  4.22e+00        1    6.31e-03    3.58e-01
  66  7.615634e-22   -5.26e-22    1.32e-06   5.33e-16   4.30e-01  4.21e+00        1    6.22e-03    3.64e-01
  67  4.488941e-21   -3.73e-21    4.55e-06   2.13e-15   7.63e-02  2.62e+00        1    6.19e-03    3.70e-01
  68  2.788260e-21    1.70e-21    2.78e-06   3.43e-15   4.25e-01  2.61e+00        1    6.28e-03    3.77e-01
  69  5.446673e-21   -2.66e-21    0.00e+00   4.29e-15  -5.67e-03  1.30e+00        1    3.14e-03    3.80e-01
  70  1.299068e-21    1.49e-21    1.78e-06   3.59e-15   6.20e-01  1.32e+00        1    6.17e-03    3.86e-01
  71  5.391695e-21   -4.09e-21    0.00e+00   6.46e-15  -2.42e-03  6.61e-01        1    3.16e-03    3.89e-01
  72  4.557418e-22    8.43e-22    1.10e-06   4.68e-15   8.76e-01  1.15e+00        1    6.10e-03    3.95e-01
  73  9.571657e-21   -9.12e-21    0.00e+00   1.59e-15  -2.24e-01  5.76e-01        1    3.13e-03    3.99e-01
  74  1.267989e-20   -1.22e-20    0.00e+00   1.14e-15  -3.90e-01  1.44e-01        1    3.10e-03    4.02e-01
  75  1.779465e-21   -1.32e-21    2.32e-06   4.65e-16   1.91e-01  1.16e-01        1    6.16e-03    4.08e-01
  76  1.946027e-21   -1.67e-22    2.34e-06   9.00e-16   1.77e-01  9.18e-02        1    6.14e-03    4.14e-01
  77  8.230812e-22    1.12e-21    2.25e-06   6.94e-16   2.19e+00  2.75e-01        1    6.11e-03    4.20e-01
  78  3.449534e-22    4.78e-22    9.49e-07   3.02e-16   9.91e-01  8.26e-01        1    6.10e-03    4.26e-01
  79  7.996047e-21   -7.65e-21    0.00e+00   1.14e-15  -1.31e-01  4.13e-01        1    3.14e-03    4.29e-01
  80  7.673225e-21   -7.33e-21    0.00e+00   9.22e-16  -1.15e-01  1.03e-01        1    3.13e-03    4.33e-01
  81  4.729898e-21   -4.38e-21    4.54e-06   2.51e-16   3.05e-02  5.65e-02        1    6.10e-03    4.39e-01
  82  7.842590e-21   -3.11e-21    0.00e+00   5.85e-16  -1.16e-01  2.82e-02        1    3.14e-03    4.42e-01
  83  1.886232e-21    2.84e-21    2.32e-06   3.26e-16   3.74e+00  8.47e-02        1    6.14e-03    4.48e-01
  84  4.848310e-21   -2.96e-21    3.83e-06   6.88e-16   2.32e-02  4.54e-02        1    6.25e-03    4.54e-01
  85  3.574382e-21    1.27e-21    3.13e-06   6.84e-16   1.66e+00  1.36e-01        1    6.36e-03    4.61e-01
  86  3.200199e-22    3.25e-21    1.14e-06   1.23e-15   2.09e+00  4.09e-01        1    6.26e-03    4.67e-01
  87  8.520844e-22   -5.32e-22    1.74e-06   7.51e-16   1.88e-01  3.29e-01        1    6.20e-03    4.73e-01
  88  1.653112e-21   -8.01e-22    2.02e-06   9.68e-16   1.52e-01  2.46e-01        1    6.19e-03    4.79e-01
  89  6.682065e-21   -5.03e-21    0.00e+00   1.80e-15  -5.35e-02  1.23e-01        1    3.15e-03    4.83e-01
  90  9.981943e-22    6.55e-22    1.68e-06   1.12e-15   1.54e+00  3.68e-01        1    6.18e-03    4.89e-01
  91  2.913342e-21   -1.92e-21    3.27e-06   1.17e-15   9.67e-02  2.42e-01        1    6.18e-03    4.95e-01
  92  2.014702e-21    8.99e-22    2.27e-06   2.03e-15   6.36e-01  2.47e-01        1    6.19e-03    5.01e-01
  93  1.298250e-21    7.16e-22    1.68e-06   1.80e-15   8.64e-01  4.02e-01        1    6.12e-03    5.07e-01
  94  1.553547e-20   -1.42e-20    0.00e+00   1.37e-15  -3.65e-01  2.01e-01        1    3.15e-03    5.10e-01
  95  1.112149e-20   -9.82e-21    0.00e+00   9.11e-16  -2.08e-01  5.03e-02        1    3.14e-03    5.14e-01
  96  4.240164e-21   -2.94e-21    5.70e-06   2.30e-16   4.02e-02  2.83e-02        1    6.12e-03    5.20e-01
  97  6.027629e-21   -1.79e-21    0.00e+00   3.22e-16  -2.41e-02  1.41e-02        1    3.16e-03    5.23e-01
  98  6.900704e-21   -2.66e-21    0.00e+00   2.52e-16  -5.57e-02  3.54e-03        1    3.14e-03    5.26e-01
  99  4.328099e-21   -8.79e-23    5.88e-06   9.81e-18   3.69e-02  1.97e-03        1    6.16e-03    5.32e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          3.689088e+01
Final                            1.925208e-22
Change                           3.689088e+01

Minimizer iterations                      100
Successful steps                           72
Unsuccessful steps                         28
Line search steps                          58

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0084
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5208
    Line search gradient evaluation    0.3029
  Linear solver                        0.0025
  Line search polynomial minimization  0.0003
Minimizer                              0.5353

Postprocessor                          0.0000
Total                                  0.5354

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:48:46.897644  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:46.922466  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:46.962381  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:47.109300  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:47.732657  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:48.735270  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:49.915606  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:49.967660  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:52.260253  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.606785e+04
Final                            1.777255e+02
Change                           1.589012e+04

Minimizer iterations                      501
Successful steps                          404
Unsuccessful steps                         97
Line search steps                        1320

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0375
    Line search cost evaluation        0.0000
  Jacobian evaluation                  5.8291
    Line search gradient evaluation    4.6861
  Linear solver                        0.0100
  Line search polynomial minimization  0.0111
Minimizer                              5.8984

Postprocessor                          0.0000
Total                                  5.8984

Termination:                   NO_CONVERGENCE (Maximum number of iterations reached. Number of iterations: 500.)

*) 
fitErrUA68 = {
{-0.0265539,0.2754235,0.1226796}
};
fitErrEl68 = {
{-0.0497320,0.2682399,0.1306171}
};
fitErrLa68 = {
{-0.0507989,0.2820026,0.1343697}
};
fitErrWr68 = {
{-0.1339470,0.2461385,0.1835452}
};
fitErrEe68 = {
{-0.1918786,0.2718847,0.2516034}
};
rMatsBase68 = {
{-0.2581143,0.6029930,-0.7548354},
{0.8530078,0.5090740,0.1149846},
{0.4536020,-0.6142013,-0.6457570}
};
outThetasWam68 = {
{-0.0955433,-0.3581508,-0.0458975,1.4142471,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3026772
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  4.091106e+01    0.00e+00    2.78e+00   0.00e+00   0.00e+00  1.00e+04        0    2.87e-03    2.91e-03
   1  4.936432e+00    3.60e+01    2.78e+00   1.28e-02   1.76e+00  3.00e+04        1    5.83e-03    8.75e-03
   2  3.384471e-04    4.94e+00    2.78e+00   6.62e-04   1.95e+00  9.00e+04        1    5.52e-03    1.43e-02
   3  1.204779e-12    3.38e-04    2.07e-02   2.19e-06   1.78e+00  2.70e+05        1    5.44e-03    1.98e-02
   4  1.164847e-20    1.20e-12    3.41e-06   5.65e-10   1.78e+00  8.10e+05        1    5.81e-03    2.56e-02
   5  3.871704e-21    7.78e-21    3.89e-06   4.39e-14   1.78e+00  2.43e+06        1    5.51e-03    3.11e-02
   6  4.360580e-21   -4.89e-22    3.70e-06   6.61e-15   1.78e+00  7.29e+06        1    5.60e-03    3.67e-02
   7  9.395258e-21   -5.03e-21    8.76e-06   9.24e-15   1.78e+00  2.19e+07        1    5.76e-03    4.25e-02
   8  7.874683e-22    8.61e-21    1.65e-06   1.13e-14   1.78e+00  6.56e+07        1    5.72e-03    4.82e-02
   9  1.334510e-20   -1.26e-20    7.00e-06   2.90e-15   1.78e+00  1.97e+08        1    5.99e-03    5.42e-02
  10  4.927699e-21    8.42e-21    4.48e-06   1.01e-14   1.78e+00  5.90e+08        1    5.89e-03    6.01e-02
  11  2.888730e-21    2.04e-21    3.27e-06   6.79e-15   1.78e+00  1.77e+09        1    5.65e-03    6.58e-02
  12  1.894668e-21    9.94e-22    2.25e-06   3.68e-15   1.78e+00  5.31e+09        1    5.50e-03    7.13e-02
  13  6.453860e-22    1.25e-21    1.63e-06   4.57e-15   1.78e+00  1.59e+10        1    5.76e-03    7.71e-02
  14  1.488650e-21   -8.43e-22    2.49e-06   2.95e-15   1.78e+00  4.78e+10        1    5.60e-03    8.27e-02
  15  1.343203e-20   -1.19e-20    6.95e-06   3.62e-15   1.78e+00  1.43e+11        1    5.43e-03    8.82e-02
  16  2.904622e-21    1.05e-20    4.42e-06   1.65e-14   1.78e+00  4.30e+11        1    5.72e-03    9.39e-02
  17  2.932549e-21   -2.79e-23    4.80e-06   1.39e-15   1.78e+00  1.29e+12        1    5.77e-03    9.97e-02
  18  1.587600e-20   -1.29e-20    6.59e-06   1.91e-15   1.78e+00  3.87e+12        1    5.99e-03    1.06e-01
  19  6.952723e-21    8.92e-21    4.61e-06   1.34e-14   5.69e-01  3.88e+12        1    5.77e-03    1.11e-01
  20  8.942817e-21   -1.99e-21    5.96e-06   4.73e-15   3.17e-01  3.70e+12        1    5.75e-03    1.17e-01
  21  5.134833e-21    3.81e-21    4.43e-06   1.22e-14   4.28e-01  3.69e+12        1    5.67e-03    1.23e-01
  22  6.643644e-21   -1.51e-21    4.76e-06   8.39e-15   2.59e-01  3.32e+12        1    5.76e-03    1.29e-01
  23  1.481856e-21    5.16e-21    2.68e-06   1.15e-14   7.92e-01  4.14e+12        1    5.74e-03    1.34e-01
  24  2.638939e-21   -1.16e-21    3.64e-06   4.06e-15   3.04e-01  3.90e+12        1    5.91e-03    1.40e-01
  25  4.571260e-22    2.18e-21    1.41e-06   4.01e-15   8.44e-01  5.78e+12        1    5.78e-03    1.46e-01
  26  6.609849e-21   -6.15e-21    5.54e-06   8.16e-16   1.99e-01  4.75e+12        1    5.61e-03    1.52e-01
  27  1.712890e-20   -1.05e-20    0.00e+00   7.77e-15  -2.37e-02  2.37e+12        1    2.88e-03    1.55e-01
  28  1.217460e-21    5.39e-21    3.09e-06   7.77e-15   8.67e-01  3.93e+12        1    5.52e-03    1.60e-01
  29  4.465278e-21   -3.25e-21    3.98e-06   3.02e-15   2.12e-01  3.30e+12        1    5.64e-03    1.66e-01
  30  2.783840e-21    1.68e-21    3.93e-06   3.45e-15   3.90e-01  3.27e+12        1    5.96e-03    1.72e-01
  31  6.495083e-21   -3.71e-21    7.53e-06   1.67e-15   1.54e-01  2.45e+12        1    6.01e-03    1.78e-01
  32  4.227084e-21    2.27e-21    5.81e-06   3.52e-15   3.59e-01  2.40e+12        1    5.62e-03    1.84e-01
  33  1.099777e-21    3.13e-21    2.24e-06   3.60e-15   7.48e-01  2.73e+12        1    5.83e-03    1.89e-01
  34  9.323490e-21   -8.22e-21    0.00e+00   5.46e-15  -1.05e-01  1.37e+12        1    2.84e-03    1.92e-01
  35  9.323490e-21   -8.22e-21    0.00e+00   5.46e-15  -1.05e-01  3.42e+11        1    2.81e-03    1.95e-01
  36  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  4.27e+10        1    2.85e-03    1.98e-01
  37  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  2.67e+09        1    2.89e-03    2.01e-01
  38  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  8.34e+07        1    3.24e-03    2.04e-01
  39  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  1.30e+06        1    3.45e-03    2.08e-01
  40  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  1.02e+04        1    2.87e-03    2.11e-01
  41  9.141471e-21   -8.04e-21    0.00e+00   5.46e-15  -9.80e-02  3.98e+01        1    2.85e-03    2.13e-01
  42  2.075756e-21   -9.76e-22    2.52e-06   4.05e-15   1.76e-01  3.13e+01        1    5.64e-03    2.19e-01
  43  2.832084e-21   -7.56e-22    3.34e-06   3.91e-15   1.38e-01  2.27e+01        1    5.77e-03    2.25e-01
  44  7.111504e-21   -4.28e-21    0.00e+00   3.20e-15  -1.67e-02  1.13e+01        1    2.85e-03    2.28e-01
  45  1.560942e-21    1.27e-21    3.08e-06   3.37e-15   4.63e-01  1.13e+01        1    5.47e-03    2.33e-01
  46  1.016733e-21    5.44e-22    2.47e-06   1.18e-15   4.05e-01  1.13e+01        1    6.53e-03    2.40e-01
  47  6.443147e-21   -5.43e-21    4.87e-06   2.08e-15   5.19e-03  5.71e+00        1    5.67e-03    2.46e-01
  48  3.291125e-21    3.15e-21    3.46e-06   1.02e-14   5.04e-01  5.71e+00        1    5.49e-03    2.51e-01
  49  2.699839e-22    3.02e-21    9.14e-07   5.92e-15   9.44e-01  1.71e+01        1    5.66e-03    2.57e-01
  50  8.009545e-21   -7.74e-21    0.00e+00   3.88e-16  -3.35e-02  8.57e+00        1    2.83e-03    2.60e-01
  51  4.103146e-22   -1.40e-22    9.31e-07   3.39e-16   1.49e-01  6.36e+00        1    5.51e-03    2.65e-01
  52  2.613200e-21   -2.20e-21    4.74e-06   1.82e-15   9.50e-02  4.16e+00        1    6.04e-03    2.71e-01
  53  5.724772e-22    2.04e-21    1.99e-06   3.22e-15   8.02e-01  5.34e+00        1    6.10e-03    2.77e-01
  54  4.049410e-21   -3.48e-21    3.59e-06   1.00e-15   5.67e-02  3.14e+00        1    5.64e-03    2.83e-01
  55  6.830725e-22    3.37e-21    1.30e-06   4.86e-15   8.89e-01  5.94e+00        1    5.77e-03    2.89e-01
  56  2.136673e-21   -1.45e-21    2.95e-06   1.71e-15   4.38e-01  5.93e+00        1    5.48e-03    2.94e-01
  57  1.150169e-20   -9.37e-21    0.00e+00   1.83e-15  -1.22e+00  2.97e+00        1    2.81e-03    2.97e-01
  58  6.970987e-22    1.44e-21    1.22e-06   1.88e-15   8.35e-01  4.25e+00        1    5.63e-03    3.03e-01
  59  1.724209e-21   -1.03e-21    2.62e-06   8.36e-16   3.66e-01  4.17e+00        1    6.51e-03    3.09e-01
  60  7.261348e-21   -5.54e-21    0.00e+00   2.18e-15  -4.01e-01  2.08e+00        1    2.81e-03    3.12e-01
  61  1.076019e-20   -9.04e-21    0.00e+00   2.36e-15  -8.43e-01  5.21e-01        1    2.87e-03    3.15e-01
  62  1.780488e-20   -1.61e-20    0.00e+00   2.05e-15  -1.80e+00  6.51e-02        1    2.87e-03    3.18e-01
  63  3.949532e-21   -2.23e-21    4.04e-06   6.73e-16   1.48e-02  3.40e-02        1    5.64e-03    3.23e-01
  64  6.851889e-22    3.26e-21    1.54e-06   4.56e-16   6.28e+00  1.02e-01        1    5.56e-03    3.29e-01
  65  3.433514e-21   -2.75e-21    4.18e-06   4.66e-16   8.24e-02  6.45e-02        1    5.88e-03    3.35e-01
  66  1.485992e-21    1.95e-21    2.06e-06   7.16e-16   2.05e+00  1.93e-01        1    6.51e-03    3.41e-01
  67  3.378867e-21   -1.89e-21    3.04e-06   1.13e-15   7.52e-02  1.20e-01        1    5.75e-03    3.47e-01
  68  1.776391e-21    1.60e-21    2.41e-06   1.16e-15   1.53e+00  3.60e-01        1    5.54e-03    3.53e-01
  69  1.924636e-20   -1.75e-20    0.00e+00   1.85e-15  -1.36e+00  1.80e-01        1    2.98e-03    3.56e-01
  70  3.532776e-21   -1.76e-21    3.76e-06   1.38e-15   4.76e-02  1.03e-01        1    5.57e-03    3.61e-01
  71  5.433638e-22    2.99e-21    1.52e-06   1.15e-15   2.50e+00  3.10e-01        1    5.49e-03    3.67e-01
  72  5.288905e-21   -4.75e-21    0.00e+00   4.48e-16  -9.99e-02  1.55e-01        1    2.95e-03    3.70e-01
  73  6.871849e-22   -1.44e-22    1.74e-06   3.45e-16   2.73e-01  1.42e-01        1    6.53e-03    3.76e-01
  74  9.755824e-21   -9.07e-21    0.00e+00   3.42e-16  -4.51e-01  7.09e-02        1    2.88e-03    3.79e-01
  75  1.558892e-22    5.31e-22    6.26e-07   2.58e-16   2.49e+00  2.13e-01        1    5.58e-03    3.85e-01
  76  3.730230e-22   -2.17e-22    9.66e-07   2.37e-16   2.92e-01  1.98e-01        1    5.67e-03    3.90e-01
  77  9.765695e-21   -9.39e-21    0.00e+00   6.72e-16  -4.49e-01  9.92e-02        1    2.86e-03    3.93e-01
  78  9.738648e-21   -9.37e-21    0.00e+00   4.52e-16  -4.49e-01  2.48e-02        1    2.84e-03    3.96e-01
  79  4.039002e-22   -3.09e-23    1.05e-06   2.22e-16   2.89e-01  2.31e-02        1    5.52e-03    4.02e-01
  80  3.454359e-22    5.85e-23    9.88e-07   1.43e-17   2.17e+00  6.92e-02        1    6.55e-03    4.08e-01
  81  3.248061e-21   -2.90e-21    5.26e-06   2.25e-16   6.30e-02  4.15e-02        1    5.73e-03    4.14e-01
  82  8.839562e-21   -5.59e-21    0.00e+00   2.51e-16  -3.53e-01  2.07e-02        1    3.12e-03    4.17e-01
  83  8.372223e-21   -5.12e-21    0.00e+00   1.27e-16  -3.28e-01  5.19e-03        1    3.08e-03    4.20e-01
  84  3.121412e-21    1.27e-22    5.15e-06   1.25e-17   9.71e-01  1.56e-02        1    5.97e-03    4.26e-01
  85  8.372223e-21   -5.25e-21    0.00e+00   1.22e-16  -1.06e+01  7.78e-03        1    2.91e-03    4.29e-01
  86  3.111567e-21    9.85e-24    5.14e-06   2.22e-17   4.34e-01  7.76e-03        1    5.68e-03    4.35e-01
  87  2.641994e-21    4.70e-22    4.71e-06   2.22e-17   2.57e+00  2.33e-02        1    6.63e-03    4.42e-01
  88  9.692282e-21   -7.05e-21    0.00e+00   1.27e-16  -7.05e+00  1.16e-02        1    3.01e-03    4.45e-01
  89  1.315930e-21    1.33e-21    3.17e-06   1.15e-16   5.95e+00  3.49e-02        1    5.76e-03    4.50e-01
  90  5.360893e-21   -4.04e-21    0.00e+00   1.29e-16  -2.11e+00  1.75e-02        1    2.94e-03    4.53e-01
  91  1.040597e-21    2.75e-22    1.81e-06   1.15e-16   2.52e+00  5.24e-02        1    5.75e-03    4.59e-01
  92  1.022245e-21    1.84e-23    2.06e-06   4.65e-16   2.06e+00  1.57e-01        1    5.62e-03    4.65e-01
  93  7.749448e-22    2.47e-22    1.98e-06   7.12e-16   1.66e+00  4.71e-01        1    5.69e-03    4.70e-01
  94  1.298445e-20   -1.22e-20    0.00e+00   8.42e-16  -4.62e+00  2.36e-01        1    2.87e-03    4.73e-01
  95  1.423534e-21   -6.49e-22    2.93e-06   5.90e-16   9.14e-01  5.46e-01        1    5.48e-03    4.79e-01
  96  2.183964e-21   -7.60e-22    3.33e-06   9.74e-16   3.41e-01  5.29e-01        1    6.53e-03    4.85e-01
  97  9.041803e-21   -6.86e-21    0.00e+00   1.63e-15  -1.20e+00  2.64e-01        1    2.88e-03    4.88e-01
  98  2.283137e-22    1.96e-21    1.02e-06   1.11e-15   1.36e+00  7.93e-01        1    5.65e-03    4.94e-01
  99  3.561949e-21   -3.33e-21    0.00e+00   3.35e-16  -6.71e-02  3.97e-01        1    2.86e-03    4.97e-01
 100  4.546049e-21   -4.32e-21    0.00e+00   2.39e-16  -2.78e-01  9.92e-02        1    2.99e-03    5.00e-01
 101  5.718930e-21   -5.49e-21    0.00e+00   1.21e-16  -5.34e-01  1.24e-02        1    2.89e-03    5.03e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          4.091106e+01
Final                            1.558892e-22
Change                           4.091106e+01

Minimizer iterations                      102
Successful steps                           72
Unsuccessful steps                         30
Line search steps                          62

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0078
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4919
    Line search gradient evaluation    0.2880
  Linear solver                        0.0026
  Line search polynomial minimization  0.0003
Minimizer                              0.5055

Postprocessor                          0.0000
Total                                  0.5055

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.611118e+04
Final                            1.738598e+02
Change                           1.593732e+04

Minimizer iterations                       97
Successful steps                           55
Unsuccessful steps                         42
Line search steps                         120

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0070
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5806
    Line search gradient evaluation    0.4314
  Linear solver                        0.0015
  Line search polynomial minimization  0.0008
Minimizer                              0.5913

Postprocessor                          0.0000
Total                                  0.5914

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA69 = {
{-0.0283668,0.2845569,0.1274777}
};
fitErrEl69 = {
{-0.0522831,0.2770611,0.1356437}
};
fitErrLa69 = {
{-0.0533833,0.2914761,0.1395969}
};
fitErrWr69 = {
{-0.1403045,0.2546875,0.1901702}
};
fitErrEe69 = {
{-0.1977794,0.2800420,0.2593388}
};
rMatsBase69 = {
{-0.2736397,0.6241682,-0.7318029},
{0.8453369,0.5190193,0.1265882},
{0.4588321,-0.5839804,-0.6696566}
};
outThetasWam69 = {
{-0.0875062,-0.3810878,-0.0454076,1.4065307,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3130940
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  7.259623e+01    0.00e+00    2.82e+00   0.00e+00   0.00e+00  1.00e+04        0    2.87e-03    2.90e-03
   1  1.544541e+00    7.11e+01    2.82e+00   7.17e-03   1.95e+00  3.00e+04        1    5.84e-03    8.76e-03
   2  7.906250e-06    1.54e+00    2.78e+00   2.42e-04   1.95e+00  9.00e+04        1    5.72e-03    1.45e-02
   3  3.696213e-14    7.91e-06    1.87e-03   4.09e-07   1.95e+00  2.70e+05        1    5.54e-03    2.01e-02
   4  8.058896e-21    3.70e-14    5.24e-06   1.04e-10   1.95e+00  8.10e+05        1    5.54e-03    2.56e-02
   5  7.853262e-21    2.06e-22    4.80e-06   1.17e-14   1.95e+00  2.43e+06        1    5.62e-03    3.12e-02
   6  8.573597e-21   -7.20e-22    5.79e-06   8.20e-15   1.95e+00  7.29e+06        1    5.61e-03    3.69e-02
   7  8.244600e-21    3.29e-22    5.23e-06   1.19e-14   1.95e+00  2.19e+07        1    5.54e-03    4.24e-02
   8  9.091277e-21   -8.47e-22    6.13e-06   8.65e-15   1.95e+00  6.56e+07        1    5.51e-03    4.79e-02
   9  4.040242e-21    5.05e-21    3.16e-06   1.18e-14   1.95e+00  1.97e+08        1    5.92e-03    5.39e-02
  10  2.236554e-20   -1.83e-20    9.30e-06   9.10e-15   1.95e+00  5.90e+08        1    5.75e-03    5.96e-02
  11  9.213939e-21    1.32e-20    6.15e-06   1.87e-14   1.95e+00  1.77e+09        1    5.55e-03    6.52e-02
  12  3.289994e-20   -2.37e-20    1.10e-05   1.11e-14   1.95e+00  5.31e+09        1    5.75e-03    7.10e-02
  13  2.171219e-20    1.12e-20    9.13e-06   2.27e-14   1.95e+00  1.59e+10        1    5.53e-03    7.65e-02
  14  1.442407e-21    2.03e-20    1.75e-06   2.22e-14   1.95e+00  4.78e+10        1    5.58e-03    8.21e-02
  15  2.452091e-20   -2.31e-20    9.81e-06   4.80e-15   1.95e+00  1.43e+11        1    5.56e-03    8.77e-02
  16  3.303437e-21    2.12e-20    3.23e-06   1.57e-14   1.95e+00  4.30e+11        1    5.54e-03    9.32e-02
  17  3.092173e-21    2.11e-22    2.69e-06   7.42e-15   1.95e+00  1.29e+12        1    5.52e-03    9.88e-02
  18  8.887214e-21   -5.80e-21    5.93e-06   8.25e-15   1.95e+00  3.87e+12        1    5.51e-03    1.04e-01
  19  6.289909e-22    8.26e-21    1.88e-06   1.06e-14   1.95e+00  1.16e+13        1    5.52e-03    1.10e-01
  20  4.424804e-21   -3.80e-21    4.40e-06   2.14e-15   1.95e+00  3.49e+13        1    5.74e-03    1.16e-01
  21  3.467840e-21    9.57e-22    3.59e-06   7.36e-15   1.95e+00  1.05e+14        1    5.87e-03    1.21e-01
  22  8.897490e-22    2.58e-21    2.20e-06   7.60e-15   1.95e+00  3.14e+14        1    5.77e-03    1.27e-01
  23  5.778235e-21   -4.89e-21    6.96e-06   6.93e-15   1.95e+00  9.41e+14        1    5.71e-03    1.33e-01
  24  3.852589e-21    1.93e-21    3.45e-06   8.93e-15   1.95e+00  2.82e+15        1    5.57e-03    1.39e-01
  25  1.713532e-21    2.14e-21    1.31e-06   1.58e-14   7.30e-01  3.13e+15        1    5.57e-03    1.44e-01
  26  8.452349e-21   -6.74e-21    0.00e+00   8.77e-15  -2.90e-01  1.56e+15        1    2.86e-03    1.47e-01
  27  1.070089e-20   -8.99e-21    0.00e+00   8.26e-15  -5.34e-01  3.91e+14        1    2.84e-03    1.50e-01
  28  3.420200e-20   -3.25e-20    0.00e+00   8.35e-15  -3.08e+00  4.89e+13        1    2.86e-03    1.53e-01
  29  9.199751e-21   -7.49e-21    0.00e+00   8.39e-15  -3.71e-01  3.05e+12        1    2.88e-03    1.56e-01
  30  1.084105e-20   -9.13e-21    0.00e+00   8.42e-15  -5.49e-01  9.54e+10        1    2.88e-03    1.59e-01
  31  1.084105e-20   -9.13e-21    0.00e+00   8.42e-15  -5.49e-01  1.49e+09        1    2.86e-03    1.61e-01
  32  1.084105e-20   -9.13e-21    0.00e+00   8.42e-15  -5.49e-01  1.16e+07        1    2.91e-03    1.64e-01
  33  1.084105e-20   -9.13e-21    0.00e+00   8.42e-15  -5.49e-01  4.55e+04        1    2.87e-03    1.67e-01
  34  1.084105e-20   -9.13e-21    0.00e+00   8.42e-15  -5.49e-01  8.89e+01        1    2.82e-03    1.70e-01
  35  1.122750e-20   -9.51e-21    0.00e+00   7.81e-15  -5.91e-01  8.68e-02        1    2.92e-03    1.73e-01
  36  2.014818e-21   -3.01e-22    2.88e-06   4.66e-16   4.34e-01  8.66e-02        1    5.86e-03    1.79e-01
  37  8.066737e-21   -6.05e-21    0.00e+00   2.59e-16  -2.49e-01  4.33e-02        1    2.95e-03    1.82e-01
  38  4.070673e-20   -3.87e-20    0.00e+00   1.36e-16  -3.89e+00  1.08e-02        1    2.85e-03    1.85e-01
  39  1.760803e-21    2.54e-22    2.45e-06   1.96e-17   2.70e+00  3.25e-02        1    5.60e-03    1.90e-01
  40  4.293200e-20   -4.12e-20    0.00e+00   1.20e-16  -4.15e+00  1.62e-02        1    2.84e-03    1.93e-01
  41  1.824649e-21   -6.38e-23    2.54e-06   2.71e-17   4.46e-01  1.62e-02        1    5.58e-03    1.99e-01
  42  1.793872e-21    3.08e-23    2.58e-06   2.71e-17   4.44e-01  1.62e-02        1    5.58e-03    2.04e-01
  43  1.817520e-21   -2.36e-23    2.56e-06   2.71e-17   4.37e-01  1.62e-02        1    5.54e-03    2.10e-01
  44  5.086536e-21   -3.27e-21    4.39e-06   2.71e-17   7.53e-02  1.00e-02        1    6.01e-03    2.16e-01
  45  3.425302e-20   -2.92e-20    0.00e+00   1.16e-16  -3.01e+00  5.01e-03        1    2.99e-03    2.19e-01
  46  4.769814e-21    3.17e-22    5.36e-06   1.73e-17   2.21e+00  1.50e-02        1    5.82e-03    2.25e-01
  47  3.575744e-20   -3.10e-20    0.00e+00   1.20e-16  -3.08e+00  7.52e-03        1    2.89e-03    2.28e-01
  48  4.171574e-21    5.98e-22    4.86e-06   2.22e-17   2.86e+00  2.25e-02        1    5.67e-03    2.33e-01
  49  3.160578e-20   -2.74e-20    0.00e+00   1.29e-16  -2.58e+00  1.13e-02        1    3.22e-03    2.37e-01
  50  3.529625e-20   -3.11e-20    0.00e+00   1.15e-16  -3.02e+00  2.82e-03        1    2.93e-03    2.40e-01
  51  4.618587e-21   -4.47e-22    5.12e-06   9.81e-18   1.21e-01  1.96e-03        1    5.78e-03    2.45e-01
  52  4.493784e-21    1.25e-22    5.04e-06   7.76e-18   2.31e+00  5.89e-03        1    5.53e-03    2.51e-01
  53  4.749006e-21   -2.55e-22    5.26e-06   1.96e-17   1.05e-01  3.94e-03        1    5.51e-03    2.56e-01
  54  4.749512e-21   -5.06e-25    5.23e-06   1.25e-17   1.04e-01  2.63e-03        1    5.50e-03    2.62e-01
  55  4.761829e-21   -1.23e-23    5.37e-06   9.81e-18   1.02e-01  1.75e-03        1    5.85e-03    2.68e-01
  56  4.646330e-21    1.15e-22    5.30e-06   7.76e-18   2.28e+00  5.25e-03        1    5.70e-03    2.73e-01
  57  4.057980e-21    5.88e-22    4.75e-06   1.73e-17   4.12e+00  1.57e-02        1    5.57e-03    2.79e-01
  58  3.537559e-20   -3.13e-20    0.00e+00   1.19e-16  -2.82e+00  7.87e-03        1    2.84e-03    2.82e-01
  59  4.285479e-21   -2.27e-22    4.96e-06   1.96e-17   1.44e-01  5.78e-03        1    5.54e-03    2.87e-01
  60  1.012064e-20   -5.84e-21    0.00e+00   1.73e-17  -4.14e-01  2.89e-03        1    2.84e-03    2.90e-01
  61  1.012064e-20   -5.84e-21    0.00e+00   9.81e-18  -4.17e-01  7.23e-04        1    2.83e-03    2.93e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          7.259623e+01
Final                            6.289909e-22
Change                           7.259623e+01

Minimizer iterations                       62
Successful steps                           42
Unsuccessful steps                         20
Line search steps                          38

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0045
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2883
    Line search gradient evaluation    0.1736
  Linear solver                        0.0016
  Line search polynomial minimization  0.0002
Minimizer                              0.2960

Postprocessor                          0.0000
Total                                  0.2960

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.621218e+04
Final                            1.674227e+02
Change                           1.604476e+04

Minimizer iterations                      175
Successful steps                           99
Unsuccessful steps                         76
Line search steps                         234

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0127
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.0838
    Line search gradient evaluation    0.8127
  Linear solver                        0.0032
  Line search polynomial minimization  0.0017
Minimizer                              1.1044

Postprocessor                          0.0000
Total                                  1.1045

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA70 = {
{-0.0334114,0.3158468,0.1429140}
};
fitErrEl70 = {
{-0.0599704,0.3072579,0.1519044}
};
fitErrLa70 = {
{-0.0611739,0.3240084,0.1566107}
};
fitErrWr70 = {
{-0.1625600,0.2822840,0.2135666}
};
fitErrEe70 = {
{-0.2209386,0.3076943,0.2846941}
};
rMatsBase70 = {
{-0.2895034,0.6317773,-0.7190586},
{0.8344781,0.5345723,0.1337115},
{0.4688647,-0.5613287,-0.6819648}
};
outThetasWam70 = {
{-0.0882035,-0.3620970,-0.0458010,1.3899447,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3482814
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  2.140013e+02    0.00e+00    2.82e+00   0.00e+00   0.00e+00  1.00e+04        0    2.90e-03    2.95e-03
   1  1.631673e+01    1.98e+02    2.78e+00   2.43e-02   1.85e+00  3.00e+04        1    5.82e-03    8.79e-03
   2  4.420494e-02    1.63e+01    2.78e+00   2.08e-03   1.98e+00  9.00e+04        1    5.71e-03    1.45e-02
   3  5.013929e-10    4.42e-02    1.11e+00   1.95e-05   1.86e+00  2.70e+05        1    5.86e-03    2.04e-02
   4  5.308496e-19    5.01e-10    7.03e-06   4.79e-09   1.86e+00  8.10e+05        1    5.72e-03    2.64e-02
   5  7.002066e-21    5.24e-19    4.34e-06   3.93e-13   1.86e+00  2.43e+06        1    5.72e-03    3.22e-02
   6  2.459714e-20   -1.76e-20    9.91e-06   1.12e-14   1.86e+00  7.29e+06        1    5.68e-03    3.79e-02
   7  6.972085e-21    1.76e-20    4.94e-06   1.79e-14   1.86e+00  2.19e+07        1    5.75e-03    4.36e-02
   8  7.297557e-22    6.24e-21    1.38e-06   6.91e-15   1.86e+00  6.56e+07        1    5.52e-03    4.92e-02
   9  4.641514e-22    2.66e-22    1.02e-06   4.75e-15   1.86e+00  1.97e+08        1    5.84e-03    5.50e-02
  10  1.635661e-21   -1.17e-21    2.62e-06   4.94e-15   1.86e+00  5.90e+08        1    5.84e-03    6.09e-02
  11  1.647134e-20   -1.48e-20    8.23e-06   3.56e-15   1.86e+00  1.77e+09        1    5.83e-03    6.67e-02
  12  5.546741e-21    1.09e-20    4.93e-06   1.77e-14   1.86e+00  5.31e+09        1    5.81e-03    7.25e-02
  13  4.673513e-21    8.73e-22    4.34e-06   8.87e-15   1.86e+00  1.59e+10        1    5.70e-03    7.83e-02
  14  4.773695e-21   -1.00e-22    3.88e-06   5.49e-15   1.86e+00  4.78e+10        1    5.64e-03    8.39e-02
  15  6.686739e-21   -1.91e-21    7.66e-06   9.07e-15   3.16e-01  4.56e+10        1    5.72e-03    8.97e-02
  16  3.296886e-21    3.39e-21    3.68e-06   4.61e-15   5.20e-01  4.56e+10        1    5.66e-03    9.53e-02
  17  9.357447e-21   -6.06e-21    5.89e-06   7.96e-15   1.75e-01  3.57e+10        1    5.76e-03    1.01e-01
  18  6.579558e-21    2.78e-21    5.39e-06   7.46e-15   3.23e-01  3.42e+10        1    5.65e-03    1.07e-01
  19  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  1.71e+10        1    2.99e-03    1.10e-01
  20  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  4.28e+09        1    2.80e-03    1.13e-01
  21  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  5.35e+08        1    2.80e-03    1.15e-01
  22  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  3.34e+07        1    2.79e-03    1.18e-01
  23  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  1.04e+06        1    2.82e-03    1.21e-01
  24  1.859762e-20   -1.20e-20    0.00e+00   7.67e-15  -3.81e-02  1.63e+04        1    2.93e-03    1.24e-01
  25  3.399248e-21    3.18e-21    3.82e-06   7.67e-15   4.88e-01  1.63e+04        1    5.50e-03    1.29e-01
  26  3.258109e-21    1.41e-22    4.59e-06   6.71e-15   2.23e-01  1.39e+04        1    5.57e-03    1.35e-01
  27  2.827372e-21    4.31e-22    3.12e-06   3.76e-15   2.19e-01  1.18e+04        1    5.52e-03    1.41e-01
  28  3.758356e-21   -9.31e-22    3.96e-06   6.50e-15   1.95e-01  9.65e+03        1    7.21e-03    1.48e-01
  29  1.589244e-21    2.17e-21    2.39e-06   5.86e-15   6.23e-01  9.80e+03        1    5.87e-03    1.54e-01
  30  6.991895e-21   -5.40e-21    5.44e-06   7.81e-15   1.35e-01  7.06e+03        1    5.96e-03    1.60e-01
  31  2.847755e-21    4.14e-21    3.41e-06   6.61e-15   6.04e-01  7.12e+03        1    5.94e-03    1.66e-01
  32  3.453495e-21   -6.06e-22    3.73e-06   5.61e-15   1.63e-01  5.46e+03        1    5.82e-03    1.72e-01
  33  1.029697e-20   -6.84e-21    6.78e-06   6.50e-15   7.44e-02  3.37e+03        1    5.95e-03    1.77e-01
  34  2.164559e-21    8.13e-21    3.01e-06   9.98e-15   8.05e-01  4.37e+03        1    5.91e-03    1.83e-01
  35  1.476835e-21    6.88e-22    2.19e-06   5.18e-15   3.21e-01  4.18e+03        1    5.88e-03    1.89e-01
  36  1.900147e-21   -4.23e-22    2.99e-06   6.92e-15   1.51e-01  3.12e+03        1    5.83e-03    1.95e-01
  37  3.624725e-21   -1.72e-21    5.42e-06   7.61e-15   1.30e-01  2.22e+03        1    6.17e-03    2.01e-01
  38  6.282983e-21   -2.66e-21    4.21e-06   5.43e-15   9.99e-02  1.47e+03        1    5.73e-03    2.07e-01
  39  1.242175e-20   -6.14e-21    7.07e-06   8.55e-15   3.75e-02  8.19e+02        1    5.78e-03    2.13e-01
  40  3.294534e-21    9.13e-21    4.04e-06   1.71e-14   7.44e-01  9.27e+02        1    5.57e-03    2.18e-01
  41  3.149910e-21    1.45e-22    3.31e-06   7.01e-15   1.08e-01  6.26e+02        1    5.76e-03    2.24e-01
  42  8.287297e-21   -5.14e-21    6.00e-06   5.14e-15   6.48e-02  3.77e+02        1    5.76e-03    2.30e-01
  43  5.419174e-22    7.75e-21    1.83e-06   8.84e-15   9.38e-01  1.13e+03        1    5.76e-03    2.36e-01
  44  2.096059e-21   -1.55e-21    3.05e-06   2.59e-15   1.06e-01  7.60e+02        1    5.55e-03    2.41e-01
  45  1.123670e-20   -9.14e-21    6.75e-06   3.53e-15   3.82e-02  4.25e+02        1    5.50e-03    2.47e-01
  46  1.012715e-20    1.11e-21    6.08e-06   9.75e-15   1.02e-01  2.83e+02        1    5.48e-03    2.52e-01
  47  5.095404e-21    5.03e-21    4.70e-06   9.13e-15   4.98e-01  2.83e+02        1    5.52e-03    2.58e-01
  48  2.810513e-21    2.28e-21    4.36e-06   7.31e-15   4.72e-01  2.82e+02        1    5.62e-03    2.64e-01
  49  1.273934e-20   -9.93e-21    1.05e-05   5.10e-15   2.25e-02  1.51e+02        1    5.53e-03    2.69e-01
  50  1.128631e-20    1.45e-21    8.54e-06   4.11e-15   1.19e-01  1.05e+02        1    5.47e-03    2.75e-01
  51  5.067075e-21    6.22e-21    3.93e-06   6.62e-15   5.55e-01  1.05e+02        1    5.50e-03    2.80e-01
  52  6.299690e-21   -1.23e-21    4.93e-06   9.62e-15   5.24e-02  6.10e+01        1    5.53e-03    2.86e-01
  53  7.496965e-21   -1.20e-21    8.16e-06   7.63e-15   4.48e-02  3.48e+01        1    5.82e-03    2.91e-01
  54  2.145281e-21    5.35e-21    2.83e-06   3.27e-15   7.32e-01  3.86e+01        1    5.66e-03    2.97e-01
  55  1.547248e-20   -1.33e-20    7.43e-06   1.99e-15   4.77e-03  1.96e+01        1    5.62e-03    3.03e-01
  56  9.722332e-21    5.75e-21    6.52e-06   9.83e-15   3.76e-01  1.93e+01        1    5.56e-03    3.08e-01
  57  6.369171e-21    3.35e-21    6.30e-06   9.97e-15   3.51e-01  1.88e+01        1    5.65e-03    3.14e-01
  58  6.068554e-21    3.01e-22    6.09e-06   4.40e-15   4.81e-02  1.08e+01        1    5.53e-03    3.20e-01
  59  1.887765e-21    4.18e-21    3.57e-06   5.62e-15   6.95e-01  1.15e+01        1    7.52e-03    3.27e-01
  60  5.444093e-21   -3.56e-21    6.56e-06   2.49e-15   4.45e-02  6.55e+00        1    6.09e-03    3.33e-01
  61  9.027720e-21   -3.58e-21    6.45e-06   2.46e-15   2.94e-02  3.57e+00        1    5.70e-03    3.39e-01
  62  3.259820e-20   -2.36e-20    0.00e+00   7.76e-15  -6.16e-02  1.79e+00        1    2.91e-03    3.42e-01
  63  1.139447e-20   -2.37e-21    8.62e-06   7.06e-15   1.94e-02  9.46e-01        1    5.62e-03    3.47e-01
  64  5.760014e-22    1.08e-20    9.49e-07   5.13e-15   1.04e+00  2.84e+00        1    5.82e-03    3.53e-01
  65  1.009319e-20   -9.52e-21    6.44e-06   1.84e-15   2.34e-02  1.52e+00        1    5.48e-03    3.59e-01
  66  4.738832e-21    5.35e-21    4.62e-06   5.66e-15   5.74e-01  1.53e+00        1    5.82e-03    3.65e-01
  67  2.169250e-21    2.57e-21    3.05e-06   5.42e-15   5.69e-01  1.53e+00        1    5.53e-03    3.70e-01
  68  6.419259e-21   -4.25e-21    5.50e-06   3.67e-15   3.49e-02  8.47e-01        1    5.56e-03    3.76e-01
  69  7.207973e-21   -7.89e-22    7.94e-06   4.56e-15   3.15e-02  4.65e-01        1    5.85e-03    3.82e-01
  70  1.897370e-21    5.31e-21    3.69e-06   2.55e-15   8.52e-01  7.14e-01        1    5.51e-03    3.87e-01
  71  2.992027e-20   -2.80e-20    0.00e+00   1.39e-15  -4.46e-02  3.57e-01        1    2.87e-03    3.90e-01
  72  3.352847e-21   -1.46e-21    3.80e-06   9.64e-16   4.35e-02  2.03e-01        1    5.50e-03    3.96e-01
  73  2.933343e-22    3.06e-21    7.41e-07   2.03e-15   1.68e+00  6.09e-01        1    5.62e-03    4.01e-01
  74  4.820431e-22   -1.89e-22    1.54e-06   1.13e-15   5.27e-02  3.55e-01        1    5.55e-03    4.07e-01
  75  2.084825e-21   -1.60e-21    2.77e-06   3.80e-16   4.73e-02  2.04e-01        1    7.04e-03    4.14e-01
  76  4.000828e-22    1.68e-21    1.28e-06   1.22e-15   1.46e+00  6.11e-01        1    5.97e-03    4.20e-01
  77  3.297645e-22    7.03e-23    1.07e-06   7.24e-16   2.91e-01  5.69e-01        1    6.09e-03    4.26e-01
  78  8.493782e-22   -5.20e-22    1.68e-06   6.92e-16   5.11e-02  3.30e-01        1    5.82e-03    4.32e-01
  79  1.811283e-20   -1.73e-20    0.00e+00   1.35e-15  -7.77e+00  1.65e-01        1    3.12e-03    4.35e-01
  80  1.897920e-20   -1.81e-20    0.00e+00   9.04e-16  -8.80e+00  4.13e-02        1    3.32e-03    4.38e-01
  81  6.495864e-22    2.00e-22    1.38e-06   2.24e-16   1.63e+00  1.24e-01        1    5.93e-03    4.44e-01
  82  2.976167e-20   -2.91e-20    0.00e+00   4.57e-16  -1.45e+01  6.19e-02        1    3.12e-03    4.47e-01
  83  1.004944e-21   -3.55e-22    1.76e-06   2.27e-16   5.91e-01  6.23e-02        1    5.93e-03    4.53e-01
  84  3.029120e-21   -2.02e-21    0.00e+00   4.49e-16  -4.61e-01  3.11e-02        1    3.11e-03    4.56e-01
  85  3.514621e-21   -2.51e-21    0.00e+00   2.24e-16  -7.33e-01  7.78e-03        1    3.09e-03    4.60e-01
  86  1.082375e-21   -7.74e-23    1.79e-06   7.76e-18   5.39e-01  7.79e-03        1    5.98e-03    4.66e-01
  87  6.583187e-22    4.24e-22    1.25e-06   7.76e-18   1.14e+01  2.34e-02        1    5.90e-03    4.71e-01
  88  7.551168e-22   -9.68e-23    2.15e-06   2.50e-17   6.77e-01  2.44e-02        1    5.91e-03    4.77e-01
  89  5.460682e-21   -4.71e-21    0.00e+00   1.13e-16  -1.63e+00  1.22e-02        1    3.03e-03    4.80e-01
  90  8.614581e-22   -1.06e-22    2.36e-06   1.25e-17   6.06e-01  1.23e-02        1    5.89e-03    4.86e-01
  91  8.749723e-22   -1.35e-23    2.23e-06   1.25e-17   5.81e-01  1.24e-02        1    6.09e-03    4.92e-01
  92  6.786964e-22    1.96e-22    1.30e-06   1.25e-17   3.30e+00  3.72e-02        1    5.68e-03    4.98e-01
  93  3.459318e-21   -2.78e-21    0.00e+00   2.26e-16  -6.12e-01  1.86e-02        1    3.01e-03    5.01e-01
  94  8.876398e-22   -2.09e-22    2.30e-06   1.73e-17   5.44e-01  1.86e-02        1    5.74e-03    5.07e-01
  95  5.287953e-21   -4.40e-21    0.00e+00   1.12e-16  -1.40e+00  9.30e-03        1    2.92e-03    5.10e-01
  96  8.749723e-22    1.27e-23    2.23e-06   9.81e-18   5.39e-01  9.30e-03        1    5.63e-03    5.16e-01
  97  6.786964e-22    1.96e-22    1.30e-06   9.81e-18   4.32e+00  2.79e-02        1    5.65e-03    5.21e-01
  98  8.323366e-22   -1.54e-22    2.19e-06   3.27e-17   5.28e-01  2.79e-02        1    5.73e-03    5.27e-01
  99  5.460180e-21   -4.63e-21    0.00e+00   1.14e-16  -1.36e+00  1.40e-02        1    2.89e-03    5.30e-01
 100  8.173292e-22    1.50e-23    2.13e-06   1.25e-17   5.20e-01  1.40e-02        1    5.61e-03    5.36e-01
 101  8.818358e-22   -6.45e-23    2.31e-06   1.25e-17   4.82e-01  1.40e-02        1    5.70e-03    5.41e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          2.140013e+02
Final                            2.933343e-22
Change                           2.140013e+02

Minimizer iterations                      102
Successful steps                           85
Unsuccessful steps                         17
Line search steps                          57

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0078
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5294
    Line search gradient evaluation    0.2924
  Linear solver                        0.0031
  Line search polynomial minimization  0.0003
Minimizer                              0.5441

Postprocessor                          0.0000
Total                                  0.5441

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.618902e+04
Final                            1.652218e+02
Change                           1.602380e+04

Minimizer iterations                      161
Successful steps                          108
Unsuccessful steps                         53
Line search steps                         212

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0118
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.0542
    Line search gradient evaluation    0.7581
  Linear solver                        0.0028
  Line search polynomial minimization  0.0016
Minimizer                              1.0730

Postprocessor                          0.0000
Total                                  1.0731

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA71 = {
{-0.0362544,0.3299781,0.1496065}
};
fitErrEl71 = {
{-0.0639952,0.3209028,0.1589655}
};
fitErrLa71 = {
{-0.0652387,0.3387355,0.1640364}
};
fitErrWr71 = {
{-0.1734548,0.2952317,0.2238430}
};
fitErrEe71 = {
{-0.2317253,0.3205968,0.2962110}
};
rMatsBase71 = {
{-0.2950053,0.6396992,-0.7097583},
{0.8324065,0.5367607,0.1377949},
{0.4691176,-0.5501571,-0.6908370}
};
outThetasWam71 = {
{-0.0886065,-0.3567908,-0.0464265,1.3814219,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3641182
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  5.793072e+01    0.00e+00    2.78e+00   0.00e+00   0.00e+00  1.00e+04        0    3.04e-03    3.08e-03
   1  3.694572e+00    5.42e+01    2.78e+00   1.06e-02   1.87e+00  3.00e+04        1    6.17e-03    9.27e-03
   2  9.138668e-05    3.69e+00    2.78e+00   4.29e-04   1.93e+00  9.00e+04        1    6.18e-03    1.55e-02
   3  1.432714e-13    9.14e-05    6.15e-03   8.85e-07   1.87e+00  2.70e+05        1    6.21e-03    2.17e-02
   4  9.745710e-22    1.43e-13    1.37e-06   1.96e-10   1.87e+00  8.10e+05        1    6.16e-03    2.79e-02
   5  2.103552e-21   -1.13e-21    2.83e-06   1.18e-14   1.87e+00  2.43e+06        1    6.19e-03    3.41e-02
   6  2.253159e-21   -1.50e-22    2.65e-06   3.88e-15   1.87e+00  7.29e+06        1    6.15e-03    4.02e-02
   7  4.323002e-21   -2.07e-21    4.68e-06   6.28e-15   1.87e+00  2.19e+07        1    6.20e-03    4.65e-02
   8  5.308300e-21   -9.85e-22    4.29e-06   4.52e-15   1.87e+00  6.56e+07        1    6.41e-03    5.29e-02
   9  5.505068e-21   -1.97e-22    4.57e-06   1.28e-14   1.87e+00  1.97e+08        1    6.88e-03    5.98e-02
  10  6.929252e-22    4.81e-21    1.74e-06   9.42e-15   8.82e-01  3.55e+08        1    6.16e-03    6.60e-02
  11  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  1.78e+08        1    3.13e-03    6.91e-02
  12  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  4.44e+07        1    3.15e-03    7.23e-02
  13  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  5.55e+06        1    3.15e-03    7.54e-02
  14  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  3.47e+05        1    3.18e-03    7.86e-02
  15  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  1.08e+04        1    3.14e-03    8.18e-02
  16  8.965531e-21   -8.27e-21    0.00e+00   2.11e-15  -5.87e-01  1.69e+02        1    3.14e-03    8.49e-02
  17  6.456176e-21   -5.76e-21    0.00e+00   2.01e-15  -1.61e-01  1.32e+00        1    3.11e-03    8.81e-02
  18  1.136323e-21   -4.43e-22    2.18e-06   1.25e-15   7.44e-01  1.50e+00        1    6.17e-03    9.42e-02
  19  6.230364e-21   -5.09e-21    0.00e+00   2.58e-15  -1.06e-01  7.49e-01        1    3.14e-03    9.74e-02
  20  5.359458e-21   -4.22e-21    4.41e-06   1.91e-15   2.14e-02  3.99e-01        1    6.16e-03    1.04e-01
  21  1.138817e-21    4.22e-21    2.01e-06   2.86e-15   1.12e+00  1.20e+00        1    6.22e-03    1.10e-01
  22  4.530783e-21   -3.39e-21    4.26e-06   1.05e-15   8.49e-02  7.61e-01        1    6.13e-03    1.16e-01
  23  2.028258e-21    2.50e-21    2.66e-06   4.15e-15   6.27e-01  7.74e-01        1    6.16e-03    1.22e-01
  24  7.802072e-22    1.25e-21    2.34e-06   2.62e-15   7.23e-01  8.49e-01        1    6.15e-03    1.28e-01
  25  4.443054e-21   -3.66e-21    4.33e-06   1.08e-15   8.30e-02  5.38e-01        1    6.16e-03    1.34e-01
  26  5.468020e-21   -1.02e-21    0.00e+00   2.74e-15  -7.36e-03  2.69e-01        1    3.13e-03    1.38e-01
  27  2.880517e-21    1.56e-21    4.96e-06   2.02e-15   5.09e-01  2.69e-01        1    6.16e-03    1.44e-01
  28  4.604096e-21   -1.72e-21    4.23e-06   8.75e-16   4.67e-02  1.54e-01        1    6.16e-03    1.50e-01
  29  8.141350e-21   -3.54e-21    0.00e+00   1.65e-15  -1.50e-01  7.70e-02        1    3.13e-03    1.53e-01
  30  7.196310e-21   -2.59e-21    0.00e+00   9.76e-16  -1.04e-01  1.93e-02        1    3.15e-03    1.56e-01
  31  4.094813e-21    5.09e-22    4.10e-06   2.55e-16   1.08e+00  5.78e-02        1    6.16e-03    1.62e-01
  32  3.982421e-21    1.12e-22    5.17e-06   6.87e-16   1.21e-01  4.02e-02        1    6.16e-03    1.69e-01
  33  1.559693e-21    2.42e-21    2.44e-06   5.10e-16   2.60e+00  1.21e-01        1    6.16e-03    1.75e-01
  34  7.663621e-21   -6.10e-21    0.00e+00   3.67e-16  -1.21e-01  6.03e-02        1    3.13e-03    1.78e-01
  35  2.562420e-21   -1.00e-21    4.29e-06   2.68e-16   1.48e-01  4.48e-02        1    6.18e-03    1.84e-01
  36  9.342853e-22    1.63e-21    2.08e-06   3.25e-16   2.45e+00  1.34e-01        1    6.17e-03    1.90e-01
  37  1.365663e-21   -4.31e-22    2.64e-06   5.67e-16   2.00e-01  1.11e-01        1    6.17e-03    1.96e-01
  38  8.829330e-22    4.83e-22    2.06e-06   7.54e-16   7.57e-01  1.28e-01        1    7.43e-03    2.04e-01
  39  5.126491e-21   -4.24e-21    4.84e-06   5.10e-16   1.11e-02  6.61e-02        1    6.19e-03    2.10e-01
  40  3.626812e-21    1.50e-21    3.88e-06   9.18e-16   1.11e+00  1.98e-01        1    6.16e-03    2.16e-01
  41  4.765766e-21   -1.14e-21    3.69e-06   1.65e-15   2.44e-02  1.07e-01        1    6.21e-03    2.22e-01
  42  4.344374e-21    4.21e-22    4.41e-06   9.58e-16   2.29e-01  9.20e-02        1    6.16e-03    2.29e-01
  43  4.512433e-21   -1.68e-22    4.44e-06   1.14e-15   3.06e-02  5.03e-02        1    7.42e-03    2.36e-01
  44  3.132930e-21    1.38e-21    3.48e-06   6.86e-16   1.47e+00  1.51e-01        1    6.19e-03    2.42e-01
  45  5.542726e-22    2.58e-21    1.43e-06   1.19e-15   1.68e+00  4.53e-01        1    6.16e-03    2.49e-01
  46  2.380815e-21   -1.83e-21    3.09e-06   9.37e-16   9.77e-02  2.98e-01        1    6.19e-03    2.55e-01
  47  3.828774e-21   -1.45e-21    4.16e-06   1.82e-15   4.79e-02  1.71e-01        1    6.15e-03    2.61e-01
  48  2.296632e-21    1.53e-21    3.01e-06   1.61e-15   7.86e-01  2.11e-01        1    6.16e-03    2.67e-01
  49  4.299979e-21   -2.00e-21    4.04e-06   1.37e-15   3.02e-02  1.15e-01        1    6.15e-03    2.73e-01
  50  5.880294e-21   -1.58e-21    0.00e+00   1.23e-15  -1.41e-02  5.75e-02        1    3.13e-03    2.76e-01
  51  1.411519e-20   -9.82e-21    0.00e+00   7.11e-16  -2.42e-01  1.44e-02        1    3.16e-03    2.80e-01
  52  7.762311e-22    3.52e-21    1.59e-06   2.50e-16   1.01e+01  4.32e-02        1    6.16e-03    2.86e-01
  53  1.008899e-21   -2.33e-22    2.62e-06   2.27e-16   6.82e+00  1.29e-01        1    6.22e-03    2.92e-01
  54  7.073363e-21   -6.06e-21    0.00e+00   3.34e-16  -2.91e+00  6.47e-02        1    3.12e-03    2.95e-01
  55  1.369497e-20   -1.27e-20    0.00e+00   2.59e-16  -1.19e+01  1.62e-02        1    3.13e-03    2.98e-01
  56  5.747638e-22    4.34e-22    1.40e-06   1.55e-17   6.43e+00  4.86e-02        1    6.20e-03    3.04e-01
  57  1.052160e-21   -4.77e-22    2.43e-06   2.24e-16   4.94e+00  1.46e-01        1    6.22e-03    3.11e-01
  58  1.082589e-20   -9.77e-21    0.00e+00   5.11e-16  -5.57e+00  7.28e-02        1    3.15e-03    3.14e-01
  59  6.612475e-22    3.91e-22    2.06e-06   3.26e-16   3.66e+00  2.18e-01        1    6.21e-03    3.20e-01
  60  6.026321e-21   -5.37e-21    0.00e+00   3.35e-16  -1.27e+00  1.09e-01        1    3.28e-03    3.23e-01
  61  8.384896e-21   -7.72e-21    0.00e+00   3.28e-16  -3.25e+00  2.73e-02        1    3.13e-03    3.27e-01
  62  9.380742e-21   -8.72e-21    0.00e+00   1.13e-16  -4.67e+00  3.41e-03        1    3.13e-03    3.30e-01
  63  6.612475e-22   -9.40e-38    2.06e-06   3.47e-18   3.61e+00  1.02e-02        1    6.17e-03    3.36e-01
  64  6.612475e-22   -9.40e-38    2.06e-06   6.94e-18   3.48e+00  3.07e-02        1    6.17e-03    3.42e-01
  65  6.533912e-21   -5.87e-21    0.00e+00   1.17e-16  -1.94e+00  1.54e-02        1    3.14e-03    3.45e-01
  66  6.612475e-22   -9.40e-38    2.06e-06   1.25e-17   3.30e+00  4.61e-02        1    6.21e-03    3.51e-01
  67  6.526719e-21   -5.87e-21    0.00e+00   1.18e-16  -1.79e+00  2.30e-02        1    3.14e-03    3.55e-01
  68  3.117112e-21   -2.46e-21    5.16e-06   1.55e-17   1.00e+00  6.91e-02        1    6.16e-03    3.61e-01
  69  3.013469e-21    1.04e-22    4.59e-06   3.84e-16   5.63e-01  6.93e-02        1    6.14e-03    3.67e-01
  70  1.081180e-20   -7.80e-21    0.00e+00   3.73e-16  -1.95e+00  3.46e-02        1    3.16e-03    3.70e-01
  71  4.680847e-21   -1.67e-21    0.00e+00   1.44e-16  -1.31e-01  8.66e-03        1    3.14e-03    3.73e-01
  72  9.490157e-22    2.06e-21    2.55e-06   2.71e-17   1.17e+01  2.60e-02        1    6.42e-03    3.80e-01
  73  5.388030e-21   -4.44e-21    0.00e+00   1.14e-16  -4.18e-01  1.30e-02        1    3.14e-03    3.83e-01
  74  1.007802e-21   -5.88e-23    2.64e-06   1.25e-17   1.30e+00  3.90e-02        1    6.13e-03    3.89e-01
  75  6.051384e-21   -5.04e-21    0.00e+00   2.53e-16  -6.36e-01  1.95e-02        1    3.17e-03    3.92e-01
  76  5.218452e-21   -4.21e-21    0.00e+00   1.13e-16  -3.46e-01  4.87e-03        1    3.14e-03    3.95e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          5.793072e+01
Final                            5.542726e-22
Change                           5.793072e+01

Minimizer iterations                       77
Successful steps                           50
Unsuccessful steps                         27
Line search steps                          53

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0063
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3882
    Line search gradient evaluation    0.2356
  Linear solver                        0.0016
  Line search polynomial minimization  0.0002
Minimizer                              0.3984

Postprocessor                          0.0000
Total                                  0.3985

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:48:57.306151  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.355674  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.402308  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.438997  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.544008  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.559219  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.620908  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.887341  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:48:57.930408  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:49:00.391078  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.617895e+04
Final                            1.613015e+02
Change                           1.601764e+04

Minimizer iterations                      284
Successful steps                          233
Unsuccessful steps                         51
Line search steps                         725

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0221
    Line search cost evaluation        0.0000
  Jacobian evaluation                  3.5415
    Line search gradient evaluation    2.8319
  Linear solver                        0.0062
  Line search polynomial minimization  0.0068
Minimizer                              3.5834

Postprocessor                          0.0000
Total                                  3.5834

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA72 = {
{-0.0389875,0.3426733,0.1557821}
};
fitErrEl72 = {
{-0.0677614,0.3331704,0.1654635}
};
fitErrLa72 = {
{-0.0690366,0.3520339,0.1708916}
};
fitErrWr72 = {
{-0.1836459,0.3072906,0.2330367}
};
fitErrEe72 = {
{-0.2414627,0.3326003,0.3068449}
};
rMatsBase72 = {
{-0.2970843,0.6488118,-0.7005599},
{0.8317182,0.5362228,0.1439095},
{0.4690264,-0.5399152,-0.6989319}
};
outThetasWam72 = {
{-0.0897971,-0.3525193,-0.0481280,1.3734599,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3784350
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  2.913143e+01    0.00e+00    2.78e+00   0.00e+00   0.00e+00  1.00e+04        0    2.92e-03    2.96e-03
   1  3.827567e+00    2.53e+01    2.83e+00   1.02e-02   1.73e+00  3.00e+04        1    5.68e-03    8.66e-03
   2  9.795880e-05    3.83e+00    2.77e+00   4.29e-04   1.94e+00  9.00e+04        1    5.55e-03    1.42e-02
   3  1.209290e-13    9.80e-05    5.90e-03   8.43e-07   1.76e+00  2.70e+05        1    5.90e-03    2.01e-02
   4  1.237874e-20    1.21e-13    6.71e-06   1.80e-10   1.76e+00  8.10e+05        1    5.54e-03    2.57e-02
   5  8.112131e-21    4.27e-21    6.08e-06   2.02e-14   1.76e+00  2.43e+06        1    5.55e-03    3.12e-02
   6  2.142784e-21    5.97e-21    3.13e-06   8.25e-15   1.76e+00  7.29e+06        1    5.62e-03    3.69e-02
   7  2.841830e-21   -6.99e-22    4.92e-06   5.42e-15   1.76e+00  2.19e+07        1    5.59e-03    4.25e-02
   8  1.288360e-20   -1.00e-20    7.38e-06   3.15e-15   1.76e+00  6.56e+07        1    5.64e-03    4.81e-02
   9  4.163669e-20   -2.88e-20    1.31e-05   1.45e-14   1.76e+00  1.97e+08        1    5.62e-03    5.38e-02
  10  3.193146e-20    9.71e-21    1.17e-05   2.05e-14   1.76e+00  5.90e+08        1    5.62e-03    5.94e-02
  11  1.846446e-20    1.35e-20    9.08e-06   1.68e-14   1.76e+00  1.77e+09        1    5.74e-03    6.52e-02
  12  1.472387e-20    3.74e-21    7.15e-06   1.54e-14   2.95e-01  1.66e+09        1    5.61e-03    7.08e-02
  13  5.689027e-21    9.03e-21    5.10e-06   1.29e-14   6.21e-01  1.68e+09        1    7.23e-03    7.80e-02
  14  4.468442e-21    1.22e-21    3.70e-06   8.68e-15   3.34e-01  1.62e+09        1    5.69e-03    8.37e-02
  15  4.495683e-21   -2.72e-23    3.60e-06   6.10e-15   3.21e-01  1.55e+09        1    5.56e-03    8.93e-02
  16  1.422848e-20   -9.73e-21    7.04e-06   7.89e-15   2.28e-01  1.34e+09        1    5.57e-03    9.49e-02
  17  1.379979e-21    1.28e-20    2.31e-06   1.24e-14   9.23e-01  3.40e+09        1    5.55e-03    1.00e-01
  18  3.343932e-20   -3.21e-20    1.24e-05   3.15e-15   6.05e-02  2.03e+09        1    5.56e-03    1.06e-01
  19  2.763352e-21    3.07e-20    3.58e-06   1.98e-14   9.32e-01  5.69e+09        1    5.52e-03    1.12e-01
  20  1.013530e-20   -7.37e-21    5.76e-06   4.18e-15   1.84e-01  4.55e+09        1    5.63e-03    1.17e-01
  21  6.670850e-21    3.46e-21    5.01e-06   1.24e-14   3.43e-01  4.41e+09        1    5.55e-03    1.23e-01
  22  3.789669e-21    2.88e-21    3.72e-06   9.61e-15   4.43e-01  4.40e+09        1    5.79e-03    1.29e-01
  23  3.253573e-21    5.36e-22    3.83e-06   6.02e-15   5.41e-01  4.40e+09        1    5.63e-03    1.34e-01
  24  1.494187e-20   -1.17e-20    7.95e-06   6.02e-15   3.13e-01  4.19e+09        1    5.70e-03    1.40e-01
  25  1.408500e-21    1.35e-20    2.35e-06   1.16e-14   9.28e-01  1.12e+10        1    5.83e-03    1.46e-01
  26  1.395279e-20   -1.25e-20    7.34e-06   5.28e-15   2.60e-01  1.01e+10        1    5.82e-03    1.52e-01
  27  1.416068e-20   -2.08e-22    6.94e-06   8.60e-15   2.18e-01  8.56e+09        1    5.73e-03    1.57e-01
  28  1.775196e-21    1.24e-20    2.89e-06   8.36e-15   8.81e-01  1.54e+10        1    5.73e-03    1.63e-01
  29  2.863821e-21   -1.09e-21    3.66e-06   2.96e-15   2.93e-01  1.43e+10        1    5.55e-03    1.69e-01
  30  3.090994e-22    2.55e-21    8.66e-07   5.62e-15   9.12e-01  3.25e+10        1    5.54e-03    1.74e-01
  31  4.501826e-21   -4.19e-21    4.24e-06   2.35e-15   2.69e-01  2.96e+10        1    5.57e-03    1.80e-01
  32  9.192392e-21   -4.69e-21    5.76e-06   6.17e-15   2.17e-01  2.50e+10        1    5.57e-03    1.85e-01
  33  1.489374e-20   -5.70e-21    8.43e-06   5.77e-15   1.53e-01  1.88e+10        1    5.55e-03    1.91e-01
  34  1.484560e-21    1.34e-20    3.05e-06   1.20e-14   9.14e-01  4.34e+10        1    5.50e-03    1.96e-01
  35  2.580373e-20   -2.43e-20    1.03e-05   4.24e-15   5.58e-02  2.55e+10        1    5.53e-03    2.02e-01
  36  1.245403e-20    1.33e-20    8.27e-06   1.63e-14   5.23e-01  2.55e+10        1    5.55e-03    2.08e-01
  37  1.374606e-20   -1.29e-21    1.11e-05   6.04e-15   3.18e-01  2.44e+10        1    5.51e-03    2.13e-01
  38  1.193094e-20    1.82e-21    9.31e-06   5.07e-15   2.71e-01  2.22e+10        1    5.52e-03    2.19e-01
  39  1.111499e-21    1.08e-20    2.39e-06   6.13e-15   9.13e-01  5.10e+10        1    5.53e-03    2.24e-01
  40  9.001994e-21   -7.89e-21    6.24e-06   3.59e-15   2.62e-01  4.60e+10        1    6.02e-03    2.30e-01
  41  6.098742e-21    2.90e-21    4.51e-06   9.50e-15   3.45e-01  4.47e+10        1    5.78e-03    2.36e-01
  42  3.435875e-21    2.66e-21    4.99e-06   7.94e-15   4.47e-01  4.46e+10        1    5.77e-03    2.42e-01
  43  3.550633e-21   -1.15e-22    3.65e-06   3.21e-15   2.72e-01  4.07e+10        1    5.63e-03    2.47e-01
  44  1.075287e-21    2.48e-21    2.56e-06   6.30e-15   7.00e-01  4.35e+10        1    5.65e-03    2.53e-01
  45  1.568672e-21   -4.93e-22    3.12e-06   3.58e-15   2.80e-01  4.01e+10        1    5.63e-03    2.59e-01
  46  5.987161e-21   -4.42e-21    5.20e-06   6.83e-15   2.25e-01  3.44e+10        1    5.56e-03    2.64e-01
  47  6.087159e-21   -1.00e-22    5.45e-06   6.85e-15   2.10e-01  2.88e+10        1    5.50e-03    2.70e-01
  48  2.598753e-21    3.49e-21    4.61e-06   6.11e-15   5.76e-01  2.89e+10        1    5.84e-03    2.76e-01
  49  5.547419e-21   -2.95e-21    5.03e-06   2.51e-15   1.98e-01  2.37e+10        1    5.64e-03    2.81e-01
  50  3.043460e-21    2.50e-21    3.33e-06   8.46e-15   4.58e-01  2.36e+10        1    5.52e-03    2.87e-01
  51  1.165338e-21    1.88e-21    1.81e-06   4.58e-15   6.18e-01  2.40e+10        1    5.89e-03    2.93e-01
  52  1.495446e-20   -1.38e-20    6.90e-06   4.75e-15   9.68e-02  1.57e+10        1    5.58e-03    2.98e-01
  53  2.895432e-21    1.21e-20    3.99e-06   1.09e-14   8.27e-01  2.18e+10        1    5.52e-03    3.04e-01
  54  3.180855e-21   -2.85e-22    3.51e-06   3.18e-15   1.75e-01  1.71e+10        1    5.91e-03    3.10e-01
  55  3.628389e-21   -4.48e-22    4.60e-06   7.25e-15   1.68e-01  1.32e+10        1    5.83e-03    3.16e-01
  56  3.702388e-21   -7.40e-23    4.55e-06   6.38e-15   1.63e-01  1.01e+10        1    5.56e-03    3.21e-01
  57  4.904784e-21   -1.20e-21    4.39e-06   5.40e-15   1.50e-01  7.52e+09        1    5.96e-03    3.27e-01
  58  3.543259e-21    1.36e-21    4.00e-06   6.16e-15   2.87e-01  6.98e+09        1    5.70e-03    3.33e-01
  59  3.363169e-21    1.80e-22    4.73e-06   6.41e-15   1.52e-01  5.22e+09        1    5.54e-03    3.39e-01
  60  2.197880e-21    1.17e-21    3.07e-06   4.76e-15   3.58e-01  5.10e+09        1    5.85e-03    3.44e-01
  61  2.355596e-21   -1.58e-22    4.01e-06   4.93e-15   1.53e-01  3.82e+09        1    5.62e-03    3.50e-01
  62  6.485912e-21   -4.13e-21    7.43e-06   4.15e-15   1.24e-01  2.68e+09        1    5.79e-03    3.56e-01
  63  1.403931e-20   -7.55e-21    6.88e-06   7.91e-15   7.26e-02  1.65e+09        1    5.84e-03    3.62e-01
  64  3.522654e-21    1.05e-20    3.57e-06   1.28e-14   7.60e-01  1.92e+09        1    5.55e-03    3.67e-01
  65  1.103865e-21    2.42e-21    2.65e-06   4.69e-15   6.99e-01  2.05e+09        1    5.55e-03    3.73e-01
  66  1.167168e-21   -6.33e-23    2.02e-06   2.95e-15   1.37e-01  1.48e+09        1    6.03e-03    3.79e-01
  67  3.558735e-21   -2.39e-21    4.16e-06   8.11e-15   1.23e-01  1.04e+09        1    5.49e-03    3.84e-01
  68  4.856576e-21   -1.30e-21    4.32e-06   8.60e-15   1.13e-01  7.09e+08        1    5.59e-03    3.90e-01
  69  6.943252e-21   -2.09e-21    7.02e-06   7.42e-15   9.95e-02  4.68e+08        1    6.14e-03    3.96e-01
  70  5.952546e-21    9.91e-22    4.77e-06   3.55e-15   1.47e-01  3.46e+08        1    5.94e-03    4.02e-01
  71  3.561065e-21    2.39e-21    3.23e-06   7.95e-15   4.15e-01  3.45e+08        1    5.73e-03    4.08e-01
  72  1.044960e-21    2.52e-21    2.11e-06   5.02e-15   7.12e-01  3.73e+08        1    5.78e-03    4.14e-01
  73  3.564997e-21   -2.52e-21    4.50e-06   4.24e-15   1.08e-01  2.52e+08        1    5.56e-03    4.19e-01
  74  5.523225e-21   -1.96e-21    5.30e-06   6.98e-15   9.65e-02  1.65e+08        1    5.98e-03    4.25e-01
  75  6.399648e-21   -8.76e-22    7.36e-06   8.34e-15   9.00e-02  1.06e+08        1    5.75e-03    4.31e-01
  76  2.495461e-20   -1.86e-20    1.07e-05   3.82e-15   3.83e-03  5.37e+07        1    5.60e-03    4.37e-01
  77  1.252329e-20    1.24e-20    6.76e-06   1.40e-14   5.03e-01  5.37e+07        1    5.86e-03    4.43e-01
  78  2.646477e-21    9.88e-21    4.44e-06   1.24e-14   7.90e-01  6.68e+07        1    6.02e-03    4.49e-01
  79  2.561874e-21    8.46e-23    4.21e-06   5.40e-15   8.89e-02  4.30e+07        1    5.84e-03    4.54e-01
  80  4.881499e-21   -2.32e-21    4.69e-06   6.48e-15   7.92e-02  2.69e+07        1    5.81e-03    4.60e-01
  81  5.100271e-21   -2.19e-22    4.62e-06   7.08e-15   7.70e-02  1.68e+07        1    5.70e-03    4.66e-01
  82  1.786076e-21    3.31e-21    3.39e-06   9.03e-15   6.50e-01  1.72e+07        1    5.53e-03    4.72e-01
  83  4.701269e-21   -2.92e-21    4.33e-06   4.35e-15   7.65e-02  1.07e+07        1    6.06e-03    4.78e-01
  84  2.122564e-20   -1.65e-20    9.41e-06   4.60e-15   1.63e-02  5.63e+06        1    5.53e-03    4.83e-01
  85  6.169990e-21    1.51e-20    5.02e-06   1.53e-14   7.14e-01  6.11e+06        1    5.53e-03    4.89e-01
  86  3.178904e-21    2.99e-21    3.77e-06   6.36e-15   4.86e-01  6.11e+06        1    5.84e-03    4.95e-01
  87  1.783490e-21    1.40e-21    3.62e-06   7.37e-15   4.47e-01  6.10e+06        1    5.72e-03    5.00e-01
  88  7.098538e-21   -5.32e-21    7.58e-06   4.05e-15   5.99e-02  3.63e+06        1    5.63e-03    5.06e-01
  89  3.941954e-21    3.16e-21    4.38e-06   3.73e-15   4.48e-01  3.62e+06        1    5.92e-03    5.12e-01
  90  6.587268e-22    3.28e-21    1.64e-06   6.62e-15   8.60e-01  5.77e+06        1    5.78e-03    5.18e-01
  91  1.846055e-21   -1.19e-21    3.65e-06   3.82e-15   7.40e-02  3.57e+06        1    5.68e-03    5.23e-01
  92  1.967771e-21   -1.22e-22    2.59e-06   3.60e-15   7.32e-02  2.20e+06        1    5.66e-03    5.29e-01
  93  8.434563e-21   -6.47e-21    6.16e-06   6.90e-15   5.31e-02  1.28e+06        1    5.84e-03    5.35e-01
  94  6.902295e-21    1.53e-21    6.93e-06   1.22e-14   1.87e-01  1.03e+06        1    5.56e-03    5.40e-01
  95  1.909556e-21    4.99e-21    3.20e-06   3.68e-15   7.27e-01  1.14e+06        1    6.02e-03    5.46e-01
  96  4.782464e-22    1.43e-21    1.02e-06   6.98e-15   7.54e-01  1.31e+06        1    5.50e-03    5.52e-01
  97  6.444824e-21   -5.97e-21    4.70e-06   4.54e-15   5.61e-02  7.70e+05        1    5.61e-03    5.58e-01
  98  7.085849e-21   -6.41e-22    4.90e-06   1.15e-14   5.33e-02  4.50e+05        1    5.59e-03    5.63e-01
  99  2.426620e-21    4.66e-21    3.19e-06   1.26e-14   6.61e-01  4.65e+05        1    5.48e-03    5.69e-01
 100  2.604225e-20   -2.36e-20    0.00e+00   3.95e-15  -6.62e-04  2.33e+05        1    2.83e-03    5.72e-01
 101  2.604225e-20   -2.36e-20    0.00e+00   3.95e-15  -6.62e-04  5.82e+04        1    2.86e-03    5.74e-01
 102  2.604225e-20   -2.36e-20    0.00e+00   3.95e-15  -6.62e-04  7.27e+03        1    2.92e-03    5.77e-01
 103  2.604225e-20   -2.36e-20    0.00e+00   3.95e-15  -6.62e-04  4.54e+02        1    2.85e-03    5.80e-01
 104  2.414751e-20   -2.17e-20    1.04e-05   3.95e-15   4.60e-03  2.30e+02        1    5.47e-03    5.86e-01
 105  2.516602e-20   -1.02e-21    1.06e-05   1.89e-14   1.66e-03  1.16e+02        1    5.56e-03    5.91e-01
 106  2.208065e-21    2.30e-20    2.46e-06   1.90e-14   9.15e-01  2.70e+02        1    5.55e-03    5.97e-01
 107  5.488488e-21   -3.28e-21    5.07e-06   5.41e-15   4.94e-02  1.56e+02        1    5.55e-03    6.02e-01
 108  2.138945e-21    3.35e-21    3.24e-06   7.26e-15   6.21e-01  1.58e+02        1    5.56e-03    6.08e-01
 109  2.576512e-21   -4.38e-22    3.33e-06   3.93e-15   5.55e-02  9.30e+01        1    5.67e-03    6.14e-01
 110  3.951378e-21   -1.37e-21    5.83e-06   6.03e-15   5.19e-02  5.41e+01        1    5.48e-03    6.19e-01
 111  2.170279e-21    1.78e-21    2.67e-06   2.20e-15   4.59e-01  5.41e+01        1    5.69e-03    6.25e-01
 112  1.259093e-20   -1.04e-20    7.74e-06   4.92e-15   3.09e-02  2.96e+01        1    5.73e-03    6.31e-01
 113  2.429362e-21    1.02e-20    3.52e-06   9.61e-15   8.20e-01  4.02e+01        1    5.92e-03    6.37e-01
 114  3.774669e-21   -1.35e-21    3.82e-06   2.00e-15   4.99e-02  2.32e+01        1    5.87e-03    6.42e-01
 115  1.978146e-21    1.80e-21    2.89e-06   7.39e-15   4.85e-01  2.32e+01        1    5.73e-03    6.48e-01
 116  2.131096e-21   -1.53e-22    3.09e-06   3.67e-15   5.29e-02  1.35e+01        1    5.53e-03    6.54e-01
 117  6.178414e-21   -4.05e-21    5.14e-06   4.14e-15   4.37e-02  7.70e+00        1    6.04e-03    6.60e-01
 118  1.477819e-20   -8.60e-21    8.48e-06   6.00e-15   2.42e-02  4.13e+00        1    5.74e-03    6.66e-01
 119  3.455513e-21    1.13e-20    3.84e-06   8.76e-15   7.73e-01  4.94e+00        1    5.88e-03    6.71e-01
 120  1.402474e-21    2.05e-21    1.98e-06   5.48e-15   6.21e-01  5.01e+00        1    5.92e-03    6.77e-01
 121  7.427206e-21   -6.02e-21    5.74e-06   3.74e-15   3.88e-02  2.81e+00        1    5.52e-03    6.83e-01
 122  3.345907e-21    4.08e-21    4.84e-06   6.15e-15   5.67e-01  2.81e+00        1    5.59e-03    6.89e-01
 123  2.329511e-21    1.02e-21    3.94e-06   1.66e-15   3.15e-01  2.68e+00        1    5.81e-03    6.94e-01
 124  5.357361e-21   -3.03e-21    6.20e-06   1.45e-15   4.20e-02  1.51e+00        1    5.72e-03    7.00e-01
 125  4.919211e-21    4.38e-22    5.24e-06   3.29e-15   8.59e-02  9.65e-01        1    5.55e-03    7.06e-01
 126  2.547435e-21    2.37e-21    3.42e-06   3.16e-15   5.13e-01  9.65e-01        1    5.89e-03    7.12e-01
 127  1.016471e-20   -7.62e-21    6.77e-06   2.53e-15   3.14e-02  5.29e-01        1    5.48e-03    7.17e-01
 128  3.461270e-21    6.70e-21    3.77e-06   4.28e-15   8.06e-01  6.87e-01        1    5.65e-03    7.23e-01
 129  3.491966e-21   -3.07e-23    4.05e-06   2.99e-15   4.38e-02  3.90e-01        1    5.83e-03    7.29e-01
 130  2.414736e-21    1.08e-21    2.95e-06   2.30e-15   4.15e-01  3.89e-01        1    6.06e-03    7.35e-01
 131  6.582751e-21   -4.17e-21    5.59e-06   1.83e-15   3.74e-02  2.17e-01        1    5.66e-03    7.40e-01
 132  2.530989e-21    4.05e-21    3.12e-06   2.12e-15   1.01e+00  6.50e-01        1    6.15e-03    7.47e-01
 133  3.692262e-21   -1.16e-21    3.82e-06   2.33e-15   4.25e-02  3.68e-01        1    5.79e-03    7.52e-01
 134  2.582413e-21    1.11e-21    3.13e-06   2.19e-15   3.86e-01  3.64e-01        1    5.73e-03    7.58e-01
 135  5.447832e-21   -2.87e-21    4.55e-06   1.93e-15   3.88e-02  2.04e-01        1    5.59e-03    7.64e-01
 136  3.165458e-21    2.28e-21    3.96e-06   1.93e-15   7.03e-01  2.19e-01        1    5.73e-03    7.69e-01
 137  4.246518e-21   -1.08e-21    3.92e-06   1.53e-15   4.07e-02  1.23e-01        1    5.68e-03    7.75e-01
 138  3.478962e-21    7.68e-22    4.79e-06   1.23e-15   3.95e-01  1.22e-01        1    5.72e-03    7.81e-01
 139  1.671659e-21    1.81e-21    2.56e-06   8.96e-16   1.05e+00  3.66e-01        1    5.48e-03    7.86e-01
 140  8.155457e-21   -6.48e-21    5.58e-06   1.59e-15   3.30e-02  2.02e-01        1    6.47e-03    7.93e-01
 141  4.107153e-21    4.05e-21    5.10e-06   2.28e-15   7.86e-01  2.48e-01        1    5.56e-03    7.98e-01
 142  6.040125e-21   -1.93e-21    7.03e-06   1.65e-15   3.64e-02  1.38e-01        1    5.53e-03    8.04e-01
 143  6.230884e-21   -1.91e-22    7.07e-06   1.24e-15   3.58e-02  7.68e-02        1    5.73e-03    8.10e-01
 144  7.570777e-21   -1.34e-21    5.95e-06   7.44e-16   3.32e-02  4.23e-02        1    5.80e-03    8.15e-01
 145  3.223393e-21    4.35e-21    5.33e-06   6.92e-16   3.02e+00  1.27e-01        1    5.53e-03    8.21e-01
 146  1.209907e-20   -8.88e-21    7.06e-06   7.58e-16   2.48e-02  6.84e-02        1    5.75e-03    8.27e-01
 147  6.005428e-22    1.15e-20    1.83e-06   1.16e-15   3.47e+00  2.05e-01        1    5.61e-03    8.32e-01
 148  6.956497e-21   -6.36e-21    5.62e-06   4.19e-16   3.39e-02  1.13e-01        1    5.49e-03    8.38e-01
 149  7.432460e-22    6.21e-21    2.39e-06   1.39e-15   2.28e+00  3.40e-01        1    5.71e-03    8.44e-01
 150  8.991533e-22   -1.56e-22    2.04e-06   6.65e-16   4.46e-02  1.94e-01        1    5.54e-03    8.49e-01
 151  1.261555e-21   -3.62e-22    2.14e-06   7.55e-16   4.39e-02  1.10e-01        1    5.53e-03    8.55e-01
 152  4.332141e-21   -3.07e-21    3.67e-06   4.67e-16   3.84e-02  6.16e-02        1    5.84e-03    8.61e-01
 153  3.379400e-21    9.53e-22    3.71e-06   4.92e-16   8.72e-01  1.04e-01        1    5.53e-03    8.66e-01
 154  6.088656e-21   -2.71e-21    5.33e-06   9.77e-16   3.51e-02  5.79e-02        1    5.52e-03    8.72e-01
 155  7.572312e-22    5.33e-21    2.29e-06   7.24e-16   3.37e+00  1.74e-01        1    5.65e-03    8.77e-01
 156  5.732185e-21   -4.97e-21    5.17e-06   4.22e-16   3.56e-02  9.64e-02        1    5.54e-03    8.83e-01
 157  2.906553e-21    2.83e-21    4.47e-06   1.17e-15   1.34e+00  2.89e-01        1    5.48e-03    8.88e-01
 158  8.389997e-21   -5.48e-21    4.81e-06   1.47e-15   3.06e-02  1.58e-01        1    5.88e-03    8.94e-01
 159  6.019173e-21    2.37e-21    5.28e-06   1.45e-15   5.57e-01  1.59e-01        1    5.52e-03    9.00e-01
 160  1.741818e-21    4.28e-21    2.27e-06   1.59e-15   1.28e+00  4.76e-01        1    5.54e-03    9.05e-01
 161  3.540109e-22    1.39e-21    8.88e-07   1.42e-15   1.03e+00  1.43e+00        1    5.78e-03    9.11e-01
 162  3.678716e-21   -3.32e-21    4.45e-06   3.39e-16   3.83e-02  7.99e-01        1    5.86e-03    9.17e-01
 163  4.523527e-21   -8.45e-22    4.42e-06   2.64e-15   3.66e-02  4.45e-01        1    5.78e-03    9.23e-01
 164  1.013067e-20   -5.61e-21    9.42e-06   2.53e-15   2.68e-02  2.41e-01        1    5.63e-03    9.28e-01
 165  6.439998e-21    3.69e-21    5.47e-06   1.96e-15   5.03e-01  2.41e-01        1    5.64e-03    9.34e-01
 166  1.792931e-21    4.65e-21    3.66e-06   2.34e-15   1.15e+00  7.22e-01        1    5.54e-03    9.40e-01
 167  9.283600e-21   -7.49e-21    9.12e-06   1.47e-15   2.77e-02  3.92e-01        1    5.82e-03    9.46e-01
 168  5.740663e-21    3.54e-21    4.63e-06   2.06e-15   4.58e-01  3.92e-01        1    5.82e-03    9.51e-01
 169  9.496696e-21   -3.76e-21    5.60e-06   2.90e-15   2.68e-02  2.12e-01        1    5.68e-03    9.57e-01
 170  3.075927e-21    6.42e-21    3.69e-06   2.12e-15   1.16e+00  6.36e-01        1    5.72e-03    9.63e-01
 171  5.808970e-21   -2.73e-21    5.06e-06   2.77e-15   3.24e-02  3.50e-01        1    5.52e-03    9.68e-01
 172  1.198423e-22    5.69e-21    2.93e-07   2.54e-15   1.38e+00  1.05e+00        1    5.64e-03    9.74e-01
 173  4.805938e-21   -4.69e-21    4.71e-06   7.03e-16   3.38e-02  5.79e-01        1    5.74e-03    9.80e-01
 174  4.760089e-21    4.58e-23    6.46e-06   2.84e-15   3.36e-02  3.20e-01        1    5.53e-03    9.85e-01
 175  3.302074e-21    1.46e-21    3.58e-06   1.31e-15   3.92e-01  3.17e-01        1    5.75e-03    9.91e-01
 176  1.200619e-20   -8.70e-21    7.40e-06   1.94e-15   2.18e-02  1.69e-01        1    5.70e-03    9.97e-01
 177  2.892305e-21    9.11e-21    3.73e-06   2.53e-15   1.51e+00  5.07e-01        1    5.80e-03    1.00e+00
 178  4.168974e-21   -1.28e-21    4.36e-06   2.34e-15   9.39e-01  1.52e+00        1    5.76e-03    1.01e+00
 179  2.231043e-21    1.94e-21    2.43e-06   3.93e-15   7.94e-01  1.91e+00        1    5.64e-03    1.01e+00
 180  4.714772e-21   -2.48e-21    5.34e-06   3.82e-15   5.12e-01  1.91e+00        1    5.57e-03    1.02e+00
 181  6.166376e-21   -1.45e-21    5.36e-06   3.70e-15   3.16e-01  1.81e+00        1    6.08e-03    1.03e+00
 182  2.384269e-21    3.78e-21    3.38e-06   4.95e-15   6.35e-01  1.85e+00        1    5.58e-03    1.03e+00
 183  3.136152e-21   -7.52e-22    4.29e-06   2.57e-15   3.35e-01  1.79e+00        1    5.83e-03    1.04e+00
 184  3.968467e-21   -8.32e-22    5.77e-06   3.08e-15   2.73e-01  1.63e+00        1    5.85e-03    1.04e+00
 185  5.230075e-21   -1.26e-21    4.49e-06   2.47e-15   2.03e-01  1.35e+00        1    5.52e-03    1.05e+00
 186  8.950872e-21   -3.72e-21    6.40e-06   4.31e-15   8.01e-02  8.49e-01        1    5.52e-03    1.05e+00
 187  9.178624e-22    8.03e-21    1.73e-06   4.90e-15   1.00e+00  2.55e+00        1    5.89e-03    1.06e+00
 188  6.460237e-22    2.72e-22    1.66e-06   2.70e-15   3.39e-01  2.46e+00        1    5.71e-03    1.07e+00
 189  3.701295e-21   -3.06e-21    4.04e-06   5.63e-16   1.75e-01  1.93e+00        1    5.46e-03    1.07e+00
 190  4.368184e-21   -6.67e-22    4.33e-06   4.14e-15   1.50e-01  1.44e+00        1    5.99e-03    1.08e+00
 191  4.932105e-21   -5.64e-22    5.58e-06   3.91e-15   1.29e-01  1.02e+00        1    5.63e-03    1.08e+00
 192  4.227446e-21    7.05e-22    4.30e-06   3.11e-15   1.56e-01  7.70e-01        1    5.53e-03    1.09e+00
 193  2.869986e-21    1.36e-21    4.83e-06   3.43e-15   3.69e-01  7.57e-01        1    6.29e-03    1.09e+00
 194  5.370469e-21   -2.50e-21    5.61e-06   1.31e-15   1.01e-01  5.02e-01        1    5.50e-03    1.10e+00
 195  2.740119e-21    2.63e-21    3.32e-06   2.89e-15   5.73e-01  5.04e-01        1    5.54e-03    1.11e+00
 196  1.306333e-20   -1.03e-20    0.00e+00   2.56e-15  -1.46e-02  2.52e-01        1    2.93e-03    1.11e+00
 197  4.350782e-21   -1.61e-21    5.93e-06   1.65e-15   1.07e-01  1.69e-01        1    5.60e-03    1.11e+00
 198  2.073497e-21    2.28e-21    2.71e-06   8.18e-16   8.55e-01  2.63e-01        1    5.46e-03    1.12e+00
 199  3.444736e-21   -1.37e-21    3.94e-06   9.89e-16   1.13e-01  1.80e-01        1    5.59e-03    1.13e+00
 200  2.474151e-21    9.71e-22    3.19e-06   1.33e-15   4.61e-01  1.80e-01        1    5.64e-03    1.13e+00
 201  2.522106e-21   -4.80e-23    3.42e-06   1.19e-15   1.20e-01  1.25e-01        1    5.46e-03    1.14e+00
 202  6.392524e-21   -3.87e-21    5.20e-06   9.44e-16   6.98e-02  7.63e-02        1    5.74e-03    1.14e+00
 203  3.194165e-21    3.20e-21    3.86e-06   9.33e-16   1.72e+00  2.29e-01        1    5.61e-03    1.15e+00
 204  4.572951e-21   -1.38e-21    4.56e-06   1.61e-15   8.83e-02  1.47e-01        1    5.48e-03    1.15e+00
 205  2.704681e-21    1.87e-21    4.85e-06   1.39e-15   8.86e-01  2.72e-01        1    6.04e-03    1.16e+00
 206  6.324384e-21   -3.62e-21    5.32e-06   9.67e-16   6.44e-02  1.64e-01        1    5.63e-03    1.17e+00
 207  5.193880e-21    1.13e-21    4.77e-06   1.90e-15   3.44e-01  1.59e-01        1    5.47e-03    1.17e+00
 208  3.214521e-21    1.98e-21    3.37e-06   1.66e-15   7.69e-01  1.88e-01        1    5.85e-03    1.18e+00
 209  3.179213e-21    3.53e-23    3.59e-06   1.18e-15   9.20e-02  1.22e-01        1    5.91e-03    1.18e+00
 210  5.902511e-21   -2.72e-21    5.00e-06   7.50e-16   6.27e-02  7.32e-02        1    5.86e-03    1.19e+00
 211  6.147574e-21   -2.45e-22    5.22e-06   9.20e-16   5.92e-02  4.34e-02        1    5.92e-03    1.19e+00
 212  1.944079e-21    4.20e-21    3.72e-06   6.86e-16   3.67e+00  1.30e-01        1    5.84e-03    1.20e+00
 213  4.001852e-21   -2.06e-21    3.93e-06   3.97e-16   7.91e-02  8.16e-02        1    5.55e-03    1.21e+00
 214  3.161326e-21    8.41e-22    3.49e-06   7.71e-16   5.88e-01  8.20e-02        1    5.90e-03    1.21e+00
 215  1.799740e-21    1.36e-21    2.33e-06   7.57e-16   1.27e+00  2.46e-01        1    5.50e-03    1.22e+00
 216  3.358427e-21   -1.56e-21    4.66e-06   1.15e-15   8.26e-02  1.56e-01        1    5.57e-03    1.22e+00
 217  3.065474e-21    2.93e-22    3.71e-06   1.09e-15   1.53e-01  1.17e-01        1    6.11e-03    1.23e+00
 218  1.021986e-20   -7.15e-21    6.75e-06   9.47e-16   1.66e-02  6.13e-02        1    5.82e-03    1.23e+00
 219  3.723575e-21    6.50e-21    5.22e-06   9.34e-16   2.55e+00  1.84e-01        1    5.72e-03    1.24e+00
 220  6.553537e-21   -2.83e-21    5.25e-06   1.17e-15   4.83e-02  1.06e-01        1    6.11e-03    1.25e+00
 221  5.006423e-21    1.55e-21    4.72e-06   1.16e-15   6.33e-01  1.08e-01        1    5.57e-03    1.25e+00
 222  2.645765e-22    4.74e-21    8.64e-07   1.17e-15   2.53e+00  3.24e-01        1    5.92e-03    1.26e+00
 223  7.973136e-21   -7.71e-21    5.46e-06   2.46e-16   3.44e-02  1.79e-01        1    5.77e-03    1.26e+00
 224  2.623687e-21    5.35e-21    4.44e-06   2.19e-15   1.17e+00  5.37e-01        1    5.51e-03    1.27e+00
 225  7.044351e-21   -4.42e-21    5.05e-06   1.55e-15   4.00e-02  3.02e-01        1    5.78e-03    1.28e+00
 226  1.053670e-20   -3.49e-21    6.80e-06   2.69e-15   1.14e-02  1.56e-01        1    5.75e-03    1.28e+00
 227  2.222018e-21    8.31e-21    3.02e-06   2.08e-15   1.63e+00  4.69e-01        1    5.60e-03    1.29e+00
 228  9.091411e-21   -6.87e-21    8.19e-06   1.77e-15   2.15e-02  2.50e-01        1    5.76e-03    1.29e+00
 229  2.676008e-21    6.42e-21    4.81e-06   2.30e-15   9.60e-01  7.49e-01        1    5.77e-03    1.30e+00
 230  3.671862e-21   -9.96e-22    3.75e-06   1.66e-15   5.75e-02  4.42e-01        1    5.64e-03    1.30e+00
 231  6.259078e-21   -2.59e-21    5.86e-06   2.47e-15   3.88e-02  2.48e-01        1    5.55e-03    1.31e+00
 232  4.229046e-21    2.03e-21    3.85e-06   2.09e-15   4.70e-01  2.48e-01        1    5.81e-03    1.32e+00
 233  7.432488e-21   -3.20e-21    7.43e-06   1.97e-15   2.95e-02  1.35e-01        1    6.07e-03    1.32e+00
 234  7.696525e-22    6.66e-21    1.44e-06   1.48e-15   1.63e+00  4.05e-01        1    5.58e-03    1.33e+00
 235  4.288217e-21   -3.52e-21    3.90e-06   1.17e-15   4.83e-02  2.33e-01        1    5.52e-03    1.33e+00
 236  1.669595e-21    2.62e-21    3.40e-06   1.62e-15   1.07e+00  7.00e-01        1    6.61e-03    1.34e+00
 237  3.211176e-21   -1.54e-21    3.86e-06   1.47e-15   5.38e-02  4.09e-01        1    5.58e-03    1.34e+00
 238  7.984633e-22    2.41e-21    2.24e-06   2.08e-15   1.01e+00  1.23e+00        1    5.52e-03    1.35e+00
 239  1.518277e-20   -1.44e-20    0.00e+00   1.13e-15  -1.91e-02  6.14e-01        1    2.84e-03    1.35e+00
 240  2.150263e-22    5.83e-22    6.13e-07   8.90e-16   9.69e-01  1.84e+00        1    5.47e-03    1.36e+00
 241  9.786049e-21   -9.57e-21    6.59e-06   1.00e-15   1.33e-02  9.58e-01        1    5.53e-03    1.36e+00
 242  6.128561e-21    3.66e-21    4.31e-06   5.49e-15   4.24e-01  9.55e-01        1    5.53e-03    1.37e+00
 243  3.086812e-21    3.04e-21    3.26e-06   3.11e-15   5.39e-01  9.55e-01        1    5.50e-03    1.37e+00
 244  1.705555e-21    1.38e-21    2.66e-06   2.90e-15   5.00e-01  9.55e-01        1    5.48e-03    1.38e+00
 245  1.013425e-20   -8.43e-21    8.13e-06   2.33e-15   1.01e-02  4.92e-01        1    5.50e-03    1.39e+00
 246  1.943258e-22    9.94e-21    3.99e-07   3.49e-15   1.13e+00  1.48e+00        1    5.48e-03    1.39e+00
 247  1.005452e-20   -9.86e-21    6.63e-06   9.50e-16   1.01e-02  7.61e-01        1    5.54e-03    1.40e+00
 248  3.347767e-22    9.72e-21    1.03e-07   4.82e-15   1.13e+00  2.28e+00        1    5.57e-03    1.40e+00
 249  2.636544e-21   -2.30e-21    3.52e-06   1.58e-15   4.62e-02  1.31e+00        1    5.60e-03    1.41e+00
 250  1.292939e-20   -1.03e-20    0.00e+00   3.22e-15  -4.50e-03  6.53e-01        1    2.87e-03    1.41e+00
 251  6.029830e-21   -3.39e-21    5.16e-06   2.53e-15   2.92e-02  3.56e-01        1    5.57e-03    1.42e+00
 252  8.920113e-21   -2.89e-21    6.45e-06   2.76e-15   1.47e-02  1.86e-01        1    5.55e-03    1.42e+00
 253  1.216753e-21    7.70e-21    2.90e-06   2.31e-15   1.62e+00  5.58e-01        1    5.51e-03    1.43e+00
 254  4.587636e-22    7.58e-22    1.76e-06   1.38e-15   7.22e-01  6.11e-01        1    5.60e-03    1.43e+00
 255  2.428764e-21   -1.97e-21    4.05e-06   6.62e-16   4.45e-02  3.48e-01        1    5.45e-03    1.44e+00
 256  5.633742e-21   -3.20e-21    4.92e-06   8.54e-16   2.93e-02  1.90e-01        1    5.42e-03    1.44e+00
 257  8.876463e-21   -3.24e-21    7.88e-06   1.30e-15   1.42e-02  9.90e-02        1    5.76e-03    1.45e+00
 258  2.311608e-21    6.56e-21    3.17e-06   1.24e-15   1.63e+00  2.97e-01        1    5.83e-03    1.46e+00
 259  3.838481e-21   -1.53e-21    4.13e-06   1.61e-15   3.61e-02  1.65e-01        1    5.66e-03    1.46e+00
 260  2.517859e-21    1.32e-21    4.05e-06   1.41e-15   6.89e-01  1.75e-01        1    5.67e-03    1.47e+00
 261  1.341411e-20   -1.09e-20    0.00e+00   1.09e-15  -6.13e-03  8.73e-02        1    2.87e-03    1.47e+00
 262  9.331380e-21   -6.81e-21    5.97e-06   5.68e-16   1.17e-02  4.52e-02        1    5.74e-03    1.48e+00
 263  5.410706e-21    3.92e-21    4.80e-06   7.62e-16   1.85e+00  1.36e-01        1    5.60e-03    1.48e+00
 264  2.373127e-20   -1.83e-20    0.00e+00   1.41e-15  -5.02e-02  6.78e-02        1    2.88e-03    1.48e+00
 265  1.969667e-21    3.44e-21    2.80e-06   9.35e-16   2.32e+00  2.03e-01        1    5.62e-03    1.49e+00
 266  2.799387e-21   -8.30e-22    2.95e-06   1.02e-15   3.94e-02  1.14e-01        1    5.94e-03    1.50e+00
 267  5.416659e-21   -2.62e-21    4.53e-06   9.62e-16   2.81e-02  6.20e-02        1    5.72e-03    1.50e+00
 268  1.249375e-21    4.17e-21    3.05e-06   6.98e-16   3.37e+00  1.86e-01        1    5.64e-03    1.51e+00
 269  1.240782e-21    8.59e-24    1.88e-06   3.89e-16   4.55e-02  1.06e-01        1    5.66e-03    1.51e+00
 270  1.279266e-20   -1.16e-20    0.00e+00   4.70e-16  -3.32e-03  5.31e-02        1    2.88e-03    1.52e+00
 271  3.748670e-21   -2.51e-21    4.32e-06   2.32e-16   3.48e-02  2.94e-02        1    5.57e-03    1.52e+00
 272  1.272005e-21    2.48e-21    1.80e-06   1.44e-16   4.20e+00  8.83e-02        1    5.55e-03    1.53e+00
 273  1.454159e-20   -1.33e-20    0.00e+00   4.58e-16  -1.07e-02  4.41e-02        1    2.80e-03    1.53e+00
 274  1.162530e-20   -1.04e-20    7.18e-06   2.27e-16   1.60e-03  2.22e-02        1    5.61e-03    1.54e+00
 275  4.708212e-21    6.92e-21    3.97e-06   4.66e-16   5.03e+00  6.65e-02        1    5.47e-03    1.54e+00
 276  7.350534e-21   -2.64e-21    5.96e-06   6.93e-16   1.94e-02  3.52e-02        1    5.59e-03    1.55e+00
 277  1.047597e-21    6.30e-21    2.68e-06   4.72e-16   5.30e+00  1.06e-01        1    5.90e-03    1.55e+00
 278  3.369586e-21   -2.32e-21    3.98e-06   3.29e-16   3.57e-02  5.87e-02        1    5.55e-03    1.56e+00
 279  2.499532e-21    8.70e-22    4.54e-06   4.71e-16   1.05e+00  1.76e-01        1    5.55e-03    1.56e+00
 280  2.047011e-20   -1.80e-20    0.00e+00   7.61e-16  -3.47e-02  8.80e-02        1    2.87e-03    1.57e+00
 281  6.411684e-21   -3.91e-21    6.14e-06   4.47e-16   2.29e-02  4.71e-02        1    5.57e-03    1.57e+00
 282  8.482456e-21   -2.07e-21    5.69e-06   3.65e-16   1.44e-02  2.46e-02        1    5.67e-03    1.58e+00
 283  1.080947e-20   -2.33e-21    6.78e-06   5.08e-16   4.85e-03  1.25e-02        1    5.52e-03    1.58e+00
 284  6.381988e-21    4.43e-21    6.56e-06   2.55e-16   5.78e+00  3.74e-02        1    5.53e-03    1.59e+00
 285  1.507631e-21    4.87e-21    2.27e-06   5.69e-16   3.33e+00  1.12e-01        1    5.87e-03    1.59e+00
 286  1.676052e-20   -1.53e-20    0.00e+00   4.89e-16  -1.91e-02  5.61e-02        1    3.02e-03    1.60e+00
 287  1.892631e-20   -1.74e-20    0.00e+00   2.64e-16  -2.78e-02  1.40e-02        1    3.01e-03    1.60e+00
 288  1.855418e-21   -3.48e-22    2.44e-06   2.50e-17   4.08e-02  7.91e-03        1    5.65e-03    1.61e+00
 289  6.123583e-21   -4.27e-21    5.45e-06   1.73e-17   2.36e-02  4.24e-03        1    5.60e-03    1.61e+00

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          2.913143e+01
Final                            1.198423e-22
Change                           2.913143e+01

Minimizer iterations                      290
Successful steps                          276
Unsuccessful steps                         14
Line search steps                         155

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0217
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.5765
    Line search gradient evaluation    0.8151
  Linear solver                        0.0081
  Line search polynomial minimization  0.0007
Minimizer                              1.6150

Postprocessor                          0.0000
Total                                  1.6151

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.617299e+04
Final                            1.563017e+02
Change                           1.601669e+04

Minimizer iterations                      246
Successful steps                          137
Unsuccessful steps                        109
Line search steps                         302

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0176
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.4091
    Line search gradient evaluation    1.0378
  Linear solver                        0.0041
  Line search polynomial minimization  0.0019
Minimizer                              1.4367

Postprocessor                          0.0000
Total                                  1.4367

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA73 = {
{-0.0416106,0.3548695,0.1616767}
};
fitErrEl73 = {
{-0.0713900,0.3449356,0.1716678}
};
fitErrLa73 = {
{-0.0726904,0.3648722,0.1774815}
};
fitErrWr73 = {
{-0.1941160,0.3186831,0.2421233}
};
fitErrEe73 = {
{-0.2518954,0.3440733,0.3170145}
};
rMatsBase73 = {
{-0.3008732,0.6554709,-0.6927000},
{0.8296902,0.5380407,0.1487491},
{0.4702015,-0.5299718,-0.7057198}
};
outThetasWam73 = {
{-0.0903802,-0.3472898,-0.0486324,1.3672068,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.3921775
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  5.387703e+01    0.00e+00    2.83e+00   0.00e+00   0.00e+00  1.00e+04        0    2.86e-03    2.90e-03
   1  3.672194e+00    5.02e+01    2.83e+00   1.01e-02   1.86e+00  3.00e+04        1    5.62e-03    8.55e-03
   2  7.440114e-05    3.67e+00    2.77e+00   3.99e-04   1.93e+00  9.00e+04        1    5.60e-03    1.42e-02
   3  6.916010e-14    7.44e-05    4.50e-03   6.88e-07   1.86e+00  2.70e+05        1    5.49e-03    1.97e-02
   4  5.484196e-21    6.92e-14    3.97e-06   1.33e-10   1.86e+00  8.10e+05        1    5.50e-03    2.52e-02
   5  6.067258e-21   -5.83e-22    4.88e-06   1.81e-14   1.86e+00  2.43e+06        1    5.52e-03    3.07e-02
   6  7.126095e-22    5.35e-21    1.67e-06   8.96e-15   1.86e+00  7.29e+06        1    5.47e-03    3.62e-02
   7  7.572237e-22   -4.46e-23    1.57e-06   5.48e-15   1.86e+00  2.19e+07        1    5.51e-03    4.17e-02
   8  1.287027e-21   -5.30e-22    2.39e-06   5.78e-15   1.86e+00  6.56e+07        1    5.49e-03    4.72e-02
   9  5.537918e-22    7.33e-22    1.54e-06   4.06e-15   1.86e+00  1.97e+08        1    5.46e-03    5.27e-02
  10  2.293262e-21   -1.74e-21    3.15e-06   3.67e-15   1.86e+00  5.90e+08        1    5.49e-03    5.82e-02
  11  3.240734e-20   -3.01e-20    1.24e-05   5.90e-15   1.86e+00  1.77e+09        1    5.50e-03    6.37e-02
  12  2.020502e-20    1.22e-20    9.75e-06   1.80e-14   1.86e+00  5.31e+09        1    5.48e-03    6.92e-02
  13  3.759852e-21    1.64e-20    4.38e-06   1.43e-14   1.86e+00  1.59e+10        1    5.77e-03    7.50e-02
  14  9.521012e-22    2.81e-21    1.89e-06   5.10e-15   1.86e+00  4.78e+10        1    5.76e-03    8.08e-02
  15  4.485821e-21   -3.53e-21    4.61e-06   4.29e-15   4.91e-01  4.78e+10        1    5.77e-03    8.65e-02
  16  2.933893e-21    1.55e-21    3.52e-06   8.91e-15   4.81e-01  4.78e+10        1    5.79e-03    9.23e-02
  17  1.238884e-21    1.70e-21    2.26e-06   8.14e-15   5.79e-01  4.80e+10        1    5.75e-03    9.81e-02
  18  3.351676e-21   -2.11e-21    3.66e-06   5.57e-15   4.44e-01  4.80e+10        1    5.75e-03    1.04e-01
  19  2.105089e-21    1.25e-21    2.33e-06   5.88e-15   4.41e-01  4.79e+10        1    5.68e-03    1.10e-01
  20  2.159707e-21   -5.46e-23    3.37e-06   7.45e-15   4.27e-01  4.77e+10        1    5.70e-03    1.15e-01
  21  9.530959e-22    1.21e-21    1.71e-06   3.18e-15   5.89e-01  4.80e+10        1    5.67e-03    1.21e-01
  22  3.463722e-21   -2.51e-21    3.75e-06   3.84e-15   3.92e-01  4.75e+10        1    5.63e-03    1.27e-01
  23  5.577825e-21   -2.11e-21    4.52e-06   8.31e-15   3.47e-01  4.62e+10        1    5.73e-03    1.32e-01
  24  2.356077e-22    5.34e-21    7.67e-07   1.04e-14   9.67e-01  1.39e+11        1    5.51e-03    1.38e-01
  25  3.414502e-21   -3.18e-21    4.11e-06   2.49e-15   3.50e-01  1.35e+11        1    5.50e-03    1.43e-01
  26  6.111043e-21   -2.70e-21    5.23e-06   5.17e-15   3.05e-01  1.27e+11        1    5.50e-03    1.49e-01
  27  1.511257e-21    4.60e-21    3.16e-06   8.75e-15   7.73e-01  1.52e+11        1    5.46e-03    1.54e-01
  28  9.079020e-21   -7.57e-21    6.73e-06   2.53e-15   2.50e-01  1.35e+11        1    5.46e-03    1.60e-01
  29  3.225600e-21    5.85e-21    3.64e-06   7.11e-15   6.48e-01  1.39e+11        1    5.48e-03    1.65e-01
  30  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  6.95e+10        1    2.80e-03    1.68e-01
  31  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  1.74e+10        1    2.84e-03    1.71e-01
  32  3.619784e-20   -3.30e-20    0.00e+00   7.15e-15  -2.24e+00  2.17e+09        1    2.84e-03    1.74e-01
  33  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  1.36e+08        1    2.80e-03    1.77e-01
  34  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  4.24e+06        1    3.19e-03    1.80e-01
  35  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  6.63e+04        1    2.83e-03    1.83e-01
  36  4.061085e-20   -3.74e-20    0.00e+00   7.15e-15  -2.60e+00  5.18e+02        1    2.80e-03    1.86e-01
  37  4.060837e-20   -3.74e-20    0.00e+00   6.93e-15  -2.60e+00  2.02e+00        1    2.82e-03    1.88e-01
  38  2.272247e-21    9.53e-22    4.07e-06   3.67e-15   5.68e-01  2.03e+00        1    5.46e-03    1.94e-01
  39  7.305699e-21   -5.03e-21    5.98e-06   2.17e-15   1.27e-01  1.43e+00        1    5.56e-03    1.99e-01
  40  3.224472e-21    4.08e-21    3.67e-06   4.90e-15   5.87e-01  1.44e+00        1    5.48e-03    2.05e-01
  41  2.479027e-21    7.45e-22    2.94e-06   3.52e-15   2.76e-01  1.32e+00        1    5.48e-03    2.10e-01
  42  2.903370e-21   -4.24e-22    2.55e-06   3.08e-15   2.37e-01  1.15e+00        1    5.49e-03    2.16e-01
  43  7.739642e-21   -4.84e-21    5.64e-06   2.74e-15   4.73e-02  6.61e-01        1    5.46e-03    2.21e-01
  44  1.804077e-20   -1.03e-20    0.00e+00   3.29e-15  -2.56e-01  3.31e-01        1    2.79e-03    2.24e-01
  45  9.714379e-22    6.77e-21    2.02e-06   2.36e-15   1.22e+00  9.92e-01        1    5.48e-03    2.30e-01
  46  1.123237e-21   -1.52e-22    2.70e-06   1.68e-15   2.29e-01  8.56e-01        1    5.43e-03    2.35e-01
  47  3.373008e-21   -2.25e-21    5.38e-06   1.38e-15   1.60e-01  6.51e-01        1    5.49e-03    2.41e-01
  48  6.076794e-21   -2.70e-21    5.45e-06   1.26e-15   7.78e-02  4.06e-01        1    5.46e-03    2.46e-01
  49  7.015608e-21   -9.39e-22    5.23e-06   2.85e-15   4.76e-02  2.33e-01        1    5.45e-03    2.52e-01
  50  8.680050e-21   -1.66e-21    6.25e-06   2.23e-15   8.33e-03  1.20e-01        1    5.46e-03    2.57e-01
  51  1.265646e-20   -3.98e-21    0.00e+00   1.41e-15  -6.95e-02  5.98e-02        1    2.96e-03    2.60e-01
  52  1.929402e-21    6.75e-21    3.22e-06   7.29e-16   3.13e+00  1.80e-01        1    5.84e-03    2.66e-01
  53  6.491990e-21   -4.56e-21    5.31e-06   8.24e-16   5.05e-02  1.04e-01        1    5.50e-03    2.71e-01
  54  1.172924e-21    5.32e-21    1.72e-06   1.16e-15   2.23e+00  3.12e-01        1    5.56e-03    2.77e-01
  55  6.442293e-22    5.29e-22    1.37e-06   7.29e-16   6.90e-01  3.30e-01        1    5.74e-03    2.83e-01
  56  4.373365e-22    2.07e-22    1.60e-06   7.53e-16   4.78e-01  3.30e-01        1    5.50e-03    2.88e-01
  57  2.207327e-21   -1.77e-21    2.70e-06   5.70e-16   1.25e-01  2.32e-01        1    5.52e-03    2.94e-01
  58  3.295017e-21   -1.09e-21    3.86e-06   1.27e-15   1.02e-01  1.54e-01        1    5.45e-03    2.99e-01
  59  1.664773e-21    1.63e-21    3.72e-06   1.17e-15   1.02e+00  4.63e-01        1    5.71e-03    3.05e-01
  60  6.317720e-22    1.03e-21    1.57e-06   9.58e-16   7.55e-01  5.34e-01        1    5.87e-03    3.11e-01
  61  1.673523e-21   -1.04e-21    2.64e-06   7.19e-16   1.24e-01  3.74e-01        1    5.66e-03    3.16e-01
  62  7.255086e-21   -5.58e-21    5.88e-06   1.44e-15   2.99e-02  2.05e-01        1    5.85e-03    3.22e-01
  63  2.580765e-21    4.67e-21    3.43e-06   1.95e-15   1.08e+00  6.14e-01        1    5.68e-03    3.28e-01
  64  5.011502e-21   -2.43e-21    6.53e-06   2.36e-15   6.03e-02  3.65e-01        1    5.68e-03    3.34e-01
  65  2.838489e-21    2.17e-21    3.62e-06   1.20e-15   5.47e-01  3.65e-01        1    5.66e-03    3.39e-01
  66  7.237093e-21   -4.40e-21    5.15e-06   1.65e-15   2.51e-02  1.97e-01        1    5.63e-03    3.45e-01
  67  2.829081e-21    4.41e-21    3.66e-06   2.03e-15   9.86e-01  5.90e-01        1    5.57e-03    3.51e-01
  68  6.954936e-21   -4.13e-21    5.67e-06   2.16e-15   2.64e-02  3.19e-01        1    5.56e-03    3.56e-01
  69  1.768967e-20   -1.07e-20    0.00e+00   2.58e-15  -1.01e-01  1.60e-01        1    2.84e-03    3.59e-01
  70  3.775162e-21    3.18e-21    4.21e-06   1.64e-15   9.40e-01  4.79e-01        1    5.48e-03    3.65e-01
  71  3.113161e-21    6.62e-22    3.81e-06   2.34e-15   2.22e-01  4.09e-01        1    5.49e-03    3.70e-01
  72  7.159688e-21   -4.05e-21    5.72e-06   2.12e-15   2.16e-02  2.18e-01        1    5.51e-03    3.76e-01
  73  5.493354e-21    1.67e-21    5.72e-06   2.16e-15   3.98e-01  2.16e-01        1    5.50e-03    3.81e-01
  74  4.896338e-21    5.97e-22    6.61e-06   9.04e-16   1.80e-01  1.71e-01        1    5.51e-03    3.87e-01
  75  5.103182e-21   -2.07e-22    4.95e-06   9.83e-16   3.99e-02  9.61e-02        1    5.51e-03    3.92e-01
  76  3.550884e-21    1.55e-21    4.03e-06   9.53e-16   8.41e-01  1.41e-01        1    5.49e-03    3.98e-01
  77  4.624366e-21   -1.07e-21    6.10e-06   9.47e-16   4.32e-02  7.98e-02        1    5.52e-03    4.03e-01
  78  7.110273e-21   -2.49e-21    5.45e-06   4.17e-16   1.88e-02  4.22e-02        1    5.58e-03    4.09e-01
  79  4.915743e-21    2.19e-21    4.74e-06   4.71e-16   1.68e+00  1.26e-01        1    5.58e-03    4.14e-01
  80  7.600366e-21   -2.68e-21    5.88e-06   1.19e-15   1.36e-02  6.59e-02        1    5.56e-03    4.20e-01
  81  1.959702e-21    5.64e-21    3.02e-06   9.44e-16   2.71e+00  1.98e-01        1    5.50e-03    4.25e-01
  82  2.686306e-21   -7.27e-22    3.60e-06   9.36e-16   5.73e-02  1.17e-01        1    5.51e-03    4.31e-01
  83  1.261065e-21    1.43e-21    2.34e-06   9.51e-16   1.28e+00  3.50e-01        1    5.50e-03    4.36e-01
  84  2.595579e-21   -1.33e-21    3.50e-06   1.08e-15   5.70e-02  2.06e-01        1    5.56e-03    4.42e-01
  85  3.792149e-22    2.22e-21    1.36e-06   1.23e-15   1.42e+00  6.19e-01        1    5.52e-03    4.48e-01
  86  2.617458e-21   -2.24e-21    3.34e-06   4.90e-16   5.60e-02  3.64e-01        1    5.52e-03    4.53e-01
  87  2.153426e-21    4.64e-22    3.14e-06   1.73e-15   2.41e-01  3.20e-01        1    5.50e-03    4.59e-01
  88  2.675125e-21   -5.22e-22    4.23e-06   1.44e-15   5.39e-02  1.87e-01        1    5.54e-03    4.64e-01
  89  5.501577e-21   -2.83e-21    4.54e-06   5.49e-16   2.97e-02  1.02e-01        1    5.53e-03    4.70e-01
  90  6.828759e-21   -1.33e-21    7.47e-06   1.03e-15   1.83e-02  5.39e-02        1    5.53e-03    4.75e-01
  91  2.109746e-21    4.72e-21    3.25e-06   4.05e-16   2.32e+00  1.62e-01        1    5.54e-03    4.81e-01
  92  3.792426e-21   -1.68e-21    5.22e-06   8.22e-16   4.20e-02  9.14e-02        1    5.98e-03    4.87e-01
  93  1.639773e-21    2.15e-21    2.52e-06   6.60e-16   1.28e+00  2.74e-01        1    5.73e-03    4.93e-01
  94  3.622420e-21   -1.98e-21    4.75e-06   1.27e-15   4.24e-02  1.55e-01        1    5.74e-03    4.98e-01
  95  3.264755e-21    3.58e-22    3.70e-06   1.15e-15   1.65e-01  1.19e-01        1    5.67e-03    5.04e-01
  96  3.334742e-21   -7.00e-23    3.88e-06   9.37e-16   4.35e-02  6.78e-02        1    5.73e-03    5.10e-01
  97  1.642670e-21    1.69e-21    3.60e-06   7.16e-16   1.71e+00  2.03e-01        1    5.66e-03    5.15e-01
  98  9.848028e-22    6.58e-22    2.00e-06   5.57e-16   6.47e-01  2.09e-01        1    5.84e-03    5.21e-01
  99  1.681804e-21   -6.97e-22    2.31e-06   6.96e-16   5.49e-02  1.22e-01        1    5.81e-03    5.27e-01
 100  4.891772e-21   -3.21e-21    6.43e-06   6.94e-16   3.09e-02  6.70e-02        1    5.83e-03    5.33e-01
 101  2.475096e-21    2.42e-21    3.40e-06   5.36e-16   1.33e+00  2.01e-01        1    5.77e-03    5.39e-01
 102  1.381418e-21    1.09e-21    2.22e-06   1.17e-15   7.87e-01  2.48e-01        1    5.94e-03    5.45e-01
 103  1.647315e-21   -2.66e-22    3.62e-06   1.02e-15   5.33e-02  1.45e-01        1    5.88e-03    5.51e-01
 104  3.667896e-21   -2.02e-21    5.12e-06   4.56e-16   3.86e-02  8.10e-02        1    5.66e-03    5.56e-01
 105  2.799321e-21    8.69e-22    3.52e-06   6.53e-16   5.76e-01  8.13e-02        1    5.66e-03    5.62e-01
 106  1.645354e-20   -1.37e-20    0.00e+00   6.94e-16  -5.17e-02  4.06e-02        1    2.89e-03    5.65e-01
 107  1.807741e-21    9.92e-22    3.77e-06   2.69e-16   2.01e+00  1.22e-01        1    5.51e-03    5.70e-01
 108  3.664361e-21   -1.86e-21    5.11e-06   3.96e-16   3.78e-02  6.81e-02        1    6.02e-03    5.76e-01
 109  1.164647e-21    2.50e-21    2.02e-06   5.78e-16   1.87e+00  2.04e-01        1    5.78e-03    5.82e-01
 110  5.203059e-21   -4.04e-21    6.68e-06   7.62e-16   2.67e-02  1.11e-01        1    5.76e-03    5.88e-01
 111  2.391184e-21    2.81e-21    3.27e-06   8.45e-16   1.06e+00  3.32e-01        1    5.74e-03    5.94e-01
 112  7.799800e-21   -5.41e-21    5.83e-06   1.63e-15   8.56e-03  1.70e-01        1    5.73e-03    5.99e-01
 113  3.671862e-21    4.13e-21    4.11e-06   1.64e-15   1.02e+00  5.10e-01        1    5.70e-03    6.05e-01
 114  7.528677e-22    2.92e-21    2.29e-06   2.58e-15   9.93e-01  1.53e+00        1    5.86e-03    6.11e-01
 115  9.533041e-22   -2.00e-22    2.61e-06   1.14e-15   5.17e-02  8.90e-01        1    5.92e-03    6.17e-01
 116  3.320896e-21   -2.37e-21    3.86e-06   1.14e-15   3.65e-02  4.95e-01        1    5.90e-03    6.23e-01
 117  9.844795e-22    2.34e-21    2.00e-06   2.08e-15   8.36e-01  7.10e-01        1    5.87e-03    6.29e-01
 118  1.854774e-20   -1.76e-20    0.00e+00   1.60e-15  -5.86e-02  3.55e-01        1    2.96e-03    6.32e-01
 119  4.252323e-21   -3.27e-21    4.15e-06   1.16e-15   2.99e-02  1.94e-01        1    5.68e-03    6.37e-01
 120  9.767428e-22    3.28e-21    1.52e-06   1.57e-15   1.23e+00  5.82e-01        1    5.62e-03    6.43e-01
 121  6.969205e-21   -5.99e-21    5.82e-06   1.16e-15   1.28e-02  3.02e-01        1    5.66e-03    6.49e-01
 122  1.192288e-21    5.78e-21    1.96e-06   2.60e-15   1.22e+00  9.06e-01        1    5.64e-03    6.54e-01
 123  3.732482e-21   -2.54e-21    4.28e-06   1.67e-15   3.14e-02  4.97e-01        1    5.65e-03    6.60e-01
 124  6.628350e-21   -2.90e-21    6.82e-06   2.38e-15   1.41e-02  2.59e-01        1    5.84e-03    6.66e-01
 125  6.648124e-21   -1.98e-23    6.14e-06   1.80e-15   1.36e-02  1.35e-01        1    5.68e-03    6.72e-01
 126  3.047627e-21    3.60e-21    3.72e-06   1.40e-15   1.00e+00  4.05e-01        1    5.62e-03    6.77e-01
 127  5.310407e-21   -2.26e-21    5.42e-06   2.12e-15   2.05e-02  2.15e-01        1    5.95e-03    6.83e-01
 128  2.611747e-21    2.70e-21    2.84e-06   1.03e-15   8.12e-01  2.84e-01        1    5.60e-03    6.89e-01
 129  1.096998e-20   -8.36e-21    0.00e+00   9.97e-16  -1.00e-02  1.42e-01        1    2.91e-03    6.92e-01
 130  1.110164e-20   -8.49e-21    0.00e+00   7.26e-16  -1.07e-02  3.55e-02        1    2.84e-03    6.95e-01
 131  2.538768e-22    2.36e-21    6.65e-07   2.35e-16   6.02e+00  1.07e-01        1    5.55e-03    7.00e-01
 132  2.527617e-20   -2.50e-20    0.00e+00   1.16e-16  -8.62e-02  5.33e-02        1    2.84e-03    7.03e-01
 133  7.615323e-22   -5.08e-22    1.64e-06   1.96e-17   4.43e-02  3.03e-02        1    6.13e-03    7.09e-01
 134  1.185094e-21   -4.24e-22    2.24e-06   2.22e-16   4.20e-02  1.71e-02        1    5.90e-03    7.15e-01
 135  1.923435e-22    9.93e-22    4.41e-07   1.43e-17   1.20e+01  5.14e-02        1    5.63e-03    7.21e-01
 136  9.097874e-21   -8.91e-21    0.00e+00   7.76e-18  -1.00e-04  2.57e-02        1    2.87e-03    7.24e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          5.387703e+01
Final                            1.923435e-22
Change                           5.387703e+01

Minimizer iterations                      137
Successful steps                          120
Unsuccessful steps                         17
Line search steps                          78

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0100
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7090
    Line search gradient evaluation    0.3798
  Linear solver                        0.0036
  Line search polynomial minimization  0.0003
Minimizer                              0.7265

Postprocessor                          0.0000
Total                                  0.7266

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:49:04.689891  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.615706e+04
Final                            1.511277e+02
Change                           1.600593e+04

Minimizer iterations                      411
Successful steps                          281
Unsuccessful steps                        130
Line search steps                         661

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0339
    Line search cost evaluation        0.0000
  Jacobian evaluation                  3.3042
    Line search gradient evaluation    2.4630
  Linear solver                        0.0094
  Line search polynomial minimization  0.0066
Minimizer                              3.3633

Postprocessor                          0.0000
Total                                  3.3634

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA74 = {
{-0.0445824,0.3678503,0.1679035}
};
fitErrEl74 = {
{-0.0754198,0.3574620,0.1782202}
};
fitErrLa74 = {
{-0.0767454,0.3785645,0.1844570}
};
fitErrWr74 = {
{-0.2055695,0.3310205,0.2517035}
};
fitErrEe74 = {
{-0.2632573,0.3565144,0.3277286}
};
rMatsBase74 = {
{-0.3018087,0.6623354,-0.6857283},
{0.8294514,0.5370318,0.1536462},
{0.4700232,-0.5224066,-0.7114559}
};
outThetasWam74 = {
{-0.0922475,-0.3390342,-0.0504613,1.3606366,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4068083
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  5.376528e+01    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    3.04e-03    3.07e-03
   1  4.580322e+00    4.92e+01    2.83e+00   1.10e-02   1.83e+00  3.00e+04        1    6.23e-03    9.32e-03
   2  1.330955e-04    4.58e+00    2.77e+00   4.60e-04   1.95e+00  9.00e+04        1    6.15e-03    1.55e-02
   3  8.965630e-14    1.33e-04    6.08e-03   8.42e-07   1.84e+00  2.70e+05        1    6.15e-03    2.16e-02
   4  1.145992e-20    8.97e-14    7.24e-06   1.47e-10   1.84e+00  8.10e+05        1    6.16e-03    2.78e-02
   5  3.537330e-20   -2.39e-20    1.34e-05   1.85e-14   1.84e+00  2.43e+06        1    6.16e-03    3.40e-02
   6  5.562260e-21    2.98e-20    4.84e-06   1.71e-14   1.84e+00  7.29e+06        1    6.21e-03    4.02e-02
   7  4.087123e-21    1.48e-21    4.19e-06   8.79e-15   1.84e+00  2.19e+07        1    6.11e-03    4.64e-02
   8  2.005854e-20   -1.60e-20    9.44e-06   5.87e-15   1.84e+00  6.56e+07        1    6.11e-03    5.25e-02
   9  1.346921e-21    1.87e-20    2.29e-06   1.65e-14   1.84e+00  1.97e+08        1    6.17e-03    5.87e-02
  10  1.808069e-21   -4.61e-22    2.64e-06   4.75e-15   1.84e+00  5.90e+08        1    6.15e-03    6.48e-02
  11  1.372191e-20   -1.19e-20    8.02e-06   4.94e-15   1.84e+00  1.77e+09        1    6.16e-03    7.10e-02
  12  3.553273e-21    1.02e-20    3.15e-06   1.51e-14   1.84e+00  5.31e+09        1    6.15e-03    7.72e-02
  13  9.742402e-22    2.58e-21    2.51e-06   7.84e-15   1.84e+00  1.59e+10        1    6.14e-03    8.33e-02
  14  6.284748e-21   -5.31e-21    7.42e-06   3.42e-15   1.84e+00  4.78e+10        1    6.15e-03    8.95e-02
  15  6.544990e-21   -2.60e-22    5.60e-06   3.79e-15   1.84e+00  1.43e+11        1    6.16e-03    9.57e-02
  16  9.505044e-21   -2.96e-21    5.65e-06   5.84e-15   1.84e+00  4.30e+11        1    6.13e-03    1.02e-01
  17  1.645513e-21    7.86e-21    3.51e-06   1.18e-14   1.84e+00  1.29e+12        1    6.12e-03    1.08e-01
  18  3.870107e-21   -2.22e-21    5.76e-06   6.56e-15   1.84e+00  3.87e+12        1    6.19e-03    1.14e-01
  19  5.783825e-22    3.29e-21    1.02e-06   4.45e-15   8.62e-01  6.24e+12        1    6.14e-03    1.20e-01
  20  6.134729e-21   -5.56e-21    6.00e-06   3.40e-15   2.19e-01  5.29e+12        1    6.16e-03    1.26e-01
  21  4.616671e-21    1.52e-21    6.33e-06   8.49e-15   2.49e-01  4.70e+12        1    6.20e-03    1.33e-01
  22  4.626216e-21   -9.54e-24    4.55e-06   3.32e-15   1.87e-01  3.78e+12        1    6.16e-03    1.39e-01
  23  4.487212e-21    1.39e-22    4.17e-06   4.85e-15   1.64e-01  2.90e+12        1    6.14e-03    1.45e-01
  24  5.649413e-21   -1.16e-21    7.11e-06   4.72e-15   1.10e-01  1.96e+12        1    6.18e-03    1.51e-01
  25  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  9.82e+11        1    3.10e-03    1.54e-01
  26  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  2.46e+11        1    3.12e-03    1.57e-01
  27  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  3.07e+10        1    3.15e-03    1.61e-01
  28  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  1.92e+09        1    3.20e-03    1.64e-01
  29  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  6.00e+07        1    3.14e-03    1.67e-01
  30  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  9.37e+05        1    3.14e-03    1.70e-01
  31  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  7.32e+03        1    3.14e-03    1.73e-01
  32  8.722245e-21   -3.07e-21    0.00e+00   3.69e-15  -1.03e-01  2.86e+01        1    3.22e-03    1.77e-01
  33  1.967736e-21    3.68e-21    3.98e-06   3.05e-15   6.57e-01  2.95e+01        1    6.21e-03    1.83e-01
  34  2.153347e-21   -1.86e-22    3.26e-06   3.08e-15   1.47e-01  2.18e+01        1    6.19e-03    1.89e-01
  35  1.460350e-21    6.93e-22    2.40e-06   3.50e-15   3.34e-01  2.10e+01        1    6.36e-03    1.95e-01
  36  1.100721e-20   -9.55e-21    0.00e+00   3.97e-15  -1.59e-01  1.05e+01        1    3.21e-03    1.99e-01
  37  6.468708e-21   -5.01e-21    0.00e+00   3.51e-15  -1.09e-02  2.63e+00        1    3.14e-03    2.02e-01
  38  4.361349e-21   -2.90e-21    6.10e-06   2.58e-15   5.81e-02  1.56e+00        1    6.18e-03    2.08e-01
  39  6.654992e-21   -2.29e-21    0.00e+00   1.62e-15  -1.50e-02  7.78e-01        1    3.11e-03    2.11e-01
  40  7.959543e-22    3.57e-21    1.85e-06   1.46e-15   8.94e-01  1.52e+00        1    6.20e-03    2.17e-01
  41  1.287059e-20   -1.21e-20    0.00e+00   1.68e-15  -1.91e-01  7.61e-01        1    3.17e-03    2.20e-01
  42  4.293842e-22    3.67e-22    1.09e-06   1.22e-15   5.42e-01  7.61e-01        1    6.15e-03    2.27e-01
  43  2.947171e-21   -2.52e-21    3.10e-06   3.66e-16   8.99e-02  4.91e-01        1    6.24e-03    2.33e-01
  44  1.569032e-21    1.38e-21    2.55e-06   1.46e-15   6.10e-01  4.96e-01        1    6.11e-03    2.39e-01
  45  5.930926e-21   -4.36e-21    5.49e-06   1.42e-15   5.25e-03  2.52e-01        1    6.24e-03    2.45e-01
  46  5.405778e-21    5.25e-22    5.95e-06   1.92e-15   1.35e-01  1.82e-01        1    6.15e-03    2.51e-01
  47  7.672061e-21   -2.27e-21    0.00e+00   8.80e-16  -3.35e-02  9.08e-02        1    3.20e-03    2.55e-01
  48  2.202200e-21    3.20e-21    3.22e-06   4.90e-16   1.50e+00  2.72e-01        1    6.18e-03    2.61e-01
  49  3.922775e-21   -1.72e-21    5.28e-06   1.15e-15   2.66e-01  2.47e-01        1    6.22e-03    2.67e-01
  50  5.684105e-21   -1.76e-21    7.16e-06   1.31e-15   2.42e-02  1.33e-01        1    6.15e-03    2.73e-01
  51  5.149140e-21    5.35e-22    4.82e-06   7.95e-16   1.70e-01  1.03e-01        1    6.18e-03    2.79e-01
  52  2.972873e-21    2.18e-21    3.64e-06   9.55e-16   1.15e+00  3.09e-01        1    6.14e-03    2.86e-01
  53  3.576874e-21   -6.04e-22    3.82e-06   1.53e-15   1.35e-01  2.22e-01        1    6.12e-03    2.92e-01
  54  4.782941e-21   -1.21e-21    4.53e-06   1.33e-15   5.82e-02  1.32e-01        1    6.22e-03    2.98e-01
  55  1.315218e-20   -8.37e-21    0.00e+00   9.58e-16  -3.31e-01  6.58e-02        1    3.13e-03    3.01e-01
  56  1.177872e-21    3.61e-21    2.27e-06   5.01e-16   2.79e+00  1.97e-01        1    6.14e-03    3.07e-01
  57  1.882299e-21   -7.04e-22    2.79e-06   6.44e-16   1.87e-01  1.58e-01        1    6.19e-03    3.13e-01
  58  4.657976e-21   -2.78e-21    5.26e-06   5.17e-16   5.63e-02  9.32e-02        1    6.12e-03    3.20e-01
  59  7.738498e-21   -3.08e-21    0.00e+00   8.43e-16  -7.35e-02  4.66e-02        1    3.14e-03    3.23e-01
  60  2.639282e-21    2.02e-21    3.46e-06   3.36e-16   1.64e+00  1.40e-01        1    6.23e-03    3.29e-01
  61  3.130302e-21   -4.91e-22    3.15e-06   9.79e-16   1.12e-01  9.52e-02        1    6.20e-03    3.35e-01
  62  1.967106e-22    2.93e-21    5.82e-07   4.93e-16   2.81e+00  2.86e-01        1    6.35e-03    3.42e-01
  63  1.715310e-21   -1.52e-21    2.52e-06   1.35e-16   1.61e-01  2.18e-01        1    6.82e-03    3.48e-01
  64  7.013692e-21   -5.30e-21    0.00e+00   9.52e-16  -4.01e-02  1.09e-01        1    3.18e-03    3.52e-01
  65  6.624976e-22    1.05e-21    1.39e-06   4.72e-16   1.88e+00  3.27e-01        1    6.17e-03    3.58e-01
  66  1.039307e-20   -9.73e-21    0.00e+00   7.53e-16  -1.64e-01  1.63e-01        1    3.22e-03    3.61e-01
  67  7.147005e-21   -6.48e-21    0.00e+00   5.04e-16  -4.50e-02  4.08e-02        1    3.20e-03    3.64e-01
  68  1.595201e-21   -9.33e-22    2.38e-06   2.48e-16   1.61e-01  3.12e-02        1    6.27e-03    3.71e-01
  69  1.041477e-20   -8.82e-21    0.00e+00   2.50e-16  -1.66e-01  1.56e-02        1    3.13e-03    3.74e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          5.376528e+01
Final                            1.967106e-22
Change                           5.376528e+01

Minimizer iterations                       70
Successful steps                           51
Unsuccessful steps                         19
Line search steps                          44

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0058
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3673
    Line search gradient evaluation    0.2128
  Linear solver                        0.0015
  Line search polynomial minimization  0.0003
Minimizer                              0.3769

Postprocessor                          0.0000
Total                                  0.3769

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.613285e+04
Final                            1.462740e+02
Change                           1.598658e+04

Minimizer iterations                      112
Successful steps                           62
Unsuccessful steps                         50
Line search steps                         127

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0086
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6738
    Line search gradient evaluation    0.4946
  Linear solver                        0.0021
  Line search polynomial minimization  0.0010
Minimizer                              0.6874

Postprocessor                          0.0000
Total                                  0.6875

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA75 = {
{-0.0475285,0.3803032,0.1737827}
};
fitErrEl75 = {
{-0.0793871,0.3694693,0.1844114}
};
fitErrLa75 = {
{-0.0807344,0.3917305,0.1910754}
};
fitErrWr75 = {
{-0.2170130,0.3428019,0.2609628}
};
fitErrEe75 = {
{-0.2749289,0.3685377,0.3378023}
};
rMatsBase75 = {
{-0.3077784,0.6712801,-0.6742814},
{0.8268701,0.5393074,0.1594788},
{0.4706999,-0.5084590,-0.7210486}
};
outThetasWam75 = {
{-0.0916838,-0.3379892,-0.0500397,1.3551074,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4208205
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  7.528367e+01    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    2.87e-03    2.91e-03
   1  4.343408e+00    7.09e+01    2.83e+00   1.07e-02   1.88e+00  3.00e+04        1    5.75e-03    8.68e-03
   2  8.361570e-05    4.34e+00    2.77e+00   4.10e-04   1.94e+00  9.00e+04        1    5.70e-03    1.44e-02
   3  4.079238e-14    8.36e-05    4.03e-03   6.29e-07   1.89e+00  2.70e+05        1    5.79e-03    2.02e-02
   4  3.103932e-21    4.08e-14    3.04e-06   9.53e-11   1.89e+00  8.10e+05        1    5.83e-03    2.60e-02
   5  4.302382e-21   -1.20e-21    5.18e-06   4.42e-15   1.89e+00  2.43e+06        1    5.66e-03    3.17e-02
   6  8.501521e-21   -4.20e-21    7.58e-06   9.60e-15   1.89e+00  7.29e+06        1    5.68e-03    3.74e-02
   7  3.324742e-21    5.18e-21    4.08e-06   5.23e-15   1.89e+00  2.19e+07        1    5.60e-03    4.30e-02
   8  1.096529e-20   -7.64e-21    5.72e-06   5.06e-15   1.89e+00  6.56e+07        1    5.73e-03    4.88e-02
   9  4.084366e-21    6.88e-21    3.59e-06   9.04e-15   1.89e+00  1.97e+08        1    5.82e-03    5.46e-02
  10  5.416785e-21   -1.33e-21    4.78e-06   5.86e-15   3.72e-01  1.94e+08        1    5.72e-03    6.03e-02
  11  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  9.68e+07        1    2.90e-03    6.32e-02
  12  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  2.42e+07        1    2.93e-03    6.62e-02
  13  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  3.02e+06        1    2.94e-03    6.91e-02
  14  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  1.89e+05        1    2.96e-03    7.21e-02
  15  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  5.91e+03        1    3.10e-03    7.52e-02
  16  1.377017e-20   -8.35e-21    0.00e+00   4.86e-15  -1.39e-01  9.23e+01        1    2.94e-03    7.82e-02
  17  1.451174e-20   -9.09e-21    0.00e+00   4.66e-15  -1.75e-01  7.21e-01        1    2.97e-03    8.12e-02
  18  3.376030e-21    2.04e-21    5.36e-06   1.82e-15   4.39e-01  7.20e-01        1    5.84e-03    8.70e-02
  19  2.502760e-21    8.73e-22    3.54e-06   1.53e-15   3.73e-01  7.08e-01        1    5.89e-03    9.29e-02
  20  6.055631e-21   -3.55e-21    5.34e-06   1.93e-15   1.98e-01  5.80e-01        1    5.68e-03    9.86e-02
  21  2.179717e-20   -1.57e-20    0.00e+00   2.61e-15  -3.63e-01  2.90e-01        1    3.03e-03    1.02e-01
  22  2.529649e-21    3.53e-21    3.26e-06   2.04e-15   8.35e-01  4.16e-01        1    5.87e-03    1.08e-01
  23  4.640279e-21   -2.11e-21    4.87e-06   1.41e-15   2.03e-01  3.44e-01        1    5.70e-03    1.13e-01
  24  2.414968e-21    2.23e-21    3.37e-06   1.95e-15   6.57e-01  3.55e-01        1    5.64e-03    1.19e-01
  25  2.648246e-21   -2.33e-22    3.36e-06   1.43e-15   2.30e-01  3.06e-01        1    5.79e-03    1.25e-01
  26  3.457486e-21   -8.09e-22    3.77e-06   1.34e-15   1.97e-01  2.51e-01        1    5.67e-03    1.30e-01
  27  2.900432e-20   -2.55e-20    0.00e+00   1.34e-15  -4.46e-01  1.25e-01        1    2.92e-03    1.33e-01
  28  5.168531e-21   -1.71e-21    4.88e-06   8.33e-16   1.46e-01  9.24e-02        1    5.74e-03    1.39e-01
  29  3.457486e-21    1.71e-21    3.77e-06   8.39e-16   7.92e-01  1.15e-01        1    6.01e-03    1.45e-01
  30  4.865521e-21   -1.41e-21    5.11e-06   8.33e-16   1.40e-01  8.41e-02        1    5.66e-03    1.51e-01
  31  2.950104e-21    1.92e-21    3.94e-06   7.47e-16   1.11e+00  2.52e-01        1    5.69e-03    1.56e-01
  32  8.247848e-22    2.13e-21    2.13e-06   1.25e-15   1.10e+00  7.57e-01        1    5.70e-03    1.62e-01
  33  2.715934e-22    5.53e-22    7.36e-07   1.13e-15   7.70e-01  8.98e-01        1    5.69e-03    1.68e-01
  34  1.522373e-21   -1.25e-21    2.58e-06   6.93e-16   4.40e-01  8.96e-01        1    5.67e-03    1.74e-01
  35  3.324460e-21   -1.80e-21    3.90e-06   1.65e-15   1.92e-01  7.27e-01        1    5.63e-03    1.79e-01
  36  2.689041e-21    6.35e-22    3.74e-06   2.28e-15   2.21e-01  6.19e-01        1    5.85e-03    1.85e-01
  37  5.031962e-21   -2.34e-21    5.00e-06   1.74e-15   9.24e-03  3.18e-01        1    5.82e-03    1.91e-01
  38  2.433363e-21    2.60e-21    3.08e-06   1.94e-15   7.46e-01  3.61e-01        1    5.65e-03    1.97e-01
  39  7.277270e-21   -4.84e-21    0.00e+00   1.34e-15  -4.13e-01  1.81e-01        1    2.93e-03    2.00e-01
  40  4.473325e-21   -2.04e-21    4.56e-06   9.09e-16   1.12e-01  1.23e-01        1    5.65e-03    2.05e-01
  41  1.899759e-21    2.57e-21    3.14e-06   1.03e-15   1.27e+00  3.69e-01        1    5.69e-03    2.11e-01
  42  1.704572e-21    1.95e-22    2.73e-06   1.24e-15   3.94e-01  3.66e-01        1    5.70e-03    2.17e-01
  43  4.926251e-21   -3.22e-21    4.97e-06   1.19e-15   1.09e-02  1.89e-01        1    5.64e-03    2.22e-01
  44  3.391078e-21    1.54e-21    3.80e-06   1.26e-15   5.61e-01  1.89e-01        1    5.82e-03    2.28e-01
  45  5.827763e-21   -2.44e-21    0.00e+00   1.08e-15  -5.55e-02  9.46e-02        1    3.03e-03    2.31e-01
  46  4.772640e-21   -1.38e-21    4.98e-06   7.66e-16   1.89e-02  5.00e-02        1    5.71e-03    2.37e-01
  47  8.607249e-21   -3.83e-21    0.00e+00   5.11e-16  -2.40e-01  2.50e-02        1    2.81e-03    2.40e-01
  48  2.304936e-20   -1.83e-20    0.00e+00   2.63e-16  -1.25e+00  6.25e-03        1    2.85e-03    2.43e-01
  49  3.495875e-21    1.28e-21    4.29e-06   1.04e-17   7.06e+00  1.88e-02        1    5.55e-03    2.48e-01
  50  3.128149e-20   -2.78e-20    0.00e+00   2.56e-16  -1.84e+00  9.38e-03        1    2.82e-03    2.51e-01
  51  3.794784e-21   -2.99e-22    4.47e-06   1.39e-17   8.78e-02  6.01e-03        1    5.56e-03    2.56e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          7.528367e+01
Final                            2.715934e-22
Change                           7.528367e+01

Minimizer iterations                       52
Successful steps                           38
Unsuccessful steps                         14
Line search steps                          32

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0039
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2525
    Line search gradient evaluation    0.1469
  Linear solver                        0.0014
  Line search polynomial minimization  0.0001
Minimizer                              0.2593

Postprocessor                          0.0000
Total                                  0.2594

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:49:09.587824  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.610039e+04
Final                            1.423501e+02
Change                           1.595803e+04

Minimizer iterations                      108
Successful steps                           71
Unsuccessful steps                         37
Line search steps                         180

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0082
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8425
    Line search gradient evaluation    0.6424
  Linear solver                        0.0023
  Line search polynomial minimization  0.0018
Minimizer                              0.8572

Postprocessor                          0.0000
Total                                  0.8573

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA76 = {
{-0.0506185,0.3927612,0.1796113}
};
fitErrEl76 = {
{-0.0834855,0.3814912,0.1905493}
};
fitErrLa76 = {
{-0.0848554,0.4049083,0.1976378}
};
fitErrWr76 = {
{-0.2285280,0.3547944,0.2700778}
};
fitErrEe76 = {
{-0.2866525,0.3808733,0.3477054}
};
rMatsBase76 = {
{-0.3102769,0.6796962,-0.6646362},
{0.8261441,0.5386906,0.1652220},
{0.4703341,-0.4978208,-0.7286703}
};
outThetasWam76 = {
{-0.0923131,-0.3337384,-0.0507870,1.3495383,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4348377
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  7.080339e+01    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    2.87e-03    2.90e-03
   1  4.473231e+00    6.63e+01    2.83e+00   1.06e-02   1.87e+00  3.00e+04        1    5.80e-03    8.72e-03
   2  7.237922e-05    4.47e+00    2.77e+00   3.93e-04   1.95e+00  9.00e+04        1    5.63e-03    1.44e-02
   3  2.784695e-14    7.24e-05    3.41e-03   5.44e-07   1.88e+00  2.70e+05        1    5.77e-03    2.02e-02
   4  9.534565e-22    2.78e-14    1.92e-06   7.65e-11   1.88e+00  8.10e+05        1    5.64e-03    2.58e-02
   5  2.330551e-21   -1.38e-21    3.73e-06   9.41e-15   1.88e+00  2.43e+06        1    5.63e-03    3.15e-02
   6  4.634602e-21   -2.30e-21    4.25e-06   7.68e-15   1.88e+00  7.29e+06        1    5.69e-03    3.72e-02
   7  9.122535e-21   -4.49e-21    6.85e-06   1.23e-14   1.88e+00  2.19e+07        1    5.65e-03    4.28e-02
   8  5.628729e-21    3.49e-21    4.87e-06   1.19e-14   1.88e+00  6.56e+07        1    5.58e-03    4.84e-02
   9  4.967947e-21    6.61e-22    5.26e-06   6.62e-15   1.88e+00  1.97e+08        1    5.64e-03    5.41e-02
  10  1.061753e-20   -5.65e-21    0.00e+00   4.79e-15  -7.71e-02  9.84e+07        1    2.97e-03    5.71e-02
  11  1.061753e-20   -5.65e-21    0.00e+00   4.79e-15  -7.71e-02  2.46e+07        1    3.02e-03    6.01e-02
  12  1.061753e-20   -5.65e-21    0.00e+00   4.79e-15  -7.71e-02  3.08e+06        1    2.93e-03    6.30e-02
  13  1.061753e-20   -5.65e-21    0.00e+00   4.79e-15  -7.71e-02  1.92e+05        1    2.93e-03    6.60e-02
  14  1.061753e-20   -5.65e-21    0.00e+00   4.79e-15  -7.71e-02  6.01e+03        1    2.83e-03    6.88e-02
  15  1.277099e-20   -7.80e-21    0.00e+00   4.79e-15  -1.88e-01  9.39e+01        1    2.88e-03    7.17e-02
  16  1.120687e-22    4.86e-21    5.92e-07   4.35e-15   1.00e+00  2.82e+02        1    5.62e-03    7.73e-02
  17  7.627208e-21   -7.52e-21    5.39e-06   1.05e-15   7.68e-02  1.75e+02        1    5.68e-03    8.30e-02
  18  2.276305e-20   -1.51e-20    0.00e+00   6.01e-15  -5.04e-01  8.76e+01        1    2.89e-03    8.59e-02
  19  2.278076e-20   -1.52e-20    0.00e+00   5.83e-15  -5.05e-01  2.19e+01        1    2.87e-03    8.88e-02
  20  1.725880e-20   -9.63e-21    0.00e+00   5.58e-15  -3.01e-01  2.74e+00        1    2.95e-03    9.18e-02
  21  1.918952e-21    5.71e-21    4.09e-06   4.31e-15   7.67e-01  3.23e+00        1    5.61e-03    9.74e-02
  22  2.826888e-21   -9.08e-22    5.01e-06   1.17e-15   2.19e-01  2.74e+00        1    5.81e-03    1.03e-01
  23  2.285927e-21    5.41e-22    4.55e-06   1.24e-15   2.17e-01  2.32e+00        1    5.78e-03    1.09e-01
  24  1.109016e-21    1.18e-21    2.02e-06   1.29e-15   5.30e-01  2.32e+00        1    5.54e-03    1.15e-01
  25  8.048869e-22    3.04e-22    2.46e-06   1.23e-15   4.46e-01  2.32e+00        1    5.49e-03    1.20e-01
  26  4.264931e-21   -3.46e-21    4.82e-06   7.21e-16   2.11e-01  1.94e+00        1    5.53e-03    1.26e-01
  27  1.305810e-21    2.96e-21    2.67e-06   2.59e-15   7.45e-01  2.20e+00        1    5.53e-03    1.31e-01
  28  8.960432e-23    1.22e-21    3.41e-07   1.38e-15   9.67e-01  6.61e+00        1    5.52e-03    1.37e-01
  29  1.529042e-21   -1.44e-21    2.41e-06   2.70e-16   2.87e-01  6.14e+00        1    5.61e-03    1.42e-01
  30  1.275819e-20   -1.12e-20    0.00e+00   1.70e-15  -2.26e-01  3.07e+00        1    2.95e-03    1.45e-01
  31  1.373913e-20   -1.22e-20    0.00e+00   1.49e-15  -2.69e-01  7.67e-01        1    3.02e-03    1.48e-01
  32  7.734755e-22    7.56e-22    2.01e-06   1.03e-15   5.60e-01  7.68e-01        1    5.71e-03    1.54e-01
  33  1.830066e-22    5.90e-22    8.99e-07   5.84e-16   8.85e-01  1.41e+00        1    5.55e-03    1.60e-01
  34  6.671680e-22   -4.84e-22    1.79e-06   3.41e-16   2.97e-01  1.32e+00        1    5.60e-03    1.65e-01
  35  1.047130e-20   -9.80e-21    0.00e+00   9.61e-16  -1.19e-01  6.62e-01        1    2.87e-03    1.68e-01
  36  1.402820e-20   -1.34e-20    0.00e+00   7.55e-16  -2.68e-01  1.66e-01        1    2.90e-03    1.71e-01
  37  1.122205e-21   -4.55e-22    2.45e-06   4.70e-16   2.74e-01  1.52e-01        1    5.52e-03    1.77e-01
  38  1.834125e-20   -1.72e-20    0.00e+00   5.69e-16  -5.36e+00  7.58e-02        1    2.82e-03    1.79e-01
  39  6.971793e-21   -5.85e-21    0.00e+00   3.27e-16  -1.86e+00  1.89e-02        1    2.86e-03    1.82e-01
  40  7.863667e-21   -6.74e-21    0.00e+00   1.12e-16  -2.39e+00  2.37e-03        1    2.87e-03    1.85e-01
  41  1.689821e-21   -5.68e-22    0.00e+00   3.47e-18  -6.36e-02  1.48e-04        1    3.03e-03    1.88e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          7.080339e+01
Final                            8.960432e-23
Change                           7.080339e+01

Minimizer iterations                       42
Successful steps                           25
Unsuccessful steps                         17
Line search steps                          27

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0031
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1859
    Line search gradient evaluation    0.1172
  Linear solver                        0.0009
  Line search polynomial minimization  0.0001
Minimizer                              0.1911

Postprocessor                          0.0000
Total                                  0.1911

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.606260e+04
Final                            1.389909e+02
Change                           1.592361e+04

Minimizer iterations                      104
Successful steps                           55
Unsuccessful steps                         49
Line search steps                         118

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0076
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5618
    Line search gradient evaluation    0.4110
  Linear solver                        0.0018
  Line search polynomial minimization  0.0008
Minimizer                              0.5737

Postprocessor                          0.0000
Total                                  0.5737

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA77 = {
{-0.0536090,0.4050171,0.1852437}
};
fitErrEl77 = {
{-0.0874886,0.3933027,0.1964902}
};
fitErrLa77 = {
{-0.0888787,0.4178852,0.2040121}
};
fitErrWr77 = {
{-0.2401553,0.3663283,0.2792053}
};
fitErrEe77 = {
{-0.2986686,0.3927308,0.3575024}
};
rMatsBase77 = {
{-0.3147527,0.6860959,-0.6558987},
{0.8241584,0.5403336,0.1697131},
{0.4708436,-0.4871468,-0.7355232}
};
outThetasWam77 = {
{-0.0920834,-0.3288886,-0.0503232,1.3451860,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4485845
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.092317e+02    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    2.84e-03    2.87e-03
   1  4.197905e+00    1.05e+02    2.83e+00   1.04e-02   1.92e+00  3.00e+04        1    5.79e-03    8.68e-03
   2  4.273555e-05    4.20e+00    2.77e+00   3.49e-04   1.94e+00  9.00e+04        1    5.53e-03    1.42e-02
   3  9.897604e-15    4.27e-05    2.20e-03   4.03e-07   1.92e+00  2.70e+05        1    5.61e-03    1.99e-02
   4  6.416288e-21    9.90e-15    5.51e-06   3.98e-11   1.92e+00  8.10e+05        1    5.54e-03    2.54e-02
   5  3.585253e-21    2.83e-21    4.42e-06   1.34e-14   1.92e+00  2.43e+06        1    5.60e-03    3.10e-02
   6  4.778974e-21   -1.19e-21    5.11e-06   4.56e-15   1.92e+00  7.29e+06        1    5.66e-03    3.67e-02
   7  1.907089e-20   -1.43e-20    9.71e-06   4.88e-15   1.92e+00  2.19e+07        1    5.79e-03    4.25e-02
   8  2.176063e-20   -2.69e-21    1.03e-05   1.14e-14   1.92e+00  6.56e+07        1    5.61e-03    4.81e-02
   9  4.600602e-21    1.72e-20    6.19e-06   1.32e-14   1.92e+00  1.97e+08        1    5.75e-03    5.39e-02
  10  1.014562e-20   -5.55e-21    6.03e-06   2.66e-15   1.92e+00  5.90e+08        1    5.79e-03    5.97e-02
  11  2.486537e-21    7.66e-21    3.40e-06   1.39e-14   7.57e-01  6.83e+08        1    5.72e-03    6.54e-02
  12  1.569456e-21    9.17e-22    2.36e-06   4.27e-15   5.21e-01  6.83e+08        1    5.65e-03    7.11e-02
  13  2.157464e-21   -5.88e-22    3.45e-06   9.91e-15   4.87e-01  6.83e+08        1    5.59e-03    7.67e-02
  14  1.819494e-20   -1.60e-20    9.54e-06   2.66e-15   8.41e-02  4.34e+08        1    5.48e-03    8.22e-02
  15  9.905690e-21    8.29e-21    5.74e-06   1.60e-14   4.58e-01  4.33e+08        1    5.52e-03    8.77e-02
  16  4.129360e-21    5.78e-21    5.87e-06   1.48e-14   5.83e-01  4.35e+08        1    5.47e-03    9.32e-02
  17  1.333881e-21    2.80e-21    2.49e-06   3.02e-15   6.92e-01  4.61e+08        1    5.68e-03    9.89e-02
  18  7.123771e-21   -5.79e-21    6.30e-06   1.02e-15   1.94e-01  3.75e+08        1    5.48e-03    1.04e-01
  19  3.779589e-21    3.34e-21    4.03e-06   9.69e-15   4.71e-01  3.75e+08        1    5.68e-03    1.10e-01
  20  7.321760e-21   -3.54e-21    6.33e-06   3.26e-15   1.67e-01  2.90e+08        1    5.85e-03    1.16e-01
  21  3.754000e-21    3.57e-21    4.16e-06   8.07e-15   4.88e-01  2.90e+08        1    5.75e-03    1.22e-01
  22  1.473467e-21    2.28e-21    3.31e-06   3.80e-15   6.27e-01  2.94e+08        1    5.48e-03    1.27e-01
  23  2.507750e-21   -1.03e-21    4.65e-06   1.83e-15   3.89e-01  2.91e+08        1    5.63e-03    1.33e-01
  24  3.795093e-21   -1.29e-21    4.81e-06   1.83e-15   2.40e-01  2.55e+08        1    5.98e-03    1.39e-01
  25  3.289752e-21    5.05e-22    4.24e-06   6.99e-15   2.18e-01  2.16e+08        1    5.48e-03    1.44e-01
  26  4.899704e-21   -1.61e-21    5.67e-06   5.34e-15   1.11e-01  1.47e+08        1    5.51e-03    1.50e-01
  27  5.703492e-21   -8.04e-22    4.09e-06   7.77e-15   6.10e-02  8.78e+07        1    5.46e-03    1.55e-01
  28  6.166772e-22    5.09e-21    1.40e-06   5.50e-15   8.96e-01  1.75e+08        1    5.53e-03    1.61e-01
  29  5.917065e-21   -5.30e-21    5.30e-06   1.86e-15   4.28e-02  9.91e+07        1    5.70e-03    1.67e-01
  30  4.290146e-21    1.63e-21    4.19e-06   9.70e-15   2.81e-01  9.14e+07        1    5.84e-03    1.72e-01
  31  4.374213e-21   -8.41e-23    6.16e-06   3.28e-15   6.88e-02  5.57e+07        1    5.79e-03    1.78e-01
  32  1.799873e-21    2.57e-21    3.22e-06   2.82e-15   5.95e-01  5.61e+07        1    5.76e-03    1.84e-01
  33  3.226315e-21   -1.43e-21    4.21e-06   4.50e-15   8.37e-02  3.55e+07        1    5.76e-03    1.90e-01
  34  6.827031e-22    2.54e-21    2.29e-06   5.34e-15   7.98e-01  4.51e+07        1    5.83e-03    1.96e-01
  35  2.130734e-21   -1.45e-21    3.21e-06   1.64e-15   1.89e-01  3.64e+07        1    5.94e-03    2.02e-01
  36  5.783355e-21   -3.65e-21    6.03e-06   6.49e-15   6.04e-03  1.85e+07        1    5.75e-03    2.07e-01
  37  4.611245e-21    1.17e-21    4.80e-06   7.80e-15   2.10e-01  1.55e+07        1    5.87e-03    2.13e-01
  38  2.750011e-21    1.86e-21    3.80e-06   7.64e-15   4.11e-01  1.54e+07        1    5.84e-03    2.19e-01
  39  2.394323e-21    3.56e-22    2.98e-06   4.37e-15   1.31e-01  1.10e+07        1    5.83e-03    2.25e-01
  40  8.033962e-22    1.59e-21    1.70e-06   5.82e-15   6.81e-01  1.15e+07        1    5.63e-03    2.31e-01
  41  1.256244e-21   -4.53e-22    2.22e-06   3.80e-15   1.23e-01  8.06e+06        1    5.77e-03    2.36e-01
  42  1.590076e-20   -1.46e-20    0.00e+00   3.52e-15  -2.55e-01  4.03e+06        1    2.93e-03    2.39e-01
  43  1.590076e-20   -1.46e-20    0.00e+00   3.52e-15  -2.55e-01  1.01e+06        1    2.95e-03    2.42e-01
  44  1.590076e-20   -1.46e-20    0.00e+00   3.52e-15  -2.55e-01  1.26e+05        1    2.92e-03    2.45e-01
  45  1.590076e-20   -1.46e-20    0.00e+00   3.52e-15  -2.55e-01  7.87e+03        1    2.88e-03    2.48e-01
  46  1.590076e-20   -1.46e-20    0.00e+00   3.52e-15  -2.55e-01  2.46e+02        1    2.89e-03    2.51e-01
  47  7.554578e-21   -6.30e-21    0.00e+00   3.22e-15  -4.18e-02  3.85e+00        1    2.85e-03    2.54e-01
  48  1.805889e-21   -5.50e-22    3.53e-06   1.07e-15   1.05e-01  2.58e+00        1    5.93e-03    2.60e-01
  49  5.871784e-21   -4.07e-21    5.24e-06   9.34e-16   1.11e-03  1.29e+00        1    5.78e-03    2.66e-01
  50  2.400682e-21    3.47e-21    3.06e-06   2.74e-15   6.50e-01  1.33e+00        1    5.76e-03    2.71e-01
  51  6.385927e-21   -3.99e-21    0.00e+00   1.88e-15  -9.75e-03  6.64e-01        1    2.90e-03    2.74e-01
  52  2.439473e-20   -2.20e-20    0.00e+00   1.46e-15  -3.85e-01  1.66e-01        1    2.93e-03    2.77e-01
  53  4.303809e-21   -1.90e-21    4.82e-06   6.61e-16   3.41e-02  9.18e-02        1    5.56e-03    2.83e-01
  54  7.908201e-21   -3.60e-21    0.00e+00   5.62e-16  -4.07e-02  4.59e-02        1    2.83e-03    2.86e-01
  55  2.997027e-20   -2.57e-20    0.00e+00   2.79e-16  -4.98e-01  1.15e-02        1    2.79e-03    2.89e-01
  56  3.679093e-21    6.25e-22    4.39e-06   2.53e-17   2.29e+00  3.44e-02        1    5.48e-03    2.94e-01
  57  3.898610e-20   -3.53e-20    0.00e+00   2.63e-16  -6.84e-01  1.72e-02        1    2.82e-03    2.97e-01
  58  2.909961e-20   -2.54e-20    0.00e+00   2.55e-16  -4.83e-01  4.30e-03        1    3.00e-03    3.00e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.092317e+02
Final                            6.166772e-22
Change                           1.092317e+02

Minimizer iterations                       59
Successful steps                           47
Unsuccessful steps                         12
Line search steps                          34

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0044
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2951
    Line search gradient evaluation    0.1641
  Linear solver                        0.0015
  Line search polynomial minimization  0.0002
Minimizer                              0.3027

Postprocessor                          0.0000
Total                                  0.3027

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.599575e+04
Final                            1.371740e+02
Change                           1.585858e+04

Minimizer iterations                       97
Successful steps                           72
Unsuccessful steps                         25
Line search steps                         170

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0077
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8115
    Line search gradient evaluation    0.6082
  Linear solver                        0.0021
  Line search polynomial minimization  0.0016
Minimizer                              0.8251

Postprocessor                          0.0000
Total                                  0.8251

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA78 = {
{-0.0570992,0.4178090,0.1909919}
};
fitErrEl78 = {
{-0.0920163,0.4056489,0.2025567}
};
fitErrLa78 = {
{-0.0934316,0.4314063,0.2105079}
};
fitErrWr78 = {
{-0.2523185,0.3787644,0.2883904}
};
fitErrEe78 = {
{-0.3111332,0.4055942,0.3673180}
};
rMatsBase78 = {
{-0.3167328,0.6951901,-0.6452837},
{0.8246112,0.5379988,0.1748534},
{0.4687182,-0.4767263,-0.7436634}
};
outThetasWam78 = {
{-0.0926372,-0.3245892,-0.0510902,1.3396856,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4629283
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.059350e+02    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    2.86e-03    2.90e-03
   1  4.688922e+00    1.01e+02    2.83e+00   1.05e-02   1.91e+00  3.00e+04        1    5.77e-03    8.68e-03
   2  4.783476e-05    4.69e+00    2.77e+00   3.52e-04   1.95e+00  9.00e+04        1    5.85e-03    1.46e-02
   3  1.084509e-14    4.78e-05    2.29e-03   3.89e-07   1.91e+00  2.70e+05        1    5.67e-03    2.02e-02
   4  3.271098e-21    1.08e-14    4.15e-06   4.27e-11   1.91e+00  8.10e+05        1    5.68e-03    2.59e-02
   5  3.046317e-21    2.25e-22    4.34e-06   9.79e-15   1.91e+00  2.43e+06        1    5.85e-03    3.18e-02
   6  7.119478e-21   -4.07e-21    6.50e-06   6.82e-15   1.91e+00  7.29e+06        1    5.66e-03    3.75e-02
   7  2.062061e-21    5.06e-21    3.09e-06   3.77e-15   1.91e+00  2.19e+07        1    5.70e-03    4.32e-02
   8  6.318089e-21   -4.26e-21    7.20e-06   6.12e-15   1.91e+00  6.56e+07        1    5.71e-03    4.89e-02
   9  3.814178e-20   -3.18e-20    1.37e-05   3.61e-15   1.91e+00  1.97e+08        1    5.72e-03    5.47e-02
  10  1.639803e-20    2.17e-20    8.21e-06   1.28e-14   1.91e+00  5.90e+08        1    5.85e-03    6.05e-02
  11  6.741377e-21    9.66e-21    6.09e-06   7.51e-15   1.91e+00  1.77e+09        1    5.68e-03    6.62e-02
  12  4.883277e-22    6.25e-21    1.19e-06   6.18e-15   1.91e+00  5.31e+09        1    5.65e-03    7.19e-02
  13  1.398118e-21   -9.10e-22    2.46e-06   1.81e-15   1.91e+00  1.59e+10        1    5.87e-03    7.78e-02
  14  5.782091e-22    8.20e-22    1.65e-06   2.70e-15   1.91e+00  4.78e+10        1    5.69e-03    8.35e-02
  15  1.875834e-21   -1.30e-21    2.83e-06   3.84e-15   1.91e+00  1.43e+11        1    5.80e-03    8.93e-02
  16  1.415138e-21    4.61e-22    3.40e-06   3.72e-15   1.91e+00  4.30e+11        1    6.01e-03    9.53e-02
  17  3.972821e-21   -2.56e-21    4.32e-06   2.18e-15   1.91e+00  1.29e+12        1    5.81e-03    1.01e-01
  18  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  6.46e+11        1    2.95e-03    1.04e-01
  19  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  1.61e+11        1    2.88e-03    1.07e-01
  20  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  2.02e+10        1    3.03e-03    1.10e-01
  21  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  1.26e+09        1    3.00e-03    1.13e-01
  22  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  3.94e+07        1    2.92e-03    1.16e-01
  23  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  6.16e+05        1    2.90e-03    1.19e-01
  24  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  4.81e+03        1    2.96e-03    1.22e-01
  25  1.332744e-20   -9.35e-21    0.00e+00   4.96e-15  -2.36e+00  1.88e+01        1    2.88e-03    1.25e-01
  26  1.199705e-21    2.77e-21    2.63e-06   4.29e-15   7.03e-01  2.01e+01        1    5.97e-03    1.31e-01
  27  4.307620e-21   -3.11e-21    0.00e+00   1.79e-15  -6.53e-02  1.01e+01        1    2.95e-03    1.34e-01
  28  2.274653e-22    9.72e-22    7.82e-07   1.79e-15   8.26e-01  1.39e+01        1    5.69e-03    1.40e-01
  29  7.457847e-21   -7.23e-21    0.00e+00   9.53e-16  -6.62e-01  6.96e+00        1    2.99e-03    1.43e-01
  30  1.227690e-20   -1.20e-20    0.00e+00   9.54e-16  -1.58e+00  1.74e+00        1    3.20e-03    1.46e-01
  31  3.156066e-21   -2.93e-21    4.03e-06   5.07e-16   1.56e-01  1.31e+00        1    5.53e-03    1.51e-01
  32  1.620144e-20   -1.30e-20    0.00e+00   2.14e-15  -1.50e+00  6.56e-01        1    2.83e-03    1.54e-01
  33  2.774221e-20   -2.46e-20    0.00e+00   1.65e-15  -2.99e+00  1.64e-01        1    3.01e-03    1.57e-01
  34  1.042272e-21    2.11e-21    2.28e-06   8.43e-16   1.21e+00  4.92e-01        1    5.86e-03    1.63e-01
  35  3.108913e-21   -2.07e-21    4.05e-06   8.38e-16   1.10e-01  3.34e-01        1    5.57e-03    1.69e-01
  36  1.840644e-20   -1.53e-20    0.00e+00   1.34e-15  -1.43e+00  1.67e-01        1    2.92e-03    1.72e-01
  37  5.751700e-21   -2.64e-21    0.00e+00   8.45e-16  -1.86e-01  4.17e-02        1    2.98e-03    1.75e-01
  38  7.186210e-21   -4.08e-21    0.00e+00   2.64e-16  -3.77e-01  5.21e-03        1    3.07e-03    1.78e-01
  39  3.128731e-21   -1.98e-23    4.04e-06   6.94e-18   1.06e-01  3.50e-03        1    5.67e-03    1.83e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.059350e+02
Final                            2.274653e-22
Change                           1.059350e+02

Minimizer iterations                       40
Successful steps                           24
Unsuccessful steps                         16
Line search steps                          26

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0032
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1806
    Line search gradient evaluation    0.1133
  Linear solver                        0.0012
  Line search polynomial minimization  0.0002
Minimizer                              0.1863

Postprocessor                          0.0000
Total                                  0.1864

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.594369e+04
Final                            1.361770e+02
Change                           1.580751e+04

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0518
    Line search gradient evaluation    0.0268
  Linear solver                        0.0002
  Line search polynomial minimization  0.0000
Minimizer                              0.0527

Postprocessor                          0.0000
Total                                  0.0528

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA79 = {
{-0.0596520,0.4278200,0.1954314}
};
fitErrEl79 = {
{-0.0954077,0.4152965,0.2072524}
};
fitErrLa79 = {
{-0.0968411,0.4419849,0.2155474}
};
fitErrWr79 = {
{-0.2619025,0.3881398,0.2957816}
};
fitErrEe79 = {
{-0.3208067,0.4152277,0.3754566}
};
rMatsBase79 = {
{-0.3212819,0.7001715,-0.6376032},
{0.8226662,0.5398460,0.1782880},
{0.4690397,-0.4672539,-0.7494501}
};
outThetasWam79 = {
{-0.0916668,-0.3211693,-0.0496562,1.3364671,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4741115
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.188681e+02    0.00e+00    2.77e+00   0.00e+00   0.00e+00  1.00e+04        0    3.04e-03    3.07e-03
   1  2.596576e+00    1.16e+02    2.78e+00   8.30e-03   1.95e+00  3.00e+04        1    5.69e-03    8.79e-03
   2  3.853308e-06    2.60e+00    2.78e+00   1.90e-04   1.95e+00  9.00e+04        1    5.52e-03    1.43e-02
   3  9.404551e-16    3.85e-06    5.08e-04   1.10e-07   1.95e+00  2.70e+05        1    5.78e-03    2.01e-02
   4  5.358576e-21    9.40e-16    4.11e-06   1.23e-11   1.95e+00  8.10e+05        1    5.57e-03    2.57e-02
   5  1.358633e-20   -8.23e-21    1.09e-05   7.93e-15   1.95e+00  2.43e+06        1    5.51e-03    3.12e-02
   6  1.224536e-20    1.34e-21    7.91e-06   8.95e-15   1.95e+00  7.29e+06        1    5.76e-03    3.70e-02
   7  2.945470e-22    1.20e-20    1.23e-06   5.65e-15   1.95e+00  2.19e+07        1    5.65e-03    4.27e-02
   8  1.996616e-22    9.49e-23    1.05e-06   7.25e-16   1.95e+00  6.56e+07        1    5.90e-03    4.86e-02
   9  5.153730e-22   -3.16e-22    1.80e-06   2.30e-15   1.95e+00  1.97e+08        1    5.83e-03    5.44e-02
  10  2.860721e-21   -2.35e-21    3.93e-06   1.37e-15   1.95e+00  5.90e+08        1    5.70e-03    6.02e-02
  11  2.983392e-21   -1.23e-22    3.63e-06   3.67e-15   1.95e+00  1.77e+09        1    5.86e-03    6.60e-02
  12  2.768780e-22    2.71e-21    1.21e-06   6.47e-15   1.95e+00  5.31e+09        1    5.67e-03    7.17e-02
  13  3.153220e-21   -2.88e-21    3.72e-06   1.96e-15   1.95e+00  1.59e+10        1    5.64e-03    7.74e-02
  14  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  7.97e+09        1    2.90e-03    8.03e-02
  15  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  1.99e+09        1    2.92e-03    8.32e-02
  16  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  2.49e+08        1    2.94e-03    8.62e-02
  17  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  1.56e+07        1    2.86e-03    8.90e-02
  18  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  4.87e+05        1    2.91e-03    9.20e-02
  19  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  7.60e+03        1    2.88e-03    9.49e-02
  20  4.024743e-21   -8.72e-22    0.00e+00   3.21e-15  -2.91e-01  5.94e+01        1    2.92e-03    9.78e-02
  21  2.122674e-21    1.03e-21    3.44e-06   2.82e-15   3.44e-01  5.77e+01        1    5.66e-03    1.03e-01
  22  5.086257e-21   -2.96e-21    0.00e+00   1.47e-15  -3.82e-01  2.88e+01        1    2.87e-03    1.06e-01
  23  6.079861e-21   -3.96e-21    0.00e+00   1.47e-15  -5.78e-01  7.21e+00        1    2.93e-03    1.09e-01
  24  4.155181e-21   -2.03e-21    0.00e+00   1.43e-15  -1.98e-01  9.01e-01        1    2.90e-03    1.12e-01
  25  3.294558e-21   -1.17e-21    0.00e+00   1.12e-15  -2.88e-02  5.63e-02        1    2.89e-03    1.15e-01
  26  2.523226e-21   -4.01e-22    2.76e-06   2.76e-16   1.78e-01  4.44e-02        1    5.65e-03    1.21e-01
  27  2.096659e-21    4.27e-22    3.40e-06   2.45e-16   8.34e-01  6.34e-02        1    5.84e-03    1.27e-01
  28  5.089551e-21   -2.99e-21    0.00e+00   2.85e-16  -4.17e-01  3.17e-02        1    2.92e-03    1.30e-01
  29  1.664969e-21    4.32e-22    2.64e-06   2.30e-16   1.29e+00  9.50e-02        1    5.74e-03    1.35e-01
  30  1.281318e-22    1.54e-21    7.36e-07   2.81e-16   2.49e+00  2.85e-01        1    5.83e-03    1.41e-01
  31  3.319874e-21   -3.19e-21    0.00e+00   1.27e-16  -3.30e-02  1.43e-01        1    2.92e-03    1.44e-01
  32  3.123875e-22   -1.84e-22    1.22e-06   3.93e-17   5.63e-01  1.43e-01        1    5.69e-03    1.50e-01
  33  4.617145e-22   -1.49e-22    1.53e-06   9.57e-17   5.20e-01  1.43e-01        1    5.74e-03    1.56e-01
  34  8.769718e-21   -8.31e-21    0.00e+00   2.68e-16  -1.05e+00  7.14e-02        1    2.88e-03    1.58e-01
  35  6.507983e-21   -6.05e-21    0.00e+00   1.20e-16  -6.33e-01  1.79e-02        1    2.90e-03    1.61e-01
  36  3.811150e-22    8.06e-23    1.33e-06   1.04e-17   2.15e+00  5.36e-02        1    5.65e-03    1.67e-01
  37  1.111368e-21   -7.30e-22    2.35e-06   2.08e-17   3.86e-01  5.29e-02        1    5.70e-03    1.73e-01
  38  6.260788e-22    4.85e-22    1.56e-06   2.33e-16   1.86e+00  1.59e-01        1    5.77e-03    1.78e-01
  39  8.614043e-22   -2.35e-22    2.08e-06   2.73e-16   4.43e-01  1.59e-01        1    5.62e-03    1.84e-01
  40  4.788829e-21   -3.93e-21    0.00e+00   2.93e-16  -3.79e+00  7.93e-02        1    2.91e-03    1.87e-01
  41  8.684132e-22   -7.01e-24    2.10e-06   2.70e-16   2.94e-01  7.41e-02        1    5.59e-03    1.93e-01
  42  7.334923e-22    1.35e-22    1.88e-06   2.67e-16   4.86e-01  7.41e-02        1    5.62e-03    1.98e-01
  43  3.182846e-22    4.15e-22    1.12e-06   2.63e-16   2.00e+00  2.22e-01        1    5.85e-03    2.04e-01
  44  5.184394e-21   -4.87e-21    0.00e+00   2.68e-16  -2.70e+00  1.11e-01        1    2.95e-03    2.07e-01
  45  2.764072e-21   -2.45e-21    0.00e+00   2.33e-16  -1.14e+00  2.78e-02        1    2.94e-03    2.10e-01
  46  1.135504e-21   -8.17e-22    0.00e+00   2.22e-17  -1.78e-02  3.48e-03        1    3.01e-03    2.13e-01
  47  1.011635e-21   -6.93e-22    1.93e-06   3.47e-18   7.57e-02  2.16e-03        1    5.78e-03    2.19e-01
  48  3.182846e-22    6.93e-22    1.12e-06   3.47e-18   5.79e+01  6.47e-03        1    5.76e-03    2.25e-01
  49  1.135504e-21   -8.17e-22    0.00e+00   3.47e-18  -1.80e-02  3.24e-03        1    2.94e-03    2.28e-01
  50  1.135504e-21   -8.17e-22    0.00e+00   3.47e-18  -1.81e-02  8.09e-04        1    2.94e-03    2.31e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.188681e+02
Final                            1.281318e-22
Change                           1.188681e+02

Minimizer iterations                       51
Successful steps                           30
Unsuccessful steps                         21
Line search steps                          34

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2270
    Line search gradient evaluation    0.1433
  Linear solver                        0.0013
  Line search polynomial minimization  0.0001
Minimizer                              0.2334

Postprocessor                          0.0000
Total                                  0.2335

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.590608e+04
Final                            1.352796e+02
Change                           1.577080e+04

Minimizer iterations                       75
Successful steps                           53
Unsuccessful steps                         22
Line search steps                          98

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0056
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5215
    Line search gradient evaluation    0.3706
  Linear solver                        0.0013
  Line search polynomial minimization  0.0007
Minimizer                              0.5304

Postprocessor                          0.0000
Total                                  0.5304

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA80 = {
{-0.0620578,0.4375099,0.1997871}
};
fitErrEl80 = {
{-0.0986173,0.4246379,0.2118541}
};
fitErrLa80 = {
{-0.1000679,0.4522470,0.2204903}
};
fitErrWr80 = {
{-0.2711814,0.3972573,0.3029600}
};
fitErrEe80 = {
{-0.3301538,0.4244775,0.3833425}
};
rMatsBase80 = {
{-0.3247754,0.7046196,-0.6308979},
{0.8209567,0.5412484,0.1818800},
{0.4696287,-0.4588697,-0.7542463}
};
outThetasWam80 = {
{-0.0911761,-0.3169496,-0.0487657,1.3337308,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4849546
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.092683e+02    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.05e-03    3.09e-03
   1  2.442475e+00    1.07e+02    2.79e+00   8.00e-03   1.95e+00  3.00e+04        1    6.20e-03    9.30e-03
   2  2.874257e-06    2.44e+00    2.78e+00   1.76e-04   1.95e+00  9.00e+04        1    6.20e-03    1.55e-02
   3  4.135851e-16    2.87e-06    4.01e-04   9.27e-08   1.95e+00  2.70e+05        1    6.15e-03    2.17e-02
   4  1.004123e-20    4.14e-16    7.38e-06   6.19e-12   1.95e+00  8.10e+05        1    6.14e-03    2.78e-02
   5  5.025910e-21    5.02e-21    5.18e-06   8.06e-15   1.95e+00  2.43e+06        1    6.15e-03    3.40e-02
   6  3.118950e-21    1.91e-21    3.44e-06   2.68e-15   1.95e+00  7.29e+06        1    6.18e-03    4.02e-02
   7  8.097747e-22    2.31e-21    2.52e-06   3.09e-15   1.95e+00  2.19e+07        1    6.14e-03    4.63e-02
   8  1.244020e-22    6.85e-22    1.00e-06   8.13e-16   1.95e+00  6.56e+07        1    7.10e-03    5.35e-02
   9  1.240915e-21   -1.12e-21    2.54e-06   4.62e-16   1.95e+00  1.97e+08        1    6.18e-03    5.97e-02
  10  1.480847e-21   -2.40e-22    2.38e-06   3.52e-15   1.95e+00  5.90e+08        1    6.15e-03    6.58e-02
  11  3.077634e-21   -1.60e-21    3.25e-06   2.50e-15   1.95e+00  1.77e+09        1    6.12e-03    7.20e-02
  12  1.517718e-20   -1.21e-20    9.19e-06   5.48e-15   1.95e+00  5.31e+09        1    6.19e-03    7.82e-02
  13  2.311705e-21    1.29e-20    3.83e-06   1.15e-14   1.95e+00  1.59e+10        1    6.11e-03    8.43e-02
  14  6.438668e-22    1.67e-21    1.57e-06   5.34e-15   8.37e-01  2.30e+10        1    6.21e-03    9.05e-02
  15  3.856554e-22    2.58e-22    1.47e-06   1.62e-15   8.25e-01  3.17e+10        1    6.35e-03    9.69e-02
  16  1.135377e-20   -1.10e-20    8.14e-06   7.22e-16   2.09e-01  2.65e+10        1    6.14e-03    1.03e-01
  17  7.212751e-21    4.14e-21    6.45e-06   1.03e-14   3.66e-01  2.60e+10        1    6.18e-03    1.09e-01
  18  1.530266e-21    5.68e-21    2.75e-06   7.35e-15   7.88e-01  3.21e+10        1    6.15e-03    1.15e-01
  19  7.456094e-21   -5.93e-21    5.96e-06   2.08e-15   2.02e-01  2.65e+10        1    6.19e-03    1.22e-01
  20  2.215338e-21    5.24e-21    4.11e-06   4.79e-15   7.13e-01  2.87e+10        1    6.14e-03    1.28e-01
  21  2.325637e-21   -1.10e-22    3.72e-06   3.54e-15   2.69e-01  2.61e+10        1    6.15e-03    1.34e-01
  22  6.141478e-21   -3.82e-21    5.42e-06   2.93e-15   1.80e-01  2.07e+10        1    6.17e-03    1.40e-01
  23  6.775777e-21   -6.34e-22    5.84e-06   8.92e-15   1.49e-01  1.54e+10        1    6.23e-03    1.46e-01
  24  1.309606e-21    5.47e-21    2.34e-06   5.38e-15   8.08e-01  2.01e+10        1    6.15e-03    1.53e-01
  25  1.615112e-21   -3.06e-22    3.80e-06   2.34e-15   2.11e-01  1.69e+10        1    6.15e-03    1.59e-01
  26  1.930183e-21   -3.15e-22    4.02e-06   1.55e-15   2.01e-01  1.39e+10        1    6.15e-03    1.65e-01
  27  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  6.95e+09        1    3.18e-03    1.68e-01
  28  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  1.74e+09        1    3.14e-03    1.71e-01
  29  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  2.17e+08        1    3.12e-03    1.74e-01
  30  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  1.36e+07        1    3.12e-03    1.77e-01
  31  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  4.24e+05        1    3.12e-03    1.81e-01
  32  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  6.63e+03        1    3.12e-03    1.84e-01
  33  1.526585e-20   -1.33e-20    0.00e+00   1.71e-15  -1.31e-03  5.18e+01        1    3.19e-03    1.87e-01
  34  1.572602e-20   -1.38e-20    0.00e+00   1.31e-15  -8.11e-03  2.02e-01        1    3.14e-03    1.90e-01
  35  8.958797e-21   -7.03e-21    7.12e-06   3.74e-16   9.28e-02  1.31e-01        1    6.12e-03    1.96e-01
  36  2.213271e-22    8.74e-21    1.26e-06   1.08e-15   2.06e+00  3.94e-01        1    6.14e-03    2.02e-01
  37  1.056424e-20   -1.03e-20    7.82e-06   1.68e-16   6.46e-02  2.37e-01        1    6.14e-03    2.09e-01
  38  1.144248e-21    9.42e-21    2.56e-06   1.75e-15   1.30e+00  7.12e-01        1    6.16e-03    2.15e-01
  39  5.015640e-22    6.43e-22    2.04e-06   8.33e-16   6.35e-01  7.26e-01        1    6.12e-03    2.21e-01
  40  2.944809e-22    2.07e-22    1.51e-06   3.43e-16   4.65e-01  7.26e-01        1    6.18e-03    2.27e-01
  41  5.369327e-21   -5.07e-21    5.19e-06   3.17e-16   1.22e-01  5.07e-01        1    6.17e-03    2.33e-01
  42  1.957203e-21    3.41e-21    4.07e-06   1.80e-15   7.75e-01  6.08e-01        1    6.14e-03    2.39e-01
  43  1.235985e-21    7.21e-22    2.72e-06   6.82e-16   4.35e-01  6.07e-01        1    6.14e-03    2.46e-01
  44  1.086675e-21    1.49e-22    2.96e-06   7.22e-16   1.61e-01  4.63e-01        1    6.10e-03    2.52e-01
  45  7.678176e-21   -6.59e-21    6.67e-06   4.06e-16   8.49e-02  2.94e-01        1    6.15e-03    2.58e-01
  46  1.212891e-20   -4.45e-21    7.73e-06   1.68e-15   3.25e-02  1.62e-01        1    6.10e-03    2.64e-01
  47  1.687772e-21    1.04e-20    3.74e-06   1.49e-15   1.45e+00  4.86e-01        1    6.19e-03    2.70e-01
  48  1.763811e-21   -7.60e-23    3.91e-06   5.72e-16   1.31e-01  3.46e-01        1    6.11e-03    2.76e-01
  49  3.610766e-21   -1.85e-21    3.31e-06   4.73e-16   1.11e-01  2.36e-01        1    6.15e-03    2.82e-01
  50  1.249996e-21    2.36e-21    2.89e-06   6.49e-16   1.07e+00  7.07e-01        1    6.10e-03    2.89e-01
  51  2.103404e-21   -8.53e-22    4.23e-06   5.53e-16   1.22e-01  4.94e-01        1    6.11e-03    2.95e-01
  52  2.609653e-21   -5.06e-22    4.84e-06   6.63e-16   1.16e-01  3.40e-01        1    6.11e-03    3.01e-01
  53  1.703189e-21    9.06e-22    3.31e-06   7.60e-16   4.44e-01  3.39e-01        1    6.12e-03    3.07e-01
  54  2.507570e-21   -8.04e-22    2.91e-06   4.75e-16   1.13e-01  2.32e-01        1    6.11e-03    3.13e-01
  55  4.784456e-22    2.03e-21    1.60e-06   6.12e-16   1.30e+00  6.95e-01        1    6.17e-03    3.19e-01
  56  1.717368e-22    3.07e-22    1.09e-06   5.84e-16   8.31e-01  9.79e-01        1    6.10e-03    3.25e-01
  57  4.659445e-22   -2.94e-22    1.37e-06   2.86e-16   1.29e-01  6.95e-01        1    6.14e-03    3.31e-01
  58  7.932693e-21   -7.47e-21    7.84e-06   5.95e-16   6.33e-02  4.17e-01        1    6.15e-03    3.38e-01
  59  6.345277e-21    1.59e-21    5.93e-06   1.65e-15   2.41e-01  3.66e-01        1    6.19e-03    3.44e-01
  60  1.603273e-20   -9.69e-21    0.00e+00   1.64e-15  -6.79e-03  1.83e-01        1    3.20e-03    3.47e-01
  61  1.452405e-22    6.20e-21    2.76e-07   1.10e-15   1.57e+00  5.50e-01        1    6.17e-03    3.53e-01
  62  1.158514e-21   -1.01e-21    1.80e-06   1.12e-16   1.12e-01  3.75e-01        1    6.13e-03    3.59e-01
  63  3.395363e-22    8.19e-22    1.44e-06   5.43e-16   1.06e+00  1.12e+00        1    6.18e-03    3.66e-01
  64  4.367977e-22   -9.73e-23    1.88e-06   2.77e-16   1.17e-01  7.75e-01        1    6.11e-03    3.72e-01
  65  2.773802e-22    1.59e-22    1.26e-06   3.60e-16   4.23e-01  7.72e-01        1    6.13e-03    3.78e-01
  66  6.552724e-22   -3.78e-22    1.81e-06   2.05e-16   1.15e-01  5.30e-01        1    6.16e-03    3.84e-01
  67  2.507081e-21   -1.85e-21    3.74e-06   3.91e-16   9.96e-02  3.50e-01        1    6.20e-03    3.90e-01
  68  1.885735e-21    6.21e-22    3.92e-06   6.75e-16   3.43e-01  3.40e-01        1    6.23e-03    3.96e-01
  69  3.130833e-21   -1.25e-21    4.06e-06   6.02e-16   9.23e-02  2.20e-01        1    6.08e-03    4.03e-01
  70  6.950528e-22    2.44e-21    1.58e-06   6.19e-16   1.37e+00  6.61e-01        1    6.13e-03    4.09e-01
  71  7.813421e-22   -8.63e-23    1.76e-06   4.16e-16   1.08e-01  4.46e-01        1    6.15e-03    4.15e-01
  72  6.145807e-22    1.67e-22    2.06e-06   5.25e-16   3.13e-01  4.24e-01        1    6.13e-03    4.21e-01
  73  3.539836e-21   -2.93e-21    4.90e-06   3.13e-16   8.70e-02  2.71e-01        1    6.14e-03    4.27e-01
  74  1.816094e-22    3.36e-21    1.01e-06   6.22e-16   1.36e+00  8.14e-01        1    6.19e-03    4.33e-01
  75  7.241688e-21   -7.06e-21    5.70e-06   1.84e-16   5.82e-02  4.82e-01        1    6.08e-03    4.39e-01
  76  1.864612e-21    5.38e-21    2.97e-06   1.89e-15   8.83e-01  8.72e-01        1    6.11e-03    4.46e-01
  77  4.498191e-22    1.41e-21    1.78e-06   1.19e-15   8.36e-01  1.25e+00        1    6.14e-03    4.52e-01
  78  2.097721e-21   -1.65e-21    4.23e-06   3.41e-16   9.06e-02  8.07e-01        1    6.18e-03    4.58e-01
  79  1.129218e-21    9.69e-22    2.53e-06   9.79e-16   5.07e-01  8.07e-01        1    6.13e-03    4.64e-01
  80  4.596678e-21   -3.47e-21    5.10e-06   8.74e-16   7.18e-02  4.96e-01        1    6.14e-03    4.70e-01
  81  6.446963e-21   -1.85e-21    5.33e-06   1.40e-15   5.78e-02  2.93e-01        1    6.16e-03    4.76e-01
  82  6.145702e-22    5.83e-21    2.34e-06   1.14e-15   1.30e+00  8.79e-01        1    6.13e-03    4.83e-01
  83  2.354611e-21   -1.74e-21    3.55e-06   4.43e-16   8.22e-02  5.55e-01        1    6.22e-03    4.89e-01
  84  1.156808e-21    1.20e-21    2.26e-06   7.55e-16   6.15e-01  5.62e-01        1    6.06e-03    4.95e-01
  85  2.389956e-21   -1.23e-21    3.66e-06   6.34e-16   8.04e-02  3.53e-01        1    6.09e-03    5.01e-01
  86  3.971299e-22    1.99e-21    1.33e-06   8.55e-16   1.16e+00  1.06e+00        1    6.14e-03    5.07e-01
  87  1.074434e-21   -6.77e-22    2.69e-06   4.55e-16   8.76e-02  6.79e-01        1    6.12e-03    5.13e-01
  88  2.617224e-21   -1.54e-21    4.68e-06   6.95e-16   7.75e-02  4.23e-01        1    6.18e-03    5.19e-01
  89  5.131406e-22    2.10e-21    1.99e-06   6.73e-16   1.05e+00  1.27e+00        1    6.14e-03    5.26e-01
  90  1.259219e-20   -1.21e-20    8.68e-06   4.90e-16   1.57e-02  6.66e-01        1    6.25e-03    5.32e-01
  91  1.468450e-21    1.11e-20    2.69e-06   3.00e-15   1.02e+00  2.00e+00        1    6.09e-03    5.38e-01
  92  2.646602e-21   -1.18e-21    3.96e-06   1.07e-15   7.09e-02  1.22e+00        1    6.10e-03    5.44e-01
  93  3.833071e-21   -1.19e-21    5.90e-06   1.04e-15   6.34e-02  7.35e-01        1    6.15e-03    5.50e-01
  94  4.349554e-21   -5.16e-22    4.55e-06   1.02e-15   5.94e-02  4.36e-01        1    6.16e-03    5.56e-01
  95  1.097331e-21    3.25e-21    2.39e-06   1.32e-15   9.84e-01  1.31e+00        1    6.13e-03    5.63e-01
  96  2.539690e-21   -1.44e-21    4.57e-06   5.62e-16   6.77e-02  7.95e-01        1    6.15e-03    5.69e-01
  97  1.900298e-21    6.39e-22    3.88e-06   1.04e-15   2.71e-01  7.25e-01        1    6.17e-03    5.75e-01
  98  2.895844e-21   -9.96e-22    5.00e-06   6.83e-16   6.44e-02  4.36e-01        1    6.20e-03    5.81e-01
  99  1.407036e-20   -1.12e-20    8.88e-06   7.47e-16   5.74e-03  2.22e-01        1    6.28e-03    5.87e-01
 100  1.554494e-20   -1.47e-21    0.00e+00   2.01e-15  -1.82e-03  1.11e-01        1    3.18e-03    5.91e-01
 101  9.230126e-21    4.84e-21    7.22e-06   1.25e-15   7.30e-01  1.23e-01        1    6.12e-03    5.97e-01
 102  3.390923e-22    8.89e-21    1.53e-06   1.17e-15   1.93e+00  3.69e-01        1    6.17e-03    6.03e-01
 103  1.333982e-21   -9.95e-22    2.66e-06   3.50e-16   6.77e-02  2.24e-01        1    6.17e-03    6.09e-01
 104  7.382952e-23    1.26e-21    6.35e-07   5.62e-16   1.55e+00  6.72e-01        1    6.12e-03    6.15e-01
 105  2.350000e-21   -2.28e-21    2.86e-06   9.44e-17   6.25e-02  4.02e-01        1    7.11e-03    6.22e-01
 106  2.107858e-22    2.14e-21    1.21e-06   6.70e-16   1.21e+00  1.21e+00        1    6.14e-03    6.29e-01
 107  1.689428e-22    4.18e-23    1.02e-06   2.22e-16   2.75e-01  1.11e+00        1    6.13e-03    6.35e-01
 108  3.053524e-21   -2.88e-21    3.15e-06   2.78e-16   5.85e-02  6.56e-01        1    6.16e-03    6.41e-01
 109  6.731209e-22    2.38e-21    1.63e-06   1.12e-15   9.43e-01  1.97e+00        1    6.15e-03    6.47e-01
 110  7.236321e-21   -6.56e-21    0.00e+00   6.75e-16  -1.33e+00  9.83e-01        1    3.13e-03    6.50e-01
 111  1.308006e-20   -1.24e-20    0.00e+00   6.28e-16  -3.22e+00  2.46e-01        1    3.13e-03    6.53e-01
 112  5.212340e-21   -4.54e-21    0.00e+00   3.34e-16  -7.34e-01  3.07e-02        1    3.13e-03    6.56e-01
 113  3.418308e-21   -2.75e-21    0.00e+00   3.75e-17  -1.39e-01  1.92e-03        1    3.13e-03    6.60e-01
 114  3.980044e-21   -3.31e-21    0.00e+00   3.47e-18  -3.66e-01  6.00e-05        1    3.15e-03    6.63e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.092683e+02
Final                            7.382952e-23
Change                           1.092683e+02

Minimizer iterations                      115
Successful steps                          100
Unsuccessful steps                         15
Line search steps                          64

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0093
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6511
    Line search gradient evaluation    0.3492
  Linear solver                        0.0022
  Line search polynomial minimization  0.0003
Minimizer                              0.6659

Postprocessor                          0.0000
Total                                  0.6660

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.585273e+04
Final                            1.355766e+02
Change                           1.571715e+04

Minimizer iterations                       48
Successful steps                           38
Unsuccessful steps                         10
Line search steps                          77

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4305
    Line search gradient evaluation    0.3157
  Linear solver                        0.0009
  Line search polynomial minimization  0.0007
Minimizer                              0.4367

Postprocessor                          0.0000
Total                                  0.4368

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA81 = {
{-0.0645108,0.4471402,0.2040212}
};
fitErrEl81 = {
{-0.1018737,0.4339297,0.2163364}
};
fitErrLa81 = {
{-0.1033448,0.4624029,0.2252858}
};
fitErrWr81 = {
{-0.2801623,0.4063445,0.3099611}
};
fitErrEe81 = {
{-0.3390235,0.4336152,0.3911114}
};
rMatsBase81 = {
{-0.3279607,0.7093337,-0.6239290},
{0.8197947,0.5418976,0.1851585},
{0.4694448,-0.4507690,-0.7592291}
};
outThetasWam81 = {
{-0.0904397,-0.3129183,-0.0479572,1.3306216,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.4957022
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.153257e+02    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.11e-03    3.16e-03
   1  2.162620e+00    1.13e+02    2.84e+00   7.66e-03   1.96e+00  3.00e+04        1    6.23e-03    9.41e-03
   2  1.378348e-06    2.16e+00    2.79e+00   1.43e-04   1.96e+00  9.00e+04        1    6.15e-03    1.56e-02
   3  9.109346e-16    1.38e-06    3.33e-04   6.22e-08   1.96e+00  2.70e+05        1    6.14e-03    2.17e-02
   4  7.388983e-21    9.11e-16    6.29e-06   1.38e-11   1.96e+00  8.10e+05        1    6.14e-03    2.79e-02
   5  2.996174e-21    4.39e-21    4.11e-06   8.46e-15   1.96e+00  2.43e+06        1    6.19e-03    3.41e-02
   6  9.065860e-21   -6.07e-21    7.09e-06   3.71e-15   1.96e+00  7.29e+06        1    6.13e-03    4.03e-02
   7  1.672765e-21    7.39e-21    3.69e-06   5.37e-15   1.96e+00  2.19e+07        1    6.16e-03    4.64e-02
   8  5.502772e-21   -3.83e-21    5.75e-06   2.86e-15   1.96e+00  6.56e+07        1    6.22e-03    5.27e-02
   9  2.075531e-21    3.43e-21    4.13e-06   6.97e-15   1.96e+00  1.97e+08        1    6.15e-03    5.88e-02
  10  1.214078e-21    8.61e-22    2.87e-06   4.86e-15   1.96e+00  5.90e+08        1    6.14e-03    6.50e-02
  11  1.661189e-21   -4.47e-22    3.66e-06   2.02e-15   1.96e+00  1.77e+09        1    6.14e-03    7.12e-02
  12  1.004338e-20   -8.38e-21    7.95e-06   2.55e-15   1.96e+00  5.31e+09        1    6.26e-03    7.74e-02
  13  1.009145e-21    9.03e-21    2.51e-06   7.15e-15   1.96e+00  1.59e+10        1    6.10e-03    8.35e-02
  14  6.583929e-22    3.51e-22    1.88e-06   2.02e-15   1.96e+00  4.78e+10        1    6.15e-03    8.97e-02
  15  1.061134e-21   -4.03e-22    3.02e-06   1.79e-15   1.96e+00  1.43e+11        1    6.97e-03    9.67e-02
  16  6.229316e-21   -5.17e-21    6.01e-06   1.75e-15   1.96e+00  4.30e+11        1    6.18e-03    1.03e-01
  17  1.011331e-20   -3.88e-21    7.48e-06   4.70e-15   1.96e+00  1.29e+12        1    6.17e-03    1.09e-01
  18  1.343787e-21    8.77e-21    2.43e-06   8.67e-15   1.96e+00  3.87e+12        1    6.14e-03    1.15e-01
  19  1.648858e-20   -1.51e-20    9.80e-06   6.87e-15   1.96e+00  1.16e+13        1    6.16e-03    1.21e-01
  20  5.374154e-21    1.11e-20    5.73e-06   1.07e-14   6.78e-01  1.22e+13        1    6.14e-03    1.28e-01
  21  5.254108e-21    1.20e-22    6.36e-06   5.38e-15   5.16e-01  1.22e+13        1    6.14e-03    1.34e-01
  22  3.019117e-21    2.23e-21    3.82e-06   2.90e-15   4.99e-01  1.22e+13        1    6.20e-03    1.40e-01
  23  6.403540e-21   -3.38e-21    5.53e-06   5.58e-15   3.37e-01  1.18e+13        1    6.17e-03    1.46e-01
  24  8.728161e-21   -2.32e-21    7.02e-06   1.19e-14   2.14e-01  9.90e+12        1    6.15e-03    1.52e-01
  25  1.885820e-20   -1.01e-20    0.00e+00   8.55e-15  -5.28e-02  4.95e+12        1    3.15e-03    1.55e-01
  26  1.610460e-20   -7.38e-21    8.91e-06   8.55e-15   8.55e-03  2.54e+12        1    6.12e-03    1.62e-01
  27  6.575198e-21    9.53e-21    5.61e-06   8.57e-15   5.92e-01  2.56e+12        1    6.14e-03    1.68e-01
  28  8.335600e-21   -1.76e-21    8.30e-06   5.08e-15   1.21e-01  1.78e+12        1    6.13e-03    1.74e-01
  29  2.168595e-21    6.17e-21    3.37e-06   5.22e-15   7.55e-01  2.05e+12        1    6.12e-03    1.80e-01
  30  6.403020e-21   -4.23e-21    5.28e-06   2.90e-15   1.30e-01  1.46e+12        1    6.18e-03    1.86e-01
  31  2.148656e-21    4.25e-21    3.27e-06   4.36e-15   6.75e-01  1.52e+12        1    6.19e-03    1.92e-01
  32  1.208691e-20   -9.94e-21    8.14e-06   2.33e-15   5.10e-02  8.84e+11        1    6.20e-03    1.99e-01
  33  9.027573e-22    1.12e-20    2.23e-06   7.21e-15   9.26e-01  2.33e+12        1    6.14e-03    2.05e-01
  34  6.038928e-21   -5.14e-21    6.00e-06   4.47e-15   1.05e-01  1.56e+12        1    6.19e-03    2.11e-01
  35  1.086927e-20   -4.83e-21    8.02e-06   8.87e-15   5.34e-02  9.11e+11        1    6.16e-03    2.17e-01
  36  2.011777e-20   -9.25e-21    0.00e+00   8.93e-15  -3.13e-02  4.55e+11        1    3.13e-03    2.20e-01
  37  2.011777e-20   -9.25e-21    0.00e+00   8.93e-15  -3.13e-02  1.14e+11        1    3.13e-03    2.23e-01
  38  1.885234e-20   -7.98e-21    0.00e+00   8.93e-15  -2.04e-02  1.42e+10        1    3.19e-03    2.27e-01
  39  1.885234e-20   -7.98e-21    0.00e+00   8.93e-15  -2.04e-02  8.89e+08        1    3.14e-03    2.30e-01
  40  1.885234e-20   -7.98e-21    0.00e+00   8.93e-15  -2.04e-02  2.78e+07        1    3.15e-03    2.33e-01
  41  1.885234e-20   -7.98e-21    0.00e+00   8.93e-15  -2.04e-02  4.34e+05        1    3.16e-03    2.36e-01
  42  1.885234e-20   -7.98e-21    0.00e+00   8.93e-15  -2.04e-02  3.39e+03        1    3.27e-03    2.39e-01
  43  1.920599e-20   -8.34e-21    0.00e+00   8.71e-15  -2.34e-02  1.33e+01        1    3.22e-03    2.43e-01
  44  5.841875e-21    5.03e-21    6.74e-06   5.23e-15   4.72e-01  1.32e+01        1    6.14e-03    2.49e-01
  45  2.789216e-20   -2.21e-20    0.00e+00   2.04e-15  -9.39e-02  6.62e+00        1    3.13e-03    2.52e-01
  46  1.012704e-20   -4.29e-21    7.20e-06   1.89e-15   5.24e-02  3.86e+00        1    6.21e-03    2.58e-01
  47  1.439285e-20   -4.27e-21    8.68e-06   2.68e-15   1.59e-02  2.02e+00        1    6.24e-03    2.64e-01
  48  2.975370e-21    1.14e-20    4.52e-06   4.36e-15   8.39e-01  2.94e+00        1    6.16e-03    2.71e-01
  49  9.991671e-21   -7.02e-21    8.01e-06   1.30e-15   4.40e-02  1.67e+00        1    6.19e-03    2.77e-01
  50  4.416971e-21    5.57e-21    6.36e-06   3.33e-15   5.77e-01  1.68e+00        1    6.17e-03    2.83e-01
  51  2.021674e-21    2.40e-21    3.50e-06   1.34e-15   5.56e-01  1.68e+00        1    6.27e-03    2.89e-01
  52  2.658907e-22    1.76e-21    6.19e-07   1.34e-15   9.56e-01  5.03e+00        1    6.17e-03    2.96e-01
  53  8.229143e-21   -7.96e-21    6.48e-06   1.00e-15   5.05e-02  2.92e+00        1    6.19e-03    3.02e-01
  54  5.629893e-21    2.60e-21    5.05e-06   3.32e-15   3.22e-01  2.79e+00        1    6.18e-03    3.08e-01
  55  2.681553e-21    2.95e-21    3.05e-06   2.96e-15   5.64e-01  2.80e+00        1    6.16e-03    3.14e-01
  56  5.370206e-21   -2.69e-21    5.84e-06   1.29e-15   6.20e-02  1.67e+00        1    6.19e-03    3.20e-01
  57  1.557517e-21    3.81e-21    3.08e-06   2.29e-15   7.34e-01  1.86e+00        1    6.19e-03    3.27e-01
  58  5.031826e-22    1.05e-21    1.87e-06   1.24e-15   7.12e-01  2.02e+00        1    6.24e-03    3.33e-01
  59  1.142827e-21   -6.40e-22    1.92e-06   4.70e-16   3.08e-01  1.91e+00        1    6.17e-03    3.39e-01
  60  1.619673e-22    9.81e-22    8.76e-07   1.05e-15   9.15e-01  4.43e+00        1    6.22e-03    3.45e-01
  61  9.590352e-21   -9.43e-21    0.00e+00   5.41e-16  -5.63e-02  2.22e+00        1    3.14e-03    3.48e-01
  62  1.629724e-22   -1.01e-24    2.02e-07   3.42e-16   3.34e-01  2.14e+00        1    6.50e-03    3.55e-01
  63  8.599567e-21   -8.44e-21    0.00e+00   2.64e-16  -1.53e-02  1.07e+00        1    3.17e-03    3.58e-01
  64  8.549319e-21   -8.39e-21    0.00e+00   2.56e-16  -1.32e-02  2.67e-01        1    3.15e-03    3.61e-01
  65  1.693315e-22   -6.36e-24    2.05e-07   9.81e-18   3.34e-01  2.58e-01        1    6.16e-03    3.67e-01
  66  8.352590e-22   -6.66e-22    1.59e-06   9.81e-18   3.06e-01  2.44e-01        1    6.32e-03    3.74e-01
  67  1.060131e-20   -9.77e-21    0.00e+00   2.99e-16  -9.68e-02  1.22e-01        1    3.20e-03    3.77e-01
  68  6.699250e-21   -5.86e-21    6.46e-06   2.68e-16   6.27e-02  7.30e-02        1    6.17e-03    3.83e-01
  69  2.861196e-22    6.41e-21    1.03e-06   6.02e-16   2.75e+00  2.19e-01        1    6.13e-03    3.90e-01
  70  9.889040e-22   -7.03e-22    2.90e-06   2.62e-16   2.30e+00  6.57e-01        1    6.53e-03    3.96e-01
  71  1.622226e-21   -6.33e-22    3.04e-06   5.25e-16   1.53e+00  1.97e+00        1    6.11e-03    4.02e-01
  72  6.559110e-21   -4.94e-21    6.27e-06   8.32e-16   2.88e-02  1.07e+00        1    6.16e-03    4.08e-01
  73  3.545917e-21    3.01e-21    4.47e-06   2.50e-15   4.98e-01  1.07e+00        1    6.24e-03    4.15e-01
  74  1.389807e-20   -1.04e-20    0.00e+00   1.61e-15  -5.04e-01  5.36e-01        1    3.19e-03    4.18e-01
  75  1.182712e-20   -8.28e-21    0.00e+00   1.35e-15  -3.65e-01  1.34e-01        1    3.20e-03    4.21e-01
  76  1.397285e-21    2.15e-21    2.85e-06   6.78e-16   1.10e+00  4.02e-01        1    6.35e-03    4.27e-01
  77  2.767953e-22    1.12e-21    9.47e-07   7.03e-16   9.67e-01  1.21e+00        1    6.21e-03    4.34e-01
  78  3.910603e-22   -1.14e-22    1.26e-06   3.43e-16   4.45e-01  1.21e+00        1    6.28e-03    4.40e-01
  79  1.621718e-21   -1.23e-21    3.17e-06   5.60e-16   3.52e-01  1.17e+00        1    6.42e-03    4.46e-01
  80  1.511029e-21    1.11e-22    3.15e-06   1.09e-15   3.26e-01  1.13e+00        1    6.16e-03    4.53e-01
  81  1.436962e-20   -1.29e-20    0.00e+00   1.01e-15  -4.44e-01  5.64e-01        1    3.13e-03    4.56e-01
  82  1.389773e-21    1.21e-22    3.52e-06   7.75e-16   3.09e-01  5.34e-01        1    6.44e-03    4.62e-01
  83  1.518831e-21   -1.29e-22    3.59e-06   5.06e-16   2.83e-01  4.93e-01        1    6.31e-03    4.69e-01
  84  1.297222e-20   -1.15e-20    0.00e+00   5.57e-16  -3.20e-01  2.47e-01        1    3.13e-03    4.72e-01
  85  9.563077e-21   -8.04e-21    0.00e+00   3.73e-16  -1.48e-01  6.16e-02        1    3.17e-03    4.75e-01
  86  9.875151e-21   -8.36e-21    0.00e+00   1.52e-16  -1.69e-01  7.71e-03        1    3.38e-03    4.78e-01
  87  1.705182e-21   -1.86e-22    3.80e-06   1.73e-17   2.71e-01  7.03e-03        1    6.64e-03    4.85e-01
  88  1.823732e-22    1.52e-21    1.10e-06   1.73e-17   2.07e+01  2.11e-02        1    6.17e-03    4.91e-01
  89  5.633261e-23    1.26e-22    2.04e-07   9.81e-18   6.85e+00  6.33e-02        1    6.90e-03    4.98e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.153257e+02
Final                            5.633261e-23
Change                           1.153257e+02

Minimizer iterations                       90
Successful steps                           70
Unsuccessful steps                         20
Line search steps                          54

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0074
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4882
    Line search gradient evaluation    0.2752
  Linear solver                        0.0022
  Line search polynomial minimization  0.0003
Minimizer                              0.5014

Postprocessor                          0.0000
Total                                  0.5014

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.580401e+04
Final                            1.362198e+02
Change                           1.566779e+04

Minimizer iterations                      264
Successful steps                          171
Unsuccessful steps                         93
Line search steps                         300

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0214
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.7159
    Line search gradient evaluation    1.1979
  Linear solver                        0.0054
  Line search polynomial minimization  0.0022
Minimizer                              1.7501

Postprocessor                          0.0000
Total                                  1.7502

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA82 = {
{-0.0666533,0.4551813,0.2075383}
};
fitErrEl82 = {
{-0.1046780,0.4416958,0.2200591}
};
fitErrLa82 = {
{-0.1061679,0.4708780,0.2292622}
};
fitErrWr82 = {
{-0.2876255,0.4140736,0.3157000}
};
fitErrEe82 = {
{-0.3463575,0.4414151,0.3974632}
};
rMatsBase82 = {
{-0.3297674,0.7139026,-0.6177350},
{0.8193555,0.5414603,0.1883545},
{0.4689457,-0.4440314,-0.7634959}
};
outThetasWam82 = {
{-0.0902457,-0.3097493,-0.0472241,1.3277405,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5046829
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  8.958857e+01    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.04e-03    3.11e-03
   1  1.442519e+00    8.81e+01    2.84e+00   6.18e-03   1.97e+00  3.00e+04        1    6.20e-03    9.33e-03
   2  2.809782e-07    1.44e+00    2.80e+00   9.41e-05   1.96e+00  9.00e+04        1    6.13e-03    1.55e-02
   3  4.570352e-16    2.81e-07    1.81e-04   3.13e-08   1.96e+00  2.70e+05        1    6.27e-03    2.18e-02
   4  4.513062e-21    4.57e-16    4.67e-06   1.01e-11   1.96e+00  8.10e+05        1    6.14e-03    2.79e-02
   5  9.742900e-22    3.54e-21    2.69e-06   6.23e-15   1.96e+00  2.43e+06        1    6.29e-03    3.42e-02
   6  3.883976e-21   -2.91e-21    4.84e-06   1.37e-15   1.96e+00  7.29e+06        1    6.31e-03    4.06e-02
   7  1.846669e-21    2.04e-21    3.25e-06   5.11e-15   1.96e+00  2.19e+07        1    6.12e-03    4.67e-02
   8  3.023289e-21   -1.18e-21    4.71e-06   1.19e-15   1.96e+00  6.56e+07        1    6.26e-03    5.30e-02
   9  6.751519e-21   -3.73e-21    4.81e-06   1.64e-15   1.96e+00  1.97e+08        1    6.23e-03    5.92e-02
  10  2.580075e-21    4.17e-21    2.98e-06   4.21e-15   1.96e+00  5.90e+08        1    6.15e-03    6.54e-02
  11  8.322129e-22    1.75e-21    2.62e-06   4.49e-15   6.86e-01  6.22e+08        1    6.18e-03    7.16e-02
  12  6.657074e-21   -5.82e-21    6.03e-06   1.32e-15   9.35e-03  3.20e+08        1    6.45e-03    7.81e-02
  13  2.240706e-21    4.42e-21    3.18e-06   5.24e-15   6.75e-01  3.34e+08        1    6.49e-03    8.46e-02
  14  6.308220e-21   -4.07e-21    6.32e-06   1.92e-15   2.35e-02  1.79e+08        1    6.52e-03    9.11e-02
  15  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  8.96e+07        1    3.15e-03    9.43e-02
  16  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  2.24e+07        1    3.11e-03    9.74e-02
  17  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  2.80e+06        1    3.11e-03    1.01e-01
  18  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  1.75e+05        1    3.16e-03    1.04e-01
  19  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  5.47e+03        1    3.27e-03    1.07e-01
  20  1.076572e-20   -4.46e-21    0.00e+00   4.06e-15  -1.61e-01  8.55e+01        1    3.18e-03    1.10e-01
  21  5.869103e-21    4.39e-22    5.70e-06   3.70e-15   7.12e-02  5.24e+01        1    6.13e-03    1.16e-01
  22  3.249928e-21    2.62e-21    4.48e-06   4.11e-15   4.48e-01  5.24e+01        1    6.53e-03    1.23e-01
  23  2.308167e-21    9.42e-22    4.14e-06   3.60e-15   2.97e-01  4.91e+01        1    6.17e-03    1.29e-01
  24  4.420069e-21   -2.11e-21    5.29e-06   2.18e-15   8.56e-02  3.13e+01        1    6.38e-03    1.35e-01
  25  1.693644e-21    2.73e-21    2.71e-06   3.03e-15   6.22e-01  3.17e+01        1    6.35e-03    1.42e-01
  26  1.225741e-21    4.68e-22    3.17e-06   2.31e-15   2.84e-01  2.94e+01        1    6.17e-03    1.48e-01
  27  5.706797e-21   -4.48e-21    5.32e-06   1.92e-15   2.85e-02  1.60e+01        1    6.41e-03    1.55e-01
  28  4.720834e-21    9.86e-22    5.96e-06   3.33e-15   1.75e-01  1.25e+01        1    6.21e-03    1.61e-01
  29  7.443809e-21   -2.72e-21    0.00e+00   2.06e-15  -1.80e-02  6.27e+00        1    3.32e-03    1.64e-01
  30  7.757933e-22    3.95e-21    2.49e-06   1.97e-15   8.52e-01  9.62e+00        1    6.35e-03    1.71e-01
  31  1.604727e-20   -1.53e-20    0.00e+00   8.79e-16  -2.12e-01  4.81e+00        1    3.26e-03    1.74e-01
  32  2.564570e-20   -2.49e-20    0.00e+00   6.95e-16  -4.28e-01  1.20e+00        1    3.27e-03    1.77e-01
  33  5.585610e-21   -4.81e-21    5.43e-06   5.77e-16   2.42e-02  6.46e-01        1    6.22e-03    1.83e-01
  34  1.009653e-21    4.58e-21    2.50e-06   1.67e-15   9.30e-01  1.77e+00        1    6.19e-03    1.90e-01
  35  1.986110e-21   -9.76e-22    3.22e-06   1.07e-15   9.31e-02  1.15e+00        1    6.40e-03    1.96e-01
  36  6.627075e-22    1.32e-21    1.85e-06   1.28e-15   7.42e-01  1.30e+00        1    6.17e-03    2.02e-01
  37  8.361376e-21   -7.70e-21    0.00e+00   8.22e-16  -3.25e-02  6.48e-01        1    3.17e-03    2.05e-01
  38  2.485224e-21   -1.82e-21    3.72e-06   5.87e-16   7.95e-02  4.06e-01        1    6.38e-03    2.12e-01
  39  6.965780e-22    1.79e-21    1.86e-06   1.00e-15   9.03e-01  8.51e-01        1    6.28e-03    2.18e-01
  40  2.083793e-21   -1.39e-21    3.62e-06   8.14e-16   8.31e-02  5.39e-01        1    6.31e-03    2.24e-01
  41  2.382370e-22    1.85e-21    1.01e-06   1.01e-15   1.03e+00  1.62e+00        1    6.49e-03    2.31e-01
  42  9.197448e-21   -8.96e-21    0.00e+00   5.12e-16  -4.46e-02  8.08e-01        1    3.12e-03    2.34e-01
  43  1.278154e-20   -1.25e-20    0.00e+00   2.68e-16  -1.08e-01  2.02e-01        1    3.14e-03    2.37e-01
  44  1.970481e-21   -1.73e-21    2.74e-06   6.40e-17   8.24e-02  1.28e-01        1    6.48e-03    2.44e-01
  45  5.259931e-21   -3.29e-21    5.45e-06   3.32e-16   2.42e-02  6.85e-02        1    6.21e-03    2.50e-01
  46  8.311791e-21   -3.05e-21    0.00e+00   5.34e-16  -2.79e-02  3.43e-02        1    3.18e-03    2.53e-01
  47  4.793260e-22    4.78e-21    1.86e-06   2.65e-16   5.29e+00  1.03e-01        1    6.22e-03    2.59e-01
  48  3.562165e-21   -3.08e-21    4.62e-06   1.26e-16   5.26e-02  5.99e-02        1    6.39e-03    2.66e-01
  49  8.477031e-21   -4.91e-21    0.00e+00   3.49e-16  -3.04e-02  2.99e-02        1    3.14e-03    2.69e-01
  50  6.734611e-22    2.89e-21    2.30e-06   2.59e-16   5.09e+00  8.98e-02        1    6.37e-03    2.75e-01
  51  1.319503e-21   -6.46e-22    2.48e-06   1.40e-16   2.08e+00  2.69e-01        1    6.31e-03    2.82e-01
  52  6.600558e-22    6.59e-22    1.94e-06   6.63e-16   1.66e+00  8.08e-01        1    6.39e-03    2.88e-01
  53  5.270310e-22    1.33e-22    1.46e-06   3.81e-16   1.43e+00  2.43e+00        1    6.25e-03    2.94e-01
  54  6.331663e-22   -1.06e-22    1.71e-06   4.24e-16   1.25e+00  7.28e+00        1    6.35e-03    3.01e-01
  55  3.197016e-21   -2.56e-21    3.90e-06   1.38e-15   4.82e-01  7.28e+00        1    6.33e-03    3.07e-01
  56  1.222425e-20   -9.03e-21    0.00e+00   2.02e-15  -9.37e-01  3.64e+00        1    3.60e-03    3.11e-01
  57  2.353263e-21    8.44e-22    4.57e-06   1.94e-15   3.92e-01  3.60e+00        1    6.53e-03    3.17e-01
  58  7.103089e-21   -4.75e-21    0.00e+00   1.07e-15  -1.91e-01  1.80e+00        1    3.15e-03    3.21e-01
  59  2.095207e-21    2.58e-22    3.11e-06   9.54e-16   3.30e-01  1.73e+00        1    6.16e-03    3.27e-01
  60  1.766999e-20   -1.56e-20    0.00e+00   1.42e-15  -1.07e+00  8.66e-01        1    3.36e-03    3.30e-01
  61  8.407609e-22    1.25e-21    2.61e-06   1.19e-15   6.63e-01  8.97e-01        1    6.14e-03    3.36e-01
  62  5.095932e-21   -4.26e-21    6.78e-06   5.14e-16   1.34e-02  4.67e-01        1    6.76e-03    3.43e-01
  63  1.264406e-20   -7.55e-21    0.00e+00   1.02e-15  -4.51e-01  2.33e-01        1    3.29e-03    3.46e-01
  64  4.812244e-21    2.84e-22    5.19e-06   8.08e-16   8.35e-02  1.48e-01        1    6.22e-03    3.53e-01
  65  4.142567e-21    6.70e-22    4.74e-06   7.88e-16   2.42e-01  1.30e-01        1    6.17e-03    3.59e-01
  66  5.375188e-21   -1.23e-21    0.00e+00   6.78e-16  -5.63e-03  6.51e-02        1    3.56e-03    3.62e-01
  67  2.802960e-22    3.86e-21    9.78e-07   3.42e-16   2.85e+00  1.95e-01        1    5.93e-03    3.68e-01
  68  1.728223e-22    1.07e-22    6.25e-07   9.72e-17   9.00e-01  4.01e-01        1    6.24e-03    3.75e-01
  69  9.664995e-22   -7.94e-22    1.64e-06   1.14e-16   2.16e-01  3.39e-01        1    6.00e-03    3.81e-01
  70  4.677676e-21   -3.71e-21    4.46e-06   5.24e-16   2.84e-02  1.84e-01        1    5.74e-03    3.86e-01
  71  6.444569e-21   -1.77e-21    0.00e+00   8.26e-16  -5.17e-02  9.22e-02        1    3.07e-03    3.89e-01
  72  3.706172e-21    9.72e-22    4.17e-06   5.22e-16   6.11e-01  9.32e-02        1    5.95e-03    3.95e-01
  73  9.056307e-21   -5.35e-21    0.00e+00   4.55e-16  -1.60e-01  4.66e-02        1    2.99e-03    3.98e-01
  74  1.160685e-20   -7.90e-21    0.00e+00   3.41e-16  -2.75e-01  1.16e-02        1    2.89e-03    4.01e-01
  75  2.759660e-21    9.47e-22    3.92e-06   1.39e-17   3.32e+00  3.49e-02        1    5.87e-03    4.07e-01
  76  5.966193e-21   -3.21e-21    0.00e+00   2.57e-16  -3.08e-02  1.75e-02        1    2.85e-03    4.10e-01
  77  7.579714e-21   -4.82e-21    0.00e+00   1.13e-16  -1.02e-01  4.37e-03        1    3.12e-03    4.13e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          8.958857e+01
Final                            1.728223e-22
Change                           8.958857e+01

Minimizer iterations                       78
Successful steps                           54
Unsuccessful steps                         24
Line search steps                          45

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0066
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4037
    Line search gradient evaluation    0.2387
  Linear solver                        0.0025
  Line search polynomial minimization  0.0003
Minimizer                              0.4165

Postprocessor                          0.0000
Total                                  0.4166

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.576912e+04
Final                            1.369147e+02
Change                           1.563220e+04

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0010
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0644
    Line search gradient evaluation    0.0324
  Linear solver                        0.0004
  Line search polynomial minimization  0.0000
Minimizer                              0.0662

Postprocessor                          0.0000
Total                                  0.0662

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA83 = {
{-0.0684619,0.4629932,0.2109861}
};
fitErrEl83 = {
{-0.1071473,0.4492328,0.2237122}
};
fitErrLa83 = {
{-0.1086542,0.4791081,0.2331655}
};
fitErrWr83 = {
{-0.2947055,0.4212911,0.3214535}
};
fitErrEe83 = {
{-0.3534433,0.4488272,0.4038159}
};
rMatsBase83 = {
{-0.3329604,0.7164150,-0.6130962},
{0.8175928,0.5432660,0.1907985},
{0.4697652,-0.4377347,-0.7666218}
};
outThetasWam83 = {
{-0.0895518,-0.3056156,-0.0459192,1.3257238,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5133857
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.059371e+02    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.01e-03    3.06e-03
   1  1.285545e+00    1.05e+02    2.80e+00   6.35e-03   1.97e+00  3.00e+04        1    6.13e-03    9.31e-03
   2  1.557986e-07    1.29e+00    2.80e+00   8.27e-05   1.97e+00  9.00e+04        1    5.95e-03    1.53e-02
   3  1.520146e-16    1.56e-07    1.11e-04   2.15e-08   1.97e+00  2.70e+05        1    5.76e-03    2.11e-02
   4  2.172532e-20    1.52e-16    1.07e-05   5.53e-12   1.97e+00  8.10e+05        1    6.06e-03    2.72e-02
   5  1.177733e-20    9.95e-21    9.14e-06   7.86e-15   1.97e+00  2.43e+06        1    5.92e-03    3.31e-02
   6  3.397184e-21    8.38e-21    5.44e-06   3.96e-15   1.97e+00  7.29e+06        1    6.78e-03    3.99e-02
   7  7.922527e-21   -4.53e-21    7.83e-06   5.11e-15   1.97e+00  2.19e+07        1    5.78e-03    4.58e-02
   8  7.889063e-21    3.35e-23    6.56e-06   4.27e-15   1.97e+00  6.56e+07        1    6.01e-03    5.18e-02
   9  4.394441e-22    7.45e-21    1.43e-06   6.08e-15   1.97e+00  1.97e+08        1    5.89e-03    5.77e-02
  10  4.314250e-22    8.02e-24    1.31e-06   5.10e-15   1.97e+00  5.90e+08        1    5.63e-03    6.33e-02
  11  6.614343e-22   -2.30e-22    2.11e-06   2.12e-15   1.97e+00  1.77e+09        1    6.25e-03    6.96e-02
  12  6.914144e-22   -3.00e-23    2.36e-06   1.29e-15   1.97e+00  5.31e+09        1    6.25e-03    7.59e-02
  13  9.142313e-21   -8.45e-21    7.62e-06   1.62e-15   1.97e+00  1.59e+10        1    5.69e-03    8.16e-02
  14  1.639430e-20   -7.25e-21    1.00e-05   8.97e-15   1.97e+00  4.78e+10        1    5.60e-03    8.73e-02
  15  5.375174e-21    1.10e-20    5.20e-06   9.36e-15   1.97e+00  1.43e+11        1    5.63e-03    9.29e-02
  16  6.967497e-22    4.68e-21    2.05e-06   5.82e-15   8.75e-01  2.48e+11        1    5.55e-03    9.85e-02
  17  4.138435e-21   -3.44e-21    4.69e-06   8.53e-16   5.50e-01  2.48e+11        1    6.56e-03    1.05e-01
  18  4.333151e-21   -1.95e-22    6.06e-06   3.34e-15   4.58e-01  2.48e+11        1    5.79e-03    1.11e-01
  19  2.825739e-21    1.51e-21    4.93e-06   5.21e-15   4.43e-01  2.48e+11        1    5.60e-03    1.16e-01
  20  3.051922e-21   -2.26e-22    3.96e-06   4.59e-15   4.00e-01  2.46e+11        1    5.91e-03    1.22e-01
  21  4.670907e-21   -1.62e-21    5.15e-06   6.05e-15   3.23e-01  2.35e+11        1    5.52e-03    1.28e-01
  22  1.103123e-20   -6.36e-21    7.99e-06   4.52e-15   1.31e-01  1.68e+11        1    5.53e-03    1.33e-01
  23  5.129482e-21    5.90e-21    5.56e-06   7.42e-15   5.38e-01  1.68e+11        1    6.64e-03    1.40e-01
  24  1.623998e-21    3.51e-21    3.21e-06   7.14e-15   6.86e-01  1.77e+11        1    5.75e-03    1.46e-01
  25  3.336551e-21   -1.71e-21    4.05e-06   3.12e-15   2.23e-01  1.51e+11        1    5.77e-03    1.52e-01
  26  8.984343e-21   -5.65e-21    6.90e-06   4.29e-15   1.20e-01  1.05e+11        1    5.84e-03    1.58e-01
  27  6.107546e-21    2.88e-21    6.14e-06   8.02e-15   3.23e-01  1.00e+11        1    5.89e-03    1.63e-01
  28  3.604639e-21    2.50e-21    4.16e-06   6.67e-15   4.11e-01  9.99e+10        1    5.91e-03    1.69e-01
  29  3.270165e-21    3.34e-22    5.01e-06   4.93e-15   1.63e-01  7.65e+10        1    6.38e-03    1.76e-01
  30  2.991081e-21    2.79e-22    3.35e-06   1.27e-15   1.60e-01  5.82e+10        1    5.62e-03    1.81e-01
  31  1.148869e-20   -8.50e-21    8.19e-06   3.25e-15   5.66e-02  3.43e+10        1    5.87e-03    1.87e-01
  32  2.484255e-21    9.00e-21    3.43e-06   9.23e-15   7.87e-01  4.23e+10        1    5.84e-03    1.93e-01
  33  5.143140e-22    1.97e-21    1.60e-06   2.96e-15   8.30e-01  5.95e+10        1    5.58e-03    1.99e-01
  34  4.020550e-22    1.12e-22    1.23e-06   1.12e-15   2.47e-01  5.26e+10        1    6.09e-03    2.05e-01
  35  2.593474e-21   -2.19e-21    2.89e-06   2.62e-15   1.36e-01  3.80e+10        1    5.92e-03    2.11e-01
  36  3.063463e-21   -4.70e-22    5.27e-06   4.59e-15   1.28e-01  2.69e+10        1    5.70e-03    2.17e-01
  37  4.898027e-21   -1.83e-21    4.90e-06   3.61e-15   1.08e-01  1.82e+10        1    5.99e-03    2.23e-01
  38  2.193047e-21    2.70e-21    2.96e-06   6.77e-15   5.55e-01  1.82e+10        1    5.75e-03    2.28e-01
  39  1.810239e-21    3.83e-22    3.87e-06   7.23e-15   1.76e-01  1.43e+10        1    5.66e-03    2.34e-01
  40  1.407540e-21    4.03e-22    3.55e-06   2.45e-15   3.94e-01  1.42e+10        1    6.29e-03    2.40e-01
  41  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  7.08e+09        1    3.13e-03    2.44e-01
  42  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  1.77e+09        1    2.89e-03    2.47e-01
  43  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  2.21e+08        1    2.88e-03    2.50e-01
  44  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  1.38e+07        1    2.94e-03    2.53e-01
  45  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  4.32e+05        1    3.25e-03    2.56e-01
  46  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  6.75e+03        1    2.98e-03    2.59e-01
  47  8.912286e-21   -7.50e-21    0.00e+00   2.67e-15  -3.92e-01  5.27e+01        1    2.90e-03    2.62e-01
  48  3.875903e-22    1.02e-21    1.42e-06   1.79e-15   7.35e-01  5.88e+01        1    5.65e-03    2.67e-01
  49  2.293047e-22    1.58e-22    8.97e-07   1.45e-15   5.09e-01  5.88e+01        1    6.27e-03    2.74e-01
  50  8.485192e-21   -8.26e-21    0.00e+00   7.69e-16  -3.34e-01  2.94e+01        1    3.12e-03    2.77e-01
  51  4.030950e-21   -3.80e-21    4.51e-06   6.34e-16   8.06e-02  1.85e+01        1    5.71e-03    2.83e-01
  52  9.306184e-22    3.10e-21    2.28e-06   2.95e-15   7.74e-01  2.21e+01        1    5.63e-03    2.88e-01
  53  1.782546e-21   -8.52e-22    2.93e-06   2.02e-15   1.99e-01  1.82e+01        1    5.91e-03    2.94e-01
  54  9.236101e-22    8.59e-22    2.34e-06   1.73e-15   5.02e-01  1.82e+01        1    5.67e-03    3.00e-01
  55  3.587251e-22    5.65e-22    1.45e-06   6.88e-16   6.57e-01  1.88e+01        1    6.06e-03    3.06e-01
  56  5.642055e-23    3.02e-22    3.73e-07   9.09e-16   8.94e-01  3.67e+01        1    6.03e-03    3.12e-01
  57  7.926615e-22   -7.36e-22    2.27e-06   9.98e-16   4.13e-01  3.65e+01        1    5.61e-03    3.18e-01
  58  2.810788e-21   -2.02e-21    3.79e-06   1.24e-15   1.42e-01  2.68e+01        1    6.00e-03    3.24e-01
  59  1.172950e-20   -8.92e-21    0.00e+00   2.01e-15  -6.85e-01  1.34e+01        1    2.98e-03    3.27e-01
  60  9.338741e-21   -6.53e-21    0.00e+00   1.76e-15  -4.73e-01  3.34e+00        1    2.86e-03    3.29e-01
  61  3.555368e-21   -7.45e-22    4.38e-06   1.59e-15   4.25e-02  1.89e+00        1    5.56e-03    3.35e-01
  62  3.843131e-21   -2.88e-22    5.11e-06   1.19e-15   1.29e-02  9.84e-01        1    6.27e-03    3.41e-01
  63  3.278107e-21    5.65e-22    4.28e-06   1.53e-15   1.60e-01  7.48e-01        1    5.82e-03    3.47e-01
  64  1.170973e-21    2.11e-21    2.60e-06   1.47e-15   7.58e-01  8.67e-01        1    5.67e-03    3.53e-01
  65  3.604986e-21   -2.43e-21    4.94e-06   7.24e-16   3.23e-02  4.77e-01        1    5.89e-03    3.59e-01
  66  2.260872e-21    1.34e-21    3.60e-06   1.18e-15   4.46e-01  4.76e-01        1    5.61e-03    3.64e-01
  67  3.847207e-21   -1.59e-21    0.00e+00   6.17e-16  -3.36e-04  2.38e-01        1    2.85e-03    3.67e-01
  68  1.196947e-21    1.06e-21    3.06e-06   4.62e-16   7.67e-01  2.81e-01        1    6.38e-03    3.74e-01
  69  3.043093e-21   -1.85e-21    4.46e-06   4.84e-16   6.34e-02  1.69e-01        1    6.02e-03    3.80e-01
  70  4.548286e-21   -1.51e-21    0.00e+00   6.14e-16  -4.91e-02  8.43e-02        1    2.90e-03    3.83e-01
  71  8.857466e-22    2.16e-21    1.83e-06   3.61e-16   1.89e+00  2.53e-01        1    5.60e-03    3.88e-01
  72  3.880320e-22    4.98e-22    1.48e-06   3.22e-16   1.04e+00  7.59e-01        1    6.08e-03    3.94e-01
  73  1.009812e-21   -6.22e-22    2.37e-06   3.82e-16   1.95e-01  6.18e-01        1    5.64e-03    4.00e-01
  74  4.655538e-22    5.44e-22    1.77e-06   4.84e-16   6.65e-01  6.41e-01        1    6.12e-03    4.06e-01
  75  1.374499e-21   -9.09e-22    3.43e-06   3.39e-16   1.57e-01  4.84e-01        1    6.06e-03    4.12e-01
  76  8.336529e-21   -6.96e-21    0.00e+00   4.76e-16  -2.67e-01  2.42e-01        1    3.08e-03    4.15e-01
  77  2.792456e-21   -1.42e-21    3.34e-06   3.40e-16   6.32e-02  1.45e-01        1    5.73e-03    4.21e-01
  78  5.614346e-21   -2.82e-21    0.00e+00   5.43e-16  -9.85e-02  7.26e-02        1    3.15e-03    4.24e-01
  79  4.644672e-21   -1.85e-21    0.00e+00   3.01e-16  -4.58e-02  1.82e-02        1    2.94e-03    4.27e-01
  80  5.527878e-21   -2.74e-21    0.00e+00   4.35e-17  -9.97e-02  2.27e-03        1    3.00e-03    4.30e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.059371e+02
Final                            5.642055e-23
Change                           1.059371e+02

Minimizer iterations                       81
Successful steps                           65
Unsuccessful steps                         16
Line search steps                          44

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0065
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4198
    Line search gradient evaluation    0.2331
  Linear solver                        0.0029
  Line search polynomial minimization  0.0004
Minimizer                              0.4331

Postprocessor                          0.0000
Total                                  0.4332

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.575479e+04
Final                            1.375354e+02
Change                           1.561725e+04

Minimizer iterations                       94
Successful steps                           46
Unsuccessful steps                         48
Line search steps                          65

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0073
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3926
    Line search gradient evaluation    0.2628
  Linear solver                        0.0019
  Line search polynomial minimization  0.0003
Minimizer                              0.4038

Postprocessor                          0.0000
Total                                  0.4039

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA84 = {
{-0.0703687,0.4719702,0.2150775}
};
fitErrEl84 = {
{-0.1097969,0.4579004,0.2280351}
};
fitErrLa84 = {
{-0.1113228,0.4885997,0.2377874}
};
fitErrWr84 = {
{-0.3027109,0.4296408,0.3281042}
};
fitErrEe84 = {
{-0.3613003,0.4572637,0.4112854}
};
rMatsBase84 = {
{-0.3359349,0.7190911,-0.6083221},
{0.8150863,0.5455972,0.1948280},
{0.4719979,-0.4303855,-0.7694065}
};
outThetasWam84 = {
{-0.0890883,-0.3004851,-0.0445332,1.3238652,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5234176
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.097437e+02    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.09e-03    3.13e-03
   1  1.742370e+00    1.08e+02    2.81e+00   7.24e-03   1.97e+00  3.00e+04        1    5.87e-03    9.03e-03
   2  5.214924e-07    1.74e+00    2.81e+00   1.13e-04   1.96e+00  9.00e+04        1    5.82e-03    1.49e-02
   3  5.744239e-17    5.21e-07    1.56e-04   3.61e-08   1.96e+00  2.70e+05        1    5.63e-03    2.05e-02
   4  5.082599e-21    5.74e-17    5.34e-06   1.03e-12   1.96e+00  8.10e+05        1    5.53e-03    2.61e-02
   5  1.045660e-21    4.04e-21    2.24e-06   1.16e-14   1.96e+00  2.43e+06        1    5.76e-03    3.18e-02
   6  2.339967e-20   -2.24e-20    1.21e-05   4.69e-15   1.96e+00  7.29e+06        1    5.68e-03    3.75e-02
   7  1.165071e-20    1.17e-20    7.97e-06   1.27e-14   1.96e+00  2.19e+07        1    5.53e-03    4.31e-02
   8  1.008977e-20    1.56e-21    6.82e-06   9.99e-15   1.96e+00  6.56e+07        1    6.28e-03    4.94e-02
   9  3.376003e-21    6.71e-21    4.14e-06   7.43e-15   1.96e+00  1.97e+08        1    6.03e-03    5.55e-02
  10  1.359743e-20   -1.02e-20    8.94e-06   6.48e-15   1.96e+00  5.90e+08        1    5.56e-03    6.10e-02
  11  8.694141e-21    4.90e-21    7.03e-06   6.19e-15   3.61e-01  5.78e+08        1    5.56e-03    6.66e-02
  12  8.821069e-21   -1.27e-22    6.90e-06   8.13e-15   2.07e-01  4.81e+08        1    5.63e-03    7.23e-02
  13  4.624031e-21    4.20e-21    5.20e-06   5.12e-15   4.83e-01  4.81e+08        1    5.50e-03    7.78e-02
  14  5.086738e-21   -4.63e-22    6.61e-06   5.52e-15   2.19e-01  4.08e+08        1    5.88e-03    8.37e-02
  15  9.562120e-21   -4.48e-21    6.18e-06   4.68e-15   1.56e-01  3.08e+08        1    6.14e-03    8.99e-02
  16  3.712093e-21    5.85e-21    4.64e-06   7.51e-15   6.15e-01  3.12e+08        1    5.73e-03    9.56e-02
  17  1.228358e-20   -8.57e-21    9.13e-06   2.67e-15   1.09e-01  2.11e+08        1    5.95e-03    1.02e-01
  18  1.193689e-21    1.11e-20    1.90e-06   6.52e-15   9.06e-01  4.53e+08        1    5.64e-03    1.07e-01
  19  1.162275e-21    3.14e-23    1.99e-06   1.64e-15   1.93e-01  3.68e+08        1    5.76e-03    1.13e-01
  20  2.481116e-21   -1.32e-21    3.87e-06   1.66e-15   1.80e-01  2.91e+08        1    6.00e-03    1.19e-01
  21  5.454828e-21   -2.97e-21    5.40e-06   4.67e-15   1.51e-01  2.17e+08        1    5.82e-03    1.25e-01
  22  9.693760e-21   -4.24e-21    6.52e-06   5.15e-15   1.10e-01  1.47e+08        1    5.53e-03    1.30e-01
  23  7.861836e-21    1.83e-21    6.58e-06   9.21e-15   1.92e-01  1.20e+08        1    6.57e-03    1.37e-01
  24  2.041784e-21    5.82e-21    4.05e-06   9.20e-15   7.43e-01  1.35e+08        1    5.84e-03    1.43e-01
  25  1.676322e-21    3.65e-22    3.49e-06   3.16e-15   1.82e-01  1.07e+08        1    5.75e-03    1.49e-01
  26  6.031375e-21   -4.36e-21    7.13e-06   2.70e-15   1.20e-01  7.45e+07        1    5.98e-03    1.55e-01
  27  7.017093e-21   -9.86e-22    6.57e-06   3.50e-15   1.08e-01  5.03e+07        1    5.69e-03    1.60e-01
  28  2.041799e-20   -1.34e-20    1.16e-05   5.36e-15   1.88e-02  2.66e+07        1    5.91e-03    1.66e-01
  29  6.704133e-21    1.37e-20    6.46e-06   1.02e-14   6.72e-01  2.77e+07        1    6.03e-03    1.72e-01
  30  2.521787e-20   -1.85e-20    0.00e+00   5.36e-15  -9.81e-03  1.39e+07        1    2.86e-03    1.75e-01
  31  2.521787e-20   -1.85e-20    0.00e+00   5.36e-15  -9.81e-03  3.47e+06        1    3.49e-03    1.79e-01
  32  2.521787e-20   -1.85e-20    0.00e+00   5.36e-15  -9.81e-03  4.33e+05        1    3.10e-03    1.82e-01
  33  2.365878e-20   -1.70e-20    0.00e+00   5.36e-15  -1.40e-03  2.71e+04        1    3.02e-03    1.85e-01
  34  2.365878e-20   -1.70e-20    0.00e+00   5.36e-15  -1.40e-03  8.46e+02        1    3.10e-03    1.88e-01
  35  1.119273e-21    5.58e-21    2.38e-06   5.37e-15   8.37e-01  1.22e+03        1    5.65e-03    1.94e-01
  36  1.039868e-21    7.94e-23    1.90e-06   1.99e-15   1.20e-01  8.47e+02        1    5.66e-03    1.99e-01
  37  1.184723e-21   -1.45e-22    2.69e-06   4.31e-15   1.19e-01  5.87e+02        1    6.03e-03    2.05e-01
  38  2.070044e-21   -8.85e-22    3.64e-06   2.70e-15   1.13e-01  4.01e+02        1    5.74e-03    2.11e-01
  39  4.675936e-21   -2.61e-21    5.52e-06   3.81e-15   9.83e-02  2.64e+02        1    5.69e-03    2.17e-01
  40  1.559684e-21    3.12e-21    3.31e-06   5.57e-15   6.67e-01  2.74e+02        1    6.31e-03    2.23e-01
  41  5.220809e-21   -3.66e-21    4.73e-06   1.54e-15   9.24e-02  1.78e+02        1    6.22e-03    2.30e-01
  42  5.677076e-21   -4.56e-22    0.00e+00   5.41e-15  -8.90e-02  8.89e+01        1    2.97e-03    2.33e-01
  43  3.687529e-21    1.53e-21    5.71e-06   4.96e-15   2.99e-01  8.36e+01        1    5.87e-03    2.38e-01
  44  3.960130e-21   -2.73e-22    4.65e-06   2.03e-15   1.44e-01  6.14e+01        1    5.77e-03    2.44e-01
  45  8.278532e-21   -4.32e-21    0.00e+00   2.15e-15  -2.42e-01  3.07e+01        1    2.86e-03    2.47e-01
  46  3.039887e-21    9.20e-22    5.05e-06   2.14e-15   2.35e-01  2.67e+01        1    5.84e-03    2.53e-01
  47  8.287316e-21   -5.25e-21    0.00e+00   1.99e-15  -1.97e-01  1.34e+01        1    3.03e-03    2.56e-01
  48  5.617274e-21   -2.58e-21    0.00e+00   1.56e-15  -2.54e-02  3.34e+00        1    3.04e-03    2.59e-01
  49  7.005525e-21   -3.97e-21    0.00e+00   1.22e-15  -1.15e-01  4.18e-01        1    2.94e-03    2.62e-01
  50  8.271716e-21   -5.23e-21    0.00e+00   7.19e-16  -2.03e-01  2.61e-02        1    3.05e-03    2.65e-01
  51  4.741236e-21   -1.70e-21    5.88e-06   6.63e-17   3.67e-02  1.45e-02        1    6.44e-03    2.72e-01
  52  4.198196e-21    5.43e-22    5.96e-06   5.03e-17   1.46e+00  4.36e-02        1    6.10e-03    2.78e-01
  53  2.331326e-21    1.87e-21    3.78e-06   1.75e-16   2.04e+00  1.31e-01        1    5.90e-03    2.84e-01
  54  9.264870e-21   -6.93e-21    0.00e+00   5.44e-16  -2.61e-01  6.54e-02        1    3.00e-03    2.87e-01
  55  1.274825e-20   -1.04e-20    0.00e+00   2.83e-16  -4.99e-01  1.64e-02        1    3.07e-03    2.90e-01
  56  2.186847e-21    1.44e-22    3.57e-06   1.56e-17   6.35e-01  1.67e-02        1    6.07e-03    2.96e-01
  57  2.752197e-22    1.91e-21    1.23e-06   1.40e-17   8.40e+00  5.01e-02        1    5.70e-03    3.02e-01
  58  2.752197e-22   -4.70e-38    1.23e-06   1.55e-17   3.32e-01  4.82e-02        1    5.89e-03    3.07e-01
  59  1.291718e-21   -1.02e-21    2.76e-06   1.55e-17   2.63e-01  4.36e-02        1    6.44e-03    3.14e-01
  60  4.509636e-21   -3.22e-21    4.49e-06   2.50e-16   4.67e-02  2.50e-02        1    5.87e-03    3.20e-01
  61  4.926805e-21   -4.17e-22    5.70e-06   8.05e-17   1.86e-02  1.32e-02        1    5.93e-03    3.26e-01
  62  3.095787e-21    1.83e-21    4.88e-06   4.44e-17   5.40e+00  3.96e-02        1    5.84e-03    3.32e-01
  63  3.716295e-21   -6.21e-22    4.80e-06   9.81e-17   1.30e+00  1.19e-01        1    5.69e-03    3.37e-01
  64  2.114129e-21    1.60e-21    2.96e-06   3.79e-16   1.14e+00  3.56e-01        1    6.03e-03    3.43e-01
  65  9.248451e-21   -7.13e-21    0.00e+00   8.06e-16  -1.11e+00  1.78e-01        1    3.02e-03    3.47e-01
  66  1.339555e-20   -1.13e-20    0.00e+00   5.29e-16  -2.40e+00  4.46e-02        1    2.95e-03    3.49e-01
  67  1.512716e-21    6.01e-22    2.88e-06   2.35e-16   1.49e+00  1.34e-01        1    5.75e-03    3.55e-01
  68  5.930914e-21   -4.42e-21    0.00e+00   3.53e-16  -2.83e-01  6.68e-02        1    3.46e-03    3.59e-01
  69  5.571548e-21   -4.06e-21    0.00e+00   2.59e-16  -1.95e-01  1.67e-02        1    3.22e-03    3.62e-01
  70  4.587084e-21   -3.07e-21    4.98e-06   1.39e-17   1.13e-01  1.14e-02        1    5.80e-03    3.68e-01
  71  4.317485e-21    2.70e-22    5.11e-06   2.69e-17   9.61e-01  3.42e-02        1    5.75e-03    3.74e-01
  72  7.218509e-21   -2.90e-21    0.00e+00   2.58e-16  -5.59e-01  1.71e-02        1    3.13e-03    3.77e-01
  73  4.238275e-21    7.92e-23    4.52e-06   1.14e-16   1.85e-01  1.37e-02        1    5.68e-03    3.82e-01
  74  4.334786e-21   -9.65e-23    5.11e-06   1.12e-16   1.43e-01  1.00e-02        1    5.64e-03    3.88e-01
  75  4.051980e-21    2.83e-22    4.91e-06   1.56e-17   1.12e+00  3.01e-02        1    5.70e-03    3.94e-01
  76  3.570341e-21    4.82e-22    4.55e-06   2.59e-16   7.65e-01  3.54e-02        1    5.78e-03    4.00e-01
  77  4.548057e-21   -9.78e-22    5.16e-06   2.62e-16   6.57e-02  2.14e-02        1    6.04e-03    4.06e-01
  78  2.763420e-20   -2.31e-20    0.00e+00   1.26e-16  -3.55e+00  1.07e-02        1    2.90e-03    4.09e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.097437e+02
Final                            2.752197e-22
Change                           1.097437e+02

Minimizer iterations                       79
Successful steps                           60
Unsuccessful steps                         19
Line search steps                          46

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0066
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3991
    Line search gradient evaluation    0.2286
  Linear solver                        0.0027
  Line search polynomial minimization  0.0004
Minimizer                              0.4119

Postprocessor                          0.0000
Total                                  0.4119

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.577883e+04
Final                            1.374537e+02
Change                           1.564138e+04

Minimizer iterations                      446
Successful steps                          312
Unsuccessful steps                        134
Line search steps                         729

Time (in seconds):
Preprocessor                           0.0002

  Residual evaluation                  0.0327
    Line search cost evaluation        0.0000
  Jacobian evaluation                  3.3696
    Line search gradient evaluation    2.5102
  Linear solver                        0.0074
  Line search polynomial minimization  0.0053
Minimizer                              3.4224

Postprocessor                          0.0000
Total                                  3.4227

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA85 = {
{-0.0713782,0.4785297,0.2182115}
};
fitErrEl85 = {
{-0.1113598,0.4642172,0.2313387}
};
fitErrLa85 = {
{-0.1128935,0.4955905,0.2413479}
};
fitErrWr85 = {
{-0.3086762,0.4354143,0.3332998}
};
fitErrEe85 = {
{-0.3673621,0.4631367,0.4170815}
};
rMatsBase85 = {
{-0.3203869,0.7082729,-0.6290483},
{0.8265465,0.5334331,0.1796388},
{0.4627884,-0.4623837,-0.7563254}
};
outThetasWam85 = {
{-0.1068696,-0.2641458,-0.0534739,1.3240125,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5307558
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.203898e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    3.26e-03    3.30e-03
   1  1.106709e+00    1.19e+02    2.81e+00   6.19e-03   1.98e+00  3.00e+04        1    6.21e-03    9.54e-03
   2  1.098767e-07    1.11e+00    2.81e+00   8.43e-05   1.98e+00  9.00e+04        1    6.14e-03    1.57e-02
   3  9.712413e-16    1.10e-07    1.33e-04   4.11e-08   1.98e+00  2.70e+05        1    6.14e-03    2.19e-02
   4  1.395385e-20    9.71e-16    6.53e-06   1.46e-11   1.98e+00  8.10e+05        1    6.13e-03    2.80e-02
   5  2.347598e-21    1.16e-20    4.16e-06   1.37e-14   1.98e+00  2.43e+06        1    6.08e-03    3.41e-02
   6  1.794543e-21    5.53e-22    3.47e-06   1.24e-15   1.98e+00  7.29e+06        1    6.11e-03    4.02e-02
   7  9.741799e-22    8.20e-22    1.80e-06   1.73e-15   1.98e+00  2.19e+07        1    6.26e-03    4.65e-02
   8  3.452259e-21   -2.48e-21    4.50e-06   3.78e-15   1.98e+00  6.56e+07        1    6.14e-03    5.27e-02
   9  1.202297e-22    3.33e-21    5.97e-07   3.95e-15   1.98e+00  1.97e+08        1    6.14e-03    5.88e-02
  10  5.743810e-22   -4.54e-22    2.15e-06   2.37e-15   1.98e+00  5.90e+08        1    6.70e-03    6.55e-02
  11  1.439346e-21   -8.65e-22    3.08e-06   2.47e-15   1.98e+00  1.77e+09        1    6.23e-03    7.18e-02
  12  6.791736e-21   -5.35e-21    5.74e-06   2.71e-15   1.98e+00  5.31e+09        1    6.36e-03    7.82e-02
  13  1.523049e-20   -8.44e-21    1.00e-05   4.38e-15   1.98e+00  1.59e+10        1    6.13e-03    8.44e-02
  14  9.320774e-23    1.51e-20    6.03e-07   9.79e-15   1.98e+00  4.78e+10        1    6.17e-03    9.06e-02
  15  7.539011e-21   -7.45e-21    6.44e-06   2.62e-15   1.98e+00  1.43e+11        1    6.16e-03    9.67e-02
  16  2.121408e-21    5.42e-21    3.81e-06   9.34e-15   1.98e+00  4.30e+11        1    6.13e-03    1.03e-01
  17  7.550204e-21   -5.43e-21    7.06e-06   1.41e-15   1.98e+00  1.29e+12        1    6.28e-03    1.09e-01
  18  1.832330e-20   -1.08e-20    1.06e-05   7.63e-15   1.98e+00  3.87e+12        1    6.10e-03    1.15e-01
  19  1.605776e-21    1.67e-20    2.99e-06   1.32e-14   1.98e+00  1.16e+13        1    6.60e-03    1.22e-01
  20  9.006401e-21   -7.40e-21    7.86e-06   1.55e-15   4.70e-01  1.16e+13        1    6.22e-03    1.28e-01
  21  1.277926e-20   -3.77e-21    8.73e-06   5.26e-15   1.92e-01  9.43e+12        1    6.13e-03    1.34e-01
  22  7.078075e-21    5.70e-21    7.33e-06   5.96e-15   4.48e-01  9.41e+12        1    6.08e-03    1.40e-01
  23  1.943957e-21    5.13e-21    4.22e-06   3.59e-15   7.32e-01  1.05e+13        1    6.22e-03    1.47e-01
  24  1.899114e-21    4.48e-23    3.52e-06   2.40e-15   3.25e-01  1.00e+13        1    6.41e-03    1.53e-01
  25  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  5.02e+12        1    3.24e-03    1.56e-01
  26  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  1.25e+12        1    3.13e-03    1.59e-01
  27  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  1.57e+11        1    3.14e-03    1.63e-01
  28  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  9.80e+09        1    3.13e-03    1.66e-01
  29  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  3.06e+08        1    3.13e-03    1.69e-01
  30  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  4.78e+06        1    3.12e-03    1.72e-01
  31  3.005666e-20   -2.82e-20    0.00e+00   3.83e-15  -2.24e-01  3.74e+04        1    3.27e-03    1.75e-01
  32  1.244876e-20   -1.05e-20    8.16e-06   3.61e-15   1.12e-01  2.55e+04        1    6.11e-03    1.81e-01
  33  1.409223e-21    1.10e-20    2.79e-06   6.98e-15   8.95e-01  5.04e+04        1    6.52e-03    1.88e-01
  34  2.747789e-21   -1.34e-21    4.15e-06   1.08e-15   2.36e-01  4.39e+04        1    6.20e-03    1.94e-01
  35  5.986296e-21   -3.24e-21    6.36e-06   4.31e-15   1.80e-01  3.48e+04        1    6.11e-03    2.00e-01
  36  2.728690e-21    3.26e-21    4.22e-06   5.79e-15   5.45e-01  3.48e+04        1    6.12e-03    2.06e-01
  37  1.038615e-20   -7.66e-21    8.49e-06   2.74e-15   1.03e-01  2.32e+04        1    6.27e-03    2.13e-01
  38  4.286187e-22    9.96e-21    1.67e-06   6.26e-15   9.62e-01  6.96e+04        1    6.22e-03    2.19e-01
  39  1.863259e-21   -1.43e-21    3.09e-06   1.14e-15   1.87e-01  5.59e+04        1    6.44e-03    2.25e-01
  40  1.336509e-21    5.27e-22    3.00e-06   3.93e-15   2.84e-01  5.17e+04        1    6.15e-03    2.32e-01
  41  3.920608e-21   -2.58e-21    4.63e-06   2.24e-15   1.58e-01  3.92e+04        1    6.15e-03    2.38e-01
  42  2.500175e-22    3.67e-21    5.21e-07   2.88e-15   9.43e-01  1.18e+05        1    6.27e-03    2.44e-01
  43  4.115628e-21   -3.87e-21    5.97e-06   4.24e-15   1.49e-01  8.74e+04        1    6.14e-03    2.50e-01
  44  5.917243e-21   -1.80e-21    4.46e-06   1.58e-15   1.25e-01  6.14e+04        1    6.51e-03    2.57e-01
  45  2.073488e-22    5.71e-21    9.96e-07   4.54e-15   9.68e-01  1.84e+05        1    6.12e-03    2.63e-01
  46  7.802196e-22   -5.73e-22    2.20e-06   5.02e-16   1.66e-01  1.42e+05        1    6.15e-03    2.69e-01
  47  5.030891e-21   -4.25e-21    5.82e-06   1.20e-15   1.25e-01  1.00e+05        1    6.26e-03    2.75e-01
  48  8.109791e-21   -3.08e-21    7.26e-06   4.49e-15   9.20e-02  6.48e+04        1    6.14e-03    2.81e-01
  49  1.073781e-20   -2.63e-21    8.60e-06   7.19e-15   6.37e-02  3.89e+04        1    6.43e-03    2.88e-01
  50  1.899320e-20   -8.26e-21    0.00e+00   5.88e-15  -5.16e-03  1.95e+04        1    3.33e-03    2.91e-01
  51  1.899320e-20   -8.26e-21    0.00e+00   5.88e-15  -5.16e-03  4.86e+03        1    3.15e-03    2.94e-01
  52  1.838142e-20   -7.64e-21    0.00e+00   5.66e-15  -4.48e-04  6.08e+02        1    3.21e-03    2.98e-01
  53  2.128560e-20   -1.05e-20    0.00e+00   5.69e-15  -2.28e-02  3.80e+01        1    3.14e-03    3.01e-01
  54  5.174335e-22    1.02e-20    1.57e-06   4.82e-15   9.60e-01  1.14e+02        1    6.11e-03    3.07e-01
  55  1.068257e-20   -1.02e-20    8.41e-06   2.05e-15   5.87e-02  6.76e+01        1    6.15e-03    3.13e-01
  56  5.273936e-22    1.02e-20    1.71e-06   6.70e-15   9.54e-01  2.03e+02        1    6.28e-03    3.19e-01
  57  4.548053e-21   -4.02e-21    5.99e-06   1.79e-15   9.75e-02  1.33e+02        1    6.15e-03    3.26e-01
  58  2.437921e-22    4.30e-21    8.34e-07   2.52e-15   9.65e-01  4.00e+02        1    6.87e-03    3.32e-01
  59  1.464704e-20   -1.44e-20    9.89e-06   8.45e-16   2.52e-02  2.15e+02        1    6.43e-03    3.39e-01
  60  1.685644e-20   -2.21e-21    1.06e-05   9.38e-15   9.14e-03  1.11e+02        1    6.14e-03    3.45e-01
  61  7.926903e-21    8.93e-21    7.28e-06   6.72e-15   5.31e-01  1.11e+02        1    6.14e-03    3.51e-01
  62  1.289700e-20   -4.97e-21    9.07e-06   5.20e-15   2.93e-02  6.03e+01        1    6.28e-03    3.58e-01
  63  1.197282e-20    9.24e-22    8.42e-06   8.25e-15   7.24e-02  3.71e+01        1    6.23e-03    3.64e-01
  64  1.715098e-21    1.03e-20    3.42e-06   5.73e-15   8.64e-01  6.03e+01        1    6.72e-03    3.70e-01
  65  5.384940e-22    1.18e-21    1.99e-06   1.42e-15   6.92e-01  6.39e+01        1    6.23e-03    3.77e-01
  66  7.724440e-22   -2.34e-22    1.52e-06   1.77e-15   8.28e-02  4.04e+01        1    6.17e-03    3.83e-01
  67  2.095230e-20   -2.02e-20    0.00e+00   1.84e-15  -1.24e-02  2.02e+01        1    3.13e-03    3.86e-01
  68  2.585506e-21   -1.81e-21    4.65e-06   1.34e-15   7.40e-02  1.25e+01        1    6.13e-03    3.92e-01
  69  3.689857e-22    2.22e-21    1.79e-06   1.34e-15   8.71e-01  2.11e+01        1    6.28e-03    3.99e-01
  70  7.174200e-22   -3.48e-22    2.25e-06   4.50e-16   8.17e-02  1.33e+01        1    6.16e-03    4.05e-01
  71  6.779222e-21   -6.06e-21    5.17e-06   8.69e-16   5.34e-02  7.77e+00        1    6.83e-03    4.12e-01
  72  5.317191e-21    1.46e-21    6.78e-06   2.44e-15   2.31e-01  6.72e+00        1    6.39e-03    4.18e-01
  73  1.049074e-20   -5.17e-21    9.10e-06   1.47e-15   3.44e-02  3.72e+00        1    6.17e-03    4.24e-01
  74  1.875205e-20   -8.26e-21    0.00e+00   2.73e-15  -1.80e-03  1.86e+00        1    3.15e-03    4.27e-01
  75  4.772120e-21    5.72e-21    6.71e-06   2.49e-15   5.58e-01  1.86e+00        1    6.28e-03    4.34e-01
  76  7.769846e-21   -3.00e-21    6.76e-06   1.20e-15   4.35e-02  1.06e+00        1    6.16e-03    4.40e-01
  77  2.863900e-20   -2.09e-20    0.00e+00   2.38e-15  -4.13e-02  5.29e-01        1    3.72e-03    4.43e-01
  78  3.903349e-21    3.87e-21    5.30e-06   1.89e-15   5.83e-01  5.31e-01        1    6.74e-03    4.50e-01
  79  3.196050e-21    7.07e-22    4.69e-06   1.24e-15   2.08e-01  4.43e-01        1    6.14e-03    4.56e-01
  80  3.969963e-21   -7.74e-22    5.87e-06   1.15e-15   5.62e-02  2.61e-01        1    6.16e-03    4.63e-01
  81  9.393459e-21   -5.42e-21    7.28e-06   6.09e-16   3.46e-02  1.44e-01        1    6.31e-03    4.69e-01
  82  2.108972e-21    7.28e-21    3.65e-06   1.02e-15   1.35e+00  4.33e-01        1    6.16e-03    4.75e-01
  83  1.614995e-20   -1.40e-20    1.04e-05   7.79e-16   8.20e-03  2.22e-01        1    6.91e-03    4.82e-01
  84  3.178877e-21    1.30e-20    4.25e-06   1.80e-15   1.21e+00  6.66e-01        1    6.11e-03    4.88e-01
  85  1.525677e-21    1.65e-21    3.31e-06   8.07e-16   6.65e-01  6.91e-01        1    6.15e-03    4.94e-01
  86  9.395065e-21   -7.87e-21    8.13e-06   5.64e-16   3.19e-02  3.79e-01        1    6.28e-03    5.01e-01
  87  6.723839e-21    2.67e-21    6.61e-06   1.80e-15   3.55e-01  3.70e-01        1    6.14e-03    5.07e-01
  88  2.862057e-20   -2.19e-20    0.00e+00   1.50e-15  -3.52e-02  1.85e-01        1    3.65e-03    5.10e-01
  89  1.522481e-20   -8.50e-21    9.59e-06   9.45e-16   1.06e-02  9.56e-02        1    6.76e-03    5.17e-01
  90  8.717641e-21    6.51e-21    6.97e-06   1.00e-15   9.62e-01  2.87e-01        1    6.12e-03    5.23e-01
  91  5.451312e-21    3.27e-21    4.73e-06   1.52e-15   5.13e-01  2.87e-01        1    6.15e-03    5.30e-01
  92  8.111859e-21   -2.66e-21    6.86e-06   9.38e-16   3.32e-02  1.58e-01        1    6.30e-03    5.36e-01
  93  2.762420e-21    5.35e-21    4.40e-06   9.04e-16   1.26e+00  4.74e-01        1    6.14e-03    5.42e-01
  94  6.098074e-22    2.15e-21    1.39e-06   9.63e-16   9.30e-01  1.30e+00        1    6.89e-03    5.49e-01
  95  1.937612e-20   -1.88e-20    0.00e+00   5.68e-16  -3.34e-03  6.51e-01        1    3.11e-03    5.52e-01
  96  2.052071e-21   -1.44e-21    4.33e-06   5.33e-16   5.17e-02  3.78e-01        1    6.16e-03    5.58e-01
  97  2.933400e-22    1.76e-21    9.56e-07   6.29e-16   1.06e+00  1.14e+00        1    6.29e-03    5.64e-01
  98  1.288528e-20   -1.26e-20    9.10e-06   3.42e-16   1.72e-02  5.97e-01        1    6.16e-03    5.71e-01
  99  3.943471e-21    8.94e-21    4.47e-06   2.52e-15   7.94e-01  7.50e-01        1    6.69e-03    5.77e-01
 100  1.702396e-20   -1.31e-20    9.37e-06   1.39e-15   3.92e-03  3.79e-01        1    6.81e-03    5.84e-01
 101  7.894410e-21    9.13e-21    7.66e-06   2.21e-15   6.56e-01  3.91e-01        1    6.18e-03    5.90e-01
 102  6.004699e-21    1.89e-21    6.38e-06   1.03e-15   3.11e-01  3.71e-01        1    6.15e-03    5.97e-01
 103  1.115720e-20   -5.15e-21    8.52e-06   1.48e-15   2.01e-02  1.97e-01        1    6.30e-03    6.03e-01
 104  7.633990e-21    3.52e-21    6.96e-06   1.44e-15   5.03e-01  1.97e-01        1    6.13e-03    6.09e-01
 105  1.982642e-21    5.65e-21    4.31e-06   1.18e-15   1.14e+00  5.91e-01        1    6.94e-03    6.16e-01
 106  5.407189e-21   -3.42e-21    6.26e-06   7.30e-16   3.49e-02  3.27e-01        1    6.14e-03    6.22e-01
 107  6.166289e-21   -7.59e-22    5.60e-06   1.14e-15   3.25e-02  1.80e-01        1    6.16e-03    6.28e-01
 108  7.380917e-21   -1.21e-21    6.36e-06   8.74e-16   2.90e-02  9.81e-02        1    6.26e-03    6.35e-01
 109  1.471951e-21    5.91e-21    3.18e-06   6.79e-16   1.84e+00  2.94e-01        1    6.15e-03    6.41e-01
 110  1.249087e-22    1.35e-21    6.65e-07   6.06e-16   1.35e+00  8.83e-01        1    6.87e-03    6.48e-01
 111  3.560150e-21   -3.44e-21    4.41e-06   2.49e-16   3.87e-02  4.95e-01        1    6.15e-03    6.54e-01
 112  5.847777e-23    3.50e-21    1.53e-07   1.24e-15   1.19e+00  1.48e+00        1    6.15e-03    6.60e-01
 113  1.666812e-22   -1.08e-22    6.99e-07   2.22e-16   4.72e-02  8.51e-01        1    6.24e-03    6.66e-01
 114  1.107481e-22    5.59e-23    4.72e-07   1.39e-16   9.33e-01  2.43e+00        1    6.11e-03    6.72e-01
 115  1.004803e-21   -8.94e-22    2.47e-06   1.52e-16   4.50e-02  1.39e+00        1    6.14e-03    6.79e-01
 116  2.312138e-22    7.74e-22    1.17e-06   9.24e-16   7.96e-01  1.75e+00        1    6.13e-03    6.85e-01
 117  1.523726e-21   -1.29e-21    3.04e-06   3.55e-16   4.35e-02  9.95e-01        1    6.29e-03    6.91e-01
 118  1.094423e-20   -9.42e-21    0.00e+00   1.00e-15  -6.57e+00  4.97e-01        1    3.10e-03    6.94e-01
 119  1.580537e-21   -5.68e-23    0.00e+00   7.04e-16  -4.32e-02  1.24e-01        1    3.13e-03    6.97e-01
 120  1.185950e-21    3.38e-22    2.80e-06   3.43e-16   4.22e-01  1.24e-01        1    7.23e-03    7.05e-01
 121  1.998065e-22    9.86e-22    8.63e-07   3.43e-16   1.64e+00  3.72e-01        1    6.14e-03    7.11e-01
 122  2.448992e-21   -2.25e-21    0.00e+00   2.56e-16  -6.15e-01  1.86e-01        1    3.13e-03    7.14e-01
 123  2.371655e-21   -2.17e-21    0.00e+00   2.49e-16  -5.72e-01  4.65e-02        1    3.14e-03    7.17e-01
 124  1.900813e-22    9.73e-24    8.75e-07   9.81e-18   9.29e-01  1.25e-01        1    6.29e-03    7.23e-01
 125  1.162474e-21   -9.72e-22    2.76e-06   1.13e-16   2.41e-01  1.10e-01        1    6.15e-03    7.29e-01
 126  1.216734e-20   -1.10e-20    0.00e+00   2.89e-16  -5.29e+00  5.50e-02        1    3.42e-03    7.33e-01
 127  3.213790e-21   -2.05e-21    0.00e+00   2.58e-16  -9.30e-01  1.38e-02        1    3.72e-03    7.37e-01
 128  1.180454e-21   -1.80e-23    2.76e-06   1.21e-17   2.15e-01  1.16e-02        1    6.28e-03    7.43e-01
 129  1.144587e-21    3.59e-23    2.76e-06   6.94e-18   3.99e-01  1.15e-02        1    6.13e-03    7.49e-01
 130  9.923413e-22    1.52e-22    2.55e-06   8.67e-18   1.83e+00  3.45e-02        1    6.25e-03    7.55e-01
 131  4.650879e-22    5.27e-22    1.71e-06   1.13e-16   2.67e+00  1.04e-01        1    6.15e-03    7.61e-01
 132  3.488040e-21   -3.02e-21    0.00e+00   2.56e-16  -9.02e-01  5.18e-02        1    3.14e-03    7.65e-01
 133  2.237309e-22    2.41e-22    1.28e-06   1.13e-16   1.87e+00  1.55e-01        1    6.96e-03    7.72e-01
 134  2.242625e-22   -5.32e-25    1.28e-06   7.97e-17   5.89e-01  1.56e-01        1    6.18e-03    7.78e-01
 135  5.971194e-22   -3.73e-22    1.69e-06   8.10e-17   4.00e-01  1.55e-01        1    6.13e-03    7.84e-01
 136  6.051478e-21   -5.45e-21    0.00e+00   3.41e-16  -1.71e+00  7.75e-02        1    3.27e-03    7.87e-01
 137  4.633398e-21   -4.04e-21    0.00e+00   1.27e-16  -1.23e+00  1.94e-02        1    3.14e-03    7.90e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.203898e+02
Final                            5.847777e-23
Change                           1.203898e+02

Minimizer iterations                      138
Successful steps                          113
Unsuccessful steps                         25
Line search steps                          80

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0115
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7742
    Line search gradient evaluation    0.4275
  Linear solver                        0.0031
  Line search polynomial minimization  0.0004
Minimizer                              0.7935

Postprocessor                          0.0000
Total                                  0.7935

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.576966e+04
Final                            1.381153e+02
Change                           1.563154e+04

Minimizer iterations                       55
Successful steps                           38
Unsuccessful steps                         17
Line search steps                          59

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0044
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3690
    Line search gradient evaluation    0.2537
  Linear solver                        0.0010
  Line search polynomial minimization  0.0005
Minimizer                              0.3759

Postprocessor                          0.0000
Total                                  0.3760

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA86 = {
{-0.0726984,0.4846152,0.2209753}
};
fitErrEl86 = {
{-0.1131843,0.4700887,0.2342587}
};
fitErrLa86 = {
{-0.1147295,0.5020412,0.2444810}
};
fitErrWr86 = {
{-0.3142861,0.4410663,0.3378428}
};
fitErrEe86 = {
{-0.3728506,0.4688436,0.4221913}
};
rMatsBase86 = {
{-0.3231976,0.7108249,-0.6247169},
{0.8251323,0.5349048,0.1817510},
{0.4633572,-0.4567326,-0.7594046}
};
outThetasWam86 = {
{-0.1066701,-0.2620709,-0.0530785,1.3229918,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5375565
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  8.344645e+01    0.00e+00    2.76e+00   0.00e+00   0.00e+00  1.00e+04        0    3.45e-03    3.49e-03
   1  7.948239e-01    8.27e+01    2.82e+00   4.97e-03   1.98e+00  3.00e+04        1    6.36e-03    9.88e-03
   2  2.847983e-08    7.95e-01    2.82e+00   5.46e-05   1.98e+00  9.00e+04        1    6.16e-03    1.61e-02
   3  6.548173e-17    2.85e-08    4.37e-05   1.35e-08   1.98e+00  2.70e+05        1    6.16e-03    2.22e-02
   4  1.226898e-20    6.55e-17    8.94e-06   3.68e-12   1.98e+00  8.10e+05        1    6.23e-03    2.85e-02
   5  3.012027e-21    9.26e-21    4.48e-06   1.27e-14   1.98e+00  2.43e+06        1    6.15e-03    3.46e-02
   6  8.106695e-21   -5.09e-21    7.50e-06   4.38e-15   1.98e+00  7.29e+06        1    6.84e-03    4.15e-02
   7  6.571881e-21    1.53e-21    6.47e-06   7.15e-15   1.98e+00  2.19e+07        1    6.45e-03    4.80e-02
   8  1.948308e-21    4.62e-21    3.64e-06   7.57e-15   1.98e+00  6.56e+07        1    6.12e-03    5.41e-02
   9  6.066518e-21   -4.12e-21    5.48e-06   1.88e-15   1.98e+00  1.97e+08        1    6.26e-03    6.04e-02
  10  5.804335e-22    5.49e-21    2.16e-06   7.28e-15   1.98e+00  5.90e+08        1    6.14e-03    6.65e-02
  11  1.318250e-20   -1.26e-20    9.39e-06   2.20e-15   1.98e+00  1.77e+09        1    6.26e-03    7.28e-02
  12  2.449710e-20   -1.13e-20    1.25e-05   5.60e-15   1.98e+00  5.31e+09        1    7.27e-03    8.01e-02
  13  4.394015e-22    2.41e-20    1.50e-06   8.87e-15   1.98e+00  1.59e+10        1    6.15e-03    8.63e-02
  14  7.813583e-22   -3.42e-22    2.15e-06   2.54e-15   1.98e+00  4.78e+10        1    6.51e-03    9.28e-02
  15  9.664740e-21   -8.88e-21    8.37e-06   1.50e-15   1.98e+00  1.43e+11        1    6.26e-03    9.92e-02
  16  9.089201e-21    5.76e-22    7.14e-06   5.57e-15   1.98e+00  4.30e+11        1    6.20e-03    1.05e-01
  17  7.252058e-22    8.36e-21    1.98e-06   4.76e-15   1.98e+00  1.29e+12        1    7.21e-03    1.13e-01
  18  5.508368e-22    1.74e-22    1.55e-06   2.86e-15   1.98e+00  3.87e+12        1    6.16e-03    1.19e-01
  19  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  1.94e+12        1    3.15e-03    1.22e-01
  20  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  4.84e+11        1    3.14e-03    1.25e-01
  21  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  6.05e+10        1    3.41e-03    1.29e-01
  22  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  3.78e+09        1    3.22e-03    1.32e-01
  23  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  1.18e+08        1    3.21e-03    1.35e-01
  24  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  1.85e+06        1    3.14e-03    1.38e-01
  25  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  1.44e+04        1    3.86e-03    1.42e-01
  26  9.861341e-21   -9.31e-21    0.00e+00   8.17e-16  -9.96e-03  5.64e+01        1    4.00e-03    1.46e-01
  27  9.861341e-21   -9.31e-21    0.00e+00   8.18e-16  -9.96e-03  1.10e-01        1    3.22e-03    1.49e-01
  28  2.731881e-22    2.78e-22    1.34e-06   2.57e-16   1.17e+00  3.30e-01        1    6.18e-03    1.56e-01
  29  8.512958e-22   -5.78e-22    2.38e-06   1.57e-16   4.48e-01  3.30e-01        1    6.48e-03    1.62e-01
  30  4.370779e-23    8.08e-22    4.66e-07   2.86e-16   1.40e+00  9.90e-01        1    6.62e-03    1.69e-01
  31  2.124732e-22   -1.69e-22    1.21e-06   2.50e-16   4.66e-01  9.90e-01        1    6.86e-03    1.76e-01
  32  1.550365e-20   -1.53e-20    0.00e+00   2.97e-16  -2.85e-01  4.95e-01        1    3.62e-03    1.79e-01
  33  2.036006e-20   -2.01e-20    0.00e+00   1.54e-16  -5.23e-01  1.24e-01        1    3.26e-03    1.83e-01
  34  6.853473e-22   -4.73e-22    1.72e-06   6.87e-17   4.41e-01  1.23e-01        1    6.38e-03    1.89e-01
  35  2.127091e-21   -1.44e-21    3.79e-06   2.72e-16   3.65e-01  1.21e-01        1    6.35e-03    1.95e-01
  36  6.973288e-22    1.43e-21    2.20e-06   3.59e-16   1.44e+00  3.63e-01        1    6.23e-03    2.02e-01
  37  1.871704e-22    5.10e-22    1.07e-06   2.70e-16   1.05e+00  1.09e+00        1    6.13e-03    2.08e-01
  38  8.977977e-21   -8.79e-21    0.00e+00   3.38e-16  -4.17e+00  5.45e-01        1    3.43e-03    2.11e-01
  39  2.496748e-22   -6.25e-23    1.40e-06   2.72e-16   1.15e+00  1.63e+00        1    6.35e-03    2.18e-01
  40  9.591947e-22   -7.10e-22    2.54e-06   3.50e-16   6.32e-01  1.67e+00        1    6.54e-03    2.24e-01
  41  8.264294e-21   -7.31e-21    0.00e+00   8.67e-16  -2.23e+00  8.33e-01        1    3.14e-03    2.27e-01
  42  3.021147e-22    6.57e-22    1.17e-06   7.00e-16   7.55e-01  9.60e-01        1    6.59e-03    2.34e-01
  43  2.301055e-21   -2.00e-21    0.00e+00   4.10e-16  -5.90e-02  4.80e-01        1    3.25e-03    2.37e-01
  44  1.159596e-20   -1.13e-20    0.00e+00   3.31e-16  -3.24e+00  1.20e-01        1    3.14e-03    2.40e-01
  45  4.514881e-21   -4.21e-21    0.00e+00   1.13e-16  -8.40e-01  1.50e-02        1    3.18e-03    2.44e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          8.344645e+01
Final                            4.370779e-23
Change                           8.344645e+01

Minimizer iterations                       46
Successful steps                           30
Unsuccessful steps                         16
Line search steps                          29

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0042
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2388
    Line search gradient evaluation    0.1439
  Linear solver                        0.0015
  Line search polynomial minimization  0.0003
Minimizer                              0.2467

Postprocessor                          0.0000
Total                                  0.2467

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.580547e+04
Final                            1.384216e+02
Change                           1.566705e+04

Minimizer iterations                      187
Successful steps                          122
Unsuccessful steps                         65
Line search steps                         190

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0150
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.1702
    Line search gradient evaluation    0.8001
  Linear solver                        0.0042
  Line search polynomial minimization  0.0017
Minimizer                              1.1950

Postprocessor                          0.0000
Total                                  1.1951

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA87 = {
{-0.0733104,0.4895355,0.2234036}
};
fitErrEl87 = {
{-0.1142026,0.4748280,0.2368114}
};
fitErrLa87 = {
{-0.1157524,0.5073082,0.2472370}
};
fitErrWr87 = {
{-0.3186807,0.4453828,0.3417820}
};
fitErrEe87 = {
{-0.3771729,0.4730952,0.4266993}
};
rMatsBase87 = {
{-0.3258975,0.7105253,-0.6236542},
{0.8221842,0.5386493,0.1840383},
{0.4666948,-0.4527810,-0.7597271}
};
outThetasWam87 = {
{-0.1068752,-0.2582687,-0.0521316,1.3235186,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5430733
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  9.993322e+01    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    3.07e-03    3.11e-03
   1  5.565066e-01    9.94e+01    2.82e+00   4.82e-03   1.99e+00  3.00e+04        1    6.24e-03    9.38e-03
   2  1.542700e-08    5.57e-01    2.64e+00   4.83e-05   1.98e+00  9.00e+04        1    6.14e-03    1.55e-02
   3  4.115937e-16    1.54e-08    7.73e-05   2.27e-08   1.98e+00  2.70e+05        1    6.14e-03    2.17e-02
   4  1.561772e-20    4.12e-16    1.03e-05   9.34e-12   1.98e+00  8.10e+05        1    6.10e-03    2.78e-02
   5  3.075172e-20   -1.51e-20    1.45e-05   9.34e-15   1.98e+00  2.43e+06        1    6.20e-03    3.40e-02
   6  2.409489e-20    6.66e-21    1.29e-05   1.27e-14   1.98e+00  7.29e+06        1    6.30e-03    4.04e-02
   7  4.522129e-22    2.36e-20    1.81e-06   1.30e-14   1.98e+00  2.19e+07        1    6.12e-03    4.65e-02
   8  2.454920e-20   -2.41e-20    1.23e-05   2.76e-15   1.98e+00  6.56e+07        1    6.20e-03    5.27e-02
   9  1.268640e-20    1.19e-20    8.65e-06   1.01e-14   1.98e+00  1.97e+08        1    6.20e-03    5.89e-02
  10  2.437686e-21    1.02e-20    3.98e-06   5.26e-15   1.98e+00  5.90e+08        1    6.14e-03    6.51e-02
  11  3.669914e-21   -1.23e-21    4.32e-06   4.33e-15   1.98e+00  1.77e+09        1    6.23e-03    7.13e-02
  12  8.045086e-21   -4.38e-21    7.32e-06   2.96e-15   1.98e+00  5.31e+09        1    6.16e-03    7.75e-02
  13  1.257451e-21    6.79e-21    2.95e-06   9.98e-15   8.47e-01  7.97e+09        1    6.14e-03    8.37e-02
  14  6.587793e-22    5.99e-22    1.93e-06   3.36e-15   4.84e-01  7.97e+09        1    6.14e-03    8.98e-02
  15  4.410325e-21   -3.75e-21    4.94e-06   2.78e-15   3.80e-01  7.86e+09        1    6.09e-03    9.59e-02
  16  6.268024e-22    3.78e-21    1.69e-06   7.04e-15   8.65e-01  1.29e+10        1    6.30e-03    1.02e-01
  17  9.855404e-21   -9.23e-21    7.46e-06   1.37e-15   2.54e-01  1.15e+10        1    6.18e-03    1.08e-01
  18  2.065395e-21    7.79e-21    3.69e-06   6.13e-15   8.02e-01  1.47e+10        1    6.26e-03    1.15e-01
  19  9.172696e-22    1.15e-21    2.28e-06   2.07e-15   5.64e-01  1.48e+10        1    6.24e-03    1.21e-01
  20  1.644963e-20   -1.55e-20    9.02e-06   1.49e-15   1.15e-01  1.01e+10        1    6.12e-03    1.27e-01
  21  2.630553e-21    1.38e-20    3.54e-06   5.97e-15   8.46e-01  1.51e+10        1    6.10e-03    1.33e-01
  22  1.879233e-21    7.51e-22    3.89e-06   3.83e-15   2.92e-01  1.41e+10        1    6.30e-03    1.40e-01
  23  7.602962e-21   -5.72e-21    8.08e-06   3.63e-15   1.86e-01  1.13e+10        1    6.15e-03    1.46e-01
  24  1.892288e-21    5.71e-21    3.16e-06   3.68e-15   7.53e-01  1.30e+10        1    6.15e-03    1.52e-01
  25  9.097130e-22    9.83e-22    2.45e-06   5.64e-15   5.36e-01  1.30e+10        1    6.25e-03    1.58e-01
  26  1.683356e-21   -7.74e-22    3.83e-06   3.25e-15   2.25e-01  1.12e+10        1    6.17e-03    1.64e-01
  27  5.814589e-21   -4.13e-21    4.97e-06   2.44e-15   1.82e-01  8.87e+09        1    6.19e-03    1.71e-01
  28  2.394277e-20   -1.81e-20    1.27e-05   7.45e-15   5.56e-03  4.51e+09        1    6.11e-03    1.77e-01
  29  1.742423e-20    6.52e-21    1.07e-05   1.32e-14   2.73e-01  4.12e+09        1    6.35e-03    1.83e-01
  30  1.494167e-21    1.59e-20    3.10e-06   1.05e-14   9.15e-01  9.64e+09        1    6.08e-03    1.89e-01
  31  4.195331e-22    1.07e-21    1.36e-06   3.14e-15   7.47e-01  1.10e+10        1    6.13e-03    1.95e-01
  32  5.349419e-21   -4.93e-21    5.73e-06   1.33e-15   1.26e-01  7.73e+09        1    6.36e-03    2.02e-01
  33  5.885976e-22    4.76e-21    1.92e-06   3.45e-15   8.92e-01  1.49e+10        1    6.23e-03    2.08e-01
  34  1.666088e-21   -1.08e-21    3.12e-06   1.14e-15   1.45e-01  1.09e+10        1    6.15e-03    2.14e-01
  35  7.874184e-22    8.79e-22    2.58e-06   2.39e-15   5.50e-01  1.10e+10        1    6.18e-03    2.20e-01
  36  4.976432e-21   -4.19e-21    5.08e-06   1.24e-15   1.22e-01  7.65e+09        1    6.32e-03    2.27e-01
  37  3.281085e-21    1.70e-21    5.47e-06   5.66e-15   3.44e-01  7.42e+09        1    6.14e-03    2.33e-01
  38  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  3.71e+09        1    3.14e-03    2.36e-01
  39  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  9.28e+08        1    3.14e-03    2.39e-01
  40  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  1.16e+08        1    3.12e-03    2.42e-01
  41  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  7.25e+06        1    3.15e-03    2.45e-01
  42  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  2.27e+05        1    3.23e-03    2.49e-01
  43  8.016867e-21   -4.74e-21    0.00e+00   3.96e-15  -1.62e-01  3.54e+03        1    3.14e-03    2.52e-01
  44  1.713945e-21    1.57e-21    3.31e-06   3.92e-15   4.86e-01  3.54e+03        1    6.14e-03    2.58e-01
  45  6.902073e-21   -5.19e-21    0.00e+00   1.18e-15  -8.57e-02  1.77e+03        1    3.13e-03    2.61e-01
  46  6.902073e-21   -5.19e-21    0.00e+00   1.18e-15  -8.57e-02  4.43e+02        1    3.13e-03    2.64e-01
  47  8.275343e-21   -6.56e-21    0.00e+00   1.18e-15  -1.61e-01  5.53e+01        1    3.10e-03    2.67e-01
  48  2.492586e-22    1.46e-21    1.18e-06   1.10e-15   8.68e-01  9.21e+01        1    6.29e-03    2.74e-01
  49  9.832204e-22   -7.34e-22    2.41e-06   1.14e-15   2.38e-01  8.06e+01        1    6.12e-03    2.80e-01
  50  5.721836e-22    4.11e-22    1.88e-06   1.23e-15   4.32e-01  8.04e+01        1    6.18e-03    2.86e-01
  51  4.057469e-21   -3.49e-21    5.27e-06   1.16e-15   6.51e-02  4.85e+01        1    6.22e-03    2.92e-01
  52  1.291841e-21    2.77e-21    2.81e-06   2.85e-15   6.82e-01  5.09e+01        1    6.16e-03    2.98e-01
  53  1.986269e-21   -6.94e-22    3.51e-06   2.24e-15   1.34e-01  3.66e+01        1    6.16e-03    3.05e-01
  54  1.906842e-20   -1.71e-20    0.00e+00   2.40e-15  -2.07e+00  1.83e+01        1    3.14e-03    3.08e-01
  55  2.125173e-20   -1.93e-20    0.00e+00   2.24e-15  -2.37e+00  4.57e+00        1    3.12e-03    3.11e-01
  56  2.012740e-21   -2.65e-23    3.22e-06   1.69e-15   2.83e-01  4.22e+00        1    6.33e-03    3.17e-01
  57  2.847005e-21   -8.34e-22    3.98e-06   1.39e-15   1.32e-01  3.02e+00        1    6.15e-03    3.23e-01
  58  3.730684e-21   -8.84e-22    5.43e-06   1.63e-15   2.74e-02  1.64e+00        1    6.14e-03    3.30e-01
  59  2.358098e-21    1.37e-21    4.03e-06   1.37e-15   3.91e-01  1.62e+00        1    6.30e-03    3.36e-01
  60  1.734049e-21    6.24e-22    3.25e-06   1.44e-15   2.80e-01  1.49e+00        1    6.17e-03    3.42e-01
  61  4.131005e-21   -2.40e-21    0.00e+00   1.01e-15  -3.83e-03  7.46e-01        1    3.13e-03    3.45e-01
  62  5.884785e-21   -4.15e-21    0.00e+00   9.29e-16  -9.56e-02  1.86e-01        1    3.14e-03    3.48e-01
  63  1.516089e-21    2.18e-22    3.72e-06   5.96e-16   2.17e-01  1.58e-01        1    6.14e-03    3.54e-01
  64  7.022370e-22    8.14e-22    1.88e-06   3.07e-16   9.48e-01  4.74e-01        1    6.25e-03    3.61e-01
  65  8.505324e-22   -1.48e-22    2.61e-06   5.82e-16   1.60e-01  3.60e-01        1    6.15e-03    3.67e-01
  66  6.437980e-22    2.07e-22    2.01e-06   2.89e-16   3.31e-01  3.47e-01        1    6.13e-03    3.73e-01
  67  6.423773e-21   -5.78e-21    0.00e+00   2.67e-16  -1.12e-01  1.73e-01        1    3.16e-03    3.76e-01
  68  2.575092e-22    3.86e-22    1.07e-06   1.61e-16   1.16e+00  5.20e-01        1    6.21e-03    3.82e-01
  69  2.759206e-22   -1.84e-23    1.10e-06   3.25e-16   1.78e-01  4.11e-01        1    6.20e-03    3.89e-01
  70  9.659817e-21   -9.38e-21    0.00e+00   2.84e-16  -2.62e-01  2.05e-01        1    3.13e-03    3.92e-01
  71  2.410684e-22    3.49e-23    1.03e-06   2.64e-16   2.32e-01  1.78e-01        1    6.14e-03    3.98e-01
  72  1.758381e-22    6.52e-23    6.68e-07   8.80e-17   6.70e-01  1.85e-01        1    6.28e-03    4.04e-01
  73  2.054025e-22   -2.96e-23    1.04e-06   7.08e-17   1.79e-01  1.46e-01        1    6.11e-03    4.10e-01
  74  4.826219e-21   -4.62e-21    0.00e+00   6.77e-17  -3.56e-02  7.32e-02        1    3.13e-03    4.14e-01
  75  2.347415e-22   -2.93e-23    1.01e-06   2.26e-17   1.77e-01  5.76e-02        1    6.16e-03    4.20e-01
  76  5.271032e-22   -2.92e-22    1.64e-06   1.25e-17   1.63e-01  4.41e-02        1    6.19e-03    4.26e-01
  77  5.270515e-22    5.17e-26    1.65e-06   2.08e-17   1.62e-01  3.37e-02        1    6.15e-03    4.32e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          9.993322e+01
Final                            1.758381e-22
Change                           9.993322e+01

Minimizer iterations                       78
Successful steps                           62
Unsuccessful steps                         16
Line search steps                          42

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0063
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4246
    Line search gradient evaluation    0.2368
  Linear solver                        0.0017
  Line search polynomial minimization  0.0002
Minimizer                              0.4352

Postprocessor                          0.0000
Total                                  0.4352

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.583382e+04
Final                            1.389864e+02
Change                           1.569483e+04

Minimizer iterations                       28
Successful steps                           23
Unsuccessful steps                          5
Line search steps                          15

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0022
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1657
    Line search gradient evaluation    0.0963
  Linear solver                        0.0005
  Line search polynomial minimization  0.0001
Minimizer                              0.1691

Postprocessor                          0.0000
Total                                  0.1691

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA88 = {
{-0.0740439,0.4946261,0.2258613}
};
fitErrEl88 = {
{-0.1153677,0.4797188,0.2393987}
};
fitErrLa88 = {
{-0.1169195,0.5127689,0.2500491}
};
fitErrWr88 = {
{-0.3235972,0.4497757,0.3459286}
};
fitErrEe88 = {
{-0.3819138,0.4774566,0.4315426}
};
rMatsBase88 = {
{-0.3291430,0.7098664,-0.6226995},
{0.8191790,0.5426660,0.1856326},
{0.4696922,-0.4490026,-0.7601223}
};
outThetasWam88 = {
{-0.1070183,-0.2539161,-0.0511074,1.3242667,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5487721
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.144910e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    2.82e-03    2.86e-03
   1  7.762644e-01    1.14e+02    2.83e+00   5.19e-03   1.98e+00  3.00e+04        1    5.81e-03    8.70e-03
   2  3.259610e-08    7.76e-01    2.83e+00   6.33e-05   1.98e+00  9.00e+04        1    5.73e-03    1.44e-02
   3  1.518696e-15    3.26e-08    1.40e-04   4.06e-08   1.98e+00  2.70e+05        1    5.70e-03    2.02e-02
   4  2.246979e-22    1.52e-15    8.97e-07   1.78e-11   1.98e+00  8.10e+05        1    5.66e-03    2.58e-02
   5  6.755438e-21   -6.53e-21    6.83e-06   4.60e-15   1.98e+00  2.43e+06        1    5.81e-03    3.17e-02
   6  3.136190e-20   -2.46e-20    1.47e-05   6.22e-15   1.98e+00  7.29e+06        1    5.61e-03    3.73e-02
   7  7.917681e-21    2.34e-20    7.31e-06   1.52e-14   1.98e+00  2.19e+07        1    5.61e-03    4.29e-02
   8  1.852851e-21    6.06e-21    3.09e-06   9.25e-15   1.98e+00  6.56e+07        1    5.76e-03    4.87e-02
   9  5.044695e-21   -3.19e-21    6.69e-06   1.91e-15   1.98e+00  1.97e+08        1    5.81e-03    5.45e-02
  10  9.304387e-21   -4.26e-21    7.28e-06   2.09e-15   4.80e-01  1.97e+08        1    5.67e-03    6.02e-02
  11  9.931889e-21   -6.28e-22    8.04e-06   4.43e-15   3.88e-01  1.95e+08        1    5.75e-03    6.59e-02
  12  1.582867e-20   -5.90e-21    1.06e-05   6.47e-15   2.38e-01  1.70e+08        1    5.66e-03    7.16e-02
  13  5.322671e-21    1.05e-20    6.02e-06   1.06e-14   6.68e-01  1.77e+08        1    5.71e-03    7.73e-02
  14  4.674944e-21    6.48e-22    4.72e-06   6.49e-15   3.10e-01  1.68e+08        1    5.68e-03    8.30e-02
  15  5.286954e-22    4.15e-21    2.14e-06   3.90e-15   8.91e-01  3.21e+08        1    5.64e-03    8.87e-02
  16  3.111388e-21   -2.58e-21    3.16e-06   1.21e-15   3.09e-01  3.04e+08        1    5.73e-03    9.44e-02
  17  9.041226e-21   -5.93e-21    7.66e-06   6.33e-15   2.37e-01  2.65e+08        1    5.65e-03    1.00e-01
  18  9.649186e-21   -6.08e-22    8.08e-06   9.13e-15   2.10e-01  2.22e+08        1    5.84e-03    1.06e-01
  19  2.143858e-22    9.43e-21    1.26e-06   7.80e-15   9.89e-01  6.65e+08        1    5.80e-03    1.12e-01
  20  1.220434e-20   -1.20e-20    9.33e-06   6.56e-16   1.69e-01  5.16e+08        1    5.77e-03    1.18e-01
  21  1.767937e-20   -5.48e-21    1.11e-05   8.95e-15   1.09e-01  3.49e+08        1    5.64e-03    1.23e-01
  22  1.480148e-21    1.62e-20    2.70e-06   7.06e-15   9.19e-01  8.53e+08        1    5.68e-03    1.29e-01
  23  7.989849e-21   -6.51e-21    7.14e-06   1.06e-15   1.62e-01  6.51e+08        1    5.74e-03    1.35e-01
  24  1.079063e-20   -2.80e-21    8.56e-06   5.46e-15   1.35e-01  4.69e+08        1    5.59e-03    1.40e-01
  25  5.205815e-22    1.03e-20    1.96e-06   8.03e-15   9.57e-01  1.41e+09        1    5.66e-03    1.46e-01
  26  1.592939e-20   -1.54e-20    1.02e-05   1.25e-15   4.57e-02  8.04e+08        1    5.83e-03    1.52e-01
  27  1.745279e-20   -1.52e-21    1.08e-05   7.83e-15   4.19e-03  4.07e+08        1    5.82e-03    1.58e-01
  28  1.344285e-20    4.01e-21    8.92e-06   9.41e-15   2.30e-01  3.52e+08        1    5.74e-03    1.63e-01
  29  8.549932e-21    4.89e-21    7.59e-06   1.18e-14   3.65e-01  3.45e+08        1    5.76e-03    1.69e-01
  30  1.719608e-22    8.38e-21    9.33e-07   1.05e-14   9.86e-01  1.03e+09        1    5.88e-03    1.75e-01
  31  1.507023e-21   -1.34e-21    3.58e-06   5.95e-16   1.73e-01  8.08e+08        1    5.76e-03    1.81e-01
  32  1.229812e-20   -1.08e-20    8.11e-06   4.14e-15   5.66e-02  4.76e+08        1    5.66e-03    1.86e-01
  33  3.864519e-21    8.43e-21    4.03e-06   4.11e-15   6.86e-01  5.02e+08        1    5.62e-03    1.92e-01
  34  3.521134e-21    3.43e-22    5.61e-06   2.53e-15   1.27e-01  3.55e+08        1    5.87e-03    1.98e-01
  35  7.800984e-22    2.74e-21    2.22e-06   1.67e-15   8.00e-01  4.53e+08        1    5.76e-03    2.04e-01
  36  1.057829e-20   -9.80e-21    8.56e-06   1.98e-15   8.53e-02  2.88e+08        1    5.65e-03    2.09e-01
  37  1.491993e-21    9.09e-21    2.53e-06   1.07e-14   8.60e-01  4.60e+08        1    5.61e-03    2.15e-01
  38  3.258434e-21   -1.77e-21    4.84e-06   1.86e-15   2.81e-01  4.25e+08        1    5.68e-03    2.21e-01
  39  1.100393e-21    2.16e-21    2.64e-06   1.81e-15   6.72e-01  4.43e+08        1    5.47e-03    2.26e-01
  40  4.722650e-22    6.28e-22    1.66e-06   4.92e-15   5.83e-01  4.45e+08        1    5.46e-03    2.32e-01
  41  3.552624e-22    1.17e-22    1.70e-06   4.36e-15   3.24e-01  4.26e+08        1    5.49e-03    2.37e-01
  42  4.219694e-22   -6.67e-23    1.71e-06   1.48e-15   3.19e-01  4.07e+08        1    5.83e-03    2.43e-01
  43  6.638927e-21   -6.22e-21    6.82e-06   9.20e-16   1.51e-01  3.04e+08        1    5.69e-03    2.49e-01
  44  4.028229e-22    6.24e-21    1.63e-06   6.23e-15   9.42e-01  9.11e+08        1    5.65e-03    2.54e-01
  45  7.545849e-21   -7.14e-21    6.79e-06   2.50e-15   1.07e-01  6.12e+08        1    5.66e-03    2.60e-01
  46  8.464326e-21   -9.18e-22    6.77e-06   4.30e-15   7.35e-02  3.78e+08        1    6.29e-03    2.66e-01
  47  1.165520e-20   -3.19e-21    8.95e-06   4.06e-15   1.06e-02  1.95e+08        1    5.79e-03    2.72e-01
  48  6.760067e-21    4.90e-21    6.90e-06   5.22e-15   4.23e-01  1.94e+08        1    5.93e-03    2.78e-01
  49  1.078817e-21    5.68e-21    2.36e-06   4.45e-15   8.41e-01  2.85e+08        1    5.85e-03    2.84e-01
  50  6.966380e-21   -5.89e-21    6.37e-06   3.99e-15   6.67e-02  1.72e+08        1    5.70e-03    2.90e-01
  51  1.998476e-21    4.97e-21    2.90e-06   6.03e-15   7.22e-01  1.89e+08        1    5.60e-03    2.95e-01
  52  3.537800e-22    1.64e-21    1.22e-06   3.36e-15   8.32e-01  2.68e+08        1    6.04e-03    3.01e-01
  53  6.244230e-21   -5.89e-21    6.44e-06   1.02e-15   6.79e-02  1.63e+08        1    5.66e-03    3.07e-01
  54  7.761576e-22    5.47e-21    2.14e-06   4.74e-15   8.79e-01  2.88e+08        1    5.80e-03    3.13e-01
  55  2.974119e-22    4.79e-22    1.16e-06   2.49e-15   6.40e-01  2.94e+08        1    5.97e-03    3.19e-01
  56  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  1.47e+08        1    2.91e-03    3.22e-01
  57  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  3.68e+07        1    2.87e-03    3.25e-01
  58  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  4.60e+06        1    2.84e-03    3.28e-01
  59  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  2.87e+05        1    3.06e-03    3.31e-01
  60  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  8.98e+03        1    3.13e-03    3.34e-01
  61  1.715680e-20   -1.69e-20    0.00e+00   1.68e-15  -5.04e-02  1.40e+02        1    2.96e-03    3.37e-01
  62  1.168565e-21   -8.71e-22    3.14e-06   1.40e-15   1.16e-01  9.64e+01        1    5.80e-03    3.43e-01
  63  1.601937e-21   -4.33e-22    2.66e-06   7.10e-16   1.10e-01  6.54e+01        1    5.82e-03    3.48e-01
  64  7.781601e-22    8.24e-22    2.14e-06   3.34e-15   5.20e-01  6.54e+01        1    5.89e-03    3.54e-01
  65  8.302539e-22   -5.21e-23    2.58e-06   1.00e-15   1.15e-01  4.49e+01        1    5.66e-03    3.60e-01
  66  1.320366e-20   -1.24e-20    0.00e+00   5.76e-16  -9.01e-03  2.24e+01        1    2.90e-03    3.63e-01
  67  1.320366e-20   -1.24e-20    0.00e+00   5.77e-16  -9.01e-03  5.61e+00        1    2.97e-03    3.66e-01
  68  1.640617e-22    6.66e-22    1.20e-06   6.13e-16   8.46e-01  8.40e+00        1    5.53e-03    3.71e-01
  69  2.664620e-22   -1.02e-22    8.57e-07   2.42e-16   1.20e-01  5.83e+00        1    5.64e-03    3.77e-01
  70  8.033238e-21   -7.77e-21    7.23e-06   5.26e-16   4.23e-02  3.30e+00        1    5.69e-03    3.83e-01
  71  1.510622e-21    6.52e-21    2.85e-06   2.93e-15   8.36e-01  4.73e+00        1    5.94e-03    3.89e-01
  72  4.374569e-22    1.07e-21    1.18e-06   9.08e-16   7.38e-01  5.31e+00        1    5.81e-03    3.95e-01
  73  9.168222e-21   -8.73e-21    7.78e-06   5.65e-16   2.83e-02  2.89e+00        1    5.77e-03    4.00e-01
  74  7.756160e-21    1.41e-21    7.25e-06   3.06e-15   1.57e-01  2.18e+00        1    5.66e-03    4.06e-01
  75  1.747118e-21    6.01e-21    3.96e-06   2.31e-15   8.01e-01  2.79e+00        1    5.69e-03    4.12e-01
  76  1.673103e-22    1.58e-21    8.95e-07   7.97e-16   9.23e-01  7.04e+00        1    5.79e-03    4.18e-01
  77  2.976641e-22   -1.30e-22    9.13e-07   3.23e-16   4.83e-01  7.04e+00        1    5.97e-03    4.23e-01
  78  8.377180e-22   -5.40e-22    2.43e-06   4.15e-16   4.47e-01  7.03e+00        1    5.78e-03    4.29e-01
  79  9.828417e-22   -1.45e-22    3.05e-06   7.84e-16   4.23e-01  7.01e+00        1    5.83e-03    4.35e-01
  80  3.167542e-22    6.66e-22    1.62e-06   6.38e-16   6.82e-01  7.36e+00        1    5.69e-03    4.41e-01
  81  3.771796e-22   -6.04e-23    1.29e-06   3.39e-16   4.26e-01  7.34e+00        1    5.76e-03    4.47e-01
  82  4.130267e-22   -3.58e-23    1.33e-06   5.72e-16   4.17e-01  7.30e+00        1    5.77e-03    4.52e-01
  83  1.806811e-22    2.32e-22    9.75e-07   7.58e-16   6.56e-01  7.53e+00        1    5.84e-03    4.58e-01
  84  9.399835e-21   -9.22e-21    0.00e+00   3.59e-16  -1.08e-02  3.77e+00        1    2.94e-03    4.61e-01
  85  1.624151e-20   -1.61e-20    0.00e+00   3.50e-16  -3.29e-01  9.41e-01        1    2.93e-03    4.64e-01
  86  1.907919e-20   -1.89e-20    0.00e+00   3.06e-16  -4.61e-01  1.18e-01        1    2.94e-03    4.67e-01
  87  2.110875e-21   -1.93e-21    3.52e-06   5.59e-17   3.30e-01  1.13e-01        1    5.56e-03    4.73e-01
  88  1.383870e-20   -1.17e-20    0.00e+00   3.15e-16  -2.09e-01  5.66e-02        1    2.97e-03    4.76e-01
  89  1.579286e-20   -1.37e-20    0.00e+00   2.73e-16  -3.01e-01  1.41e-02        1    2.85e-03    4.79e-01
  90  2.537670e-21   -4.27e-22    3.94e-06   2.80e-17   3.07e-01  1.34e-02        1    5.64e-03    4.84e-01
  91  1.274827e-21    1.26e-21    3.09e-06   2.53e-17   6.49e+00  4.01e-02        1    5.96e-03    4.90e-01
  92  1.032566e-20   -9.05e-21    0.00e+00   1.15e-16  -5.24e-02  2.01e-02        1    2.95e-03    4.93e-01
  93  1.260184e-21    1.46e-23    3.09e-06   1.73e-17   3.60e-01  1.96e-02        1    5.74e-03    4.99e-01
  94  9.472691e-22    3.13e-22    2.67e-06   1.91e-17   2.04e+00  5.89e-02        1    5.67e-03    5.05e-01
  95  1.961258e-20   -1.87e-20    0.00e+00   1.30e-16  -4.66e-01  2.95e-02        1    2.93e-03    5.07e-01
  96  2.106817e-21   -1.16e-21    3.94e-06   2.08e-17   3.17e-01  2.81e-02        1    5.84e-03    5.13e-01
  97  1.037276e-20   -8.27e-21    0.00e+00   1.18e-16  -5.33e-02  1.40e-02        1    2.97e-03    5.16e-01
  98  2.065939e-21    4.09e-23    3.92e-06   2.03e-17   3.16e-01  1.34e-02        1    5.87e-03    5.22e-01
  99  1.309177e-22    1.94e-21    9.32e-07   1.39e-17   1.08e+01  4.01e-02        1    5.82e-03    5.28e-01
 100  2.643773e-22   -1.33e-22    1.36e-06   6.94e-18   3.93e-01  3.98e-02        1    5.82e-03    5.34e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.144910e+02
Final                            1.309177e-22
Change                           1.144910e+02

Minimizer iterations                      101
Successful steps                           85
Unsuccessful steps                         16
Line search steps                          58

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0078
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5238
    Line search gradient evaluation    0.2853
  Linear solver                        0.0024
  Line search polynomial minimization  0.0003
Minimizer                              0.5369

Postprocessor                          0.0000
Total                                  0.5369

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:49:25.366668  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.587233e+04
Final                            1.394324e+02
Change                           1.573290e+04

Minimizer iterations                      207
Successful steps                          123
Unsuccessful steps                         84
Line search steps                         291

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0156
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.3672
    Line search gradient evaluation    1.0234
  Linear solver                        0.0043
  Line search polynomial minimization  0.0025
Minimizer                              1.3936

Postprocessor                          0.0000
Total                                  1.3936

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA89 = {
{-0.0738587,0.4966081,0.2269379}
};
fitErrEl89 = {
{-0.1153628,0.4816187,0.2405302}
};
fitErrLa89 = {
{-0.1169137,0.5148862,0.2512687}
};
fitErrWr89 = {
{-0.3250068,0.4511510,0.3477286}
};
fitErrEe89 = {
{-0.3828113,0.4787164,0.4340710}
};
rMatsBase89 = {
{-0.3320548,0.7076436,-0.6236827},
{0.8160657,0.5471144,0.1862862},
{0.4730501,-0.4471088,-0.7591557}
};
outThetasWam89 = {
{-0.1071538,-0.2516142,-0.0494255,1.3253423,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5509769
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  7.773688e+01    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    3.06e-03    3.09e-03
   1  1.037417e-01    7.76e+01    2.83e+00   3.15e-03   1.99e+00  3.00e+04        1    6.12e-03    9.31e-03
   2  2.564618e-09    1.04e-01    5.79e-01   2.21e-05   1.99e+00  9.00e+04        1    5.66e-03    1.50e-02
   3  5.401863e-16    2.56e-09    9.23e-05   2.24e-08   1.99e+00  2.70e+05        1    6.08e-03    2.11e-02
   4  9.788253e-21    5.40e-16    8.30e-06   1.05e-11   1.99e+00  8.10e+05        1    5.74e-03    2.69e-02
   5  1.111495e-20   -1.33e-21    8.31e-06   9.71e-15   1.99e+00  2.43e+06        1    5.83e-03    3.27e-02
   6  3.943028e-21    7.17e-21    4.22e-06   1.13e-14   1.99e+00  7.29e+06        1    6.15e-03    3.89e-02
   7  1.566828e-20   -1.17e-20    1.04e-05   7.07e-15   1.99e+00  2.19e+07        1    5.71e-03    4.46e-02
   8  8.404743e-21    7.26e-21    6.89e-06   5.55e-15   1.99e+00  6.56e+07        1    5.66e-03    5.03e-02
   9  3.896646e-21    4.51e-21    5.94e-06   4.38e-15   1.99e+00  1.97e+08        1    6.09e-03    5.64e-02
  10  1.256726e-20   -8.67e-21    8.46e-06   6.05e-15   1.99e+00  5.90e+08        1    5.67e-03    6.21e-02
  11  1.520155e-20   -2.63e-21    1.06e-05   3.86e-15   1.99e+00  1.77e+09        1    5.89e-03    6.80e-02
  12  1.537053e-20   -1.69e-22    1.06e-05   6.57e-15   1.99e+00  5.31e+09        1    6.10e-03    7.42e-02
  13  1.614209e-20   -7.72e-22    1.05e-05   9.23e-15   1.99e+00  1.59e+10        1    5.62e-03    7.98e-02
  14  1.451294e-21    1.47e-20    3.39e-06   8.71e-15   1.99e+00  4.78e+10        1    6.11e-03    8.59e-02
  15  2.144790e-21   -6.93e-22    3.92e-06   8.25e-16   1.99e+00  1.43e+11        1    6.09e-03    9.21e-02
  16  1.432387e-20   -1.22e-20    1.03e-05   3.67e-15   1.99e+00  4.30e+11        1    5.63e-03    9.77e-02
  17  1.891125e-21    1.24e-20    3.53e-06   6.31e-15   1.99e+00  1.29e+12        1    6.11e-03    1.04e-01
  18  7.159285e-21   -5.27e-21    7.07e-06   1.57e-15   1.99e+00  3.87e+12        1    5.92e-03    1.10e-01
  19  1.182889e-20   -4.67e-21    8.66e-06   8.91e-15   1.99e+00  1.16e+13        1    5.63e-03    1.15e-01
  20  1.309716e-20   -1.27e-21    9.54e-06   1.32e-14   3.49e-02  6.44e+12        1    6.04e-03    1.22e-01
  21  7.425339e-21    5.67e-21    6.59e-06   5.97e-15   4.37e-01  6.43e+12        1    5.73e-03    1.27e-01
  22  7.174500e-21    2.51e-22    5.93e-06   3.49e-15   1.29e-01  4.56e+12        1    6.02e-03    1.33e-01
  23  9.813881e-23    7.08e-21    6.14e-07   9.58e-15   9.94e-01  1.37e+13        1    5.91e-03    1.39e-01
  24  1.067992e-20   -1.06e-20    8.79e-06   1.89e-15   5.82e-02  8.10e+12        1    5.83e-03    1.45e-01
  25  3.571856e-21    7.11e-21    5.14e-06   6.68e-15   6.71e-01  8.44e+12        1    5.74e-03    1.51e-01
  26  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  4.22e+12        1    3.22e-03    1.54e-01
  27  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  1.05e+12        1    2.92e-03    1.57e-01
  28  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  1.32e+11        1    2.99e-03    1.60e-01
  29  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  8.24e+09        1    2.91e-03    1.63e-01
  30  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  2.58e+08        1    3.00e-03    1.66e-01
  31  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  4.02e+06        1    3.11e-03    1.69e-01
  32  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  3.14e+04        1    2.96e-03    1.72e-01
  33  1.691629e-20   -1.33e-20    0.00e+00   5.19e-15  -3.38e-02  1.23e+02        1    2.92e-03    1.75e-01
  34  1.803473e-20   -1.45e-20    0.00e+00   4.10e-15  -4.84e-02  2.40e-01        1    2.95e-03    1.78e-01
  35  8.865340e-22    2.69e-21    2.52e-06   5.73e-16   1.22e+00  7.20e-01        1    5.65e-03    1.84e-01
  36  7.418226e-21   -6.53e-21    7.06e-06   6.21e-16   9.07e-02  4.65e-01        1    5.95e-03    1.90e-01
  37  7.639055e-22    6.65e-21    2.42e-06   1.76e-15   1.10e+00  1.39e+00        1    5.96e-03    1.96e-01
  38  1.066492e-20   -9.90e-21    0.00e+00   4.25e-16   7.39e-04  6.97e-01        1    2.89e-03    1.99e-01
  39  6.634711e-21   -5.87e-21    6.45e-06   3.77e-16   2.00e-01  5.73e-01        1    6.32e-03    2.05e-01
  40  1.253497e-21    5.38e-21    3.10e-06   1.81e-15   9.62e-01  1.72e+00        1    5.83e-03    2.11e-01
  41  1.071934e-20   -9.47e-21    0.00e+00   8.36e-16  -1.46e-03  8.59e-01        1    3.17e-03    2.14e-01
  42  1.341105e-20   -1.22e-20    0.00e+00   6.75e-16  -1.01e-01  2.15e-01        1    3.01e-03    2.17e-01
  43  1.273843e-21   -2.03e-23    2.89e-06   3.92e-16   3.53e-01  2.10e-01        1    5.81e-03    2.23e-01
  44  9.264440e-22    3.47e-22    2.52e-06   3.89e-16   4.32e-01  2.09e-01        1    5.68e-03    2.28e-01
  45  4.878957e-22    4.39e-22    1.32e-06   2.95e-16   8.98e-01  4.21e-01        1    6.12e-03    2.35e-01
  46  6.641054e-21   -6.15e-21    6.35e-06   3.01e-16   1.43e-01  3.09e-01        1    5.89e-03    2.41e-01
  47  2.360458e-21    4.28e-21    4.01e-06   1.25e-15   9.09e-01  6.79e-01        1    5.69e-03    2.46e-01
  48  2.050663e-21    3.10e-22    3.05e-06   9.29e-16   2.47e-01  6.01e-01        1    5.89e-03    2.52e-01
  49  2.082184e-21   -3.15e-23    3.34e-06   6.78e-16   2.35e-01  5.23e-01        1    5.67e-03    2.58e-01
  50  9.032932e-21   -6.95e-21    7.67e-06   8.11e-16   4.31e-02  2.97e-01        1    5.74e-03    2.64e-01
  51  5.218589e-22    8.51e-21    1.85e-06   1.50e-15   1.31e+00  8.91e-01        1    6.02e-03    2.70e-01
  52  6.017869e-22   -7.99e-23    1.78e-06   4.16e-16   2.23e-01  7.62e-01        1    5.64e-03    2.75e-01
  53  1.299327e-21   -6.98e-22    2.97e-06   4.03e-16   2.06e-01  6.33e-01        1    5.63e-03    2.81e-01
  54  1.392578e-20   -1.26e-20    0.00e+00   7.03e-16  -6.96e-02  3.16e-01        1    3.16e-03    2.84e-01
  55  3.664055e-22    9.33e-22    1.21e-06   6.05e-16   1.07e+00  9.49e-01        1    6.03e-03    2.90e-01
  56  1.817665e-22    1.85e-22    7.28e-07   3.50e-16   6.33e-01  9.67e-01        1    5.74e-03    2.96e-01
  57  2.017038e-21   -1.84e-21    2.74e-06   1.39e-16   1.85e-01  7.74e-01        1    5.74e-03    3.02e-01
  58  3.101702e-22    1.71e-21    1.44e-06   8.92e-16   9.71e-01  2.32e+00        1    5.76e-03    3.07e-01
  59  1.158658e-21   -8.48e-22    2.58e-06   4.46e-16   1.95e-01  1.89e+00        1    5.68e-03    3.13e-01
  60  1.580853e-22    1.00e-21    8.17e-07   7.68e-16   1.05e+00  5.67e+00        1    5.79e-03    3.19e-01
  61  1.544429e-21   -1.39e-21    3.14e-06   3.73e-16   1.83e-01  4.52e+00        1    5.84e-03    3.25e-01
  62  1.623238e-20   -1.47e-20    0.00e+00   8.22e-16  -1.08e-01  2.26e+00        1    2.99e-03    3.28e-01
  63  1.320154e-20   -1.17e-20    0.00e+00   7.92e-16  -4.91e-02  5.65e-01        1    2.86e-03    3.31e-01
  64  5.291526e-21   -3.75e-21    5.66e-06   5.34e-16   1.05e-01  3.79e-01        1    5.92e-03    3.37e-01
  65  7.047905e-22    4.59e-21    1.83e-06   8.57e-16   1.17e+00  1.14e+00        1    5.86e-03    3.43e-01
  66  9.124706e-22   -2.08e-22    2.91e-06   5.76e-16   1.76e-01  8.92e-01        1    5.55e-03    3.48e-01
  67  1.229048e-21   -3.17e-22    2.86e-06   5.23e-16   1.67e-01  6.89e-01        1    5.91e-03    3.54e-01
  68  7.805912e-22    4.48e-22    1.78e-06   5.56e-16   5.32e-01  6.89e-01        1    5.94e-03    3.60e-01
  69  9.497352e-21   -8.72e-21    8.03e-06   5.49e-16   2.04e-02  3.66e-01        1    5.65e-03    3.66e-01
  70  1.134001e-21    8.36e-21    2.80e-06   1.56e-15   1.15e+00  1.10e+00        1    5.86e-03    3.72e-01
  71  8.120854e-21   -6.99e-21    6.66e-06   8.48e-16   3.86e-02  6.15e-01        1    5.76e-03    3.77e-01
  72  2.148682e-21    5.97e-21    3.44e-06   1.79e-15   8.30e-01  8.65e-01        1    5.49e-03    3.83e-01
  73  1.195438e-20   -9.81e-21    0.00e+00   8.75e-16  -1.69e-02  4.32e-01        1    2.96e-03    3.86e-01
  74  1.095625e-21    1.05e-21    2.40e-06   7.99e-16   5.75e-01  4.34e-01        1    6.07e-03    3.92e-01
  75  6.510252e-21   -5.41e-21    6.53e-06   6.15e-16   5.47e-02  2.54e-01        1    5.79e-03    3.98e-01
  76  3.832691e-21    2.68e-21    4.87e-06   1.24e-15   5.88e-01  2.56e-01        1    5.71e-03    4.03e-01
  77  7.238551e-22    3.11e-21    1.70e-06   5.54e-16   1.30e+00  7.67e-01        1    5.90e-03    4.09e-01
  78  8.240885e-22   -1.00e-22    2.26e-06   5.37e-16   1.18e-01  5.30e-01        1    5.65e-03    4.15e-01
  79  5.219462e-22    3.02e-22    1.24e-06   4.45e-16   4.99e-01  5.30e-01        1    5.83e-03    4.21e-01
  80  7.198996e-21   -6.68e-21    6.84e-06   2.74e-16   4.12e-02  2.99e-01        1    6.14e-03    4.27e-01
  81  1.170114e-21    6.03e-21    3.09e-06   1.34e-15   1.11e+00  8.98e-01        1    5.69e-03    4.33e-01
  82  2.417011e-21   -1.25e-21    4.76e-06   5.68e-16   9.10e-02  5.80e-01        1    5.79e-03    4.39e-01
  83  1.304965e-21    1.11e-21    3.11e-06   6.79e-16   5.27e-01  5.80e-01        1    5.74e-03    4.44e-01
  84  1.150803e-21    1.54e-22    3.13e-06   5.92e-16   1.42e-01  4.24e-01        1    5.59e-03    4.50e-01
  85  3.897283e-22    7.61e-22    1.44e-06   3.74e-16   8.60e-01  6.78e-01        1    5.99e-03    4.56e-01
  86  3.564074e-22    3.33e-23    8.41e-07   3.14e-16   1.21e-01  4.72e-01        1    5.57e-03    4.62e-01
  87  1.700133e-21   -1.34e-21    2.95e-06   2.67e-16   9.42e-02  3.08e-01        1    5.58e-03    4.67e-01
  88  1.239971e-20   -1.07e-20    0.00e+00   5.80e-16  -1.78e-02  1.54e-01        1    2.96e-03    4.70e-01
  89  3.548453e-21   -1.85e-21    3.71e-06   3.25e-16   7.42e-02  9.51e-02        1    5.88e-03    4.76e-01
  90  2.703416e-21    8.45e-22    4.07e-06   3.31e-16   6.44e-01  9.75e-02        1    5.59e-03    4.82e-01
  91  1.052905e-21    1.65e-21    2.59e-06   2.24e-16   1.59e+00  2.92e-01        1    5.61e-03    4.87e-01
  92  4.675022e-22    5.85e-22    1.76e-06   5.35e-16   8.35e-01  4.19e-01        1    5.96e-03    4.93e-01
  93  9.412207e-21   -8.94e-21    7.21e-06   3.30e-16   1.27e-02  2.18e-01        1    5.71e-03    4.99e-01
  94  5.982750e-22    8.81e-21    2.28e-06   1.29e-15   1.35e+00  6.53e-01        1    5.63e-03    5.05e-01
  95  2.375903e-21   -1.78e-21    4.53e-06   2.96e-16   7.80e-02  4.08e-01        1    5.80e-03    5.10e-01
  96  6.243699e-22    1.75e-21    1.89e-06   5.55e-16   9.31e-01  1.13e+00        1    5.92e-03    5.16e-01
  97  2.705227e-21   -2.08e-21    3.10e-06   5.99e-16   7.32e-02  6.96e-01        1    5.75e-03    5.22e-01
  98  9.556241e-23    2.61e-21    4.48e-07   9.39e-16   1.17e+00  2.09e+00        1    5.83e-03    5.28e-01
  99  1.494378e-20   -1.48e-20    0.00e+00   1.12e-16  -3.83e-02  1.04e+00        1    2.94e-03    5.31e-01
 100  2.137880e-20   -2.13e-20    0.00e+00   8.91e-17  -9.62e-02  2.61e-01        1    2.96e-03    5.34e-01
 101  1.120166e-22   -1.65e-23    4.41e-07   1.87e-17   9.50e-02  1.70e-01        1    5.57e-03    5.39e-01
 102  1.610930e-21   -1.50e-21    2.59e-06   3.42e-17   8.15e-02  1.07e-01        1    5.98e-03    5.45e-01
 103  3.220719e-22    1.29e-21    8.69e-07   3.08e-16   1.92e+00  3.22e-01        1    5.50e-03    5.51e-01
 104  1.635365e-22    1.59e-22    4.30e-07   2.59e-16   9.50e-01  9.67e-01        1    5.74e-03    5.57e-01
 105  2.673485e-22   -1.04e-22    1.29e-06   2.39e-16   9.29e-02  6.28e-01        1    5.82e-03    5.63e-01
 106  1.175796e-21   -9.08e-22    2.61e-06   3.11e-16   3.98e-01  6.23e-01        1    5.70e-03    5.68e-01
 107  8.010440e-21   -6.83e-21    0.00e+00   6.03e-16  -3.22e+00  3.11e-01        1    2.96e-03    5.71e-01
 108  1.423857e-20   -1.31e-20    0.00e+00   5.65e-16  -6.83e+00  7.78e-02        1    2.99e-03    5.74e-01
 109  1.152941e-21    2.29e-23    3.24e-06   2.66e-16   3.14e-01  7.40e-02        1    5.81e-03    5.80e-01
 110  9.815929e-22    1.71e-22    1.73e-06   1.47e-16   4.41e-01  7.39e-02        1    5.53e-03    5.86e-01
 111  7.154946e-22    2.66e-22    1.68e-06   9.58e-17   9.39e-01  2.22e-01        1    5.62e-03    5.91e-01
 112  6.824844e-22    3.30e-23    1.78e-06   3.17e-16   3.63e-01  2.17e-01        1    6.09e-03    5.97e-01
 113  7.088541e-22   -2.64e-23    1.96e-06   3.44e-16   3.03e-01  2.05e-01        1    5.52e-03    6.03e-01
 114  4.868728e-21   -4.16e-21    0.00e+00   1.89e-16  -9.75e-01  1.02e-01        1    2.85e-03    6.06e-01
 115  9.164232e-22   -2.08e-22    2.10e-06   1.06e-16   2.16e-01  8.65e-02        1    5.95e-03    6.12e-01
 116  9.653687e-23    8.20e-22    4.84e-07   2.43e-16   2.55e+00  2.60e-01        1    5.94e-03    6.18e-01
 117  1.714832e-22   -7.49e-23    9.22e-07   2.86e-17   4.04e-01  2.58e-01        1    5.74e-03    6.23e-01
 118  1.260978e-21   -1.09e-21    2.00e-06   2.56e-16   9.56e-02  1.69e-01        1    5.75e-03    6.29e-01
 119  7.151442e-21   -5.89e-21    0.00e+00   3.04e-16  -1.30e+00  8.43e-02        1    2.98e-03    6.32e-01
 120  8.879724e-21   -7.62e-21    0.00e+00   2.57e-16  -1.80e+00  2.11e-02        1    2.85e-03    6.35e-01
 121  3.880133e-22    8.73e-22    8.79e-07   3.47e-17   7.22e+00  6.32e-02        1    5.79e-03    6.41e-01
 122  2.350761e-21   -1.96e-21    0.00e+00   4.05e-17  -1.92e-01  3.16e-02        1    2.95e-03    6.44e-01
 123  2.964606e-22    9.16e-23    9.97e-07   2.36e-17   2.35e+00  9.48e-02        1    5.75e-03    6.50e-01
 124  2.956399e-21   -2.66e-21    0.00e+00   5.16e-17  -3.46e-01  4.74e-02        1    2.80e-03    6.52e-01
 125  2.350761e-21   -2.05e-21    0.00e+00   2.94e-17  -1.92e-01  1.19e-02        1    2.90e-03    6.55e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          7.773688e+01
Final                            9.556241e-23
Change                           7.773688e+01

Minimizer iterations                      126
Successful steps                           99
Unsuccessful steps                         27
Line search steps                          73

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0099
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6396
    Line search gradient evaluation    0.3606
  Linear solver                        0.0038
  Line search polynomial minimization  0.0005
Minimizer                              0.6584

Postprocessor                          0.0000
Total                                  0.6584

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.593339e+04
Final                            1.405024e+02
Change                           1.579288e+04

Minimizer iterations                       74
Successful steps                           38
Unsuccessful steps                         36
Line search steps                          52

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0053
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.3085
    Line search gradient evaluation    0.2027
  Linear solver                        0.0013
  Line search polynomial minimization  0.0002
Minimizer                              0.3165

Postprocessor                          0.0000
Total                                  0.3166

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA90 = {
{-0.0736910,0.5000597,0.2287873}
};
fitErrEl90 = {
{-0.1155011,0.4849277,0.2424720}
};
fitErrLa90 = {
{-0.1170499,0.5185847,0.2533689}
};
fitErrWr90 = {
{-0.3276707,0.4536748,0.3507973}
};
fitErrEe90 = {
{-0.3853161,0.4809287,0.4377189}
};
rMatsBase90 = {
{-0.3359633,0.7045634,-0.6250752},
{0.8116549,0.5532679,0.1873792},
{0.4778546,-0.4443928,-0.7577401}
};
outThetasWam90 = {
{-0.1070082,-0.2474641,-0.0480734,1.3270101,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5548276
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.249706e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    2.88e-03    2.92e-03
   1  4.580263e-01    1.25e+02    2.83e+00   4.96e-03   1.99e+00  3.00e+04        1    5.94e-03    8.87e-03
   2  1.282886e-08    4.58e-01    1.51e+00   4.86e-05   1.99e+00  9.00e+04        1    5.66e-03    1.46e-02
   3  1.906022e-15    1.28e-08    1.62e-04   4.23e-08   1.99e+00  2.70e+05        1    5.69e-03    2.03e-02
   4  1.182171e-20    1.91e-15    9.20e-06   1.97e-11   1.99e+00  8.10e+05        1    5.58e-03    2.59e-02
   5  1.398165e-22    1.17e-20    4.23e-07   9.92e-15   1.99e+00  2.43e+06        1    5.77e-03    3.16e-02
   6  7.727659e-22   -6.33e-22    2.65e-06   3.57e-15   1.99e+00  7.29e+06        1    5.50e-03    3.72e-02
   7  8.020659e-21   -7.25e-21    7.54e-06   2.81e-15   1.99e+00  2.19e+07        1    5.51e-03    4.27e-02
   8  7.353068e-21    6.68e-22    6.68e-06   4.42e-15   1.99e+00  6.56e+07        1    5.75e-03    4.84e-02
   9  3.229499e-21    4.12e-21    3.26e-06   5.61e-15   1.99e+00  1.97e+08        1    5.85e-03    5.43e-02
  10  8.312693e-22    2.40e-21    2.34e-06   4.56e-15   1.99e+00  5.90e+08        1    5.71e-03    6.00e-02
  11  6.697334e-22    1.62e-22    2.11e-06   9.26e-16   3.84e-01  5.83e+08        1    5.60e-03    6.57e-02
  12  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  2.92e+08        1    2.86e-03    6.85e-02
  13  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  7.29e+07        1    2.91e-03    7.14e-02
  14  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  9.11e+06        1    2.88e-03    7.43e-02
  15  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  5.69e+05        1    2.96e-03    7.73e-02
  16  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  1.78e+04        1    2.93e-03    8.03e-02
  17  1.054568e-20   -9.88e-21    0.00e+00   3.24e-15  -1.27e-01  2.78e+02        1    2.87e-03    8.31e-02
  18  1.234300e-20   -1.17e-20    0.00e+00   2.75e-15  -2.18e-01  2.17e+00        1    2.84e-03    8.60e-02
  19  1.623248e-22    5.07e-22    9.86e-07   5.23e-16   8.29e-01  3.04e+00        1    5.69e-03    9.17e-02
  20  2.383622e-21   -2.22e-21    3.60e-06   4.80e-16   2.83e-01  2.81e+00        1    5.78e-03    9.75e-02
  21  4.923313e-22    1.89e-21    1.51e-06   1.05e-15   8.47e-01  4.23e+00        1    5.79e-03    1.03e-01
  22  9.700272e-22   -4.78e-22    2.82e-06   5.16e-16   3.13e-01  4.02e+00        1    5.69e-03    1.09e-01
  23  2.575010e-22    7.13e-22    8.73e-07   7.40e-16   7.91e-01  5.01e+00        1    5.84e-03    1.15e-01
  24  8.159206e-21   -7.90e-21    0.00e+00   3.77e-16  -5.87e-03  2.50e+00        1    2.90e-03    1.18e-01
  25  5.117029e-21   -4.86e-21    5.95e-06   2.82e-16   1.23e-01  1.75e+00        1    5.58e-03    1.23e-01
  26  1.360348e-21    3.76e-21    2.37e-06   2.03e-15   7.69e-01  2.08e+00        1    5.56e-03    1.29e-01
  27  2.564547e-23    1.33e-21    1.53e-07   8.63e-16   1.13e+00  6.23e+00        1    5.61e-03    1.35e-01
  28  5.409787e-22   -5.15e-22    2.23e-06   2.24e-16   2.52e-01  5.55e+00        1    5.62e-03    1.40e-01
  29  9.764965e-22   -4.36e-22    2.18e-06   5.55e-16   2.33e-01  4.82e+00        1    5.64e-03    1.46e-01
  30  1.049253e-20   -9.52e-21    0.00e+00   6.03e-16  -7.96e-02  2.41e+00        1    3.04e-03    1.49e-01
  31  9.899929e-22   -1.35e-23    2.46e-06   5.69e-16   2.27e-01  2.07e+00        1    5.85e-03    1.55e-01
  32  3.466942e-21   -2.48e-21    3.36e-06   6.98e-16   1.42e-01  1.52e+00        1    5.59e-03    1.60e-01
  33  1.354298e-21    2.11e-21    2.98e-06   1.15e-15   6.55e-01  1.56e+00        1    5.66e-03    1.66e-01
  34  2.392581e-22    1.12e-21    1.09e-06   6.44e-16   8.58e-01  2.47e+00        1    5.59e-03    1.72e-01
  35  5.844002e-22   -3.45e-22    2.19e-06   3.66e-16   6.17e-01  2.50e+00        1    5.74e-03    1.77e-01
  36  4.366977e-21   -3.78e-21    0.00e+00   5.20e-16  -1.72e-01  1.25e+00        1    2.82e-03    1.80e-01
  37  1.946597e-21   -1.36e-21    3.73e-06   3.59e-16   2.92e-01  1.17e+00        1    5.51e-03    1.86e-01
  38  4.217067e-22    1.52e-21    1.15e-06   9.56e-16   8.55e-01  1.82e+00        1    5.61e-03    1.91e-01
  39  4.426949e-21   -4.01e-21    0.00e+00   5.26e-16  -1.31e-01  9.09e-01        1    3.03e-03    1.94e-01
  40  4.729881e-21   -4.31e-21    0.00e+00   3.36e-16  -1.73e-01  2.27e-01        1    3.04e-03    1.97e-01
  41  6.402696e-22   -2.19e-22    2.24e-06   2.65e-16   3.92e-01  2.25e-01        1    5.53e-03    2.03e-01
  42  1.065460e-20   -1.00e-20    0.00e+00   2.20e-16  -9.48e-01  1.13e-01        1    2.96e-03    2.06e-01
  43  1.179305e-22    5.22e-22    5.59e-07   1.03e-16   2.04e+00  3.38e-01        1    5.59e-03    2.12e-01
  44  1.073617e-22    1.06e-23    5.37e-07   6.40e-17   4.47e-01  3.37e-01        1    5.60e-03    2.17e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.249706e+02
Final                            2.564547e-23
Change                           1.249706e+02

Minimizer iterations                       45
Successful steps                           32
Unsuccessful steps                         13
Line search steps                          26

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0034
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2143
    Line search gradient evaluation    0.1262
  Linear solver                        0.0012
  Line search polynomial minimization  0.0001
Minimizer                              0.2202

Postprocessor                          0.0000
Total                                  0.2203

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.598815e+04
Final                            1.412368e+02
Change                           1.584691e+04

Minimizer iterations                      131
Successful steps                           76
Unsuccessful steps                         55
Line search steps                         179

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0095
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8203
    Line search gradient evaluation    0.6139
  Linear solver                        0.0022
  Line search polynomial minimization  0.0013
Minimizer                              0.8355

Postprocessor                          0.0000
Total                                  0.8356

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA91 = {
{-0.0731608,0.5011003,0.2295098}
};
fitErrEl91 = {
{-0.1150621,0.4859240,0.2432223}
};
fitErrLa91 = {
{-0.1166077,0.5197118,0.2541757}
};
fitErrWr91 = {
{-0.3279915,0.4541863,0.3518835}
};
fitErrEe91 = {
{-0.3849503,0.4809811,0.4395192}
};
rMatsBase91 = {
{-0.3379685,0.7020071,-0.6268679},
{0.8085040,0.5575062,0.1884360},
{0.4817661,-0.4431397,-0.7559951}
};
outThetasWam91 = {
{-0.1069046,-0.2455005,-0.0470457,1.3283821,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5559935
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  7.681644e+01    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    2.83e-03    2.87e-03
   1  1.742028e-02    7.68e+01    2.84e+00   2.83e-03   2.00e+00  3.00e+04        1    5.86e-03    8.76e-03
   2  5.228180e-10    1.74e-02    2.19e-01   1.09e-05   2.00e+00  9.00e+04        1    5.53e-03    1.43e-02
   3  1.066475e-16    5.23e-10    3.59e-05   9.85e-09   2.00e+00  2.70e+05        1    5.61e-03    1.99e-02
   4  1.111110e-20    1.07e-16    8.87e-06   4.65e-12   2.00e+00  8.10e+05        1    5.67e-03    2.56e-02
   5  2.420745e-21    8.69e-21    3.72e-06   8.94e-15   2.00e+00  2.43e+06        1    5.67e-03    3.13e-02
   6  3.899119e-21   -1.48e-21    5.07e-06   3.09e-15   2.00e+00  7.29e+06        1    5.56e-03    3.69e-02
   7  9.944046e-22    2.90e-21    2.67e-06   3.85e-15   2.00e+00  2.19e+07        1    5.52e-03    4.24e-02
   8  1.417839e-21   -4.23e-22    3.57e-06   1.27e-15   2.00e+00  6.56e+07        1    5.78e-03    4.82e-02
   9  2.359425e-22    1.18e-21    9.18e-07   3.19e-15   2.00e+00  1.97e+08        1    5.50e-03    5.37e-02
  10  1.414658e-20   -1.39e-20    1.02e-05   2.86e-15   2.00e+00  5.90e+08        1    5.74e-03    5.95e-02
  11  3.649056e-22    1.38e-20    6.53e-07   1.06e-14   2.00e+00  1.77e+09        1    5.51e-03    6.50e-02
  12  1.765274e-20   -1.73e-20    1.16e-05   5.65e-15   2.00e+00  5.31e+09        1    5.51e-03    7.05e-02
  13  7.807052e-22    1.69e-20    2.38e-06   7.18e-15   2.00e+00  1.59e+10        1    5.66e-03    7.62e-02
  14  5.585919e-21   -4.81e-21    6.33e-06   6.09e-16   2.00e+00  4.78e+10        1    5.50e-03    8.17e-02
  15  9.210391e-21   -3.62e-21    8.01e-06   4.20e-15   3.52e-01  4.66e+10        1    5.47e-03    8.72e-02
  16  1.292777e-20   -3.72e-21    9.85e-06   4.36e-15   1.43e-01  3.41e+10        1    5.99e-03    9.32e-02
  17  2.665529e-21    1.03e-20    2.92e-06   6.71e-15   7.97e-01  4.32e+10        1    6.19e-03    9.94e-02
  18  8.284004e-22    1.84e-21    1.54e-06   3.25e-15   7.03e-01  4.63e+10        1    6.13e-03    1.06e-01
  19  1.276750e-20   -1.19e-20    9.65e-06   4.24e-15   9.88e-02  3.05e+10        1    6.11e-03    1.12e-01
  20  9.950474e-22    1.18e-20    2.63e-06   1.09e-14   9.24e-01  7.79e+10        1    6.10e-03    1.18e-01
  21  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  3.90e+10        1    3.21e-03    1.21e-01
  22  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  9.74e+09        1    3.14e-03    1.24e-01
  23  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  1.22e+09        1    3.11e-03    1.27e-01
  24  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  7.61e+07        1    3.37e-03    1.31e-01
  25  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  2.38e+06        1    3.13e-03    1.34e-01
  26  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  3.72e+04        1    3.12e-03    1.37e-01
  27  1.759711e-20   -1.66e-20    0.00e+00   9.77e-16   8.84e-04  2.90e+02        1    3.14e-03    1.40e-01
  28  1.122672e-20   -1.02e-20    8.11e-06   9.26e-16   1.02e-01  1.93e+02        1    6.37e-03    1.46e-01
  29  1.139481e-21    1.01e-20    1.99e-06   6.74e-15   9.00e-01  3.97e+02        1    6.40e-03    1.53e-01
  30  1.006428e-22    1.04e-21    4.96e-07   2.20e-15   9.20e-01  9.69e+02        1    7.23e-03    1.60e-01
  31  1.062479e-20   -1.05e-20    8.89e-06   1.61e-15   9.33e-02  6.30e+02        1    6.22e-03    1.66e-01
  32  2.180110e-20   -1.12e-20    0.00e+00   6.68e-15  -4.83e-02  3.15e+02        1    3.13e-03    1.70e-01
  33  1.395639e-20   -3.33e-21    9.82e-06   6.46e-15   4.30e-02  1.79e+02        1    6.15e-03    1.76e-01
  34  2.149937e-22    1.37e-20    1.39e-06   6.15e-15   9.85e-01  5.36e+02        1    6.14e-03    1.82e-01
  35  4.583501e-21   -4.37e-21    4.90e-06   5.41e-16   1.31e-01  3.82e+02        1    6.15e-03    1.88e-01
  36  1.341827e-20   -8.83e-21    9.89e-06   6.34e-15   4.05e-02  2.15e+02        1    6.08e-03    1.94e-01
  37  1.543493e-20   -2.02e-21    0.00e+00   9.06e-15  -4.62e-02  1.08e+02        1    3.36e-03    1.97e-01
  38  8.190561e-21    5.23e-21    7.61e-06   8.10e-15   3.91e-01  1.06e+02        1    6.16e-03    2.04e-01
  39  1.279811e-22    8.06e-21    9.15e-07   4.31e-15   9.86e-01  3.19e+02        1    6.15e-03    2.10e-01
  40  1.192269e-20   -1.18e-20    9.36e-06   1.87e-15   5.05e-02  1.85e+02        1    6.17e-03    2.16e-01
  41  6.013857e-21    5.91e-21    6.37e-06   6.27e-15   4.98e-01  1.85e+02        1    6.14e-03    2.22e-01
  42  6.298093e-22    5.38e-21    1.99e-06   3.85e-15   9.03e-01  3.87e+02        1    6.94e-03    2.29e-01
  43  5.760912e-22    5.37e-23    1.51e-06   8.86e-16   2.28e-01  3.34e+02        1    6.15e-03    2.35e-01
  44  2.494490e-21   -1.92e-21    4.73e-06   1.10e-15   1.93e-01  2.71e+02        1    6.12e-03    2.41e-01
  45  9.379498e-22    1.56e-21    2.76e-06   1.15e-15   6.45e-01  2.78e+02        1    6.14e-03    2.48e-01
  46  1.409257e-20   -1.32e-20    0.00e+00   7.16e-16  -2.18e-03  1.39e+02        1    3.14e-03    2.51e-01
  47  8.929669e-21   -7.99e-21    8.09e-06   6.34e-16   8.03e-02  8.73e+01        1    6.27e-03    2.57e-01
  48  7.047028e-21    1.88e-21    7.49e-06   4.66e-15   2.12e-01  7.33e+01        1    6.11e-03    2.63e-01
  49  9.295767e-21   -2.25e-21    7.53e-06   2.82e-15   5.96e-02  4.35e+01        1    6.15e-03    2.69e-01
  50  1.076299e-20   -1.47e-21    8.58e-06   3.76e-15   3.65e-02  2.42e+01        1    6.14e-03    2.75e-01
  51  6.428902e-21    4.33e-21    6.74e-06   4.21e-15   4.06e-01  2.41e+01        1    6.14e-03    2.82e-01
  52  2.686609e-21    3.74e-21    4.21e-06   3.24e-15   5.90e-01  2.42e+01        1    6.09e-03    2.88e-01
  53  2.300275e-22    2.46e-21    1.20e-06   1.94e-15   9.34e-01  6.95e+01        1    6.11e-03    2.94e-01
  54  2.652793e-21   -2.42e-21    4.37e-06   1.16e-15   1.05e-01  4.66e+01        1    6.13e-03    3.00e-01
  55  7.075069e-21   -4.42e-21    7.86e-06   1.33e-15   6.26e-02  2.79e+01        1    6.16e-03    3.06e-01
  56  4.505351e-22    6.62e-21    1.59e-06   2.80e-15   9.47e-01  8.38e+01        1    6.12e-03    3.12e-01
  57  6.091592e-21   -5.64e-21    5.59e-06   2.16e-15   6.70e-02  5.08e+01        1    6.16e-03    3.18e-01
  58  1.338520e-20   -7.29e-21    8.42e-06   3.06e-15   4.63e-03  2.57e+01        1    6.31e-03    3.25e-01
  59  4.427286e-21    8.96e-21    6.36e-06   4.86e-15   6.75e-01  2.69e+01        1    6.14e-03    3.31e-01
  60  1.023271e-20   -5.81e-21    8.51e-06   1.96e-15   2.64e-02  1.45e+01        1    6.25e-03    3.37e-01
  61  1.270933e-20   -2.48e-21    9.01e-06   3.96e-15   8.25e-03  7.45e+00        1    6.34e-03    3.44e-01
  62  1.319680e-21    1.14e-20    3.17e-06   3.64e-15   9.00e-01  1.53e+01        1    6.16e-03    3.50e-01
  63  8.378334e-21   -7.06e-21    7.69e-06   1.38e-15   3.38e-02  8.46e+00        1    6.65e-03    3.56e-01
  64  1.282381e-20   -4.45e-21    9.78e-06   3.21e-15   6.53e-03  4.31e+00        1    6.35e-03    3.63e-01
  65  1.709600e-22    1.27e-20    9.33e-07   3.69e-15   1.00e+00  1.29e+01        1    6.13e-03    3.69e-01
  66  6.085790e-21   -5.91e-21    6.42e-06   8.18e-16   4.23e-02  7.32e+00        1    6.16e-03    3.75e-01
  67  1.212525e-20   -6.04e-21    8.86e-06   2.80e-15   9.52e-03  3.77e+00        1    6.20e-03    3.81e-01
  68  1.611997e-20   -3.99e-21    0.00e+00   3.50e-15  -1.06e-02  1.88e+00        1    3.16e-03    3.85e-01
  69  1.237958e-21    1.09e-20    3.12e-06   3.06e-15   9.26e-01  4.91e+00        1    6.15e-03    3.91e-01
  70  5.095856e-21   -3.86e-21    5.88e-06   9.00e-16   4.32e-02  2.79e+00        1    6.39e-03    3.97e-01
  71  7.539780e-22    4.34e-21    2.03e-06   2.20e-15   8.88e-01  5.22e+00        1    6.11e-03    4.03e-01
  72  1.807245e-22    5.73e-22    1.02e-06   7.23e-16   7.69e-01  6.18e+00        1    6.37e-03    4.10e-01
  73  2.008796e-21   -1.83e-21    4.24e-06   4.87e-16   5.66e-02  3.64e+00        1    6.41e-03    4.16e-01
  74  3.457260e-21   -1.45e-21    4.17e-06   8.87e-16   4.93e-02  2.10e+00        1    6.11e-03    4.22e-01
  75  3.191381e-21    2.66e-22    4.25e-06   1.45e-15   8.17e-02  1.33e+00        1    6.16e-03    4.28e-01
  76  4.376261e-21   -1.18e-21    5.84e-06   1.23e-15   4.37e-02  7.54e-01        1    6.12e-03    4.35e-01
  77  1.165418e-20   -7.28e-21    9.30e-06   9.44e-16   1.03e-02  3.89e-01        1    6.30e-03    4.41e-01
  78  1.551136e-20   -3.86e-21    0.00e+00   1.89e-15  -6.69e-03  1.94e-01        1    3.12e-03    4.44e-01
  79  5.428778e-23    1.16e-20    5.05e-07   1.30e-15   1.58e+00  5.83e-01        1    6.29e-03    4.50e-01
  80  5.984459e-23   -5.56e-24    6.24e-07   6.18e-17   6.03e-02  3.47e-01        1    6.38e-03    4.57e-01
  81  1.394125e-20   -1.39e-20    0.00e+00   6.63e-17   6.57e-05  1.73e-01        1    3.26e-03    4.60e-01
  82  1.116180e-22   -5.18e-23    7.37e-07   2.19e-17   6.00e-02  1.03e-01        1    6.21e-03    4.66e-01
  83  1.372751e-22   -2.57e-23    9.55e-07   4.31e-17   5.99e-02  6.13e-02        1    6.19e-03    4.73e-01
  84  5.984459e-23    7.74e-23    6.24e-07   2.82e-17   2.51e+00  1.84e-01        1    6.12e-03    4.79e-01
  85  5.963622e-23    2.08e-25    6.36e-07   2.86e-17   6.02e-02  1.10e-01        1    6.16e-03    4.85e-01
  86  5.984459e-23   -2.08e-25    6.24e-07   2.15e-17   9.35e-01  3.20e-01        1    6.28e-03    4.91e-01
  87  8.792368e-21   -8.73e-21    0.00e+00   6.63e-17  -7.27e+01  1.60e-01        1    3.35e-03    4.95e-01
  88  1.192086e-22   -5.94e-23    7.89e-07   2.19e-17   1.64e-01  1.23e-01        1    6.15e-03    5.01e-01
  89  1.372751e-22   -1.81e-23    0.00e+00   5.29e-17   0.00e+00  6.15e-02        1    3.16e-03    5.04e-01
  90  5.984459e-23    5.94e-23    6.24e-07   3.07e-17   2.05e+00  1.84e-01        1    6.53e-03    5.10e-01
  91  6.743521e-23   -7.59e-24    5.73e-07   2.86e-17   4.15e-01  1.83e-01        1    6.17e-03    5.17e-01
  92  6.364537e-23    3.79e-24    5.84e-07   2.15e-17   3.79e-01  1.81e-01        1    6.21e-03    5.23e-01
  93  1.154188e-22   -5.18e-23    7.78e-07   2.15e-17   9.89e-02  1.19e-01        1    6.30e-03    5.29e-01
  94  1.410759e-22   -2.57e-23    0.00e+00   4.72e-17  -1.43e-02  5.96e-02        1    3.16e-03    5.32e-01
  95  1.410759e-22   -2.57e-23    0.00e+00   3.07e-17  -1.53e-02  1.49e-02        1    3.16e-03    5.36e-01
  96  6.364537e-23    5.18e-23    5.84e-07   9.81e-18   6.30e+00  4.47e-02        1    6.23e-03    5.42e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          7.681644e+01
Final                            5.428778e-23
Change                           7.681644e+01

Minimizer iterations                       97
Successful steps                           80
Unsuccessful steps                         17
Line search steps                          58

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0079
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.5310
    Line search gradient evaluation    0.2918
  Linear solver                        0.0025
  Line search polynomial minimization  0.0003
Minimizer                              0.5450

Postprocessor                          0.0000
Total                                  0.5450

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.607815e+04
Final                            1.429660e+02
Change                           1.593518e+04

Minimizer iterations                      139
Successful steps                           83
Unsuccessful steps                         56
Line search steps                         158

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0112
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8734
    Line search gradient evaluation    0.6228
  Linear solver                        0.0027
  Line search polynomial minimization  0.0011
Minimizer                              0.8909

Postprocessor                          0.0000
Total                                  0.8910

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA92 = {
{-0.0725481,0.5026883,0.2306257}
};
fitErrEl92 = {
{-0.1145790,0.4874261,0.2443715}
};
fitErrLa92 = {
{-0.1161129,0.5215108,0.2554617}
};
fitErrWr92 = {
{-0.3293275,0.4550469,0.3536405}
};
fitErrEe92 = {
{-0.3860163,0.4812927,0.4418278}
};
rMatsBase92 = {
{-0.3411108,0.6983629,-0.6292318},
{0.8033892,0.5641300,0.1905860},
{0.4880667,-0.4405071,-0.7534881}
};
outThetasWam92 = {
{-0.1071514,-0.2426418,-0.0450450,1.3311286,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5578055
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.294196e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    3.08e-03    3.12e-03
   1  9.091080e-02    1.29e+02    2.84e+00   4.16e-03   2.00e+00  3.00e+04        1    6.34e-03    9.49e-03
   2  1.342798e-09    9.09e-02    1.12e+00   2.03e-05   2.00e+00  9.00e+04        1    6.17e-03    1.57e-02
   3  1.486257e-17    1.34e-09    1.95e-05   4.94e-09   2.00e+00  2.70e+05        1    6.20e-03    2.19e-02
   4  7.759256e-21    1.49e-17    7.41e-06   1.70e-12   2.00e+00  8.10e+05        1    6.21e-03    2.82e-02
   5  7.392746e-21    3.67e-22    7.44e-06   5.65e-15   2.00e+00  2.43e+06        1    6.30e-03    3.45e-02
   6  7.011123e-21    3.82e-22    6.78e-06   4.41e-15   2.00e+00  7.29e+06        1    6.16e-03    4.06e-02
   7  1.063805e-20   -3.63e-21    8.84e-06   9.69e-15   2.00e+00  2.19e+07        1    6.22e-03    4.69e-02
   8  6.893808e-22    9.95e-21    2.23e-06   9.44e-15   2.00e+00  6.56e+07        1    6.22e-03    5.31e-02
   9  7.221296e-21   -6.53e-21    7.34e-06   1.85e-15   2.00e+00  1.97e+08        1    6.19e-03    5.93e-02
  10  1.593540e-20   -8.71e-21    1.10e-05   6.23e-15   2.00e+00  5.90e+08        1    6.15e-03    6.55e-02
  11  1.038705e-20    5.55e-21    8.36e-06   8.45e-15   2.00e+00  1.77e+09        1    6.31e-03    7.18e-02
  12  3.230888e-21    7.16e-21    4.52e-06   6.06e-15   2.00e+00  5.31e+09        1    6.20e-03    7.80e-02
  13  7.317455e-21   -4.09e-21    6.38e-06   2.53e-15   2.00e+00  1.59e+10        1    6.17e-03    8.42e-02
  14  1.554750e-21    5.76e-21    3.75e-06   5.30e-15   7.93e-01  2.00e+10        1    6.17e-03    9.04e-02
  15  8.893065e-23    1.47e-21    5.19e-07   1.36e-15   9.47e-01  5.99e+10        1    6.11e-03    9.65e-02
  16  1.328952e-20   -1.32e-20    9.62e-06   1.02e-15   6.90e-02  3.65e+10        1    6.17e-03    1.03e-01
  17  7.125290e-21    6.16e-21    7.03e-06   6.94e-15   4.65e-01  3.65e+10        1    6.16e-03    1.09e-01
  18  3.473364e-22    6.78e-21    1.61e-06   7.96e-15   9.52e-01  1.10e+11        1    6.14e-03    1.15e-01
  19  8.639980e-21   -8.29e-21    7.79e-06   2.09e-15   1.24e-01  7.68e+10        1    6.14e-03    1.21e-01
  20  1.347521e-20   -4.84e-21    9.80e-06   4.35e-15   3.64e-02  4.27e+10        1    6.38e-03    1.28e-01
  21  5.822089e-21    7.65e-21    6.18e-06   5.44e-15   5.69e-01  4.28e+10        1    6.18e-03    1.34e-01
  22  9.468619e-21   -3.65e-21    8.27e-06   2.73e-15   2.08e-01  3.57e+10        1    6.24e-03    1.40e-01
  23  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  1.79e+10        1    3.15e-03    1.43e-01
  24  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  4.46e+09        1    3.13e-03    1.46e-01
  25  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  5.58e+08        1    3.12e-03    1.50e-01
  26  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  3.49e+07        1    3.10e-03    1.53e-01
  27  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  1.09e+06        1    3.25e-03    1.56e-01
  28  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  1.70e+04        1    3.13e-03    1.59e-01
  29  2.591284e-20   -1.64e-20    0.00e+00   7.33e-15  -4.33e-01  1.33e+02        1    3.13e-03    1.62e-01
  30  1.281808e-21    8.19e-21    3.31e-06   6.25e-15   8.67e-01  2.20e+02        1    6.14e-03    1.68e-01
  31  3.923240e-21   -2.64e-21    4.83e-06   2.20e-15   3.19e-01  2.10e+02        1    6.19e-03    1.75e-01
  32  9.810495e-23    3.83e-21    4.04e-07   2.70e-15   9.84e-01  6.30e+02        1    6.13e-03    1.81e-01
  33  2.160857e-21   -2.06e-21    4.45e-06   4.39e-16   3.34e-01  6.08e+02        1    6.13e-03    1.87e-01
  34  7.343809e-21   -5.18e-21    7.31e-06   2.21e-15   1.70e-01  4.72e+02        1    6.18e-03    1.93e-01
  35  1.445765e-20   -7.11e-21    0.00e+00   7.18e-15  -2.27e-02  2.36e+02        1    3.13e-03    1.96e-01
  36  8.655115e-21   -1.31e-21    7.87e-06   6.71e-15   1.11e-01  1.61e+02        1    6.15e-03    2.02e-01
  37  5.149909e-21    3.51e-21    6.01e-06   7.12e-15   4.07e-01  1.60e+02        1    6.13e-03    2.08e-01
  38  7.591685e-22    4.39e-21    2.25e-06   5.80e-15   8.55e-01  2.49e+02        1    6.27e-03    2.15e-01
  39  5.862496e-21   -5.10e-21    5.59e-06   2.05e-15   1.32e-01  1.78e+02        1    6.14e-03    2.21e-01
  40  1.346326e-20   -7.60e-21    0.00e+00   4.51e-15   1.88e-04  8.88e+01        1    3.17e-03    2.24e-01
  41  1.979759e-20   -1.39e-20    0.00e+00   4.10e-15  -9.94e-02  2.22e+01        1    3.20e-03    2.27e-01
  42  2.968569e-21    2.89e-21    5.24e-06   3.16e-15   5.02e-01  2.22e+01        1    6.16e-03    2.33e-01
  43  9.871333e-22    1.98e-21    2.74e-06   1.37e-15   6.71e-01  2.31e+01        1    6.29e-03    2.40e-01
  44  2.698001e-22    7.17e-22    1.50e-06   7.75e-16   7.40e-01  2.60e+01        1    6.45e-03    2.46e-01
  45  2.040792e-21   -1.77e-21    4.22e-06   5.14e-16   1.69e-01  2.02e+01        1    6.16e-03    2.52e-01
  46  7.123679e-22    1.33e-21    2.32e-06   1.32e-15   6.77e-01  2.11e+01        1    6.44e-03    2.59e-01
  47  9.967709e-21   -9.26e-21    8.36e-06   9.27e-16   4.98e-02  1.22e+01        1    6.55e-03    2.66e-01
  48  1.518583e-20   -5.22e-21    0.00e+00   3.02e-15  -2.13e-02  6.10e+00        1    3.16e-03    2.69e-01
  49  1.608483e-21    8.36e-21    3.41e-06   2.83e-15   8.45e-01  9.08e+00        1    6.16e-03    2.75e-01
  50  7.031481e-22    9.05e-22    1.98e-06   9.40e-16   6.06e-01  9.17e+00        1    6.30e-03    2.81e-01
  51  4.339559e-21   -3.64e-21    4.92e-06   7.09e-16   1.11e-01  6.23e+00        1    6.19e-03    2.87e-01
  52  1.242159e-21    3.10e-21    2.49e-06   2.08e-15   7.34e-01  6.95e+00        1    6.34e-03    2.94e-01
  53  2.687047e-22    9.73e-22    9.75e-07   1.24e-15   8.66e-01  1.14e+01        1    6.22e-03    3.00e-01
  54  3.851530e-21   -3.58e-21    5.01e-06   7.81e-16   1.09e-01  7.75e+00        1    6.14e-03    3.06e-01
  55  7.572555e-21   -3.72e-21    6.90e-06   1.26e-15   6.44e-02  4.66e+00        1    6.25e-03    3.12e-01
  56  3.973164e-21    3.60e-21    5.49e-06   2.80e-15   4.88e-01  4.66e+00        1    6.14e-03    3.19e-01
  57  2.685121e-22    3.70e-21    1.46e-06   1.75e-15   9.42e-01  1.40e+01        1    6.21e-03    3.25e-01
  58  4.371670e-21   -4.10e-21    5.59e-06   6.27e-16   8.82e-02  8.98e+00        1    6.25e-03    3.31e-01
  59  1.392504e-21    2.98e-21    2.36e-06   2.78e-15   6.94e-01  9.54e+00        1    6.16e-03    3.37e-01
  60  1.757837e-21   -3.65e-22    3.39e-06   1.10e-15   1.08e-01  6.43e+00        1    6.25e-03    3.44e-01
  61  6.646056e-22    1.09e-21    1.48e-06   1.18e-15   6.30e-01  6.54e+00        1    6.21e-03    3.50e-01
  62  9.894148e-22   -3.25e-22    2.59e-06   9.80e-16   1.12e-01  4.46e+00        1    6.17e-03    3.56e-01
  63  9.352917e-21   -8.36e-21    8.40e-06   9.83e-16   3.68e-02  2.49e+00        1    6.29e-03    3.62e-01
  64  3.886102e-21    5.47e-21    6.01e-06   2.70e-15   5.97e-01  2.50e+00        1    6.16e-03    3.68e-01
  65  7.141661e-22    3.17e-21    2.29e-06   1.20e-15   8.52e-01  3.84e+00        1    6.17e-03    3.75e-01
  66  8.105614e-21   -7.39e-21    7.58e-06   6.44e-16   4.28e-02  2.18e+00        1    6.31e-03    3.81e-01
  67  2.016975e-20   -1.21e-20    0.00e+00   2.75e-15  -5.03e-02  1.09e+00        1    3.14e-03    3.84e-01
  68  2.906312e-20   -2.10e-20    0.00e+00   2.27e-15  -1.17e-01  2.72e-01        1    3.14e-03    3.87e-01
  69  6.269031e-21    1.84e-21    5.14e-06   1.27e-15   3.27e-01  2.61e-01        1    6.27e-03    3.94e-01
  70  1.559816e-21    4.71e-21    3.30e-06   9.66e-16   1.11e+00  7.83e-01        1    6.19e-03    4.00e-01
  71  2.681465e-22    1.29e-21    1.42e-06   8.58e-16   9.17e-01  1.87e+00        1    6.16e-03    4.06e-01
  72  9.797354e-22   -7.12e-22    2.68e-06   2.59e-16   9.12e-02  1.21e+00        1    6.31e-03    4.12e-01
  73  7.894794e-22    1.90e-22    1.78e-06   8.18e-16   2.11e-01  1.01e+00        1    6.14e-03    4.18e-01
  74  2.406002e-22    5.49e-22    1.23e-06   4.75e-16   8.35e-01  1.45e+00        1    6.21e-03    4.25e-01
  75  6.677858e-21   -6.44e-21    6.49e-06   3.50e-16   4.90e-02  8.35e-01        1    6.25e-03    4.31e-01
  76  1.268431e-20   -6.01e-21    9.79e-06   1.91e-15   5.45e-03  4.24e-01        1    6.15e-03    4.37e-01
  77  6.997975e-21    5.69e-21    6.54e-06   2.12e-15   5.39e-01  4.24e-01        1    6.15e-03    4.43e-01
  78  2.770662e-21    4.23e-21    4.12e-06   1.37e-15   7.22e-01  4.65e-01        1    6.27e-03    4.49e-01
  79  5.546926e-22    2.22e-21    1.73e-06   1.00e-15   9.51e-01  1.40e+00        1    6.16e-03    4.56e-01
  80  8.410754e-22   -2.86e-22    2.56e-06   4.60e-16   7.69e-02  8.69e-01        1    6.57e-03    4.62e-01
  81  1.866220e-21   -1.03e-21    3.37e-06   5.06e-16   7.04e-02  5.32e-01        1    6.14e-03    4.68e-01
  82  3.788067e-21   -1.92e-21    4.95e-06   5.49e-16   5.82e-02  3.15e-01        1    6.13e-03    4.75e-01
  83  5.382794e-22    3.25e-21    1.67e-06   6.26e-16   1.24e+00  9.44e-01        1    6.22e-03    4.81e-01
  84  2.510663e-22    2.87e-22    1.32e-06   3.89e-16   5.98e-01  9.51e-01        1    6.14e-03    4.87e-01
  85  9.348162e-21   -9.10e-21    8.23e-06   3.50e-16   2.43e-02  5.11e-01        1    6.19e-03    4.93e-01
  86  3.705917e-21    5.64e-21    5.08e-06   1.87e-15   7.27e-01  5.64e-01        1    6.13e-03    4.99e-01
  87  4.476706e-21   -7.71e-22    5.77e-06   1.25e-15   4.98e-02  3.26e-01        1    6.25e-03    5.06e-01
  88  6.573887e-21   -2.10e-21    6.96e-06   1.15e-15   3.75e-02  1.82e-01        1    6.11e-03    5.12e-01
  89  1.019327e-21    5.55e-21    2.75e-06   9.36e-16   1.39e+00  5.46e-01        1    6.28e-03    5.18e-01
  90  3.174722e-22    7.02e-22    1.33e-06   5.81e-16   8.33e-01  7.75e-01        1    6.16e-03    5.24e-01
  91  2.862503e-21   -2.55e-21    4.30e-06   2.97e-16   5.61e-02  4.56e-01        1    6.15e-03    5.30e-01
  92  5.531301e-23    2.81e-21    1.12e-07   9.15e-16   1.25e+00  1.37e+00        1    6.25e-03    5.37e-01
  93  9.639815e-23   -4.11e-23    4.16e-07   6.94e-18   6.99e-02  8.36e-01        1    6.11e-03    5.43e-01
  94  2.336749e-22   -1.37e-22    7.49e-07   6.14e-17   6.92e-02  5.10e-01        1    6.20e-03    5.49e-01
  95  3.131517e-22   -7.95e-23    1.44e-06   2.66e-16   6.87e-02  3.10e-01        1    6.23e-03    5.55e-01
  96  1.518641e-22    1.61e-22    7.64e-07   2.82e-16   7.47e-01  3.53e-01        1    6.11e-03    5.61e-01
  97  5.756584e-23    9.43e-23    1.19e-07   1.18e-16   1.63e+00  1.06e+00        1    6.28e-03    5.68e-01
  98  9.873318e-23   -4.12e-23    4.15e-07   8.67e-18   7.77e-01  1.28e+00        1    6.11e-03    5.74e-01
  99  2.080882e-21   -1.98e-21    0.00e+00   1.29e-16  -5.89e+00  6.39e-01        1    3.13e-03    5.77e-01
 100  2.358455e-22   -1.37e-22    7.42e-07   5.55e-17   2.60e-01  5.75e-01        1    6.17e-03    5.83e-01
 101  8.583641e-22   -6.23e-22    0.00e+00   2.68e-16  -1.26e+00  2.87e-01        1    3.22e-03    5.86e-01
 102  3.252672e-22   -8.94e-23    0.00e+00   1.02e-16  -2.96e-02  7.18e-02        1    3.12e-03    5.89e-01
 103  9.873318e-23    1.37e-22    4.15e-07   3.90e-17   2.74e+00  2.16e-01        1    6.31e-03    5.96e-01
 104  2.358455e-22   -1.37e-22    7.42e-07   3.33e-17   2.13e-01  1.81e-01        1    6.30e-03    6.02e-01
 105  3.252672e-22   -8.94e-23    0.00e+00   7.65e-17  -2.67e-02  9.06e-02        1    3.10e-03    6.05e-01
 106  9.873318e-23    1.37e-22    4.15e-07   4.72e-17   2.32e+00  2.72e-01        1    6.14e-03    6.11e-01
 107  1.518641e-22   -5.31e-23    7.64e-07   4.05e-17   3.67e-01  2.67e-01        1    6.22e-03    6.18e-01
 108  2.582054e-21   -2.43e-21    0.00e+00   1.16e-16  -4.61e+00  1.33e-01        1    3.12e-03    6.21e-01
 109  9.873318e-23    5.31e-23    4.15e-07   2.26e-17   1.36e+00  4.00e-01        1    6.12e-03    6.27e-01
 110  2.358455e-22   -1.37e-22    7.42e-07   4.44e-17   1.55e-01  3.02e-01        1    6.29e-03    6.33e-01
 111  1.970736e-22    3.88e-23    1.00e-06   1.03e-16   3.42e-01  2.92e-01        1    6.17e-03    6.39e-01
 112  1.367325e-22    6.03e-23    7.49e-07   2.62e-16   5.53e-01  2.93e-01        1    6.24e-03    6.46e-01
 113  8.360157e-23    5.31e-23    4.83e-07   1.15e-16   9.94e-01  8.78e-01        1    6.31e-03    6.52e-01
 114  2.215500e-22   -1.38e-22    7.25e-07   7.25e-17   1.14e-01  6.02e-01        1    6.16e-03    6.58e-01
 115  8.636695e-22   -6.42e-22    0.00e+00   2.64e-16  -5.95e-01  3.01e-01        1    3.12e-03    6.61e-01
 116  3.205920e-22   -9.90e-23    0.00e+00   9.49e-17  -8.24e-03  7.52e-02        1    3.13e-03    6.64e-01
 117  6.464063e-23    1.57e-22    3.06e-07   3.75e-17   3.42e+00  2.26e-01        1    6.36e-03    6.71e-01
 118  8.360157e-23   -1.90e-23    4.83e-07   8.67e-18   2.68e-01  2.05e-01        1    6.18e-03    6.77e-01
 119  2.215500e-22   -1.38e-22    7.25e-07   3.93e-17   1.04e-01  1.37e-01        1    6.25e-03    6.83e-01
 120  4.243422e-23    1.79e-22    1.34e-07   6.11e-17   2.61e+00  4.12e-01        1    6.22e-03    6.89e-01
 121  8.360157e-23   -4.12e-23    4.83e-07   1.40e-17   2.42e-01  3.62e-01        1    6.25e-03    6.96e-01
 122  2.207139e-22   -1.37e-22    7.28e-07   5.16e-17   9.51e-02  2.36e-01        1    6.34e-03    7.02e-01
 123  3.205920e-22   -9.99e-23    0.00e+00   8.61e-17  -6.99e-03  1.18e-01        1    3.13e-03    7.05e-01
 124  8.360157e-23    1.37e-22    4.83e-07   5.30e-17   2.15e+00  3.55e-01        1    6.18e-03    7.11e-01
 125  4.362229e-23    4.00e-23    1.37e-07   5.16e-17   1.64e+00  1.06e+00        1    6.19e-03    7.18e-01
 126  2.207139e-22   -1.77e-22    7.28e-07   1.71e-17   8.69e-02  6.80e-01        1    6.20e-03    7.24e-01
 127  1.382320e-21   -1.16e-21    0.00e+00   2.68e-16  -5.33e+00  3.40e-01        1    3.18e-03    7.27e-01
 128  3.205920e-22   -9.99e-23    0.00e+00   1.04e-16  -5.05e-01  8.50e-02        1    3.15e-03    7.30e-01
 129  8.360157e-23    1.37e-22    4.83e-07   4.05e-17   2.68e+00  2.55e-01        1    6.23e-03    7.36e-01
 130  2.207139e-22   -1.37e-22    0.00e+00   4.18e-17   0.00e+00  1.28e-01        1    3.16e-03    7.40e-01
 131  4.362229e-23    4.00e-23    1.37e-07   2.94e-17   2.65e+00  3.83e-01        1    6.22e-03    7.46e-01
 132  2.207139e-22   -1.77e-22    0.00e+00   1.40e-17   0.00e+00  1.91e-01        1    3.13e-03    7.49e-01
 133  2.207139e-22   -1.77e-22    0.00e+00   1.11e-17   0.00e+00  4.78e-02        1    3.13e-03    7.52e-01
 134  2.207139e-22   -1.77e-22    0.00e+00   3.47e-18   0.00e+00  5.98e-03        1    3.10e-03    7.55e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.294196e+02
Final                            4.243422e-23
Change                           1.294196e+02

Minimizer iterations                      135
Successful steps                          108
Unsuccessful steps                         27
Line search steps                          75

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0115
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7392
    Line search gradient evaluation    0.4114
  Linear solver                        0.0031
  Line search polynomial minimization  0.0005
Minimizer                              0.7586

Postprocessor                          0.0000
Total                                  0.7586

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 
W1104 07:49:31.037744  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.613901e+04
Final                            1.447340e+02
Change                           1.599428e+04

Minimizer iterations                      348
Successful steps                          212
Unsuccessful steps                        136
Line search steps                         530

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0272
    Line search cost evaluation        0.0000
  Jacobian evaluation                  2.5502
    Line search gradient evaluation    1.9272
  Linear solver                        0.0068
  Line search polynomial minimization  0.0046
Minimizer                              2.5956

Postprocessor                          0.0000
Total                                  2.5958

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA93 = {
{-0.0721879,0.5042686,0.2316088}
};
fitErrEl93 = {
{-0.1143470,0.4889346,0.2453906}
};
fitErrLa93 = {
{-0.1158749,0.5232480,0.2565810}
};
fitErrWr93 = {
{-0.3304832,0.4560890,0.3551611}
};
fitErrEe93 = {
{-0.3867143,0.4819240,0.4439377}
};
rMatsBase93 = {
{-0.3430585,0.6959295,-0.6308669},
{0.7996563,0.5687456,0.1925572},
{0.4928090,-0.4384183,-0.7516174}
};
outThetasWam93 = {
{-0.1070418,-0.2400640,-0.0436252,1.3327675,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5595896
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  8.978786e+01    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    2.90e-03    2.93e-03
   1  3.228869e-02    8.98e+01    2.84e+00   3.06e-03   2.00e+00  3.00e+04        1    5.85e-03    8.81e-03
   2  3.800838e-10    3.23e-02    6.21e-01   1.23e-05   2.00e+00  9.00e+04        1    5.70e-03    1.45e-02
   3  4.541058e-17    3.80e-10    2.77e-05   6.58e-09   2.00e+00  2.70e+05        1    5.80e-03    2.03e-02
   4  6.986458e-21    4.54e-17    6.62e-06   3.03e-12   2.00e+00  8.10e+05        1    5.57e-03    2.59e-02
   5  8.922172e-22    6.09e-21    1.83e-06   4.11e-15   2.00e+00  2.43e+06        1    5.68e-03    3.16e-02
   6  6.589480e-21   -5.70e-21    7.14e-06   3.28e-15   2.00e+00  7.29e+06        1    5.92e-03    3.76e-02
   7  5.705458e-21    8.84e-22    6.24e-06   3.02e-15   2.00e+00  2.19e+07        1    5.77e-03    4.33e-02
   8  3.683407e-21    2.02e-21    5.18e-06   4.27e-15   2.00e+00  6.56e+07        1    5.92e-03    4.93e-02
   9  3.078139e-22    3.38e-21    1.05e-06   4.94e-15   2.00e+00  1.97e+08        1    5.87e-03    5.52e-02
  10  7.334360e-21   -7.03e-21    5.77e-06   1.07e-15   2.00e+00  5.90e+08        1    5.86e-03    6.11e-02
  11  7.195245e-21    1.39e-22    7.05e-06   6.34e-15   2.00e+00  1.77e+09        1    5.89e-03    6.70e-02
  12  1.428396e-21    5.77e-21    2.92e-06   5.94e-15   2.00e+00  5.31e+09        1    5.66e-03    7.27e-02
  13  2.721285e-20   -2.58e-20    1.42e-05   1.69e-15   2.00e+00  1.59e+10        1    5.68e-03    7.84e-02
  14  1.865484e-20    8.56e-21    1.19e-05   8.48e-15   2.00e+00  4.78e+10        1    5.97e-03    8.43e-02
  15  3.246196e-21    1.54e-20    4.86e-06   8.47e-15   8.27e-01  6.64e+10        1    5.88e-03    9.03e-02
  16  4.993701e-21   -1.75e-21    5.26e-06   6.17e-15   4.54e-01  6.63e+10        1    5.54e-03    9.58e-02
  17  5.117919e-21   -1.24e-22    5.43e-06   3.03e-15   4.10e-01  6.59e+10        1    5.98e-03    1.02e-01
  18  5.443183e-21   -3.25e-22    5.54e-06   2.91e-15   3.69e-01  6.48e+10        1    5.93e-03    1.08e-01
  19  6.134330e-22    4.83e-21    1.61e-06   5.05e-15   8.96e-01  1.29e+11        1    5.61e-03    1.13e-01
  20  1.651107e-20   -1.59e-20    1.02e-05   1.78e-15   1.65e-01  9.90e+10        1    6.07e-03    1.19e-01
  21  1.915917e-21    1.46e-20    4.05e-06   9.83e-15   8.87e-01  1.85e+11        1    5.60e-03    1.25e-01
  22  7.053626e-21   -5.14e-21    6.18e-06   4.68e-15   2.42e-01  1.63e+11        1    5.68e-03    1.31e-01
  23  6.574635e-21    4.79e-22    6.63e-06   4.83e-15   2.29e-01  1.40e+11        1    5.80e-03    1.37e-01
  24  8.162628e-21   -1.59e-21    7.93e-06   6.11e-15   1.97e-01  1.15e+11        1    5.54e-03    1.42e-01
  25  1.256644e-21    6.91e-21    2.77e-06   5.15e-15   8.57e-01  1.80e+11        1    5.94e-03    1.48e-01
  26  2.669088e-21   -1.41e-21    4.09e-06   2.15e-15   2.31e-01  1.56e+11        1    5.95e-03    1.54e-01
  27  6.490101e-21   -3.82e-21    7.09e-06   2.94e-15   1.91e-01  1.26e+11        1    5.79e-03    1.60e-01
  28  2.723572e-21    3.77e-21    3.88e-06   5.59e-15   5.84e-01  1.27e+11        1    5.70e-03    1.66e-01
  29  3.436198e-21   -7.13e-22    3.93e-06   3.65e-15   2.02e-01  1.05e+11        1    5.87e-03    1.72e-01
  30  5.253786e-21   -1.82e-21    6.20e-06   2.79e-15   1.81e-01  8.31e+10        1    5.78e-03    1.77e-01
  31  9.328593e-21   -4.07e-21    8.90e-06   2.71e-15   1.41e-01  6.07e+10        1    5.72e-03    1.83e-01
  32  4.777775e-21    4.55e-21    5.30e-06   3.16e-15   4.94e-01  6.07e+10        1    5.76e-03    1.89e-01
  33  1.916953e-21    2.86e-21    3.48e-06   4.51e-15   6.02e-01  6.13e+10        1    5.94e-03    1.95e-01
  34  9.290493e-22    9.88e-22    2.56e-06   3.14e-15   5.21e-01  6.13e+10        1    6.04e-03    2.01e-01
  35  4.240044e-21   -3.31e-21    5.62e-06   2.23e-15   1.60e-01  4.67e+10        1    5.76e-03    2.07e-01
  36  2.475945e-21    1.76e-21    4.09e-06   4.48e-15   4.24e-01  4.65e+10        1    5.53e-03    2.12e-01
  37  2.650978e-21   -1.75e-22    4.50e-06   5.05e-15   1.64e-01  3.57e+10        1    5.93e-03    2.18e-01
  38  3.717871e-21   -1.07e-21    5.18e-06   3.34e-15   1.54e-01  2.68e+10        1    5.74e-03    2.24e-01
  39  9.653521e-21   -5.94e-21    8.49e-06   4.25e-15   1.13e-01  1.83e+10        1    5.81e-03    2.30e-01
  40  3.876791e-21    5.78e-21    5.29e-06   7.02e-15   6.00e-01  1.84e+10        1    6.26e-03    2.36e-01
  41  1.669649e-21    2.21e-21    3.33e-06   3.17e-15   5.72e-01  1.85e+10        1    5.76e-03    2.42e-01
  42  5.115171e-21   -3.45e-21    6.25e-06   4.32e-15   1.29e-01  1.31e+10        1    5.82e-03    2.48e-01
  43  1.899544e-21    3.22e-21    3.53e-06   4.26e-15   6.30e-01  1.34e+10        1    5.82e-03    2.54e-01
  44  2.160855e-21   -2.61e-22    3.50e-06   2.09e-15   1.41e-01  9.75e+09        1    5.88e-03    2.59e-01
  45  9.568287e-21   -7.41e-21    7.40e-06   4.59e-15   9.79e-02  6.41e+09        1    5.75e-03    2.65e-01
  46  1.916888e-21    7.65e-21    4.01e-06   8.29e-15   8.06e-01  8.31e+09        1    5.66e-03    2.71e-01
  47  1.666542e-20   -1.47e-20    1.09e-05   2.59e-15   5.50e-02  4.88e+09        1    5.89e-03    2.77e-01
  48  5.466794e-21    1.12e-20    6.20e-06   1.07e-14   6.72e-01  5.09e+09        1    5.65e-03    2.83e-01
  49  5.272614e-21    1.94e-22    6.13e-06   3.84e-15   1.03e-01  3.39e+09        1    5.61e-03    2.88e-01
  50  3.129503e-21    2.14e-21    4.79e-06   2.06e-15   4.11e-01  3.37e+09        1    6.09e-03    2.94e-01
  51  3.200356e-21   -7.09e-23    4.97e-06   2.58e-15   1.08e-01  2.27e+09        1    5.82e-03    3.00e-01
  52  1.271410e-22    3.07e-21    1.99e-07   3.36e-15   9.62e-01  6.82e+09        1    5.70e-03    3.06e-01
  53  1.140258e-21   -1.01e-21    2.13e-06   2.65e-15   1.16e-01  4.69e+09        1    5.69e-03    3.12e-01
  54  3.813944e-21   -2.67e-21    5.20e-06   5.83e-15   1.03e-01  3.13e+09        1    5.82e-03    3.17e-01
  55  5.143221e-21   -1.33e-21    6.36e-06   3.38e-15   9.59e-02  2.05e+09        1    5.52e-03    3.23e-01
  56  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  1.02e+09        1    2.90e-03    3.26e-01
  57  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  2.56e+08        1    3.21e-03    3.29e-01
  58  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  3.20e+07        1    2.85e-03    3.32e-01
  59  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  2.00e+06        1    3.04e-03    3.35e-01
  60  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  6.25e+04        1    2.99e-03    3.38e-01
  61  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  9.76e+02        1    2.94e-03    3.41e-01
  62  2.954501e-20   -2.44e-20    0.00e+00   2.44e-15  -9.91e-03  7.63e+00        1    2.95e-03    3.44e-01
  63  4.588374e-21    5.55e-22    5.28e-06   2.24e-15   1.10e-01  5.17e+00        1    5.69e-03    3.50e-01
  64  4.691132e-21   -1.03e-22    5.37e-06   1.94e-15   9.40e-02  3.37e+00        1    5.68e-03    3.55e-01
  65  4.588374e-21    1.03e-22    5.28e-06   1.94e-15   3.93e-02  1.89e+00        1    5.86e-03    3.61e-01
  66  3.243318e-21    1.35e-21    4.94e-06   1.71e-15   3.07e-01  1.79e+00        1    5.75e-03    3.67e-01
  67  2.698153e-21    5.45e-22    4.34e-06   1.60e-15   1.77e-01  1.41e+00        1    5.73e-03    3.73e-01
  68  2.003752e-20   -1.73e-20    0.00e+00   1.39e-15  -6.19e-01  7.03e-01        1    2.87e-03    3.76e-01
  69  1.188646e-20   -9.19e-21    0.00e+00   1.14e-15  -2.82e-01  1.76e-01        1    2.97e-03    3.79e-01
  70  6.944925e-21   -4.25e-21    0.00e+00   6.18e-16  -7.79e-02  2.20e-02        1    2.95e-03    3.81e-01
  71  4.702343e-21   -2.00e-21    5.64e-06   3.54e-17   2.01e-02  1.17e-02        1    5.82e-03    3.87e-01
  72  3.267600e-21    1.43e-21    4.32e-06   2.86e-17   4.41e+00  3.50e-02        1    5.65e-03    3.93e-01
  73  1.919101e-21    1.35e-21    3.49e-06   2.59e-16   2.36e+00  1.05e-01        1    5.83e-03    3.99e-01
  74  2.700892e-21   -7.82e-22    4.38e-06   3.16e-16   1.03e-01  7.00e-02        1    5.81e-03    4.05e-01
  75  1.160497e-21    1.54e-21    2.57e-06   2.96e-16   1.73e+00  2.10e-01        1    5.87e-03    4.11e-01
  76  3.064840e-20   -2.95e-20    0.00e+00   3.63e-16  -1.01e+00  1.05e-01        1    2.98e-03    4.14e-01
  77  4.912604e-22    6.69e-22    1.78e-06   2.72e-16   1.51e+00  3.15e-01        1    5.57e-03    4.19e-01
  78  3.261121e-21   -2.77e-21    4.33e-06   3.51e-16   7.44e-02  1.95e-01        1    5.81e-03    4.25e-01
  79  2.694171e-21    5.67e-22    4.27e-06   5.99e-16   3.02e-01  1.83e-01        1    5.84e-03    4.31e-01
  80  3.042506e-21   -3.48e-22    4.72e-06   6.00e-16   7.29e-02  1.13e-01        1    5.78e-03    4.37e-01
  81  2.057837e-20   -1.75e-20    0.00e+00   4.13e-16  -5.10e-01  5.65e-02        1    2.89e-03    4.40e-01
  82  9.003472e-21   -5.96e-21    0.00e+00   2.88e-16  -1.30e-01  1.41e-02        1    2.96e-03    4.42e-01
  83  3.448562e-21   -4.06e-22    5.18e-06   2.15e-17   5.82e-02  8.36e-03        1    6.18e-03    4.49e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          8.978786e+01
Final                            1.271410e-22
Change                           8.978786e+01

Minimizer iterations                       84
Successful steps                           71
Unsuccessful steps                         13
Line search steps                          46

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0065
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4399
    Line search gradient evaluation    0.2397
  Linear solver                        0.0024
  Line search polynomial minimization  0.0002
Minimizer                              0.4517

Postprocessor                          0.0000
Total                                  0.4518

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.621887e+04
Final                            1.473535e+02
Change                           1.607151e+04

Minimizer iterations                      184
Successful steps                          132
Unsuccessful steps                         52
Line search steps                         296

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0136
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.3846
    Line search gradient evaluation    1.0250
  Linear solver                        0.0034
  Line search polynomial minimization  0.0023
Minimizer                              1.4072

Postprocessor                          0.0000
Total                                  1.4073

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA94 = {
{-0.0715981,0.5049879,0.2322625}
};
fitErrEl94 = {
{-0.1138122,0.4895937,0.2460523}
};
fitErrLa94 = {
{-0.1153254,0.5241327,0.2573561}
};
fitErrWr94 = {
{-0.3313359,0.4562356,0.3562039}
};
fitErrEe94 = {
{-0.3874068,0.4816506,0.4453815}
};
rMatsBase94 = {
{-0.3457443,0.6926978,-0.6329539},
{0.7950765,0.5745014,0.1944259},
{0.4983114,-0.4360251,-0.7493783}
};
outThetasWam94 = {
{-0.1071371,-0.2382186,-0.0417774,1.3354418,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5604328
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.107249e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    2.88e-03    2.92e-03
   1  2.436212e-02    1.11e+02    2.84e+00   3.44e-03   2.00e+00  3.00e+04        1    5.65e-03    8.59e-03
   2  4.522682e-10    2.44e-02    8.80e-01   1.15e-05   2.00e+00  9.00e+04        1    5.57e-03    1.42e-02
   3  3.099812e-17    4.52e-10    2.25e-05   4.93e-09   2.00e+00  2.70e+05        1    5.53e-03    1.97e-02
   4  5.752329e-21    3.10e-17    6.50e-06   2.48e-12   2.00e+00  8.10e+05        1    5.56e-03    2.53e-02
   5  3.287185e-21    2.47e-21    4.92e-06   2.31e-15   2.00e+00  2.43e+06        1    5.60e-03    3.09e-02
   6  6.406696e-21   -3.12e-21    6.47e-06   4.99e-15   2.00e+00  7.29e+06        1    5.49e-03    3.64e-02
   7  5.085184e-21    1.32e-21    6.68e-06   2.57e-15   2.00e+00  2.19e+07        1    5.46e-03    4.19e-02
   8  6.338649e-21   -1.25e-21    7.46e-06   1.58e-15   2.00e+00  6.56e+07        1    5.70e-03    4.76e-02
   9  8.398424e-22    5.50e-21    2.41e-06   3.06e-15   2.00e+00  1.97e+08        1    5.50e-03    5.31e-02
  10  3.518950e-21   -2.68e-21    4.57e-06   1.85e-15   2.00e+00  5.90e+08        1    5.51e-03    5.86e-02
  11  4.382115e-21   -8.63e-22    5.77e-06   3.18e-15   2.00e+00  1.77e+09        1    5.94e-03    6.46e-02
  12  3.836554e-21    5.46e-22    5.29e-06   4.70e-15   2.00e+00  5.31e+09        1    5.90e-03    7.05e-02
  13  2.618961e-20   -2.24e-20    1.28e-05   6.19e-15   2.00e+00  1.59e+10        1    5.70e-03    7.62e-02
  14  2.344561e-20    2.74e-21    1.34e-05   7.09e-15   2.00e+00  4.78e+10        1    5.62e-03    8.19e-02
  15  7.760487e-21    1.57e-20    5.63e-06   1.07e-14   6.72e-01  4.99e+10        1    5.65e-03    8.75e-02
  16  1.486716e-21    6.27e-21    2.78e-06   5.81e-15   8.16e-01  6.67e+10        1    5.55e-03    9.31e-02
  17  1.083821e-21    4.03e-22    2.72e-06   1.59e-15   4.28e-01  6.65e+10        1    5.58e-03    9.87e-02
  18  3.567468e-21   -2.48e-21    4.74e-06   3.76e-15   3.79e-01  6.55e+10        1    5.50e-03    1.04e-01
  19  3.114711e-21    4.53e-22    5.33e-06   4.03e-15   3.65e-01  6.43e+10        1    5.95e-03    1.10e-01
  20  3.826379e-21   -7.12e-22    5.09e-06   1.52e-15   3.37e-01  6.21e+10        1    5.56e-03    1.16e-01
  21  5.645055e-21   -1.82e-21    5.99e-06   5.85e-15   2.93e-01  5.80e+10        1    5.53e-03    1.21e-01
  22  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  2.90e+10        1    2.90e-03    1.24e-01
  23  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  7.25e+09        1    2.85e-03    1.27e-01
  24  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  9.07e+08        1    2.84e-03    1.30e-01
  25  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  5.67e+07        1    3.02e-03    1.33e-01
  26  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  1.77e+06        1    2.83e-03    1.36e-01
  27  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  2.77e+04        1    2.81e-03    1.39e-01
  28  3.759435e-20   -3.19e-20    0.00e+00   2.99e-15  -1.51e-01  2.16e+02        1    2.86e-03    1.42e-01
  29  6.208180e-20   -5.64e-20    0.00e+00   2.82e-15  -4.75e-01  8.45e-01        1    2.80e-03    1.44e-01
  30  8.520281e-21   -2.88e-21    5.24e-06   1.67e-15   2.35e-01  7.35e-01        1    5.96e-03    1.50e-01
  31  5.343793e-21    3.18e-21    6.29e-06   1.61e-15   4.36e-01  7.34e-01        1    5.89e-03    1.56e-01
  32  4.604201e-21    7.40e-22    5.59e-06   1.50e-15   2.48e-01  6.50e-01        1    5.68e-03    1.62e-01
  33  8.256884e-21   -3.65e-21    7.08e-06   9.40e-16   1.97e-01  5.32e-01        1    5.67e-03    1.68e-01
  34  3.131224e-21    5.13e-21    3.26e-06   1.68e-15   7.66e-01  6.26e-01        1    5.51e-03    1.73e-01
  35  2.446382e-21    6.85e-22    3.96e-06   1.07e-15   3.33e-01  6.04e-01        1    5.66e-03    1.79e-01
  36  2.971245e-21   -5.25e-22    3.30e-06   6.43e-16   2.29e-01  5.21e-01        1    5.49e-03    1.84e-01
  37  4.324040e-21   -1.35e-21    5.36e-06   7.83e-16   2.10e-01  4.36e-01        1    5.69e-03    1.90e-01
  38  1.907248e-21    2.42e-21    3.49e-06   1.00e-15   6.91e-01  4.62e-01        1    6.04e-03    1.96e-01
  39  1.806997e-21    1.00e-22    3.17e-06   6.63e-16   2.24e-01  3.95e-01        1    5.83e-03    2.02e-01
  40  1.522246e-21    2.85e-22    3.04e-06   7.06e-16   2.24e-01  3.38e-01        1    5.59e-03    2.08e-01
  41  5.228315e-21   -3.71e-21    6.23e-06   6.79e-16   1.88e-01  2.72e-01        1    5.69e-03    2.13e-01
  42  6.735229e-21   -1.51e-21    7.06e-06   9.27e-16   1.69e-01  2.11e-01        1    5.68e-03    2.19e-01
  43  3.036707e-21    3.70e-21    3.12e-06   9.50e-16   8.51e-01  3.23e-01        1    6.62e-03    2.26e-01
  44  2.642132e-21    3.95e-22    4.80e-06   6.65e-16   1.97e-01  2.64e-01        1    5.94e-03    2.32e-01
  45  4.826146e-21   -2.18e-21    4.83e-06   4.87e-16   1.73e-01  2.07e-01        1    5.75e-03    2.37e-01
  46  9.843926e-22    3.84e-21    1.96e-06   6.69e-16   1.40e+00  6.20e-01        1    5.87e-03    2.43e-01
  47  3.732635e-21   -2.75e-21    4.86e-06   4.74e-16   1.77e-01  4.89e-01        1    5.74e-03    2.49e-01
  48  4.684019e-21   -9.51e-22    5.81e-06   1.09e-15   1.66e-01  3.76e-01        1    5.78e-03    2.55e-01
  49  2.242267e-20   -1.77e-20    1.29e-05   9.21e-16   2.82e-02  2.05e-01        1    5.59e-03    2.60e-01
  50  1.916850e-21    2.05e-20    3.58e-06   1.87e-15   1.40e+00  6.14e-01        1    5.69e-03    2.66e-01
  51  2.148849e-21   -2.32e-22    3.90e-06   9.27e-16   1.61e-01  4.68e-01        1    5.58e-03    2.72e-01
  52  1.530831e-21    6.18e-22    2.90e-06   8.87e-16   3.65e-01  4.58e-01        1    5.54e-03    2.77e-01
  53  2.754011e-20   -2.60e-20    0.00e+00   6.59e-16  -8.86e-03  2.29e-01        1    2.83e-03    2.80e-01
  54  3.754833e-21   -2.22e-21    5.54e-06   4.26e-16   1.47e-01  1.70e-01        1    5.76e-03    2.86e-01
  55  6.813484e-21   -3.06e-21    7.21e-06   5.20e-16   1.25e-01  1.19e-01        1    5.83e-03    2.92e-01
  56  3.472244e-21    3.34e-21    5.18e-06   6.36e-16   1.03e+00  3.58e-01        1    5.63e-03    2.97e-01
  57  8.433850e-21   -4.96e-21    8.17e-06   9.60e-16   1.11e-01  2.43e-01        1    5.56e-03    3.03e-01
  58  3.377334e-21    5.06e-21    4.37e-06   1.25e-15   8.68e-01  4.05e-01        1    5.71e-03    3.09e-01
  59  4.484051e-21   -1.11e-21    6.46e-06   1.03e-15   1.28e-01  2.87e-01        1    5.73e-03    3.14e-01
  60  6.532758e-21   -2.05e-21    5.83e-06   7.59e-16   1.14e-01  1.97e-01        1    5.66e-03    3.20e-01
  61  8.616298e-21   -2.08e-21    7.96e-06   8.62e-16   9.98e-02  1.30e-01        1    5.81e-03    3.26e-01
  62  1.926427e-20   -1.06e-20    1.20e-05   9.30e-16   3.83e-02  7.28e-02        1    5.68e-03    3.32e-01
  63  7.824346e-21    1.14e-20    7.93e-06   9.33e-16   1.63e+00  2.18e-01        1    5.57e-03    3.37e-01
  64  1.742676e-21    6.08e-21    3.11e-06   1.21e-15   1.15e+00  6.55e-01        1    5.68e-03    3.43e-01
  65  2.111914e-21   -3.69e-22    3.14e-06   8.01e-16   1.24e-01  4.59e-01        1    5.55e-03    3.48e-01
  66  1.914071e-21    1.98e-22    3.45e-06   8.39e-16   1.28e-01  3.26e-01        1    5.62e-03    3.54e-01
  67  8.963731e-21   -7.05e-21    7.78e-06   6.12e-16   8.73e-02  2.08e-01        1    5.88e-03    3.60e-01
  68  8.325471e-21    6.38e-22    8.22e-06   1.20e-15   1.18e-01  1.44e-01        1    6.03e-03    3.66e-01
  69  1.027179e-20   -1.95e-21    8.90e-06   9.37e-16   7.68e-02  8.97e-02        1    5.86e-03    3.72e-01
  70  2.546544e-21    7.73e-21    3.87e-06   6.49e-16   1.84e+00  2.69e-01        1    5.82e-03    3.78e-01
  71  8.803939e-22    1.67e-21    2.44e-06   6.38e-16   1.06e+00  8.07e-01        1    5.60e-03    3.83e-01
  72  2.753078e-21   -1.87e-21    3.37e-06   4.63e-16   1.10e-01  5.47e-01        1    5.79e-03    3.89e-01
  73  1.330519e-21    1.42e-21    2.55e-06   8.66e-16   7.15e-01  5.94e-01        1    5.71e-03    3.95e-01
  74  3.539116e-22    9.77e-22    6.79e-07   4.46e-16   1.08e+00  1.78e+00        1    5.53e-03    4.00e-01
  75  2.086881e-21   -1.73e-21    3.35e-06   5.06e-16   1.11e-01  1.21e+00        1    5.67e-03    4.06e-01
  76  5.208616e-21   -3.12e-21    6.44e-06   1.09e-15   9.60e-02  7.93e-01        1    5.75e-03    4.12e-01
  77  3.200459e-21    2.01e-21    5.28e-06   1.63e-15   4.23e-01  7.91e-01        1    5.72e-03    4.18e-01
  78  8.233210e-21   -5.03e-21    7.57e-06   9.80e-16   7.95e-02  4.96e-01        1    5.79e-03    4.23e-01
  79  5.438376e-21    2.79e-21    5.40e-06   1.69e-15   3.93e-01  4.91e-01        1    5.64e-03    4.29e-01
  80  2.220341e-21    3.22e-21    3.97e-06   1.20e-15   7.53e-01  5.64e-01        1    5.76e-03    4.35e-01
  81  3.828529e-21   -1.61e-21    5.19e-06   9.26e-16   3.32e-01  5.44e-01        1    5.54e-03    4.40e-01
  82  5.091565e-21   -1.26e-21    5.96e-06   1.22e-15   1.91e-01  4.40e-01        1    5.76e-03    4.46e-01
  83  2.552554e-21    2.54e-21    3.80e-06   1.28e-15   5.94e-01  4.43e-01        1    5.52e-03    4.52e-01
  84  5.637288e-21   -3.08e-21    6.10e-06   8.16e-16   1.14e-01  3.03e-01        1    5.68e-03    4.57e-01
  85  2.068643e-20   -1.50e-20    0.00e+00   1.04e-15  -4.60e-01  1.52e-01        1    2.88e-03    4.60e-01
  86  4.636795e-21    1.00e-21    5.92e-06   7.16e-16   3.11e-01  1.44e-01        1    5.77e-03    4.66e-01
  87  3.056461e-21    1.58e-21    4.40e-06   6.47e-16   6.30e-01  1.46e-01        1    5.78e-03    4.72e-01
  88  4.951255e-21   -1.89e-21    6.04e-06   4.85e-16   1.08e-01  9.89e-02        1    5.67e-03    4.78e-01
  89  2.795339e-21    2.16e-21    4.51e-06   5.42e-16   1.03e+00  2.97e-01        1    5.50e-03    4.83e-01
  90  3.246735e-21   -4.51e-22    4.84e-06   8.73e-16   1.45e-01  2.19e-01        1    5.70e-03    4.89e-01
  91  1.737450e-21    1.51e-21    2.98e-06   6.13e-16   7.48e-01  2.49e-01        1    5.63e-03    4.94e-01
  92  8.867252e-21   -7.13e-21    0.00e+00   5.69e-16  -1.70e-02  1.24e-01        1    2.86e-03    4.97e-01
  93  1.667972e-21    6.95e-23    3.03e-06   2.92e-16   1.77e-01  9.81e-02        1    5.52e-03    5.03e-01
  94  1.109237e-20   -9.42e-21    0.00e+00   3.41e-16  -7.58e-02  4.90e-02        1    2.85e-03    5.06e-01
  95  3.373188e-21   -1.71e-21    4.35e-06   2.56e-16   1.30e-01  3.49e-02        1    5.67e-03    5.11e-01
  96  2.512492e-21    8.61e-22    4.05e-06   1.31e-16   1.24e+00  1.05e-01        1    5.67e-03    5.17e-01
  97  1.849925e-21    6.63e-22    3.96e-06   3.58e-16   5.62e-01  1.05e-01        1    5.75e-03    5.23e-01
  98  2.409008e-21   -5.59e-22    3.90e-06   2.17e-16   1.45e-01  7.73e-02        1    5.67e-03    5.29e-01
  99  2.735982e-21   -3.27e-22    4.31e-06   3.42e-16   1.34e-01  5.56e-02        1    5.58e-03    5.34e-01
 100  2.254138e-21    4.82e-22    4.25e-06   2.83e-16   6.39e-01  5.68e-02        1    5.51e-03    5.40e-01
 101  1.575644e-21    6.78e-22    2.90e-06   1.52e-16   1.12e+00  1.70e-01        1    5.74e-03    5.45e-01
 102  6.478828e-22    9.28e-22    1.06e-06   3.44e-16   1.17e+00  5.11e-01        1    5.53e-03    5.51e-01
 103  6.781472e-21   -6.13e-21    6.78e-06   2.62e-16   3.36e-02  2.82e-01        1    5.79e-03    5.57e-01
 104  3.706372e-21    3.08e-21    5.32e-06   1.18e-15   6.33e-01  2.87e-01        1    5.71e-03    5.62e-01
 105  3.973300e-21   -2.67e-22    5.39e-06   9.08e-16   8.39e-02  1.82e-01        1    5.53e-03    5.68e-01
 106  1.470922e-21    2.50e-21    3.07e-06   7.08e-16   1.01e+00  5.47e-01        1    5.63e-03    5.74e-01
 107  5.597047e-21   -4.13e-21    6.68e-06   7.85e-16   4.85e-02  3.15e-01        1    5.66e-03    5.79e-01
 108  5.107066e-21    4.90e-22    6.81e-06   1.21e-15   1.15e-01  2.16e-01        1    5.52e-03    5.85e-01
 109  3.042050e-21    2.07e-21    4.71e-06   7.10e-16   6.28e-01  2.20e-01        1    5.79e-03    5.91e-01
 110  3.014769e-21    2.73e-23    4.33e-06   6.39e-16   8.17e-02  1.39e-01        1    5.59e-03    5.96e-01
 111  3.782102e-21   -7.67e-22    5.48e-06   4.65e-16   6.79e-02  8.43e-02        1    5.56e-03    6.02e-01
 112  2.176568e-21    1.61e-21    3.35e-06   3.95e-16   1.05e+00  2.53e-01        1    5.55e-03    6.07e-01
 113  6.685839e-21   -4.51e-21    6.95e-06   4.53e-16   2.26e-02  1.35e-01        1    5.67e-03    6.13e-01
 114  1.770098e-21    4.92e-21    3.24e-06   6.62e-16   1.44e+00  4.06e-01        1    5.55e-03    6.19e-01
 115  2.898860e-20   -2.72e-20    0.00e+00   7.03e-16  -2.83e-01  2.03e-01        1    3.01e-03    6.22e-01
 116  2.502402e-20   -2.33e-20    0.00e+00   4.63e-16  -2.30e-01  5.07e-02        1    2.95e-03    6.25e-01
 117  1.436861e-21    3.33e-22    3.20e-06   1.31e-16   7.14e-01  5.50e-02        1    5.60e-03    6.30e-01
 118  9.701243e-22    4.67e-22    2.52e-06   2.59e-16   1.20e+00  1.65e-01        1    5.53e-03    6.36e-01
 119  2.007105e-20   -1.91e-20    0.00e+00   3.49e-16  -1.62e-01  8.25e-02        1    2.86e-03    6.39e-01
 120  1.436861e-21   -4.67e-22    3.20e-06   2.58e-16   9.30e-02  5.36e-02        1    5.64e-03    6.44e-01
 121  9.701243e-22    4.67e-22    2.52e-06   2.59e-16   1.23e+00  1.61e-01        1    5.91e-03    6.50e-01
 122  2.385541e-20   -2.29e-20    0.00e+00   3.44e-16  -2.11e-01  8.04e-02        1    2.83e-03    6.53e-01
 123  1.436776e-21   -4.67e-22    3.19e-06   2.58e-16   9.21e-02  5.21e-02        1    6.11e-03    6.59e-01
 124  9.701243e-22    4.67e-22    2.52e-06   2.58e-16   1.25e+00  1.56e-01        1    5.60e-03    6.65e-01
 125  2.385541e-20   -2.29e-20    0.00e+00   3.44e-16  -2.09e-01  7.82e-02        1    2.88e-03    6.68e-01
 126  1.101118e-21   -1.31e-22    2.75e-06   2.58e-16   9.57e-02  5.11e-02        1    5.66e-03    6.73e-01
 127  3.451230e-21   -2.35e-21    4.67e-06   1.17e-16   6.39e-02  3.07e-02        1    5.66e-03    6.79e-01
 128  2.263844e-21    1.19e-21    4.09e-06   2.56e-16   2.11e+00  9.22e-02        1    5.50e-03    6.85e-01
 129  4.141132e-21   -1.88e-21    4.88e-06   3.50e-16   5.37e-02  5.39e-02        1    5.78e-03    6.90e-01
 130  2.578385e-21    1.56e-21    3.71e-06   2.88e-16   1.52e+00  1.62e-01        1    5.69e-03    6.96e-01
 131  1.595742e-21    9.83e-22    2.97e-06   4.61e-16   6.61e-01  1.67e-01        1    5.70e-03    7.02e-01
 132  3.438769e-21   -1.84e-21    4.83e-06   3.85e-16   6.01e-02  9.95e-02        1    5.57e-03    7.07e-01
 133  1.888647e-20   -1.54e-20    0.00e+00   4.47e-16  -1.31e-01  4.98e-02        1    2.98e-03    7.10e-01
 134  4.707219e-21   -1.27e-21    5.78e-06   2.86e-16   4.37e-02  2.83e-02        1    5.50e-03    7.16e-01
 135  4.866537e-21   -1.59e-22    5.77e-06   2.62e-16   4.14e-02  1.60e-02        1    5.56e-03    7.21e-01
 136  5.096298e-21   -2.30e-22    5.76e-06   3.90e-17   3.83e-02  8.93e-03        1    5.54e-03    7.27e-01
 137  4.446081e-21    6.50e-22    5.81e-06   2.36e-17   2.46e+00  2.68e-02        1    6.33e-03    7.33e-01
 138  1.367014e-21    3.08e-21    2.89e-06   2.57e-16   4.24e+00  8.04e-02        1    5.50e-03    7.39e-01
 139  7.472850e-22    6.20e-22    2.08e-06   2.66e-16   1.27e+00  2.41e-01        1    5.67e-03    7.45e-01
 140  7.462491e-21   -6.72e-21    7.63e-06   3.41e-16   9.20e-03  1.24e-01        1    5.87e-03    7.50e-01
 141  1.683387e-21    5.78e-21    2.94e-06   7.39e-16   1.56e+00  3.72e-01        1    5.69e-03    7.56e-01
 142  1.640046e-20   -1.47e-20    0.00e+00   6.96e-16  -9.21e-02  1.86e-01        1    2.89e-03    7.59e-01
 143  3.011966e-21   -1.33e-21    3.61e-06   4.30e-16   5.91e-02  1.10e-01        1    5.57e-03    7.65e-01
 144  4.455220e-21   -1.44e-21    4.67e-06   3.32e-16   4.22e-02  6.24e-02        1    5.68e-03    7.70e-01
 145  2.645083e-21    1.81e-21    4.91e-06   3.06e-16   1.45e+00  1.87e-01        1    5.51e-03    7.76e-01
 146  4.254470e-21   -1.61e-21    5.78e-06   3.74e-16   4.30e-02  1.06e-01        1    5.86e-03    7.82e-01
 147  2.314014e-20   -1.89e-20    0.00e+00   4.92e-16  -1.58e-01  5.31e-02        1    2.92e-03    7.85e-01
 148  2.429457e-21    1.83e-21    4.16e-06   3.51e-16   1.49e+00  1.59e-01        1    5.61e-03    7.90e-01
 149  6.174280e-21   -3.74e-21    6.92e-06   5.98e-16   2.17e-02  8.49e-02        1    5.52e-03    7.96e-01
 150  8.483730e-22    5.33e-21    2.26e-06   6.04e-16   2.13e+00  2.55e-01        1    5.71e-03    8.02e-01
 151  1.380147e-20   -1.30e-20    0.00e+00   3.55e-16  -5.68e-02  1.27e-01        1    2.86e-03    8.05e-01
 152  5.755871e-21   -4.91e-21    6.27e-06   2.87e-16   2.53e-02  6.86e-02        1    5.54e-03    8.10e-01
 153  2.435343e-21    3.32e-21    3.90e-06   3.80e-16   1.80e+00  2.06e-01        1    5.93e-03    8.16e-01
 154  2.130990e-21    3.04e-22    3.63e-06   6.79e-16   1.89e-01  1.66e-01        1    5.66e-03    8.22e-01
 155  1.765637e-21    3.65e-22    3.53e-06   5.68e-16   3.19e-01  1.58e-01        1    5.51e-03    8.27e-01
 156  8.578984e-22    9.08e-22    1.68e-06   3.65e-16   9.49e-01  4.75e-01        1    5.64e-03    8.33e-01
 157  7.914553e-21   -7.06e-21    7.97e-06   5.13e-16   3.06e-03  2.40e-01        1    5.51e-03    8.38e-01
 158  2.355879e-21    5.56e-21    4.58e-06   1.23e-15   1.01e+00  7.19e-01        1    5.47e-03    8.44e-01
 159  3.313403e-21   -9.58e-22    4.97e-06   7.56e-16   4.41e-02  4.09e-01        1    5.88e-03    8.50e-01
 160  1.055617e-20   -7.24e-21    0.00e+00   9.56e-16  -2.03e-02  2.04e-01        1    2.85e-03    8.53e-01
 161  5.041369e-21   -1.73e-21    6.15e-06   7.09e-16   2.81e-02  1.11e-01        1    5.62e-03    8.58e-01
 162  5.307897e-21   -2.67e-22    4.86e-06   6.02e-16   2.52e-02  5.98e-02        1    5.52e-03    8.64e-01
 163  4.275170e-21    1.03e-21    5.32e-06   3.10e-16   7.67e-01  7.06e-02        1    5.64e-03    8.69e-01
 164  4.452847e-21   -1.78e-22    6.44e-06   3.14e-16   3.18e-02  3.88e-02        1    5.51e-03    8.75e-01
 165  4.190944e-21    2.62e-22    5.68e-06   1.61e-16   2.82e-01  3.58e-02        1    5.71e-03    8.81e-01
 166  3.709254e-21    4.82e-22    4.86e-06   2.63e-16   5.63e-01  3.58e-02        1    5.79e-03    8.86e-01
 167  2.315985e-21    1.39e-21    4.39e-06   1.44e-16   1.72e+00  1.08e-01        1    5.57e-03    8.92e-01
 168  6.400380e-21   -4.08e-21    7.07e-06   3.74e-16   1.50e-02  5.62e-02        1    5.52e-03    8.98e-01
 169  4.601473e-21    1.80e-21    5.71e-06   3.58e-16   9.58e-01  1.69e-01        1    5.66e-03    9.03e-01
 170  2.336620e-21    2.26e-21    4.05e-06   7.07e-16   8.12e-01  2.23e-01        1    5.51e-03    9.09e-01
 171  2.527303e-21   -1.91e-22    4.72e-06   6.34e-16   4.43e-02  1.27e-01        1    5.79e-03    9.15e-01
 172  2.212771e-21    3.15e-22    3.61e-06   3.81e-16   2.51e-01  1.13e-01        1    5.66e-03    9.20e-01
 173  3.436368e-21   -1.22e-21    3.95e-06   3.50e-16   3.66e-02  6.28e-02        1    5.55e-03    9.26e-01
 174  2.815909e-21    6.20e-22    4.45e-06   2.93e-16   6.50e-01  6.46e-02        1    5.71e-03    9.32e-01
 175  3.245972e-21   -4.30e-22    4.83e-06   3.42e-16   3.75e-02  3.60e-02        1    5.51e-03    9.37e-01
 176  4.012007e-21   -7.66e-22    5.31e-06   2.57e-16   3.16e-02  1.98e-02        1    5.58e-03    9.43e-01
 177  4.154919e-21   -1.43e-22    5.70e-06   1.14e-16   3.04e-02  1.08e-02        1    5.85e-03    9.49e-01
 178  3.094025e-21    1.06e-21    4.83e-06   1.56e-17   3.49e+00  3.25e-02        1    5.75e-03    9.54e-01
 179  1.510330e-21    1.58e-21    3.10e-06   2.57e-16   2.59e+00  9.74e-02        1    5.54e-03    9.60e-01
 180  3.094276e-21   -1.58e-21    4.85e-06   2.71e-16   3.79e-02  5.44e-02        1    5.73e-03    9.66e-01
 181  5.472181e-21   -2.38e-21    6.91e-06   2.84e-16   2.02e-02  2.89e-02        1    5.52e-03    9.71e-01
 182  3.032332e-21    2.44e-21    4.78e-06   1.42e-16   2.57e+00  8.67e-02        1    5.52e-03    9.77e-01
 183  1.942474e-21    1.09e-21    4.14e-06   3.52e-16   9.07e-01  1.89e-01        1    5.82e-03    9.82e-01
 184  7.378694e-21   -5.44e-21    4.83e-06   3.42e-16   6.12e-03  9.60e-02        1    5.60e-03    9.88e-01
 185  4.543914e-21    2.83e-21    5.31e-06   4.28e-16   1.04e+00  2.88e-01        1    5.76e-03    9.94e-01
 186  1.111526e-20   -6.57e-21    0.00e+00   9.41e-16  -1.98e-02  1.44e-01        1    2.83e-03    9.97e-01
 187  4.997460e-21   -4.54e-22    6.26e-06   7.04e-16   2.23e-02  7.70e-02        1    5.78e-03    1.00e+00
 188  1.730555e-21    3.27e-21    3.05e-06   3.65e-16   1.77e+00  2.31e-01        1    5.56e-03    1.01e+00
 189  7.634957e-22    9.67e-22    2.20e-06   4.63e-16   8.84e-01  4.22e-01        1    5.77e-03    1.01e+00
 190  1.279081e-21   -5.16e-22    2.43e-06   5.27e-16   4.69e-02  2.42e-01        1    5.72e-03    1.02e+00
 191  5.166790e-21   -3.89e-21    5.76e-06   4.29e-16   2.06e-02  1.29e-01        1    5.53e-03    1.03e+00
 192  3.541730e-21    1.63e-21    5.22e-06   6.98e-16   5.78e-01  1.29e-01        1    5.51e-03    1.03e+00
 193  1.914951e-21    1.63e-21    3.64e-06   6.04e-16   8.81e-01  2.32e-01        1    5.70e-03    1.04e+00
 194  2.119911e-22    1.70e-21    5.58e-07   5.78e-16   1.41e+00  6.96e-01        1    5.60e-03    1.04e+00
 195  5.551922e-22   -3.43e-22    1.77e-06   2.52e-16   4.95e-02  4.02e-01        1    5.65e-03    1.05e+00
 196  8.649293e-21   -8.09e-21    0.00e+00   3.49e-16  -2.68e-03  2.01e-01        1    2.94e-03    1.05e+00
 197  2.801606e-21   -2.25e-21    4.30e-06   2.68e-16   3.50e-02  1.11e-01        1    5.53e-03    1.06e+00
 198  4.160139e-21   -1.36e-21    5.31e-06   3.85e-16   2.60e-02  6.02e-02        1    5.56e-03    1.06e+00
 199  1.141537e-21    3.02e-21    2.63e-06   3.01e-16   2.58e+00  1.81e-01        1    5.69e-03    1.07e+00
 200  8.149579e-21   -7.01e-21    0.00e+00   3.50e-16   5.28e-04  9.03e-02        1    2.99e-03    1.07e+00
 201  1.848856e-21   -7.07e-22    3.55e-06   2.60e-16   4.04e-02  5.08e-02        1    5.76e-03    1.08e+00
 202  3.942025e-21   -2.09e-21    5.27e-06   2.57e-16   1.07e-01  3.42e-02        1    5.75e-03    1.08e+00
 203  3.673820e-21    2.68e-22    5.26e-06   2.58e-16   3.47e-01  3.32e-02        1    5.67e-03    1.09e+00
 204  2.785374e-21    8.88e-22    4.41e-06   2.62e-16   1.28e+00  9.97e-02        1    5.63e-03    1.09e+00
 205  1.345082e-21    1.44e-21    1.73e-06   3.60e-16   1.19e+00  2.99e-01        1    5.69e-03    1.10e+00
 206  5.746818e-21   -4.40e-21    0.00e+00   3.55e-16  -2.95e-01  1.50e-01        1    2.86e-03    1.10e+00
 207  2.068001e-21   -7.23e-22    4.19e-06   2.77e-16   4.03e-01  1.48e-01        1    5.54e-03    1.11e+00
 208  2.147578e-21   -7.96e-23    4.02e-06   2.70e-16   3.22e-01  1.42e-01        1    5.54e-03    1.11e+00
 209  5.505100e-21   -3.36e-21    0.00e+00   3.66e-16  -1.82e-01  7.10e-02        1    2.83e-03    1.12e+00
 210  3.054276e-21   -9.07e-22    4.80e-06   2.85e-16   1.58e-01  5.38e-02        1    5.50e-03    1.12e+00
 211  2.971334e-21    8.29e-23    4.38e-06   2.83e-16   1.51e-01  4.01e-02        1    5.64e-03    1.13e+00
 212  2.941190e-21    3.01e-23    4.75e-06   2.63e-16   1.44e-01  2.95e-02        1    5.47e-03    1.13e+00
 213  2.966522e-21   -2.53e-23    4.79e-06   1.19e-16   1.33e-01  2.11e-02        1    5.81e-03    1.14e+00
 214  4.796733e-21   -1.83e-21    0.00e+00   1.14e-16  -6.78e-02  1.06e-02        1    2.99e-03    1.14e+00
 215  3.224185e-21   -2.58e-22    4.81e-06   1.39e-17   1.02e-01  7.01e-03        1    5.68e-03    1.15e+00
 216  3.889885e-21   -6.66e-22    4.82e-06   9.81e-18   2.89e-02  3.82e-03        1    5.54e-03    1.15e+00

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.107249e+02
Final                            2.119911e-22
Change                           1.107249e+02

Minimizer iterations                      217
Successful steps                          189
Unsuccessful steps                         28
Line search steps                         118

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0160
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.1274
    Line search gradient evaluation    0.6074
  Linear solver                        0.0058
  Line search polynomial minimization  0.0006
Minimizer                              1.1555

Postprocessor                          0.0000
Total                                  1.1555

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.629762e+04
Final                            1.503854e+02
Change                           1.614724e+04

Minimizer iterations                      134
Successful steps                           74
Unsuccessful steps                         60
Line search steps                         122

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0105
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.6992
    Line search gradient evaluation    0.4850
  Linear solver                        0.0023
  Line search polynomial minimization  0.0007
Minimizer                              0.7147

Postprocessor                          0.0000
Total                                  0.7148

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA95 = {
{-0.0709200,0.5049024,0.2325315}
};
fitErrEl95 = {
{-0.1131199,0.4894730,0.2463068}
};
fitErrLa95 = {
{-0.1146159,0.5241729,0.2577022}
};
fitErrWr95 = {
{-0.3316167,0.4556746,0.3566291}
};
fitErrEe95 = {
{-0.3875498,0.4808349,0.4461765}
};
rMatsBase95 = {
{-0.3481251,0.6893987,-0.6352467},
{0.7907345,0.5799248,0.1960260},
{0.5035354,-0.4340698,-0.7470177}
};
outThetasWam95 = {
{-0.1073558,-0.2369893,-0.0398793,1.3382317,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5603811
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.029104e+02    0.00e+00    2.84e+00   0.00e+00   0.00e+00  1.00e+04        0    3.05e-03    3.08e-03
   1  1.158891e-02    1.03e+02    2.85e+00   3.17e-03   2.00e+00  3.00e+04        1    6.23e-03    9.33e-03
   2  1.660905e-09    1.16e-02    4.61e-01   1.23e-05   2.00e+00  9.00e+04        1    6.15e-03    1.55e-02
   3  3.764941e-16    1.66e-09    6.51e-05   1.74e-08   2.00e+00  2.70e+05        1    6.14e-03    2.17e-02
   4  8.352604e-21    3.76e-16    8.21e-06   8.73e-12   2.00e+00  8.10e+05        1    6.13e-03    2.78e-02
   5  4.209915e-22    7.93e-21    1.74e-06   3.79e-15   2.00e+00  2.43e+06        1    6.15e-03    3.40e-02
   6  1.295226e-21   -8.74e-22    3.15e-06   6.11e-16   2.00e+00  7.29e+06        1    6.14e-03    4.01e-02
   7  4.476011e-21   -3.18e-21    4.20e-06   3.26e-15   2.00e+00  2.19e+07        1    6.15e-03    4.63e-02
   8  6.609911e-22    3.82e-21    2.39e-06   3.81e-15   2.00e+00  6.56e+07        1    6.28e-03    5.26e-02
   9  1.129298e-20   -1.06e-20    8.46e-06   1.75e-15   2.00e+00  1.97e+08        1    6.15e-03    5.87e-02
  10  4.108642e-21    7.18e-21    4.78e-06   6.74e-15   2.00e+00  5.90e+08        1    6.16e-03    6.49e-02
  11  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  2.95e+08        1    3.19e-03    6.81e-02
  12  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  7.38e+07        1    3.14e-03    7.13e-02
  13  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  9.23e+06        1    3.13e-03    7.44e-02
  14  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  5.77e+05        1    3.09e-03    7.75e-02
  15  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  1.80e+04        1    3.13e-03    8.07e-02
  16  4.723199e-20   -4.31e-20    0.00e+00   3.87e-15  -2.37e+00  2.82e+02        1    3.09e-03    8.38e-02
  17  1.592831e-20   -1.18e-20    0.00e+00   3.68e-15  -3.05e-01  2.20e+00        1    3.13e-03    8.69e-02
  18  1.604991e-20   -1.19e-20    0.00e+00   1.87e-15  -3.16e-01  8.59e-03        1    3.13e-03    9.01e-02
  19  3.832994e-21    2.76e-22    4.76e-06   7.76e-18   1.15e+00  2.58e-02        1    6.29e-03    9.63e-02
  20  5.639359e-21   -1.81e-21    5.99e-06   1.27e-16   4.71e-01  2.58e-02        1    6.13e-03    1.02e-01
  21  3.794694e-21    1.84e-21    5.20e-06   1.33e-16   2.04e+00  7.73e-02        1    6.16e-03    1.09e-01
  22  5.177489e-21   -1.38e-21    5.94e-06   2.44e-16   4.32e-01  7.71e-02        1    6.19e-03    1.15e-01
  23  1.042915e-20   -5.25e-21    8.85e-06   2.72e-16   5.46e-02  4.52e-02        1    6.14e-03    1.21e-01
  24  3.986913e-22    1.00e-20    1.33e-06   3.63e-16   3.81e+00  1.36e-01        1    6.19e-03    1.27e-01
  25  1.820114e-20   -1.78e-20    0.00e+00   1.29e-16  -3.71e-01  6.78e-02        1    3.11e-03    1.30e-01
  26  3.694066e-22    2.93e-23    1.30e-06   1.13e-16   5.88e-01  6.82e-02        1    6.28e-03    1.37e-01
  27  2.353990e-21   -1.98e-21    3.68e-06   1.12e-16   4.79e-01  6.82e-02        1    6.14e-03    1.43e-01
  28  1.290965e-21    1.06e-21    2.32e-06   1.56e-16   1.55e+00  2.04e-01        1    6.09e-03    1.49e-01
  29  1.072664e-20   -9.44e-21    8.70e-06   3.33e-16   2.82e-02  1.11e-01        1    6.17e-03    1.55e-01
  30  6.644423e-21    4.08e-21    6.41e-06   8.91e-16   8.56e-01  1.74e-01        1    6.20e-03    1.61e-01
  31  5.127842e-22    6.13e-21    1.64e-06   9.34e-16   1.47e+00  5.23e-01        1    6.15e-03    1.67e-01
  32  1.337933e-20   -1.29e-20    0.00e+00   3.20e-16  -2.85e-01  2.61e-01        1    3.13e-03    1.71e-01
  33  1.225236e-20   -1.17e-20    0.00e+00   2.90e-16  -1.65e-01  6.53e-02        1    3.13e-03    1.74e-01
  34  4.017009e-22    1.11e-22    1.67e-06   4.81e-17   1.14e+00  1.96e-01        1    6.14e-03    1.80e-01
  35  8.814619e-21   -8.41e-21    7.79e-06   2.67e-16   2.05e-01  1.63e-01        1    6.28e-03    1.86e-01
  36  6.601824e-22    8.15e-21    2.08e-06   9.38e-16   1.63e+00  4.88e-01        1    6.12e-03    1.92e-01
  37  5.707105e-21   -5.05e-21    5.95e-06   3.89e-16   3.40e-01  4.73e-01        1    6.20e-03    1.99e-01
  38  1.356888e-21    4.35e-21    3.13e-06   1.37e-15   8.94e-01  9.26e-01        1    6.22e-03    2.05e-01
  39  1.238538e-21    1.18e-22    2.05e-06   9.27e-16   4.54e-01  9.25e-01        1    6.14e-03    2.11e-01
  40  1.271059e-20   -1.15e-20    0.00e+00   6.31e-16  -9.06e-02  4.62e-01        1    3.14e-03    2.14e-01
  41  6.400036e-21   -5.16e-21    6.82e-06   5.66e-16   1.99e-01  3.79e-01        1    6.11e-03    2.20e-01
  42  4.775785e-21    1.62e-21    6.25e-06   1.35e-15   3.12e-01  3.60e-01        1    6.25e-03    2.26e-01
  43  1.990960e-21    2.78e-21    3.93e-06   9.11e-16   7.38e-01  4.04e-01        1    6.14e-03    2.33e-01
  44  8.499183e-22    1.14e-21    1.62e-06   6.08e-16   7.51e-01  4.63e-01        1    6.14e-03    2.39e-01
  45  6.217025e-21   -5.37e-21    6.80e-06   3.70e-16   1.37e-01  3.35e-01        1    6.18e-03    2.45e-01
  46  9.894608e-22    5.23e-21    2.66e-06   1.27e-15   1.07e+00  1.00e+00        1    6.19e-03    2.51e-01
  47  1.336422e-21   -3.47e-22    3.35e-06   6.44e-16   2.43e-01  8.85e-01        1    6.15e-03    2.57e-01
  48  1.304798e-20   -1.17e-20    0.00e+00   5.96e-16  -5.83e-02  4.42e-01        1    3.13e-03    2.60e-01
  49  1.609868e-20   -1.48e-20    0.00e+00   4.62e-16  -1.35e-01  1.11e-01        1    3.13e-03    2.64e-01
  50  1.291229e-21    4.52e-23    2.31e-06   1.95e-16   2.41e-01  9.71e-02        1    6.27e-03    2.70e-01
  51  5.645601e-21   -4.35e-21    6.02e-06   2.66e-16   1.28e-01  6.88e-02        1    6.15e-03    2.76e-01
  52  3.531519e-22    5.29e-21    1.12e-06   3.60e-16   2.90e+00  2.06e-01        1    6.10e-03    2.82e-01
  53  9.125070e-21   -8.77e-21    8.09e-06   2.56e-16   3.85e-02  1.15e-01        1    6.17e-03    2.88e-01
  54  2.650548e-21    6.47e-21    3.03e-06   8.35e-16   1.53e+00  3.46e-01        1    6.21e-03    2.95e-01
  55  1.293395e-21    1.36e-21    2.27e-06   6.70e-16   7.45e-01  3.93e-01        1    6.15e-03    3.01e-01
  56  4.543678e-22    8.39e-22    1.77e-06   4.39e-16   8.85e-01  7.23e-01        1    6.14e-03    3.07e-01
  57  4.761590e-22   -2.18e-23    1.67e-06   4.26e-16   2.09e-01  6.04e-01        1    6.15e-03    3.13e-01
  58  1.118902e-21   -6.43e-22    2.43e-06   3.58e-16   1.04e+00  1.81e+00        1    6.30e-03    3.19e-01
  59  1.543856e-21   -4.25e-22    2.85e-06   6.65e-16   8.68e-01  3.02e+00        1    6.16e-03    3.26e-01
  60  6.237198e-21   -4.69e-21    5.49e-06   7.62e-16   2.84e-01  2.80e+00        1    6.15e-03    3.32e-01
  61  6.907006e-21   -6.70e-22    7.31e-06   1.87e-15   1.38e-01  2.03e+00        1    6.20e-03    3.38e-01
  62  1.668282e-20   -9.78e-21    0.00e+00   2.33e-15  -3.31e-01  1.01e+00        1    3.13e-03    3.41e-01
  63  1.346973e-20   -6.56e-21    0.00e+00   1.88e-15  -1.93e-01  2.53e-01        1    3.13e-03    3.44e-01
  64  2.004365e-21    4.90e-21    3.58e-06   1.17e-15   1.02e+00  7.59e-01        1    6.14e-03    3.50e-01
  65  1.916813e-20   -1.72e-20    0.00e+00   9.57e-16  -4.44e-01  3.80e-01        1    3.14e-03    3.54e-01
  66  5.593763e-21   -3.59e-21    7.27e-06   8.06e-16   1.58e-01  2.88e-01        1    6.28e-03    3.60e-01
  67  2.145732e-21    3.45e-21    3.47e-06   8.48e-16   8.37e-01  4.15e-01        1    6.19e-03    3.66e-01
  68  5.362020e-22    1.61e-21    2.04e-06   6.58e-16   9.80e-01  1.24e+00        1    6.15e-03    3.72e-01
  69  1.307409e-20   -1.25e-20    0.00e+00   4.07e-16  -1.38e-01  6.22e-01        1    3.16e-03    3.75e-01
  70  1.251280e-20   -1.20e-20    0.00e+00   3.85e-16  -1.19e-01  1.55e-01        1    3.33e-03    3.79e-01
  71  1.150015e-20   -1.10e-20    0.00e+00   1.53e-16  -8.36e-02  1.94e-02        1    3.31e-03    3.82e-01
  72  4.713138e-22    6.49e-23    1.92e-06   1.55e-17   1.17e+00  5.83e-02        1    6.12e-03    3.88e-01
  73  1.632979e-22    3.08e-22    3.37e-07   4.44e-17   2.67e+00  1.75e-01        1    6.13e-03    3.94e-01
  74  1.016828e-22    6.16e-23    5.62e-07   3.20e-17   3.29e+00  5.25e-01        1    6.14e-03    4.01e-01
  75  1.063113e-20   -1.05e-20    0.00e+00   1.19e-16  -5.31e-02  2.62e-01        1    3.27e-03    4.04e-01
  76  1.016828e-22    3.53e-38    5.62e-07   3.18e-17   3.18e-01  2.50e-01        1    6.15e-03    4.10e-01
  77  1.632979e-22   -6.16e-23    3.37e-07   3.18e-17   3.16e-01  2.38e-01        1    6.14e-03    4.16e-01
  78  1.016828e-22    6.16e-23    5.62e-07   3.47e-17   2.79e+00  7.15e-01        1    6.17e-03    4.22e-01
  79  1.065119e-20   -1.05e-20    0.00e+00   2.54e-16  -5.36e-02  3.58e-01        1    3.19e-03    4.26e-01
  80  1.063113e-20   -1.05e-20    0.00e+00   1.16e-16  -5.29e-02  8.94e-02        1    3.13e-03    4.29e-01
  81  1.016828e-22    3.53e-38    5.62e-07   1.55e-17   3.17e-01  8.53e-02        1    6.15e-03    4.35e-01
  82  1.016828e-22    3.53e-38    5.62e-07   1.55e-17   3.17e-01  8.13e-02        1    6.13e-03    4.41e-01
  83  1.632979e-22   -6.16e-23    0.00e+00   1.55e-17   0.00e+00  4.06e-02        1    3.13e-03    4.44e-01
  84  1.632979e-22   -6.16e-23    0.00e+00   7.76e-18   0.00e+00  1.02e-02        1    3.13e-03    4.47e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.029104e+02
Final                            1.016828e-22
Change                           1.029104e+02

Minimizer iterations                       85
Successful steps                           60
Unsuccessful steps                         25
Line search steps                          51

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0069
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.4394
    Line search gradient evaluation    0.2579
  Linear solver                        0.0017
  Line search polynomial minimization  0.0002
Minimizer                              0.4505

Postprocessor                          0.0000
Total                                  0.4505

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 
W1104 07:49:38.154366  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:49:38.550495  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.637312e+04
Final                            1.543244e+02
Change                           1.621880e+04

Minimizer iterations                      501
Successful steps                          313
Unsuccessful steps                        188
Line search steps                         710

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0399
    Line search cost evaluation        0.0000
  Jacobian evaluation                  3.5754
    Line search gradient evaluation    2.6476
  Linear solver                        0.0102
  Line search polynomial minimization  0.0059
Minimizer                              3.6411

Postprocessor                          0.0000
Total                                  3.6411

Termination:                   NO_CONVERGENCE (Maximum number of iterations reached. Number of iterations: 500.)

*) 
fitErrUA96 = {
{-0.0703172,0.5047977,0.2327640}
};
fitErrEl96 = {
{-0.1125080,0.4893220,0.2465235}
};
fitErrLa96 = {
{-0.1139834,0.5242052,0.2580253}
};
fitErrWr96 = {
{-0.3321964,0.4550473,0.3570895}
};
fitErrEe96 = {
{-0.3879291,0.4797382,0.4470159}
};
rMatsBase96 = {
{-0.3511693,0.6858326,-0.6374274},
{0.7855811,0.5862359,0.1979641},
{0.5094530,-0.4312321,-0.7446452}
};
outThetasWam96 = {
{-0.1071569,-0.2358453,-0.0370445,1.3412075,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5603074
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.050528e+02    0.00e+00    2.83e+00   0.00e+00   0.00e+00  1.00e+04        0    2.87e-03    2.92e-03
   1  1.816938e-02    1.05e+02    2.85e+00   3.42e-03   2.00e+00  3.00e+04        1    6.15e-03    9.09e-03
   2  3.947695e-10    1.82e-02    6.35e-01   9.34e-06   2.00e+00  9.00e+04        1    5.94e-03    1.51e-02
   3  5.273173e-17    3.95e-10    2.37e-05   6.36e-09   2.00e+00  2.70e+05        1    5.67e-03    2.08e-02
   4  6.167345e-21    5.27e-17    6.68e-06   3.26e-12   2.00e+00  8.10e+05        1    5.89e-03    2.67e-02
   5  5.861104e-22    5.58e-21    1.90e-06   4.28e-15   2.00e+00  2.43e+06        1    5.55e-03    3.23e-02
   6  1.301753e-21   -7.16e-22    3.13e-06   1.20e-15   2.00e+00  7.29e+06        1    5.83e-03    3.81e-02
   7  8.389795e-21   -7.09e-21    7.55e-06   3.55e-15   2.00e+00  2.19e+07        1    6.42e-03    4.46e-02
   8  1.837505e-21    6.55e-21    3.74e-06   4.98e-15   2.00e+00  6.56e+07        1    5.76e-03    5.04e-02
   9  2.700093e-21   -8.63e-22    4.13e-06   4.11e-15   2.00e+00  1.97e+08        1    5.70e-03    5.62e-02
  10  5.282658e-21   -2.58e-21    6.72e-06   2.17e-15   2.00e+00  5.90e+08        1    5.85e-03    6.20e-02
  11  7.500054e-21   -2.22e-21    8.03e-06   1.99e-15   4.94e-02  3.41e+08        1    5.73e-03    6.78e-02
  12  4.719211e-21    2.78e-21    6.11e-06   2.68e-15   3.71e-01  3.35e+08        1    5.56e-03    7.34e-02
  13  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  1.68e+08        1    2.84e-03    7.62e-02
  14  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  4.19e+07        1    2.89e-03    7.91e-02
  15  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  5.24e+06        1    2.85e-03    8.20e-02
  16  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  3.27e+05        1    2.99e-03    8.50e-02
  17  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  1.02e+04        1    2.94e-03    8.79e-02
  18  1.537618e-20   -1.07e-20    0.00e+00   4.91e-15  -2.31e-01  1.60e+02        1    3.33e-03    9.13e-02
  19  4.558517e-21    1.61e-22    6.08e-06   4.23e-15   1.27e-01  1.13e+02        1    5.65e-03    9.69e-02
  20  3.487971e-21    1.07e-21    4.90e-06   2.43e-15   2.37e-01  9.86e+01        1    5.81e-03    1.03e-01
  21  7.159668e-21   -3.67e-21    7.51e-06   3.24e-15   3.22e-02  5.42e+01        1    6.16e-03    1.09e-01
  22  8.154021e-21   -9.94e-22    6.93e-06   4.07e-15   5.21e-03  2.75e+01        1    5.89e-03    1.15e-01
  23  9.718756e-21   -1.56e-21    0.00e+00   3.04e-15  -2.49e-02  1.38e+01        1    2.93e-03    1.18e-01
  24  9.714567e-21   -1.56e-21    0.00e+00   2.89e-15  -2.49e-02  3.44e+00        1    2.88e-03    1.21e-01
  25  1.006449e-20   -1.91e-21    0.00e+00   2.36e-15  -3.15e-02  4.30e-01        1    3.06e-03    1.24e-01
  26  1.721185e-22    7.98e-21    4.77e-07   1.48e-15   1.22e+00  1.29e+00        1    5.94e-03    1.30e-01
  27  9.302582e-21   -9.13e-21    0.00e+00   2.61e-16  -1.76e-02  6.45e-01        1    2.90e-03    1.33e-01
  28  4.940946e-22   -3.22e-22    1.76e-06   2.49e-16   1.52e-01  4.83e-01        1    5.64e-03    1.38e-01
  29  1.290815e-21   -7.97e-22    2.24e-06   3.57e-16   1.36e-01  3.48e-01        1    5.95e-03    1.44e-01
  30  8.833414e-21   -7.54e-21    0.00e+00   5.44e-16  -8.36e-03  1.74e-01        1    3.09e-03    1.47e-01
  31  5.399245e-21   -4.11e-21    6.20e-06   3.23e-16   5.66e-02  1.03e-01        1    5.79e-03    1.53e-01
  32  8.325920e-22    4.57e-21    2.60e-06   6.00e-16   1.80e+00  3.08e-01        1    5.99e-03    1.59e-01
  33  8.217381e-21   -7.38e-21    7.87e-06   3.06e-16   3.08e-03  1.55e-01        1    5.86e-03    1.65e-01
  34  1.447938e-21    6.77e-21    3.30e-06   9.35e-16   1.49e+00  4.66e-01        1    5.72e-03    1.71e-01
  35  6.023150e-21   -4.58e-21    7.40e-06   6.45e-16   3.84e-01  4.60e-01        1    6.10e-03    1.77e-01
  36  4.061480e-21    1.96e-21    5.49e-06   1.02e-15   3.99e-01  4.57e-01        1    5.87e-03    1.83e-01
  37  6.234770e-21   -2.17e-21    7.12e-06   1.21e-15   1.41e-01  3.34e-01        1    5.57e-03    1.89e-01
  38  1.941258e-20   -1.32e-20    0.00e+00   1.23e-15  -5.92e-01  1.67e-01        1    3.16e-03    1.92e-01
  39  2.475581e-21    3.76e-21    4.56e-06   8.76e-16   1.00e+00  5.00e-01        1    5.92e-03    1.98e-01
  40  6.970087e-21   -4.49e-21    7.46e-06   7.75e-16   6.27e-02  3.00e-01        1    5.68e-03    2.03e-01
  41  3.778325e-21    3.19e-21    4.65e-06   1.24e-15   6.15e-01  3.03e-01        1    5.76e-03    2.09e-01
  42  1.982138e-21    1.80e-21    4.13e-06   8.91e-16   6.60e-01  3.14e-01        1    5.74e-03    2.15e-01
  43  6.149384e-22    1.37e-21    2.13e-06   5.21e-16   9.62e-01  9.41e-01        1    5.71e-03    2.21e-01
  44  2.301527e-21   -1.69e-21    3.04e-06   4.17e-16   1.99e-01  7.73e-01        1    5.71e-03    2.26e-01
  45  9.887102e-21   -7.59e-21    0.00e+00   9.05e-16  -5.28e-02  3.87e-01        1    3.08e-03    2.29e-01
  46  5.133267e-21   -2.83e-21    6.20e-06   6.47e-16   9.84e-02  2.55e-01        1    5.80e-03    2.35e-01
  47  1.721333e-21    3.41e-21    3.29e-06   1.01e-15   9.17e-01  6.07e-01        1    5.85e-03    2.41e-01
  48  4.782057e-21   -3.06e-21    6.14e-06   7.08e-16   9.41e-02  3.96e-01        1    5.86e-03    2.47e-01
  49  1.799119e-21    2.98e-21    3.78e-06   1.21e-15   7.84e-01  4.85e-01        1    5.72e-03    2.53e-01
  50  3.505512e-21   -1.71e-21    5.06e-06   8.77e-16   1.13e-01  3.31e-01        1    5.65e-03    2.58e-01
  51  8.022298e-21   -4.52e-21    7.36e-06   8.26e-16   4.38e-03  1.68e-01        1    6.38e-03    2.65e-01
  52  8.857350e-21   -8.35e-22    0.00e+00   1.02e-15  -1.29e-02  8.38e-02        1    2.91e-03    2.68e-01
  53  1.640413e-21    6.38e-21    3.40e-06   6.13e-16   1.91e+00  2.51e-01        1    5.80e-03    2.74e-01
  54  2.629106e-20   -2.47e-20    0.00e+00   5.41e-16  -3.69e-01  1.26e-01        1    2.99e-03    2.77e-01
  55  1.369603e-21    2.71e-22    3.29e-06   3.56e-16   3.54e-01  1.23e-01        1    6.14e-03    2.83e-01
  56  3.515615e-21   -2.15e-21    5.20e-06   3.47e-16   9.53e-02  8.01e-02        1    5.87e-03    2.89e-01
  57  3.502623e-21    1.30e-23    5.03e-06   3.61e-16   9.31e-02  5.21e-02        1    5.74e-03    2.94e-01
  58  2.185115e-21    1.32e-21    3.50e-06   2.74e-16   1.41e+00  1.56e-01        1    5.92e-03    3.00e-01
  59  1.036671e-20   -8.18e-21    0.00e+00   4.61e-16  -4.07e-02  7.81e-02        1    2.96e-03    3.03e-01
  60  1.302740e-21    8.82e-22    3.01e-06   3.43e-16   1.04e+00  2.34e-01        1    5.91e-03    3.09e-01
  61  1.660993e-20   -1.53e-20    0.00e+00   5.84e-16  -1.57e-01  1.17e-01        1    2.94e-03    3.12e-01
  62  1.898514e-21   -5.96e-22    3.31e-06   3.43e-16   1.19e-01  8.12e-02        1    5.83e-03    3.18e-01
  63  9.356490e-22    9.63e-22    2.54e-06   3.43e-16   1.24e+00  2.44e-01        1    5.67e-03    3.24e-01
  64  3.114767e-21   -2.18e-21    4.74e-06   3.49e-16   9.37e-02  1.59e-01        1    6.09e-03    3.30e-01
  65  1.434522e-21    1.68e-21    3.33e-06   6.00e-16   9.24e-01  4.08e-01        1    5.78e-03    3.36e-01
  66  6.100870e-22    8.24e-22    2.17e-06   6.85e-16   6.98e-01  4.34e-01        1    5.67e-03    3.41e-01
  67  1.004618e-21   -3.95e-22    2.38e-06   3.12e-16   1.25e-01  3.05e-01        1    5.99e-03    3.47e-01
  68  4.814439e-21   -3.81e-21    6.17e-06   4.57e-16   5.81e-02  1.81e-01        1    5.89e-03    3.53e-01
  69  2.530242e-21    2.28e-21    4.20e-06   8.72e-16   7.55e-01  2.08e-01        1    5.67e-03    3.59e-01
  70  1.072309e-20   -8.19e-21    0.00e+00   6.20e-16  -3.97e-02  1.04e-01        1    3.21e-03    3.62e-01
  71  2.159302e-20   -1.91e-20    0.00e+00   3.67e-16  -2.13e-01  2.60e-02        1    3.16e-03    3.65e-01
  72  1.209833e-21    1.32e-21    2.90e-06   1.19e-16   3.60e+00  7.80e-02        1    5.85e-03    3.71e-01
  73  9.759245e-22    2.34e-22    2.49e-06   2.80e-16   5.10e-01  7.80e-02        1    5.75e-03    3.77e-01
  74  1.109604e-21   -1.34e-22    2.84e-06   2.53e-16   1.13e-01  5.33e-02        1    6.02e-03    3.83e-01
  75  3.319715e-21   -2.21e-21    5.06e-06   1.28e-16   7.76e-02  3.33e-02        1    5.70e-03    3.89e-01
  76  3.887271e-21   -5.68e-22    5.06e-06   2.57e-16   6.79e-02  2.02e-02        1    5.90e-03    3.95e-01
  77  1.368868e-21    2.52e-21    2.93e-06   1.14e-16   4.82e+00  6.07e-02        1    6.08e-03    4.01e-01
  78  2.779779e-21   -1.41e-21    4.61e-06   2.57e-16   8.41e-02  3.85e-02        1    5.66e-03    4.06e-01
  79  3.553008e-21   -7.73e-22    4.78e-06   2.57e-16   7.14e-02  2.36e-02        1    5.89e-03    4.12e-01
  80  5.841019e-21   -2.29e-21    6.48e-06   1.14e-16   3.61e-02  1.31e-02        1    5.92e-03    4.18e-01
  81  4.147503e-21    1.69e-21    5.13e-06   3.37e-17   3.65e+00  3.94e-02        1    5.66e-03    4.24e-01
  82  3.321082e-21    8.26e-22    5.07e-06   2.70e-16   9.86e-01  1.18e-01        1    5.99e-03    4.30e-01
  83  1.175496e-21    2.15e-21    2.76e-06   6.00e-16   1.27e+00  3.55e-01        1    6.15e-03    4.36e-01
  84  6.652307e-21   -5.48e-21    6.23e-06   5.97e-16   2.24e-02  1.90e-01        1    5.83e-03    4.42e-01
  85  2.712562e-22    6.38e-21    1.03e-06   9.55e-16   1.46e+00  5.69e-01        1    5.82e-03    4.48e-01
  86  6.145143e-21   -5.87e-21    7.00e-06   3.27e-16   2.79e-02  3.09e-01        1    5.97e-03    4.54e-01
  87  6.785762e-21   -6.41e-22    7.40e-06   1.22e-15   1.81e-02  1.63e-01        1    5.79e-03    4.60e-01
  88  1.005626e-21    5.78e-21    2.36e-06   9.14e-16   1.46e+00  4.89e-01        1    6.17e-03    4.66e-01
  89  7.151735e-22    2.90e-22    1.85e-06   6.00e-16   3.44e-01  4.74e-01        1    5.84e-03    4.72e-01
  90  4.535283e-21   -3.82e-21    5.06e-06   5.57e-16   4.37e-02  2.69e-01        1    5.79e-03    4.78e-01
  91  9.077294e-22    3.63e-21    2.72e-06   8.14e-16   1.07e+00  8.08e-01        1    5.99e-03    4.84e-01
  92  9.589828e-22   -5.13e-23    2.45e-06   4.95e-16   8.21e-02  5.10e-01        1    5.80e-03    4.89e-01
  93  2.358677e-22    7.23e-22    9.75e-07   4.72e-16   9.17e-01  1.21e+00        1    6.30e-03    4.96e-01
  94  6.256607e-21   -6.02e-21    7.05e-06   3.39e-16   2.20e-02  6.48e-01        1    6.24e-03    5.02e-01
  95  4.856535e-21    1.40e-21    6.00e-06   1.57e-15   2.56e-01  5.80e-01        1    5.68e-03    5.08e-01
  96  1.596915e-21    3.26e-21    3.19e-06   1.25e-15   7.83e-01  7.09e-01        1    6.29e-03    5.14e-01
  97  7.047524e-21   -5.45e-21    7.57e-06   9.20e-16   1.17e-02  3.67e-01        1    6.04e-03    5.20e-01
  98  4.025895e-21    3.02e-21    4.58e-06   1.48e-15   5.35e-01  3.67e-01        1    5.91e-03    5.26e-01
  99  2.977473e-21    1.05e-21    4.85e-06   9.10e-16   3.45e-01  3.56e-01        1    5.72e-03    5.32e-01
 100  2.295397e-21    6.82e-22    4.16e-06   9.01e-16   2.93e-01  3.33e-01        1    6.29e-03    5.38e-01
 101  1.858843e-21    4.37e-22    3.63e-06   7.10e-16   2.43e-01  2.93e-01        1    6.07e-03    5.44e-01
 102  3.735596e-22    1.49e-21    1.26e-06   6.15e-16   1.10e+00  8.79e-01        1    5.86e-03    5.50e-01
 103  7.724207e-21   -7.35e-21    7.62e-06   4.24e-16   4.30e-03  4.45e-01        1    6.19e-03    5.56e-01
 104  3.453390e-21    4.27e-21    5.10e-06   1.63e-15   6.52e-01  4.58e-01        1    5.92e-03    5.62e-01
 105  2.556590e-21    8.97e-22    3.42e-06   1.03e-15   3.06e-01  4.33e-01        1    5.93e-03    5.68e-01
 106  5.528301e-22    2.00e-21    1.48e-06   8.67e-16   1.03e+00  1.30e+00        1    5.97e-03    5.74e-01
 107  2.025264e-21   -1.47e-21    3.66e-06   5.43e-16   4.89e-02  7.48e-01        1    6.23e-03    5.80e-01
 108  2.895468e-22    1.74e-21    1.06e-06   8.76e-16   9.71e-01  2.24e+00        1    5.98e-03    5.86e-01
 109  2.641228e-20   -2.61e-20    0.00e+00   5.21e-16  -1.41e-01  1.12e+00        1    3.21e-03    5.90e-01
 110  4.536960e-21   -4.25e-21    4.94e-06   2.82e-16   2.86e-02  6.11e-01        1    5.88e-03    5.96e-01
 111  4.639689e-21   -1.03e-22    6.22e-06   1.21e-15   2.70e-02  3.31e-01        1    5.74e-03    6.01e-01
 112  2.222637e-20   -1.76e-20    0.00e+00   9.01e-16  -1.03e-01  1.65e-01        1    2.89e-03    6.04e-01
 113  5.699585e-21   -1.06e-21    6.03e-06   6.09e-16   1.86e-02  8.74e-02        1    6.32e-03    6.11e-01
 114  6.243205e-21   -5.44e-22    6.53e-06   5.71e-16   1.44e-02  4.56e-02        1    5.83e-03    6.17e-01
 115  3.291995e-21    2.95e-21    3.72e-06   3.43e-16   1.74e+00  1.37e-01        1    6.31e-03    6.23e-01
 116  2.317027e-21    9.75e-22    3.26e-06   3.70e-16   6.48e-01  1.40e-01        1    5.96e-03    6.29e-01
 117  1.038077e-21    1.28e-21    2.34e-06   3.35e-16   1.23e+00  4.21e-01        1    5.89e-03    6.35e-01
 118  3.323839e-21   -2.29e-21    5.22e-06   5.74e-16   3.44e-02  2.33e-01        1    5.89e-03    6.41e-01
 119  4.515199e-21   -1.19e-21    6.00e-06   6.86e-16   2.56e-02  1.26e-01        1    5.84e-03    6.47e-01
 120  1.680919e-21    2.83e-21    3.40e-06   6.14e-16   1.24e+00  3.77e-01        1    5.86e-03    6.52e-01
 121  2.719310e-21   -1.04e-21    4.69e-06   6.81e-16   3.71e-02  2.10e-01        1    5.78e-03    6.58e-01
 122  2.413944e-21    3.05e-22    3.70e-06   6.23e-16   1.67e-01  1.62e-01        1    5.85e-03    6.64e-01
 123  8.224582e-22    1.59e-21    2.31e-06   4.60e-16   1.10e+00  4.87e-01        1    5.68e-03    6.70e-01
 124  1.328747e-20   -1.25e-20    0.00e+00   5.84e-16  -3.33e-02  2.44e-01        1    2.88e-03    6.73e-01
 125  6.911643e-21   -6.09e-21    7.03e-06   3.45e-16   8.59e-03  1.25e-01        1    5.79e-03    6.78e-01
 126  6.426712e-21    4.85e-22    7.01e-06   6.58e-16   1.46e-01  9.23e-02        1    5.92e-03    6.84e-01
 127  4.249073e-21    2.18e-21    5.52e-06   6.03e-16   7.81e-01  1.12e-01        1    5.60e-03    6.90e-01
 128  4.963047e-21   -7.14e-22    6.02e-06   5.42e-16   2.03e-02  5.96e-02        1    6.05e-03    6.96e-01
 129  1.603249e-21    3.36e-21    3.32e-06   3.14e-16   2.27e+00  1.79e-01        1    5.85e-03    7.02e-01
 130  1.875253e-21   -2.72e-22    3.88e-06   5.25e-16   3.91e-02  1.00e-01        1    5.75e-03    7.08e-01
 131  1.892037e-21   -1.68e-23    3.78e-06   3.52e-16   3.88e-02  5.61e-02        1    5.83e-03    7.14e-01
 132  5.490793e-22    1.34e-21    1.90e-06   2.64e-16   2.36e+00  1.68e-01        1    5.68e-03    7.19e-01
 133  2.185339e-21   -1.64e-21    3.37e-06   1.76e-16   3.68e-02  9.38e-02        1    5.60e-03    7.25e-01
 134  1.785560e-21    4.00e-22    3.79e-06   3.45e-16   4.27e-01  9.35e-02        1    5.96e-03    7.31e-01
 135  2.002538e-21   -2.17e-22    3.77e-06   2.93e-16   3.75e-02  5.22e-02        1    5.80e-03    7.37e-01
 136  1.501393e-22    1.85e-21    6.15e-07   2.62e-16   3.56e+00  1.57e-01        1    5.71e-03    7.42e-01
 137  7.083888e-22   -5.58e-22    1.49e-06   1.73e-17   4.52e-02  8.93e-02        1    5.74e-03    7.48e-01
 138  5.398162e-22    1.69e-22    1.67e-06   7.80e-17   8.93e-01  1.73e-01        1    5.78e-03    7.54e-01
 139  5.418045e-22   -1.99e-24    1.94e-06   1.36e-16   4.61e-02  9.90e-02        1    5.58e-03    7.60e-01
 140  3.468280e-22    1.95e-22    1.39e-06   2.56e-16   8.83e-01  1.80e-01        1    6.13e-03    7.66e-01
 141  1.481293e-21   -1.13e-21    2.85e-06   1.34e-16   4.03e-02  1.02e-01        1    5.81e-03    7.72e-01
 142  7.792134e-21   -6.31e-21    0.00e+00   3.48e-16  -9.05e+00  5.08e-02        1    2.89e-03    7.74e-01
 143  4.518817e-21   -3.04e-21    0.00e+00   1.29e-16  -7.02e+00  1.27e-02        1    2.94e-03    7.77e-01
 144  2.313570e-21   -8.32e-22    0.00e+00   7.15e-18  -6.36e+00  1.59e-03        1    2.97e-03    7.80e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.050528e+02
Final                            1.501393e-22
Change                           1.050528e+02

Minimizer iterations                      145
Successful steps                          120
Unsuccessful steps                         25
Line search steps                          81

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0118
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.7607
    Line search gradient evaluation    0.4187
  Linear solver                        0.0046
  Line search polynomial minimization  0.0006
Minimizer                              0.7835

Postprocessor                          0.0000
Total                                  0.7836

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.645181e+04
Final                            1.594582e+02
Change                           1.629235e+04

Minimizer iterations                      131
Successful steps                           77
Unsuccessful steps                         54
Line search steps                         174

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0096
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8168
    Line search gradient evaluation    0.6056
  Linear solver                        0.0023
  Line search polynomial minimization  0.0012
Minimizer                              0.8322

Postprocessor                          0.0000
Total                                  0.8323

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA97 = {
{-0.0700575,0.5064432,0.2337902}
};
fitErrEl97 = {
{-0.1123582,0.4908801,0.2475735}
};
fitErrLa97 = {
{-0.1138212,0.5260760,0.2592194}
};
fitErrWr97 = {
{-0.3338992,0.4562341,0.3586338}
};
fitErrEe97 = {
{-0.3894286,0.4805083,0.4489987}
};
rMatsBase97 = {
{-0.3523665,0.6835950,-0.6391681},
{0.7814785,0.5906932,0.2009300},
{0.5149070,-0.4286951,-0.7423553}
};
outThetasWam97 = {
{-0.1072987,-0.2328326,-0.0358999,1.3434238,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5621837
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.087759e+02    0.00e+00    2.83e+00   0.00e+00   0.00e+00  1.00e+04        0    2.86e-03    2.90e-03
   1  3.771903e-02    1.09e+02    2.85e+00   3.72e-03   2.00e+00  3.00e+04        1    5.84e-03    8.76e-03
   2  2.693227e-09    3.77e-02    1.13e+00   1.71e-05   2.00e+00  9.00e+04        1    5.62e-03    1.44e-02
   3  5.289125e-16    2.69e-09    7.97e-05   2.01e-08   2.00e+00  2.70e+05        1    5.58e-03    2.00e-02
   4  1.412695e-21    5.29e-16    3.23e-06   1.04e-11   2.00e+00  8.10e+05        1    5.52e-03    2.55e-02
   5  6.172350e-21   -4.76e-21    6.86e-06   2.30e-15   2.00e+00  2.43e+06        1    5.71e-03    3.12e-02
   6  1.314194e-20   -6.97e-21    1.02e-05   6.03e-15   2.00e+00  7.29e+06        1    5.50e-03    3.68e-02
   7  2.273193e-21    1.09e-20    3.75e-06   6.92e-15   2.00e+00  2.19e+07        1    5.54e-03    4.23e-02
   8  7.241691e-21   -4.97e-21    7.48e-06   2.28e-15   2.00e+00  6.56e+07        1    5.82e-03    4.81e-02
   9  5.006909e-23    7.19e-21    3.28e-07   5.35e-15   2.00e+00  1.97e+08        1    5.78e-03    5.39e-02
  10  2.100835e-21   -2.05e-21    3.84e-06   3.66e-16   2.00e+00  5.90e+08        1    5.74e-03    5.97e-02
  11  8.038016e-21   -5.94e-21    8.19e-06   3.69e-15   2.00e+00  1.77e+09        1    5.83e-03    6.55e-02
  12  1.239017e-20   -4.35e-21    6.88e-06   4.57e-15   2.00e+00  5.31e+09        1    5.79e-03    7.13e-02
  13  3.511217e-21    8.88e-21    4.86e-06   8.22e-15   2.00e+00  1.59e+10        1    5.51e-03    7.69e-02
  14  6.113541e-22    2.90e-21    1.73e-06   5.20e-15   2.00e+00  4.78e+10        1    5.55e-03    8.24e-02
  15  1.045463e-21   -4.34e-22    2.92e-06   1.10e-15   6.97e-01  5.09e+10        1    5.48e-03    8.79e-02
  16  1.115159e-21   -6.97e-23    2.78e-06   1.11e-15   6.51e-01  5.24e+10        1    5.68e-03    9.36e-02
  17  7.133929e-21   -6.02e-21    7.51e-06   4.22e-15   2.86e-01  4.86e+10        1    5.50e-03    9.91e-02
  18  1.150372e-21    5.98e-21    2.97e-06   5.56e-15   8.39e-01  7.06e+10        1    6.06e-03    1.05e-01
  19  9.390456e-22    2.11e-22    2.40e-06   1.16e-15   4.30e-01  7.04e+10        1    5.71e-03    1.11e-01
  20  6.607226e-22    2.78e-22    1.37e-06   9.58e-16   4.26e-01  7.02e+10        1    5.66e-03    1.17e-01
  21  5.662235e-21   -5.00e-21    5.95e-06   2.58e-15   2.39e-01  6.14e+10        1    5.69e-03    1.22e-01
  22  3.985837e-21    1.68e-21    5.21e-06   2.72e-15   3.04e-01  5.79e+10        1    5.61e-03    1.28e-01
  23  4.437626e-21   -4.52e-22    4.68e-06   4.12e-15   2.11e-01  4.86e+10        1    5.72e-03    1.34e-01
  24  1.355583e-21    3.08e-21    3.55e-06   6.59e-15   7.11e-01  5.25e+10        1    5.85e-03    1.40e-01
  25  1.459713e-21   -1.04e-22    2.84e-06   1.25e-15   2.52e-01  4.68e+10        1    5.68e-03    1.45e-01
  26  2.805299e-21   -1.35e-21    4.38e-06   2.55e-15   2.15e-01  3.95e+10        1    5.81e-03    1.51e-01
  27  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  1.97e+10        1    3.11e-03    1.54e-01
  28  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  4.94e+09        1    2.97e-03    1.57e-01
  29  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  6.17e+08        1    2.88e-03    1.60e-01
  30  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  3.86e+07        1    2.86e-03    1.63e-01
  31  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  1.20e+06        1    3.07e-03    1.66e-01
  32  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  1.88e+04        1    3.19e-03    1.69e-01
  33  1.259761e-20   -9.79e-21    0.00e+00   5.02e-15  -4.37e-03  1.47e+02        1    3.04e-03    1.72e-01
  34  8.614547e-21   -5.81e-21    7.90e-06   3.99e-15   7.96e-02  9.22e+01        1    5.64e-03    1.78e-01
  35  1.641450e-20   -7.80e-21    0.00e+00   4.45e-15  -7.18e-02  4.61e+01        1    2.95e-03    1.81e-01
  36  5.702064e-21    2.91e-21    5.87e-06   4.11e-15   3.40e-01  4.47e+01        1    5.78e-03    1.87e-01
  37  1.051118e-20   -4.81e-21    8.45e-06   3.92e-15   3.05e-02  2.44e+01        1    5.61e-03    1.92e-01
  38  1.139418e-21    9.37e-21    2.89e-06   3.84e-15   8.93e-01  4.75e+01        1    5.52e-03    1.98e-01
  39  6.388472e-22    5.01e-22    1.37e-06   1.60e-15   4.46e-01  4.75e+01        1    5.90e-03    2.04e-01
  40  8.892998e-22   -2.50e-22    2.65e-06   2.95e-15   1.56e-01  3.58e+01        1    5.78e-03    2.10e-01
  41  2.132201e-22    6.76e-22    1.04e-06   8.34e-16   7.71e-01  4.25e+01        1    5.57e-03    2.15e-01
  42  5.849236e-21   -5.64e-21    6.15e-06   1.17e-15   8.73e-02  2.72e+01        1    5.67e-03    2.21e-01
  43  7.605185e-22    5.09e-21    2.44e-06   3.21e-15   8.75e-01  4.71e+01        1    5.54e-03    2.26e-01
  44  2.421709e-22    5.18e-22    1.14e-06   1.54e-15   7.09e-01  5.09e+01        1    5.61e-03    2.32e-01
  45  2.865775e-21   -2.62e-21    4.66e-06   7.20e-16   1.17e-01  3.51e+01        1    5.79e-03    2.38e-01
  46  1.070113e-21    1.80e-21    2.44e-06   2.30e-15   6.52e-01  3.61e+01        1    5.73e-03    2.44e-01
  47  5.543672e-21   -4.47e-21    6.49e-06   9.40e-16   8.01e-02  2.26e+01        1    5.48e-03    2.49e-01
  48  6.069871e-22    4.94e-21    1.74e-06   3.67e-15   9.02e-01  4.73e+01        1    5.66e-03    2.55e-01
  49  1.137468e-21   -5.30e-22    1.96e-06   3.24e-15   1.23e-01  3.31e+01        1    5.51e-03    2.61e-01
  50  7.987423e-22    3.39e-22    2.53e-06   2.77e-15   3.16e-01  3.16e+01        1    5.57e-03    2.66e-01
  51  3.700636e-22    4.29e-22    1.60e-06   7.49e-16   5.57e-01  3.16e+01        1    5.53e-03    2.72e-01
  52  1.455478e-21   -1.09e-21    2.38e-06   8.27e-16   1.17e-01  2.18e+01        1    5.59e-03    2.77e-01
  53  5.766099e-21   -4.31e-21    6.62e-06   1.69e-15   6.96e-02  1.33e+01        1    5.53e-03    2.83e-01
  54  1.917799e-20   -1.34e-20    0.00e+00   2.93e-15  -6.73e-02  6.66e+00        1    2.87e-03    2.86e-01
  55  6.332332e-22    5.13e-21    2.38e-06   2.51e-15   9.01e-01  1.38e+01        1    5.62e-03    2.91e-01
  56  3.353227e-21   -2.72e-21    4.49e-06   5.48e-16   8.91e-02  8.87e+00        1    5.50e-03    2.97e-01
  57  1.271981e-20   -9.37e-21    0.00e+00   2.05e-15  -3.15e-03  4.43e+00        1    2.83e-03    3.00e-01
  58  1.634913e-21    1.72e-21    3.46e-06   1.88e-15   5.27e-01  4.43e+00        1    5.88e-03    3.06e-01
  59  5.311010e-22    1.10e-21    1.78e-06   9.17e-16   7.42e-01  5.00e+00        1    5.75e-03    3.11e-01
  60  1.834480e-21   -1.30e-21    3.71e-06   6.31e-16   9.90e-02  3.30e+00        1    5.77e-03    3.17e-01
  61  3.519017e-21   -1.68e-21    5.21e-06   8.75e-16   8.19e-02  2.08e+00        1    5.80e-03    3.23e-01
  62  1.852652e-21    1.67e-21    4.11e-06   1.53e-15   5.01e-01  2.08e+00        1    5.68e-03    3.29e-01
  63  4.635458e-22    1.39e-21    1.69e-06   9.27e-16   7.75e-01  2.50e+00        1    5.67e-03    3.34e-01
  64  7.912538e-21   -7.45e-21    7.86e-06   4.71e-16   3.93e-02  1.40e+00        1    5.63e-03    3.40e-01
  65  2.209465e-20   -1.42e-20    0.00e+00   2.29e-15  -8.00e-02  7.01e-01        1    2.86e-03    3.43e-01
  66  1.576466e-21    6.34e-21    3.59e-06   1.86e-15   8.96e-01  1.40e+00        1    5.84e-03    3.49e-01
  67  3.283637e-20   -3.13e-20    0.00e+00   9.58e-16  -1.67e-01  6.99e-01        1    2.89e-03    3.52e-01
  68  7.198873e-21   -5.62e-21    6.08e-06   7.18e-16   4.24e-02  3.96e-01        1    5.60e-03    3.57e-01
  69  3.877674e-22    6.81e-21    1.47e-06   1.23e-15   1.22e+00  1.19e+00        1    5.66e-03    3.63e-01
  70  3.107644e-21   -2.72e-21    4.80e-06   5.40e-16   7.24e-02  7.30e-01        1    5.65e-03    3.69e-01
  71  6.329616e-22    2.47e-21    2.39e-06   8.04e-16   8.96e-01  1.45e+00        1    5.64e-03    3.74e-01
  72  1.873848e-21   -1.24e-21    4.12e-06   5.12e-16   7.99e-02  9.08e-01        1    5.86e-03    3.80e-01
  73  7.071470e-21   -5.20e-21    7.37e-06   7.41e-16   3.99e-02  5.10e-01        1    5.67e-03    3.86e-01
  74  2.511283e-22    6.82e-21    9.70e-07   1.50e-15   1.16e+00  1.53e+00        1    5.69e-03    3.91e-01
  75  2.523041e-22   -1.18e-24    6.59e-07   2.64e-16   8.71e-02  9.79e-01        1    5.69e-03    3.97e-01
  76  2.755281e-21   -2.50e-21    4.02e-06   2.63e-16   6.91e-02  5.97e-01        1    5.72e-03    4.03e-01
  77  2.451787e-21    3.03e-22    4.46e-06   1.02e-15   1.35e-01  4.30e-01        1    5.74e-03    4.09e-01
  78  1.440628e-21    1.01e-21    3.47e-06   8.87e-16   4.95e-01  4.30e-01        1    5.84e-03    4.14e-01
  79  1.496444e-22    1.29e-21    8.26e-07   6.38e-16   1.07e+00  1.29e+00        1    5.75e-03    4.20e-01
  80  2.036598e-21   -1.89e-21    3.42e-06   1.78e-16   7.14e-02  7.92e-01        1    5.81e-03    4.26e-01
  81  1.838169e-21    1.98e-22    3.77e-06   7.52e-16   1.14e-01  5.42e-01        1    5.83e-03    4.32e-01
  82  2.784721e-22    1.56e-21    9.19e-07   8.71e-16   9.94e-01  1.62e+00        1    5.60e-03    4.38e-01
  83  2.565612e-21   -2.29e-21    3.66e-06   3.37e-16   6.61e-02  9.83e-01        1    5.67e-03    4.43e-01
  84  4.380020e-22    2.13e-21    1.63e-06   8.75e-16   9.00e-01  2.02e+00        1    5.87e-03    4.49e-01
  85  4.113594e-22    2.66e-23    1.50e-06   4.32e-16   7.91e-02  1.26e+00        1    5.72e-03    4.55e-01
  86  3.756817e-22    3.57e-23    1.62e-06   4.22e-16   1.10e-01  8.57e-01        1    5.82e-03    4.61e-01
  87  2.780269e-21   -2.40e-21    4.05e-06   3.72e-16   6.32e-02  5.14e-01        1    5.63e-03    4.66e-01
  88  1.754945e-21    1.03e-21    2.91e-06   9.50e-16   4.52e-01  5.14e-01        1    5.51e-03    4.72e-01
  89  1.206621e-20   -1.03e-20    9.64e-06   6.97e-16   2.08e-03  2.58e-01        1    5.69e-03    4.78e-01
  90  5.450321e-21    6.62e-21    5.87e-06   1.47e-15   7.87e-01  3.19e-01        1    5.59e-03    4.83e-01
  91  1.882745e-20   -1.34e-20    0.00e+00   1.17e-15  -3.83e-02  1.59e-01        1    2.86e-03    4.86e-01
  92  2.348926e-21    3.10e-21    4.50e-06   7.06e-16   1.01e+00  4.78e-01        1    5.75e-03    4.92e-01
  93  4.633306e-21   -2.28e-21    5.22e-06   9.01e-16   4.58e-02  2.73e-01        1    5.85e-03    4.98e-01
  94  1.116870e-21    3.52e-21    3.08e-06   8.67e-16   1.11e+00  8.20e-01        1    5.51e-03    5.03e-01
  95  1.627519e-22    9.54e-22    1.10e-06   5.55e-16   9.50e-01  2.46e+00        1    5.55e-03    5.09e-01
  96  1.107428e-21   -9.45e-22    2.85e-06   3.44e-16   6.50e-02  1.48e+00        1    5.66e-03    5.14e-01
  97  7.973870e-21   -6.87e-21    7.95e-06   9.10e-16   2.53e-02  7.99e-01        1    5.53e-03    5.20e-01
  98  1.563683e-21    6.41e-21    2.48e-06   2.03e-15   8.91e-01  1.53e+00        1    5.70e-03    5.26e-01
  99  3.571886e-22    1.21e-21    1.10e-06   7.79e-16   8.03e-01  1.97e+00        1    5.74e-03    5.31e-01
 100  1.829984e-22    1.74e-22    1.19e-06   3.52e-16   6.17e-01  1.99e+00        1    5.62e-03    5.37e-01
 101  3.176996e-22   -1.35e-22    1.60e-06   3.46e-16   6.57e-02  1.20e+00        1    5.74e-03    5.43e-01
 102  3.657918e-21   -3.34e-21    4.67e-06   3.51e-16   4.74e-02  6.91e-01        1    5.75e-03    5.49e-01
 103  1.116044e-20   -7.50e-21    8.99e-06   1.19e-15   6.57e-03  3.52e-01        1    5.60e-03    5.54e-01
 104  1.790282e-21    9.37e-21    3.80e-06   1.70e-15   1.04e+00  1.06e+00        1    5.54e-03    5.60e-01
 105  5.892733e-22    1.20e-21    1.87e-06   9.44e-16   7.28e-01  1.17e+00        1    5.71e-03    5.65e-01
 106  1.222546e-20   -1.16e-20    0.00e+00   5.59e-16   8.31e-04  5.84e-01        1    2.99e-03    5.68e-01
 107  1.188333e-20   -1.13e-20    7.95e-06   5.41e-16   2.56e-03  2.94e-01        1    5.61e-03    5.74e-01
 108  4.692794e-22    1.14e-20    1.60e-06   1.47e-15   1.36e+00  8.82e-01        1    5.58e-03    5.80e-01
 109  3.151477e-22    1.54e-22    1.51e-06   4.60e-16   3.60e-01  8.64e-01        1    5.85e-03    5.86e-01
 110  6.117360e-22   -2.97e-22    1.98e-06   3.16e-16   5.68e-02  5.09e-01        1    5.78e-03    5.91e-01
 111  8.467634e-22   -2.35e-22    2.77e-06   3.82e-16   5.55e-02  2.99e-01        1    5.74e-03    5.97e-01
 112  9.391751e-21   -8.54e-21    8.37e-06   3.31e-16   1.44e-02  1.56e-01        1    5.71e-03    6.03e-01
 113  1.489172e-21    7.90e-21    3.45e-06   1.03e-15   1.43e+00  4.68e-01        1    5.57e-03    6.08e-01
 114  2.430021e-21   -9.41e-22    2.87e-06   5.30e-16   4.63e-02  2.68e-01        1    5.68e-03    6.14e-01
 115  6.972823e-21   -4.54e-21    6.47e-06   6.20e-16   2.50e-02  1.44e-01        1    5.85e-03    6.20e-01
 116  1.252908e-21    5.72e-21    2.72e-06   5.41e-16   1.70e+00  4.33e-01        1    5.74e-03    6.26e-01
 117  4.559590e-21   -3.31e-21    5.84e-06   5.74e-16   3.54e-02  2.40e-01        1    5.70e-03    6.31e-01
 118  1.340092e-21    3.22e-21    2.81e-06   9.32e-16   1.00e+00  7.21e-01        1    5.86e-03    6.37e-01
 119  9.085299e-21   -7.75e-21    8.52e-06   7.08e-16   1.47e-02  3.76e-01        1    5.74e-03    6.43e-01
 120  1.478613e-21    7.61e-21    3.64e-06   1.62e-15   1.03e+00  1.13e+00        1    5.82e-03    6.49e-01
 121  3.108714e-22    1.17e-21    1.52e-06   7.13e-16   8.31e-01  1.59e+00        1    6.02e-03    6.55e-01
 122  3.244537e-21   -2.93e-21    4.79e-06   5.20e-16   3.90e-02  8.93e-01        1    5.71e-03    6.61e-01
 123  8.103623e-21   -4.86e-21    6.97e-06   1.24e-15   1.81e-02  4.71e-01        1    5.85e-03    6.66e-01
 124  4.096428e-21    4.01e-21    5.95e-06   1.49e-15   6.23e-01  4.78e-01        1    5.71e-03    6.72e-01
 125  1.661428e-21    2.43e-21    3.22e-06   8.14e-16   7.17e-01  5.21e-01        1    5.51e-03    6.78e-01
 126  2.692982e-22    1.39e-21    1.14e-06   6.30e-16   1.06e+00  1.56e+00        1    5.80e-03    6.84e-01
 127  2.596599e-21   -2.33e-21    4.03e-06   2.96e-16   3.94e-02  8.76e-01        1    5.77e-03    6.89e-01
 128  4.792466e-21   -2.20e-21    5.61e-06   8.02e-16   3.03e-02  4.79e-01        1    5.59e-03    6.95e-01
 129  9.188685e-22    3.87e-21    2.25e-06   8.92e-16   1.02e+00  1.44e+00        1    5.67e-03    7.01e-01
 130  4.089137e-22    5.10e-22    1.34e-06   6.19e-16   6.40e-01  1.47e+00        1    5.57e-03    7.06e-01
 131  1.213051e-21   -8.04e-22    1.97e-06   3.84e-16   4.37e-02  8.35e-01        1    5.59e-03    7.12e-01
 132  1.456271e-22    1.07e-21    4.53e-07   6.43e-16   1.05e+00  2.50e+00        1    5.93e-03    7.18e-01
 133  9.216528e-21   -9.07e-21    7.47e-06   2.71e-16   1.24e-02  1.30e+00        1    5.74e-03    7.24e-01
 134  4.935945e-21    4.28e-21    5.46e-06   2.29e-15   4.96e-01  1.30e+00        1    5.62e-03    7.29e-01
 135  1.834112e-21    3.10e-21    3.71e-06   1.80e-15   6.93e-01  1.38e+00        1    5.78e-03    7.35e-01
 136  9.299149e-21   -7.47e-21    7.58e-06   7.80e-16   1.14e-02  7.13e-01        1    5.54e-03    7.41e-01
 137  4.381941e-22    8.86e-21    1.90e-06   1.86e-15   1.07e+00  2.14e+00        1    5.49e-03    7.46e-01
 138  1.544497e-21   -1.11e-21    3.31e-06   4.65e-16   3.87e-02  1.20e+00        1    6.02e-03    7.52e-01
 139  7.872473e-21   -6.33e-21    8.03e-06   9.18e-16   1.60e-02  6.28e-01        1    5.58e-03    7.58e-01
 140  5.391896e-21    2.48e-21    6.02e-06   1.81e-15   3.51e-01  6.12e-01        1    5.58e-03    7.63e-01
 141  5.598768e-21   -2.07e-22    6.74e-06   1.58e-15   2.31e-02  3.28e-01        1    5.70e-03    7.69e-01
 142  8.450976e-22    4.75e-21    2.49e-06   1.19e-15   1.11e+00  9.84e-01        1    5.57e-03    7.75e-01
 143  2.534112e-21   -1.69e-21    4.26e-06   5.73e-16   3.30e-02  5.42e-01        1    5.50e-03    7.80e-01
 144  1.546665e-21    9.87e-22    3.51e-06   6.97e-16   4.72e-01  5.42e-01        1    5.97e-03    7.86e-01
 145  1.069751e-21    4.77e-22    2.00e-06   5.01e-16   3.93e-01  5.37e-01        1    5.57e-03    7.92e-01
 146  3.882316e-21   -2.81e-21    5.13e-06   4.61e-16   2.81e-02  2.92e-01        1    5.59e-03    7.97e-01
 147  1.547599e-21    2.33e-21    3.21e-06   8.67e-16   8.50e-01  4.44e-01        1    5.73e-03    8.03e-01
 148  1.903888e-20   -1.75e-20    0.00e+00   6.03e-16  -2.17e-02  2.22e-01        1    2.85e-03    8.06e-01
 149  6.156800e-21   -4.61e-21    7.09e-06   5.59e-16   2.04e-02  1.18e-01        1    5.62e-03    8.11e-01
 150  1.082206e-20   -4.67e-21    9.21e-06   6.22e-16   5.07e-03  5.99e-02        1    5.54e-03    8.17e-01
 151  5.545563e-21    5.28e-21    5.99e-06   5.54e-16   1.59e+00  1.80e-01        1    5.63e-03    8.23e-01
 152  7.863139e-21   -2.32e-21    8.00e-06   6.99e-16   1.43e-02  9.38e-02        1    5.67e-03    8.28e-01
 153  9.904531e-22    6.87e-21    1.89e-06   6.11e-16   2.03e+00  2.81e-01        1    5.57e-03    8.34e-01
 154  3.474849e-21   -2.48e-21    3.74e-06   3.44e-16   2.79e-02  1.53e-01        1    5.96e-03    8.40e-01
 155  2.152012e-21    1.32e-21    3.79e-06   4.17e-16   7.60e-01  1.78e-01        1    5.81e-03    8.46e-01
 156  6.333509e-22    1.52e-21    1.40e-06   4.58e-16   1.14e+00  5.33e-01        1    5.73e-03    8.51e-01
 157  1.508658e-21   -8.75e-22    3.21e-06   3.37e-16   3.37e-02  2.95e-01        1    5.63e-03    8.57e-01
 158  5.013901e-22    1.01e-21    1.82e-06   5.99e-16   9.52e-01  8.84e-01        1    5.75e-03    8.63e-01
 159  7.121504e-21   -6.62e-21    7.55e-06   4.01e-16   1.62e-02  4.64e-01        1    5.70e-03    8.69e-01
 160  1.349982e-21    5.77e-21    2.80e-06   1.55e-15   9.54e-01  1.39e+00        1    5.47e-03    8.74e-01
 161  3.466555e-21   -2.12e-21    4.96e-06   6.18e-16   2.69e-02  7.53e-01        1    5.52e-03    8.80e-01
 162  4.376465e-21   -9.10e-22    4.48e-06   1.36e-15   2.39e-02  4.04e-01        1    5.87e-03    8.85e-01
 163  1.970380e-21    2.41e-21    3.90e-06   9.80e-16   6.96e-01  4.30e-01        1    5.77e-03    8.91e-01
 164  1.006396e-21    9.64e-22    2.48e-06   6.71e-16   5.97e-01  4.33e-01        1    5.55e-03    8.97e-01
 165  5.809417e-23    9.48e-22    4.24e-07   5.99e-16   1.15e+00  1.30e+00        1    5.62e-03    9.02e-01
 166  1.168484e-21   -1.11e-21    3.22e-06   8.81e-17   3.29e-02  7.16e-01        1    5.60e-03    9.08e-01
 167  1.791497e-21   -6.23e-22    2.44e-06   5.49e-16   3.10e-02  3.92e-01        1    5.64e-03    9.14e-01
 168  3.471815e-21   -1.68e-21    4.79e-06   6.30e-16   2.60e-02  2.12e-01        1    5.52e-03    9.19e-01
 169  3.288791e-21    1.83e-22    5.16e-06   7.06e-16   8.07e-02  1.33e-01        1    5.51e-03    9.25e-01
 170  4.281714e-21   -9.93e-22    4.80e-06   6.05e-16   2.34e-02  7.14e-02        1    5.98e-03    9.31e-01
 171  1.355686e-20   -9.28e-21    0.00e+00   3.60e-16  -3.35e-03  3.57e-02        1    2.92e-03    9.34e-01
 172  1.781056e-21    2.50e-21    3.29e-06   2.64e-16   2.73e+00  1.07e-01        1    5.58e-03    9.39e-01
 173  4.579661e-21   -2.80e-21    5.69e-06   2.98e-16   2.24e-02  5.72e-02        1    5.54e-03    9.45e-01
 174  1.045861e-20   -5.88e-21    7.45e-06   3.43e-16   5.52e-03  2.91e-02        1    5.65e-03    9.51e-01
 175  3.784306e-21    6.67e-21    4.49e-06   3.44e-16   3.50e+00  8.73e-02        1    5.68e-03    9.56e-01
 176  1.660549e-20   -1.28e-20    0.00e+00   3.63e-16  -1.19e-02  4.36e-02        1    2.81e-03    9.59e-01
 177  1.153492e-20   -7.75e-21    9.14e-06   2.82e-16   2.42e-03  2.20e-02        1    5.51e-03    9.65e-01
 178  1.912225e-21    9.62e-21    3.79e-06   2.68e-16   6.51e+00  6.59e-02        1    5.47e-03    9.70e-01
 179  1.053410e-20   -8.62e-21    8.69e-06   2.70e-16   5.23e-03  3.35e-02        1    5.52e-03    9.76e-01
 180  1.153420e-20   -1.00e-21    8.76e-06   3.01e-16   2.40e-03  1.69e-02        1    5.63e-03    9.81e-01
 181  1.121883e-21    1.04e-20    2.91e-06   2.57e-16   7.91e+00  5.06e-02        1    5.88e-03    9.87e-01
 182  1.705541e-20   -1.59e-20    0.00e+00   1.28e-16  -1.30e-02  2.53e-02        1    3.02e-03    9.90e-01
 183  1.468545e-21   -3.47e-22    3.37e-06   1.55e-17   3.05e-02  1.38e-02        1    5.91e-03    9.96e-01
 184  1.936565e-21   -4.68e-22    3.39e-06   1.25e-17   2.91e-02  7.54e-03        1    5.78e-03    1.00e+00
 185  1.294314e-21    6.42e-22    2.89e-06   7.15e-18   6.11e+00  2.26e-02        1    5.65e-03    1.01e+00
 186  1.293630e-21    6.84e-25    2.88e-06   2.08e-17   3.09e-02  1.24e-02        1    6.11e-03    1.01e+00
 187  1.294314e-21   -6.84e-25    2.89e-06   1.39e-17   3.09e-02  6.79e-03        1    5.64e-03    1.02e+00

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.087759e+02
Final                            5.006909e-23
Change                           1.087759e+02

Minimizer iterations                      188
Successful steps                          170
Unsuccessful steps                         18
Line search steps                         101

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0140
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.9977
    Line search gradient evaluation    0.5287
  Linear solver                        0.0048
  Line search polynomial minimization  0.0005
Minimizer                              1.0222

Postprocessor                          0.0000
Total                                  1.0223

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
(* 
W1104 07:49:44.424211  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.
W1104 07:49:45.057052  4339 levenberg_marquardt_strategy.cc:114] Linear solver failure. Failed to compute a step: CHOLMOD warning: Matrix not positive definite.

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          1.652722e+04
Final                            1.643104e+02
Change                           1.636291e+04

Minimizer iterations                      331
Successful steps                          222
Unsuccessful steps                        109
Line search steps                         636

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0261
    Line search cost evaluation        0.0000
  Jacobian evaluation                  2.9464
    Line search gradient evaluation    2.2924
  Linear solver                        0.0072
  Line search polynomial minimization  0.0062
Minimizer                              2.9932

Postprocessor                          0.0000
Total                                  2.9932

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA98 = {
{-0.0693066,0.5053229,0.2335377}
};
fitErrEl98 = {
{-0.1115108,0.4897467,0.2472768}
};
fitErrLa98 = {
{-0.1129503,0.5250330,0.2589968}
};
fitErrWr98 = {
{-0.3336368,0.4546974,0.3582951}
};
fitErrEe98 = {
{-0.3890648,0.4786792,0.4489382}
};
rMatsBase98 = {
{-0.3543023,0.6797422,-0.6421997},
{0.7775320,0.5956749,0.2015324},
{0.5195323,-0.4279275,-0.7395703}
};
outThetasWam98 = {
{-0.1075576,-0.2315967,-0.0343707,1.3464874,0.0000000,0.0000000,0.0000000}
};
fitErrUA.norm()0.5609764
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  9.565795e+01    0.00e+00    2.83e+00   0.00e+00   0.00e+00  1.00e+04        0    3.06e-03    3.10e-03
   1  2.348747e-02    9.56e+01    2.83e+00   3.25e-03   2.00e+00  3.00e+04        1    6.20e-03    9.32e-03
   2  3.204302e-09    2.35e-02    4.79e-01   1.58e-05   2.00e+00  9.00e+04        1    6.44e-03    1.58e-02
   3  8.161015e-16    3.20e-09    9.50e-05   2.53e-08   2.00e+00  2.70e+05        1    6.13e-03    2.19e-02
   4  5.785935e-21    8.16e-16    5.55e-06   1.29e-11   2.00e+00  8.10e+05        1    6.22e-03    2.82e-02
   5  2.282163e-20   -1.70e-20    1.33e-05   6.75e-15   2.00e+00  2.43e+06        1    6.33e-03    3.46e-02
   6  1.499097e-20    7.83e-21    1.07e-05   1.24e-14   2.00e+00  7.29e+06        1    6.12e-03    4.07e-02
   7  2.376296e-21    1.26e-20    4.22e-06   8.67e-15   2.00e+00  2.19e+07        1    6.44e-03    4.72e-02
   8  2.843336e-21   -4.67e-22    4.69e-06   6.30e-15   2.00e+00  6.56e+07        1    6.27e-03    5.35e-02
   9  3.564260e-21   -7.21e-22    5.24e-06   2.18e-15   2.00e+00  1.97e+08        1    6.21e-03    5.98e-02
  10  1.134708e-21    2.43e-21    2.52e-06   2.51e-15   2.00e+00  5.90e+08        1    6.23e-03    6.60e-02
  11  4.178118e-21   -3.04e-21    4.82e-06   2.95e-15   2.00e+00  1.77e+09        1    6.28e-03    7.23e-02
  12  1.903909e-21    2.27e-21    3.86e-06   2.34e-15   2.00e+00  5.31e+09        1    6.17e-03    7.85e-02
  13  3.410625e-21   -1.51e-21    5.53e-06   3.35e-15   2.00e+00  1.59e+10        1    6.29e-03    8.48e-02
  14  1.469307e-20   -1.13e-20    1.01e-05   3.52e-15   2.00e+00  4.78e+10        1    6.16e-03    9.10e-02
  15  3.676428e-21    1.10e-20    5.21e-06   7.24e-15   2.00e+00  1.43e+11        1    6.16e-03    9.72e-02
  16  7.914602e-22    2.88e-21    2.23e-06   4.02e-15   7.89e-01  1.78e+11        1    6.41e-03    1.04e-01
  17  1.846301e-21   -1.05e-21    3.25e-06   2.07e-15   6.73e-01  1.86e+11        1    6.16e-03    1.10e-01
  18  3.532942e-21   -1.69e-21    5.20e-06   5.05e-15   5.34e-01  1.86e+11        1    6.43e-03    1.16e-01
  19  1.878959e-21    1.65e-21    3.59e-06   3.37e-15   5.25e-01  1.86e+11        1    6.42e-03    1.23e-01
  20  1.487536e-21    3.91e-22    2.86e-06   2.12e-15   5.03e-01  1.86e+11        1    6.10e-03    1.29e-01
  21  4.446474e-21   -2.96e-21    5.60e-06   2.72e-15   3.69e-01  1.82e+11        1    6.40e-03    1.35e-01
  22  1.710018e-21    2.74e-21    3.35e-06   9.09e-15   6.22e-01  1.85e+11        1    6.11e-03    1.42e-01
  23  9.256133e-22    7.84e-22    2.23e-06   4.57e-15   5.80e-01  1.86e+11        1    6.20e-03    1.48e-01
  24  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  9.29e+10        1    3.31e-03    1.51e-01
  25  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  2.32e+10        1    3.22e-03    1.54e-01
  26  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  2.90e+09        1    3.11e-03    1.58e-01
  27  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  1.82e+08        1    3.15e-03    1.61e-01
  28  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  5.67e+06        1    3.14e-03    1.64e-01
  29  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  8.86e+04        1    3.37e-03    1.67e-01
  30  1.188981e-20   -1.10e-20    0.00e+00   3.02e-15  -1.09e+00  6.92e+02        1    3.13e-03    1.70e-01
  31  6.207078e-21   -5.28e-21    0.00e+00   2.82e-15  -2.58e-01  2.71e+00        1    3.17e-03    1.74e-01
  32  3.853398e-21   -2.93e-21    4.75e-06   8.02e-16   8.81e-02  1.73e+00        1    6.22e-03    1.80e-01
  33  1.983444e-21    1.87e-21    3.41e-06   1.53e-15   5.07e-01  1.73e+00        1    6.22e-03    1.86e-01
  34  4.076348e-21   -2.09e-21    5.49e-06   1.15e-15   3.02e-02  9.48e-01        1    6.16e-03    1.92e-01
  35  4.136099e-21   -5.98e-23    5.81e-06   1.22e-15   1.94e-02  5.02e-01        1    6.15e-03    1.98e-01
  36  3.298670e-21    8.37e-22    4.67e-06   1.21e-15   2.34e-01  4.36e-01        1    6.30e-03    2.05e-01
  37  1.294086e-21    2.00e-21    2.75e-06   9.28e-16   7.70e-01  5.18e-01        1    6.17e-03    2.11e-01
  38  4.226509e-21   -2.93e-21    5.84e-06   6.09e-16   9.53e-03  2.67e-01        1    6.26e-03    2.17e-01
  39  2.940690e-21    1.29e-21    4.83e-06   9.38e-16   4.14e-01  2.65e-01        1    6.26e-03    2.23e-01
  40  4.065939e-21   -1.13e-21    5.07e-06   7.12e-16   1.34e-02  1.38e-01        1    6.14e-03    2.30e-01
  41  8.593633e-22    3.21e-21    2.49e-06   5.03e-16   1.43e+00  4.14e-01        1    6.26e-03    2.36e-01
  42  1.937731e-21   -1.08e-21    3.81e-06   5.31e-16   8.03e-02  2.60e-01        1    6.11e-03    2.42e-01
  43  6.253586e-21   -4.32e-21    0.00e+00   6.04e-16  -5.54e-02  1.30e-01        1    3.13e-03    2.45e-01
  44  1.448376e-21    4.89e-22    3.46e-06   3.61e-16   4.87e-01  1.30e-01        1    6.24e-03    2.51e-01
  45  1.306363e-21    1.42e-22    2.98e-06   3.78e-16   1.98e-01  1.07e-01        1    6.16e-03    2.58e-01
  46  4.615263e-21   -3.31e-21    0.00e+00   3.47e-16  -5.03e-03  5.33e-02        1    3.14e-03    2.61e-01
  47  6.186386e-21   -4.88e-21    0.00e+00   1.32e-16  -5.22e-02  1.33e-02        1    3.12e-03    2.64e-01
  48  1.599669e-21   -2.93e-22    3.42e-06   1.40e-17   8.61e-02  8.50e-03        1    6.27e-03    2.70e-01
  49  1.599669e-21   -1.88e-37    3.42e-06   1.10e-17   8.59e-02  5.42e-03        1    6.15e-03    2.76e-01
  50  1.599669e-21   -1.88e-37    3.42e-06   7.15e-18   8.57e-02  3.46e-03        1    6.21e-03    2.83e-01
  51  1.599669e-21   -1.88e-37    3.42e-06   3.88e-18   8.56e-02  2.20e-03        1    6.17e-03    2.89e-01
  52  1.599669e-21   -1.88e-37    3.42e-06   3.47e-18   8.56e-02  1.40e-03        1    6.14e-03    2.95e-01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            2                        2
Parameters                                 11                       11
Effective parameters                       10                       10
Residual blocks                             1                        1
Residual                                   12                       12

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                     1, 1

Cost:
Initial                          9.565795e+01
Final                            7.914602e-22
Change                           9.565795e+01

Minimizer iterations                       53
Successful steps                           42
Unsuccessful steps                         11
Line search steps                          32

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0045
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2894
    Line search gradient evaluation    0.1618
  Linear solver                        0.0016
  Line search polynomial minimization  0.0002
Minimizer                              0.2980

Postprocessor                          0.0000
Total                                  0.2981

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  2.355206e-20    0.00e+00    2.23e-06   0.00e+00   0.00e+00  1.00e+04        0    2.98e-01    2.98e-01
   1  4.583540e-19   -4.35e-19    0.00e+00   3.47e-14  -2.37e+01  5.00e+03        1    3.04e-01    6.03e-01
   2  4.801301e-19   -4.57e-19    0.00e+00   3.41e-14  -2.49e+01  1.25e+03        1    3.04e-01    9.07e-01
   3  3.966025e-19   -3.73e-19    0.00e+00   3.13e-14  -2.03e+01  1.56e+02        1    3.04e-01    1.21e+00
   4  4.343914e-19   -4.11e-19    0.00e+00   2.04e-14  -2.29e+01  9.77e+00        1    3.02e-01    1.51e+00
   5  4.263330e-19   -4.03e-19    0.00e+00   9.01e-15  -2.48e+01  3.05e-01        1    2.76e-01    1.79e+00
   6  3.677535e-19   -3.44e-19    0.00e+00   2.26e-15  -3.28e+01  4.77e-03        1    2.76e-01    2.06e+00
   7  2.330614e-20    2.46e-22    2.23e-06   2.09e-17   5.60e-01  4.78e-03        1    5.51e-01    2.62e+00
   8  2.304187e-20    2.64e-22    2.23e-06   1.94e-17   6.09e-01  4.83e-03        1    5.49e-01    3.16e+00
   9  2.332094e-20   -2.79e-22    2.23e-06   1.86e-17   1.77e-01  3.80e-03        1    5.40e-01    3.71e+00
  10  2.332094e-20    3.01e-36    2.23e-06   1.40e-17   1.40e-01  2.77e-03        1    5.38e-01    4.24e+00
  11  2.336448e-20   -4.35e-23    2.23e-06   8.52e-18   9.83e-02  1.82e-03        1    5.38e-01    4.78e+00
  12  2.336448e-20    3.01e-36    2.23e-06   4.56e-18   9.03e-02  1.18e-03        1    5.47e-01    5.33e+00
  13  2.336448e-20    3.01e-36    2.23e-06   3.03e-18   8.57e-02  7.49e-04        1    5.82e-01    5.91e+00
  14  2.336448e-20    3.01e-36    0.00e+00   9.20e-19   0.00e+00  3.75e-04        1    3.05e-01    6.22e+00
  15  2.336448e-20    3.01e-36    0.00e+00   6.23e-19   0.00e+00  9.37e-05        1    3.04e-01    6.52e+00
  16  2.336448e-20    3.01e-36    0.00e+00   2.71e-20   0.00e+00  1.17e-05        1    3.04e-01    6.82e+00

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                          198                      198
Parameters                               1089                     1089
Effective parameters                      990                      990
Residual blocks                            99                       99
Residual                                 1188                     1188

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                   99, 99

Cost:
Initial                          2.355206e-20
Final                            2.304187e-20
Change                           5.101966e-22

Minimizer iterations                       17
Successful steps                            8
Unsuccessful steps                          9
Line search steps                          15

Time (in seconds):
Preprocessor                           0.0004

  Residual evaluation                  0.1102
    Line search cost evaluation        0.0000
  Jacobian evaluation                  7.0088
    Line search gradient evaluation    4.8023
  Linear solver                        0.0074
  Line search polynomial minimization  0.0001
Minimizer                              7.1290

Postprocessor                          0.0000
Total                                  7.1295

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA Mean = 0.0000000
fitErrEl Mean = 0.0000000
fitErrLa Mean = 0.0000000
fitErrWr Mean = 0.0000000
fitErrEe Mean = 0.0790737
fitErrUA = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr = {
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe = {
{-0.0276754,-0.0136444,0.0735903},
{-0.0280952,-0.0134395,0.0732144},
{-0.0293578,-0.0130984,0.0727638},
{-0.0297578,-0.0127990,0.0724227},
{-0.0304186,-0.0123497,0.0721359},
{-0.0311093,-0.0119799,0.0718630},
{-0.0316865,-0.0115399,0.0715123},
{-0.0329024,-0.0109383,0.0710910},
{-0.0340486,-0.0107118,0.0704765},
{-0.0351091,-0.0101577,0.0699563},
{-0.0362971,-0.0097630,0.0693490},
{-0.0375240,-0.0092909,0.0688195},
{-0.0387272,-0.0089059,0.0682818},
{-0.0399683,-0.0085061,0.0676580},
{-0.0410674,-0.0081293,0.0669959},
{-0.0428187,-0.0074653,0.0663288},
{-0.0441655,-0.0069394,0.0655411},
{-0.0455112,-0.0063573,0.0646732},
{-0.0465209,-0.0057547,0.0640230},
{-0.0474746,-0.0050352,0.0634712},
{-0.0478666,-0.0045362,0.0631222},
{-0.0482198,-0.0039766,0.0629498},
{-0.0482799,-0.0034340,0.0628862},
{-0.0481398,-0.0029071,0.0628432},
{-0.0481125,-0.0023441,0.0628510},
{-0.0480505,-0.0017914,0.0629122},
{-0.0480616,-0.0014816,0.0629119},
{-0.0491522,-0.0010995,0.0620515},
{-0.0502752,-0.0005972,0.0611562},
{-0.0511993,-0.0000449,0.0603762},
{-0.0519571,0.0004538,0.0597414},
{-0.0526485,0.0009509,0.0589400},
{-0.0533811,0.0014536,0.0583158},
{-0.0536491,0.0018318,0.0579311},
{-0.0544783,0.0025116,0.0573073},
{-0.0547058,0.0028756,0.0571422},
{-0.0548957,0.0033650,0.0567897},
{-0.0552355,0.0039220,0.0565375},
{-0.0552890,0.0043143,0.0563598},
{-0.0552913,0.0043719,0.0563501},
{-0.0550847,0.0047645,0.0564008},
{-0.0549607,0.0061131,0.0562059},
{-0.0550296,0.0067426,0.0561809},
{-0.0547889,0.0071250,0.0561929},
{-0.0544912,0.0076783,0.0563475},
{-0.0546850,0.0085457,0.0560306},
{-0.0546221,0.0095484,0.0559278},
{-0.0548186,0.0106542,0.0556041},
{-0.0545238,0.0115745,0.0555017},
{-0.0543249,0.0125935,0.0554748},
{-0.0544299,0.0139929,0.0551813},
{-0.0542641,0.0150847,0.0550261},
{-0.0537810,0.0160435,0.0549414},
{-0.0532963,0.0171583,0.0549318},
{-0.0528345,0.0184656,0.0551112},
{-0.0527549,0.0202434,0.0548420},
{-0.0521247,0.0213367,0.0548629},
{-0.0515830,0.0224938,0.0547302},
{-0.0511163,0.0240147,0.0545352},
{-0.0502651,0.0249860,0.0550583},
{-0.0496142,0.0262383,0.0551639},
{-0.0484847,0.0268254,0.0557230},
{-0.0474343,0.0277481,0.0562884},
{-0.0465794,0.0285675,0.0566902},
{-0.0454923,0.0294734,0.0571267},
{-0.0447003,0.0305715,0.0573429},
{-0.0435553,0.0313339,0.0576264},
{-0.0423648,0.0320769,0.0579889},
{-0.0413020,0.0329190,0.0582232},
{-0.0400907,0.0327123,0.0590539},
{-0.0381015,0.0337551,0.0597363},
{-0.0366273,0.0340659,0.0604066},
{-0.0348949,0.0342584,0.0613792},
{-0.0334943,0.0346281,0.0619627},
{-0.0319230,0.0350027,0.0625759},
{-0.0306602,0.0355215,0.0628621},
{-0.0293900,0.0361017,0.0631396},
{-0.0282580,0.0367139,0.0632585},
{-0.0270373,0.0373582,0.0633510},
{-0.0258920,0.0378570,0.0636282},
{-0.0247497,0.0382182,0.0638885},
{-0.0234976,0.0384823,0.0642153},
{-0.0224405,0.0387025,0.0644757},
{-0.0215275,0.0390995,0.0647048},
{-0.0203119,0.0394147,0.0651179},
{-0.0195293,0.0397577,0.0653913},
{-0.0186532,0.0399722,0.0656762},
{-0.0179065,0.0400975,0.0660083},
{-0.0169811,0.0402795,0.0664381},
{-0.0161858,0.0403125,0.0670504},
{-0.0155212,0.0402359,0.0674358},
{-0.0146820,0.0398999,0.0680942},
{-0.0140458,0.0395385,0.0685515},
{-0.0133095,0.0392667,0.0690606},
{-0.0128688,0.0389944,0.0694080},
{-0.0125329,0.0388600,0.0697620},
{-0.0120901,0.0385225,0.0701135},
{-0.0115139,0.0382426,0.0704821},
{-0.0112907,0.0380490,0.0707835}
};
outShoToUaVsWam = {
{-0.3938006,-0.3705459,-0.1005826},
{-0.3948034,-0.3695158,-0.1004407},
{-0.3965285,-0.3677113,-0.1002672},
{-0.3986010,-0.3656589,-0.0995528},
{-0.4008618,-0.3634268,-0.0986446},
{-0.4031109,-0.3609329,-0.0986362},
{-0.4057808,-0.3580799,-0.0980850},
{-0.4087193,-0.3549036,-0.0974265},
{-0.4132201,-0.3492220,-0.0989604},
{-0.4174501,-0.3444710,-0.0978528},
{-0.4218082,-0.3392198,-0.0975082},
{-0.4263963,-0.3334321,-0.0975150},
{-0.4310397,-0.3275073,-0.0971788},
{-0.4358662,-0.3212874,-0.0964109},
{-0.4416850,-0.3136535,-0.0950574},
{-0.4474944,-0.3054195,-0.0946977},
{-0.4532002,-0.2974845,-0.0928035},
{-0.4584396,-0.2898569,-0.0911925},
{-0.4635210,-0.2827381,-0.0877920},
{-0.4686856,-0.2751933,-0.0842762},
{-0.4733612,-0.2683002,-0.0802754},
{-0.4783310,-0.2605870,-0.0761178},
{-0.4831411,-0.2531332,-0.0706980},
{-0.4881207,-0.2450988,-0.0645352},
{-0.4927746,-0.2374525,-0.0573541},
{-0.4972569,-0.2297068,-0.0497027},
{-0.4997187,-0.2257840,-0.0424598},
{-0.5012567,-0.2224015,-0.0421815},
{-0.5029948,-0.2184163,-0.0423147},
{-0.5052108,-0.2134711,-0.0411352},
{-0.5075882,-0.2076244,-0.0417898},
{-0.5103565,-0.2007825,-0.0415042},
{-0.5124847,-0.1952932,-0.0414727},
{-0.5148997,-0.1891908,-0.0398136},
{-0.5169122,-0.1836955,-0.0394684},
{-0.5192234,-0.1773355,-0.0381993},
{-0.5216915,-0.1704997,-0.0356060},
{-0.5237280,-0.1645819,-0.0334928},
{-0.5258802,-0.1580303,-0.0312483},
{-0.5274619,-0.1530063,-0.0295465},
{-0.5298342,-0.1452045,-0.0262948},
{-0.5329823,-0.1338259,-0.0228132},
{-0.5349841,-0.1260421,-0.0201338},
{-0.5369075,-0.1180206,-0.0173615},
{-0.5390034,-0.1086829,-0.0127832},
{-0.5406667,-0.1003838,-0.0101288},
{-0.5422026,-0.0921184,-0.0055269},
{-0.5435738,-0.0837882,-0.0026563},
{-0.5447842,-0.0755357,0.0021186},
{-0.5458055,-0.0675378,0.0059163},
{-0.5466322,-0.0598818,0.0103620},
{-0.5472868,-0.0526381,0.0143655},
{-0.5477156,-0.0460775,0.0196072},
{-0.5481531,-0.0380902,0.0240271},
{-0.5483779,-0.0308073,0.0288552},
{-0.5484755,-0.0230339,0.0338248},
{-0.5484200,-0.0157156,0.0385819},
{-0.5482365,-0.0083667,0.0432060},
{-0.5478261,-0.0035395,0.0487237},
{-0.5473764,0.0057523,0.0533481},
{-0.5465684,0.0143150,0.0596492},
{-0.5458023,0.0234429,0.0636422},
{-0.5447164,0.0315075,0.0692196},
{-0.5436785,0.0378249,0.0740471},
{-0.5425595,0.0459562,0.0775708},
{-0.5413816,0.0524758,0.0815611},
{-0.5399672,0.0594291,0.0860442},
{-0.5385914,0.0660170,0.0897831},
{-0.5371885,0.0733353,0.0924688},
{-0.5361828,0.0756162,0.0963857},
{-0.5333047,0.0906650,0.0993274},
{-0.5318825,0.0964464,0.1014848},
{-0.5303394,0.1007534,0.1053038},
{-0.5289036,0.1055950,0.1077530},
{-0.5272594,0.1104041,0.1109435},
{-0.5256876,0.1153232,0.1133717},
{-0.5239787,0.1199174,0.1164738},
{-0.5223545,0.1252361,0.1181598},
{-0.5205191,0.1299528,0.1211288},
{-0.5191435,0.1346218,0.1219302},
{-0.5176840,0.1391566,0.1230396},
{-0.5161961,0.1436733,0.1240949},
{-0.5148727,0.1471792,0.1254768},
{-0.5135712,0.1513312,0.1258710},
{-0.5118884,0.1560741,0.1269297},
{-0.5105895,0.1603382,0.1268463},
{-0.5093995,0.1636073,0.1274549},
{-0.5082990,0.1668771,0.1276093},
{-0.5072239,0.1703884,0.1272465},
{-0.5067115,0.1725196,0.1264138},
{-0.5058123,0.1759202,0.1253236},
{-0.5053918,0.1775194,0.1247639},
{-0.5047947,0.1797456,0.1239914},
{-0.5042510,0.1815420,0.1235858},
{-0.5038935,0.1830550,0.1228097},
{-0.5037330,0.1840350,0.1220008},
{-0.5036258,0.1850764,0.1208627},
{-0.5030495,0.1866735,0.1208067},
{-0.5031806,0.1870841,0.1196195}
};
outShoToElVsWam = {
{-0.3682806,-0.3889318,-0.1327647},
{-0.3692298,-0.3881410,-0.1324421},
{-0.3709565,-0.3866038,-0.1321129},
{-0.3730600,-0.3848772,-0.1312279},
{-0.3753416,-0.3830394,-0.1300941},
{-0.3775805,-0.3809189,-0.1298413},
{-0.3802513,-0.3785487,-0.1289762},
{-0.3831919,-0.3759235,-0.1279472},
{-0.3878099,-0.3707036,-0.1292567},
{-0.3921930,-0.3665612,-0.1278378},
{-0.3967395,-0.3618412,-0.1272543},
{-0.4015362,-0.3565950,-0.1270185},
{-0.4064430,-0.3511801,-0.1264977},
{-0.4115777,-0.3454937,-0.1255506},
{-0.4178311,-0.3384564,-0.1240541},
{-0.4240594,-0.3308200,-0.1235182},
{-0.4302448,-0.3235222,-0.1214407},
{-0.4359208,-0.3165422,-0.1195790},
{-0.4415301,-0.3100249,-0.1160203},
{-0.4472785,-0.3030361,-0.1124102},
{-0.4525412,-0.2966286,-0.1083650},
{-0.4581957,-0.2893147,-0.1043010},
{-0.4637323,-0.2822860,-0.0989543},
{-0.4695229,-0.2746669,-0.0929050},
{-0.4750186,-0.2674191,-0.0858449},
{-0.4803843,-0.2600335,-0.0783488},
{-0.4834471,-0.2564031,-0.0711427},
{-0.4851328,-0.2533545,-0.0705880},
{-0.4870721,-0.2496109,-0.0705700},
{-0.4896055,-0.2449950,-0.0692015},
{-0.4922849,-0.2394150,-0.0697212},
{-0.4954736,-0.2328596,-0.0693352},
{-0.4979206,-0.2276300,-0.0691714},
{-0.5007873,-0.2217842,-0.0674453},
{-0.5031556,-0.2164789,-0.0670547},
{-0.5059485,-0.2102415,-0.0658755},
{-0.5089890,-0.2035725,-0.0633519},
{-0.5115237,-0.1977493,-0.0613493},
{-0.5142335,-0.1912422,-0.0592899},
{-0.5162471,-0.1862185,-0.0577631},
{-0.5192907,-0.1785476,-0.0546156},
{-0.5232875,-0.1676563,-0.0508581},
{-0.5259229,-0.1600164,-0.0482165},
{-0.5284980,-0.1521434,-0.0454669},
{-0.5314239,-0.1429613,-0.0409354},
{-0.5337420,-0.1348454,-0.0382258},
{-0.5360246,-0.1268019,-0.0335249},
{-0.5380530,-0.1187220,-0.0304799},
{-0.5400088,-0.1107515,-0.0254866},
{-0.5417102,-0.1030301,-0.0214430},
{-0.5432224,-0.0956881,-0.0166803},
{-0.5445175,-0.0887277,-0.0123716},
{-0.5455981,-0.0824731,-0.0067724},
{-0.5467411,-0.0748018,-0.0019588},
{-0.5476484,-0.0677923,0.0032316},
{-0.5484658,-0.0603014,0.0086032},
{-0.5490865,-0.0532760,0.0138074},
{-0.5495739,-0.0462182,0.0189061},
{-0.5496593,-0.0419331,0.0253234},
{-0.5500350,-0.0327588,0.0302219},
{-0.5500695,-0.0243175,0.0368397},
{-0.5500940,-0.0152629,0.0410935},
{-0.5497818,-0.0073102,0.0470265},
{-0.5493653,-0.0010855,0.0521692},
{-0.5489415,0.0069639,0.0560331},
{-0.5483620,0.0133957,0.0603710},
{-0.5475965,0.0202815,0.0652052},
{-0.5468154,0.0268160,0.0692734},
{-0.5460240,0.0341216,0.0722395},
{-0.5453364,0.0364622,0.0761823},
{-0.5436504,0.0516889,0.0793567},
{-0.5427103,0.0574645,0.0817827},
{-0.5416107,0.0617872,0.0858206},
{-0.5406061,0.0666561,0.0884705},
{-0.5394158,0.0714880,0.0918972},
{-0.5382753,0.0764238,0.0945730},
{-0.5369972,0.0810310,0.0979436},
{-0.5358023,0.0863622,0.0999121},
{-0.5343917,0.0910621,0.1032384},
{-0.5333641,0.0957250,0.1043287},
{-0.5322582,0.1002768,0.1056917},
{-0.5311169,0.1047944,0.1070420},
{-0.5300800,0.1082997,0.1086802},
{-0.5290815,0.1124722,0.1093058},
{-0.5277731,0.1172779,0.1105733},
{-0.5267859,0.1216362,0.1105726},
{-0.5258503,0.1249524,0.1113253},
{-0.5250008,0.1283197,0.1115043},
{-0.5241746,0.1319194,0.1111900},
{-0.5237977,0.1341236,0.1103262},
{-0.5231219,0.1376431,0.1091917},
{-0.5228103,0.1393290,0.1085439},
{-0.5223670,0.1416927,0.1076148},
{-0.5219515,0.1435889,0.1071160},
{-0.5216918,0.1452157,0.1061844},
{-0.5215880,0.1462988,0.1052027},
{-0.5215288,0.1474367,0.1038998},
{-0.5210783,0.1491572,0.1037043},
{-0.5212079,0.1496536,0.1023285}
};
outShoToLaVsWam = {
{-0.4074878,-0.4106883,-0.1289637},
{-0.4085167,-0.4097701,-0.1287376},
{-0.4103476,-0.4080617,-0.1285219},
{-0.4125703,-0.4061284,-0.1277173},
{-0.4149677,-0.4040967,-0.1267230},
{-0.4173176,-0.4018049,-0.1267206},
{-0.4201118,-0.3992369,-0.1261243},
{-0.4231610,-0.3964480,-0.1254537},
{-0.4279762,-0.3908911,-0.1272237},
{-0.4325032,-0.3864910,-0.1261357},
{-0.4371881,-0.3815174,-0.1259272},
{-0.4421305,-0.3759927,-0.1261047},
{-0.4471565,-0.3703411,-0.1259869},
{-0.4524029,-0.3644221,-0.1254305},
{-0.4587922,-0.3570875,-0.1243198},
{-0.4651499,-0.3491499,-0.1242861},
{-0.4714307,-0.3416142,-0.1226217},
{-0.4771852,-0.3344207,-0.1211924},
{-0.4828689,-0.3277093,-0.1178558},
{-0.4887312,-0.3204379,-0.1143734},
{-0.4941018,-0.3137676,-0.1103563},
{-0.4999108,-0.3060820,-0.1062281},
{-0.5055926,-0.2987055,-0.1007203},
{-0.5115565,-0.2906638,-0.0944139},
{-0.5171875,-0.2830814,-0.0870585},
{-0.5226855,-0.2753580,-0.0792219},
{-0.5257541,-0.2717254,-0.0717341},
{-0.5274091,-0.2687447,-0.0715156},
{-0.5293796,-0.2648988,-0.0717347},
{-0.5319442,-0.2601797,-0.0705669},
{-0.5346958,-0.2543675,-0.0713752},
{-0.5379803,-0.2475113,-0.0712064},
{-0.5404749,-0.2421087,-0.0712907},
{-0.5434159,-0.2360280,-0.0696625},
{-0.5458553,-0.2304830,-0.0694256},
{-0.5487442,-0.2239368,-0.0683191},
{-0.5519046,-0.2168969,-0.0657419},
{-0.5545414,-0.2107479,-0.0636980},
{-0.5573808,-0.2038201,-0.0615501},
{-0.5594583,-0.1985719,-0.0600401},
{-0.5626297,-0.1904629,-0.0567967},
{-0.5668263,-0.1788419,-0.0529207},
{-0.5695649,-0.1707975,-0.0502518},
{-0.5722459,-0.1624945,-0.0474610},
{-0.5752911,-0.1528234,-0.0427803},
{-0.5777111,-0.1442507,-0.0400300},
{-0.5801031,-0.1357241,-0.0350999},
{-0.5822226,-0.1271937,-0.0319903},
{-0.5842737,-0.1187534,-0.0267481},
{-0.5860589,-0.1105815,-0.0225281},
{-0.5876439,-0.1028296,-0.0175348},
{-0.5890064,-0.0954613,-0.0130041},
{-0.5901516,-0.0887915,-0.0070260},
{-0.5913637,-0.0806178,-0.0019152},
{-0.5923311,-0.0731109,0.0036421},
{-0.5932035,-0.0650880,0.0093943},
{-0.5938662,-0.0575704,0.0149667},
{-0.5943869,-0.0500242,0.0204237},
{-0.5944734,-0.0455168,0.0272869},
{-0.5948780,-0.0357512,0.0324906},
{-0.5949208,-0.0267284,0.0395871},
{-0.5949563,-0.0170370,0.0441311},
{-0.5946312,-0.0085352,0.0504957},
{-0.5941927,-0.0018622,0.0560295},
{-0.5937464,0.0068482,0.0602181},
{-0.5931286,0.0138260,0.0649284},
{-0.5923055,0.0213453,0.0702023},
{-0.5914581,0.0285260,0.0746681},
{-0.5905953,0.0365458,0.0779421},
{-0.5898399,0.0391891,0.0822651},
{-0.5880035,0.0557816,0.0857641},
{-0.5869639,0.0621614,0.0884573},
{-0.5857387,0.0670180,0.0929168},
{-0.5846074,0.0724831,0.0958822},
{-0.5832614,0.0779416,0.0997019},
{-0.5819626,0.0835138,0.1027069},
{-0.5805084,0.0887293,0.1064592},
{-0.5791430,0.0947092,0.1086823},
{-0.5775355,0.1000167,0.1123724},
{-0.5763651,0.1052037,0.1136060},
{-0.5751079,0.1102659,0.1151323},
{-0.5738216,0.1152569,0.1166256},
{-0.5726559,0.1191341,0.1184223},
{-0.5715412,0.1236994,0.1191101},
{-0.5700822,0.1289590,0.1204975},
{-0.5689767,0.1337225,0.1205152},
{-0.5679294,0.1373610,0.1213440},
{-0.5669789,0.1410412,0.1215543},
{-0.5660449,0.1449931,0.1212379},
{-0.5656357,0.1473572,0.1202986},
{-0.5648946,0.1511505,0.1190709},
{-0.5645633,0.1529405,0.1183630},
{-0.5640616,0.1555201,0.1173802},
{-0.5636004,0.1575752,0.1168503},
{-0.5632930,0.1593748,0.1158722},
{-0.5631534,0.1605939,0.1148446},
{-0.5630537,0.1618913,0.1134780},
{-0.5625274,0.1638122,0.1133062},
{-0.5626346,0.1644156,0.1118635}
};
outShoToWrVsWam = {
{-0.3252429,-0.5973360,-0.3489601},
{-0.3257916,-0.5975198,-0.3476133},
{-0.3273932,-0.5968138,-0.3464467},
{-0.3296034,-0.5961909,-0.3444955},
{-0.3315020,-0.5956295,-0.3420104},
{-0.3328423,-0.5944807,-0.3405896},
{-0.3344372,-0.5935228,-0.3380508},
{-0.3356265,-0.5923799,-0.3350925},
{-0.3396872,-0.5875663,-0.3358476},
{-0.3431652,-0.5848307,-0.3327273},
{-0.3469054,-0.5809480,-0.3310527},
{-0.3509086,-0.5764912,-0.3297684},
{-0.3549826,-0.5715907,-0.3284779},
{-0.3593088,-0.5664862,-0.3266856},
{-0.3651883,-0.5600251,-0.3244563},
{-0.3705629,-0.5528533,-0.3231787},
{-0.3758391,-0.5463423,-0.3199759},
{-0.3802899,-0.5404293,-0.3165683},
{-0.3855792,-0.5350169,-0.3116554},
{-0.3920230,-0.5290695,-0.3070398},
{-0.3983788,-0.5235968,-0.3022126},
{-0.4063578,-0.5167647,-0.2982194},
{-0.4144229,-0.5104944,-0.2926409},
{-0.4236090,-0.5036339,-0.2865310},
{-0.4321793,-0.4970525,-0.2793864},
{-0.4408916,-0.4901543,-0.2720231},
{-0.4450476,-0.4871340,-0.2643103},
{-0.4444967,-0.4850105,-0.2621845},
{-0.4457747,-0.4818203,-0.2613535},
{-0.4477270,-0.4780725,-0.2587960},
{-0.4503058,-0.4730142,-0.2586502},
{-0.4541081,-0.4670188,-0.2577054},
{-0.4563028,-0.4623459,-0.2567918},
{-0.4599504,-0.4570406,-0.2545596},
{-0.4629460,-0.4520456,-0.2539143},
{-0.4672400,-0.4456234,-0.2532843},
{-0.4725965,-0.4390951,-0.2510477},
{-0.4772001,-0.4331029,-0.2496458},
{-0.4827729,-0.4261312,-0.2486635},
{-0.4861251,-0.4203990,-0.2482288},
{-0.4920374,-0.4126673,-0.2455875},
{-0.5001630,-0.4038617,-0.2397953},
{-0.5051293,-0.3963213,-0.2373001},
{-0.5102136,-0.3886177,-0.2345980},
{-0.5164327,-0.3795706,-0.2301874},
{-0.5213301,-0.3719546,-0.2270383},
{-0.5270856,-0.3647455,-0.2214821},
{-0.5316756,-0.3577095,-0.2172130},
{-0.5370382,-0.3510666,-0.2105942},
{-0.5417355,-0.3446959,-0.2048078},
{-0.5462054,-0.3390114,-0.1978151},
{-0.5504314,-0.3335711,-0.1913737},
{-0.5550744,-0.3290623,-0.1832063},
{-0.5599204,-0.3231619,-0.1756497},
{-0.5647942,-0.3176932,-0.1678841},
{-0.5697971,-0.3118005,-0.1596769},
{-0.5743013,-0.3064782,-0.1513526},
{-0.5785935,-0.3011295,-0.1429675},
{-0.5810036,-0.3003639,-0.1304202},
{-0.5856970,-0.2917354,-0.1236754},
{-0.5905567,-0.2838948,-0.1148357},
{-0.5951062,-0.2751213,-0.1088149},
{-0.5992256,-0.2677610,-0.1004377},
{-0.6025280,-0.2620322,-0.0931082},
{-0.6068084,-0.2543052,-0.0868476},
{-0.6104048,-0.2482599,-0.0800286},
{-0.6145222,-0.2415482,-0.0726033},
{-0.6185580,-0.2350365,-0.0660457},
{-0.6227205,-0.2274269,-0.0609332},
{-0.6249635,-0.2244499,-0.0565181},
{-0.6321076,-0.2073123,-0.0514817},
{-0.6353326,-0.2011334,-0.0469544},
{-0.6384743,-0.1962061,-0.0409937},
{-0.6417497,-0.1905694,-0.0365494},
{-0.6452096,-0.1848986,-0.0309789},
{-0.6485655,-0.1791156,-0.0260946},
{-0.6517465,-0.1736655,-0.0203244},
{-0.6548556,-0.1674609,-0.0159549},
{-0.6577567,-0.1620561,-0.0096210},
{-0.6599771,-0.1567915,-0.0062587},
{-0.6621184,-0.1514795,-0.0028444},
{-0.6639249,-0.1463863,0.0007628},
{-0.6653082,-0.1424198,0.0043825},
{-0.6666154,-0.1376882,0.0066939},
{-0.6681402,-0.1319590,0.0095631},
{-0.6695190,-0.1265223,0.0102251},
{-0.6705715,-0.1225037,0.0120968},
{-0.6716180,-0.1181251,0.0125429},
{-0.6728094,-0.1134888,0.0126631},
{-0.6731940,-0.1107008,0.0114992},
{-0.6739021,-0.1061741,0.0099773},
{-0.6740952,-0.1038937,0.0086409},
{-0.6748464,-0.1003536,0.0066761},
{-0.6753172,-0.0976323,0.0055468},
{-0.6760039,-0.0949787,0.0036201},
{-0.6766344,-0.0929496,0.0015407},
{-0.6773842,-0.0908368,-0.0007894},
{-0.6781960,-0.0879351,-0.0017769},
{-0.6788198,-0.0865758,-0.0043445}
};
outShoToEeVsWam = {
{-0.3087939,-0.6346655,-0.3929594},
{-0.3092465,-0.6350698,-0.3913884},
{-0.3108024,-0.6345643,-0.3900317},
{-0.3130100,-0.6342034,-0.3878511},
{-0.3148089,-0.6339361,-0.3850679},
{-0.3159473,-0.6330159,-0.3833634},
{-0.3173023,-0.6323800,-0.3804361},
{-0.3181196,-0.6315663,-0.3770202},
{-0.3220294,-0.6269013,-0.3775724},
{-0.3252976,-0.6244986,-0.3740457},
{-0.3288489,-0.6208341,-0.3720778},
{-0.3326642,-0.6165909,-0.3705012},
{-0.3365479,-0.6118406,-0.3689761},
{-0.3406900,-0.6068990,-0.3669366},
{-0.3464675,-0.6006126,-0.3644836},
{-0.3516455,-0.5935939,-0.3629573},
{-0.3567208,-0.5872879,-0.3594468},
{-0.3609108,-0.5816310,-0.3556435},
{-0.3661213,-0.5764785,-0.3504153},
{-0.3726814,-0.5707959,-0.3455731},
{-0.3792342,-0.5655626,-0.3405839},
{-0.3876472,-0.5589012,-0.3366176},
{-0.3961890,-0.5528522,-0.3310250},
{-0.4060196,-0.5462279,-0.3249545},
{-0.4151777,-0.5398467,-0.3178520},
{-0.4245328,-0.5331136,-0.3105833},
{-0.4289063,-0.5302157,-0.3028255},
{-0.4279142,-0.5282636,-0.3003183},
{-0.4290537,-0.5252046,-0.2992772},
{-0.4308836,-0.5216511,-0.2964418},
{-0.4334278,-0.5167435,-0.2961052},
{-0.4373337,-0.5109204,-0.2950052},
{-0.4394684,-0.5063933,-0.2938920},
{-0.4432573,-0.5012432,-0.2915390},
{-0.4463641,-0.4963581,-0.2908121},
{-0.4509391,-0.4899607,-0.2902773},
{-0.4567348,-0.4835347,-0.2881088},
{-0.4617319,-0.4775739,-0.2868354},
{-0.4678513,-0.4705934,-0.2860862},
{-0.4714585,-0.4647644,-0.2858665},
{-0.4779190,-0.4571081,-0.2833457},
{-0.4868304,-0.4488657,-0.2771702},
{-0.4922422,-0.4414261,-0.2747098},
{-0.4978072,-0.4338424,-0.2720254},
{-0.5046610,-0.4249200,-0.2676688},
{-0.5100539,-0.4174954,-0.2644400},
{-0.5164822,-0.4105498,-0.2587586},
{-0.5215662,-0.4038127,-0.2542576},
{-0.5275911,-0.3975292,-0.2473634},
{-0.5328709,-0.3915187,-0.2412638},
{-0.5379177,-0.3862478,-0.2338712},
{-0.5427164,-0.3811931,-0.2270476},
{-0.5480589,-0.3771165,-0.2184424},
{-0.5536317,-0.3716708,-0.2103966},
{-0.5592868,-0.3666096,-0.2021894},
{-0.5651158,-0.3611430,-0.1934912},
{-0.5703883,-0.3562598,-0.1846165},
{-0.5754348,-0.3513506,-0.1756457},
{-0.5783096,-0.3513333,-0.1619616},
{-0.5838608,-0.3429323,-0.1549086},
{-0.5896838,-0.3353281,-0.1457202},
{-0.5951362,-0.3267382,-0.1394041},
{-0.6001445,-0.3196062,-0.1306243},
{-0.6041950,-0.3140662,-0.1229358},
{-0.6094208,-0.3065359,-0.1162607},
{-0.6138600,-0.3006771,-0.1090200},
{-0.6189655,-0.2941268,-0.1011645},
{-0.6239779,-0.2877490,-0.0941885},
{-0.6291456,-0.2802215,-0.0887083},
{-0.6319882,-0.2771777,-0.0842748},
{-0.6409284,-0.2599311,-0.0789309},
{-0.6450063,-0.2537923,-0.0740368},
{-0.6490214,-0.2488509,-0.0677759},
{-0.6531782,-0.2431799,-0.0630358},
{-0.6575992,-0.2374667,-0.0571150},
{-0.6618861,-0.2316415,-0.0518549},
{-0.6659941,-0.2261444,-0.0456811},
{-0.6699981,-0.2198950,-0.0408823},
{-0.6738010,-0.2144707,-0.0340196},
{-0.6766994,-0.2091905,-0.0302316},
{-0.6795205,-0.2038286,-0.0264397},
{-0.6819456,-0.1987150,-0.0224097},
{-0.6838387,-0.1947306,-0.0184255},
{-0.6856302,-0.1899657,-0.0157893},
{-0.6877518,-0.1841426,-0.0126237},
{-0.6896274,-0.1785712,-0.0118329},
{-0.6910999,-0.1744766,-0.0097527},
{-0.6925458,-0.1699584,-0.0092593},
{-0.6941623,-0.1651851,-0.0090518},
{-0.6947056,-0.1623124,-0.0102607},
{-0.6957036,-0.1576391,-0.0118414},
{-0.6960016,-0.1552605,-0.0133036},
{-0.6970034,-0.1515283,-0.0154647},
{-0.6976606,-0.1486738,-0.0167139},
{-0.6985461,-0.1458494,-0.0188304},
{-0.6993306,-0.1436583,-0.0211201},
{-0.7002503,-0.1413824,-0.0236429},
{-0.7013298,-0.1382845,-0.0247935},
{-0.7020568,-0.1367741,-0.0275861}
};
outPUaWam = {
{0.1320717,0.6039440,0.1020489},
{0.1308719,0.6047931,0.1014619},
{0.1299123,0.6056138,0.1008590},
{0.1288537,0.6066690,0.0999475},
{0.1273283,0.6082064,0.0987253},
{0.1252554,0.6098357,0.0986635},
{0.1228965,0.6122171,0.0975661},
{0.1201210,0.6149927,0.0969744},
{0.1196940,0.6168544,0.1008202},
{0.1179567,0.6198755,0.1015973},
{0.1168530,0.6225343,0.1043727},
{0.1160089,0.6252794,0.1074947},
{0.1152410,0.6280980,0.1114346},
{0.1142973,0.6312513,0.1156630},
{0.1148863,0.6343114,0.1204428},
{0.1153644,0.6376736,0.1261245},
{0.1148961,0.6416544,0.1315384},
{0.1134316,0.6462341,0.1363808},
{0.1122062,0.6508111,0.1413175},
{0.1120039,0.6551334,0.1470637},
{0.1120272,0.6593035,0.1527219},
{0.1139962,0.6626614,0.1602136},
{0.1162142,0.6663752,0.1666435},
{0.1198024,0.6698496,0.1732836},
{0.1226875,0.6737180,0.1802200},
{0.1259196,0.6773561,0.1878277},
{0.1231765,0.6827956,0.1947633},
{0.1149924,0.6893745,0.2036258},
{0.1103651,0.6937596,0.2134329},
{0.1056982,0.6991277,0.2230645},
{0.1020336,0.7038170,0.2339629},
{0.0992004,0.7086000,0.2458415},
{0.0945088,0.7138098,0.2569223},
{0.0910650,0.7190774,0.2678456},
{0.0874305,0.7239707,0.2796279},
{0.0840692,0.7283134,0.2929332},
{0.0824106,0.7325024,0.3055146},
{0.0794556,0.7367578,0.3179733},
{0.0779964,0.7401228,0.3317063},
{0.0734314,0.7439653,0.3456341},
{0.0732215,0.7482044,0.3575161},
{0.0775330,0.7557959,0.3618054},
{0.0761503,0.7606762,0.3735780},
{0.0750562,0.7654792,0.3855319},
{0.0761304,0.7703885,0.3982175},
{0.0745783,0.7757239,0.4101890},
{0.0749803,0.7811751,0.4209618},
{0.0732620,0.7871427,0.4319611},
{0.0730227,0.7933387,0.4421393},
{0.0713318,0.7996898,0.4526387},
{0.0696530,0.8063085,0.4626011},
{0.0678624,0.8124067,0.4728043},
{0.0666658,0.8185166,0.4824340},
{0.0669016,0.8247300,0.4918059},
{0.0670937,0.8302324,0.5020363},
{0.0684764,0.8358328,0.5118297},
{0.0690471,0.8411588,0.5222198},
{0.0693395,0.8469125,0.5321728},
{0.0652488,0.8590787,0.5329862},
{0.0687849,0.8629355,0.5459500},
{0.0733792,0.8664868,0.5588333},
{0.0766147,0.8701406,0.5715882},
{0.0803398,0.8747471,0.5823567},
{0.0813618,0.8792581,0.5929088},
{0.0845506,0.8835477,0.6030020},
{0.0856530,0.8879653,0.6130136},
{0.0887560,0.8922360,0.6225202},
{0.0909485,0.8966175,0.6315055},
{0.0934699,0.9002143,0.6411810},
{0.0896226,0.9007450,0.6557151},
{0.1068386,0.9024943,0.6644779},
{0.1076655,0.9072473,0.6714455},
{0.1090333,0.9108284,0.6789680},
{0.1098810,0.9136006,0.6873851},
{0.1121407,0.9165936,0.6949470},
{0.1135480,0.9199398,0.7020095},
{0.1161244,0.9223752,0.7094728},
{0.1176034,0.9257793,0.7159500},
{0.1210738,0.9292920,0.7211709},
{0.1213763,0.9333376,0.7261953},
{0.1228814,0.9361512,0.7317614},
{0.1249702,0.9395296,0.7360223},
{0.1259756,0.9424065,0.7407657},
{0.1272795,0.9454119,0.7449654},
{0.1312532,0.9475731,0.7492738},
{0.1334164,0.9487766,0.7544781},
{0.1355273,0.9501576,0.7588422},
{0.1375482,0.9506610,0.7638884},
{0.1408837,0.9514808,0.7671656},
{0.1415410,0.9517663,0.7710473},
{0.1439643,0.9514938,0.7751279},
{0.1450710,0.9511670,0.7786384},
{0.1467852,0.9498617,0.7831256},
{0.1487709,0.9494831,0.7859177},
{0.1494138,0.9490746,0.7890866},
{0.1500839,0.9480456,0.7920842},
{0.1503450,0.9473541,0.7945224},
{0.1534635,0.9465993,0.7963371},
{0.1530335,0.9459905,0.7981471}
};
outPElWam = {
{0.1575917,0.5855581,0.0698668},
{0.1564456,0.5861679,0.0694606},
{0.1554843,0.5867214,0.0690133},
{0.1543947,0.5874507,0.0682724},
{0.1528484,0.5885938,0.0672758},
{0.1507858,0.5898497,0.0674584},
{0.1484261,0.5917483,0.0666749},
{0.1456484,0.5939728,0.0664537},
{0.1451041,0.5953728,0.0705239},
{0.1432138,0.5977853,0.0716123},
{0.1419216,0.5999128,0.0746265},
{0.1408691,0.6021165,0.0779912},
{0.1398377,0.6044252,0.0821156},
{0.1385859,0.6070450,0.0865233},
{0.1387401,0.6095085,0.0914460},
{0.1387994,0.6122731,0.0973040},
{0.1378516,0.6156168,0.1029012},
{0.1359505,0.6195488,0.1079942},
{0.1341971,0.6235244,0.1130892},
{0.1334109,0.6272906,0.1189298},
{0.1328473,0.6309750,0.1246323},
{0.1341314,0.6339338,0.1320304},
{0.1356231,0.6372224,0.1383873},
{0.1384002,0.6402815,0.1449137},
{0.1404435,0.6437514,0.1517292},
{0.1427922,0.6470294,0.1591815},
{0.1394481,0.6521764,0.1660804},
{0.1311163,0.6584215,0.1752193},
{0.1262878,0.6625650,0.1851775},
{0.1213035,0.6676037,0.1949982},
{0.1173369,0.6720263,0.2060315},
{0.1140834,0.6765229,0.2180106},
{0.1090729,0.6814730,0.2292236},
{0.1051774,0.6864840,0.2402139},
{0.1011870,0.6911873,0.2520416},
{0.0973441,0.6954074,0.2652569},
{0.0951132,0.6994296,0.2777687},
{0.0916599,0.7035904,0.2901169},
{0.0896430,0.7069110,0.3036647},
{0.0846462,0.7107531,0.3174175},
{0.0837649,0.7148613,0.3291952},
{0.0872279,0.7219656,0.3337605},
{0.0852115,0.7267018,0.3454953},
{0.0834657,0.7313564,0.3574264},
{0.0837099,0.7361101,0.3700653},
{0.0815031,0.7412622,0.3820920},
{0.0811583,0.7464916,0.3929638},
{0.0787828,0.7522089,0.4041375},
{0.0777981,0.7581229,0.4145341},
{0.0754271,0.7641975,0.4252795},
{0.0730629,0.7705022,0.4355589},
{0.0706317,0.7763171,0.4460673},
{0.0687833,0.7821211,0.4560545},
{0.0683136,0.7880185,0.4658199},
{0.0678232,0.7932473,0.4764126},
{0.0684860,0.7985653,0.4866080},
{0.0683805,0.8035985,0.4974453},
{0.0680021,0.8090611,0.5078730},
{0.0634156,0.8206851,0.5095860},
{0.0661263,0.8244243,0.5228238},
{0.0698781,0.8278543,0.5360237},
{0.0723230,0.8314348,0.5490395},
{0.0752744,0.8359294,0.5601637},
{0.0756750,0.8403478,0.5710309},
{0.0781685,0.8445554,0.5814644},
{0.0786727,0.8488852,0.5918235},
{0.0811267,0.8530884,0.6016813},
{0.0827245,0.8574165,0.6109957},
{0.0846344,0.8610007,0.6209518},
{0.0804690,0.8615910,0.6355117},
{0.0964929,0.8635182,0.6445072},
{0.0968376,0.8682654,0.6517434},
{0.0977620,0.8718622,0.6594848},
{0.0981785,0.8746617,0.6681025},
{0.0999843,0.8776775,0.6759008},
{0.1009602,0.8810405,0.6832109},
{0.1031058,0.8834888,0.6909426},
{0.1041555,0.8869055,0.6977023},
{0.1072011,0.8904014,0.7032805},
{0.1071557,0.8944408,0.7085938},
{0.1083071,0.8972713,0.7144135},
{0.1100495,0.9006506,0.7189694},
{0.1107683,0.9035271,0.7239691},
{0.1117692,0.9065529,0.7284002},
{0.1153685,0.9087770,0.7329174},
{0.1172201,0.9100746,0.7382044},
{0.1190765,0.9115027,0.7427126},
{0.1208464,0.9121035,0.7477834},
{0.1239330,0.9130118,0.7511091},
{0.1244548,0.9133704,0.7549597},
{0.1266547,0.9132167,0.7589960},
{0.1276524,0.9129766,0.7624184},
{0.1292129,0.9118088,0.7667490},
{0.1310704,0.9115300,0.7694479},
{0.1316155,0.9112352,0.7724613},
{0.1322289,0.9103094,0.7752861},
{0.1324420,0.9097144,0.7775596},
{0.1354347,0.9090831,0.7792347},
{0.1350062,0.9085601,0.7808562}
};
outPLaWam = {
{0.1183845,0.5638016,0.0736678},
{0.1171587,0.5645388,0.0731651},
{0.1160932,0.5652634,0.0726043},
{0.1148845,0.5661995,0.0717830},
{0.1132223,0.5675365,0.0706469},
{0.1110487,0.5689637,0.0705791},
{0.1085656,0.5710601,0.0695268},
{0.1056793,0.5734483,0.0689472},
{0.1049378,0.5751853,0.0725569},
{0.1029037,0.5778555,0.0733144},
{0.1014730,0.5802366,0.0759536},
{0.1002748,0.5827188,0.0789051},
{0.0991242,0.5852642,0.0826264},
{0.0977607,0.5881166,0.0866434},
{0.0977790,0.5908774,0.0911804},
{0.0977089,0.5939432,0.0965361},
{0.0966657,0.5975247,0.1017202},
{0.0946860,0.6016703,0.1063809},
{0.0928583,0.6058400,0.1112537},
{0.0919583,0.6098888,0.1169665},
{0.0912866,0.6138360,0.1226410},
{0.0924164,0.6171665,0.1301033},
{0.0937628,0.6208030,0.1366213},
{0.0963666,0.6242846,0.1434049},
{0.0982746,0.6280890,0.1505156},
{0.1004910,0.6317049,0.1583084},
{0.0971411,0.6368542,0.1654889},
{0.0888400,0.6430313,0.1742917},
{0.0839803,0.6472771,0.1840129},
{0.0789648,0.6524191,0.1936328},
{0.0749259,0.6570739,0.2043774},
{0.0715766,0.6618712,0.2161394},
{0.0665186,0.6669943,0.2271042},
{0.0625488,0.6722401,0.2379968},
{0.0584874,0.6771831,0.2496707},
{0.0545484,0.6817121,0.2628134},
{0.0521976,0.6861051,0.2753787},
{0.0486422,0.6905918,0.2877681},
{0.0464957,0.6943330,0.3014046},
{0.0414350,0.6983998,0.3151404},
{0.0404259,0.7029460,0.3270141},
{0.0436891,0.7107799,0.3316979},
{0.0415695,0.7159207,0.3434600},
{0.0397178,0.7210054,0.3554323},
{0.0398427,0.7262480,0.3682204},
{0.0375340,0.7318569,0.3802878},
{0.0370798,0.7375694,0.3913888},
{0.0346133,0.7437371,0.4026271},
{0.0335332,0.7501210,0.4132726},
{0.0310784,0.7566462,0.4241944},
{0.0286414,0.7633607,0.4347043},
{0.0261429,0.7695836,0.4454347},
{0.0242298,0.7758026,0.4558008},
{0.0236910,0.7822024,0.4658635},
{0.0231405,0.7879287,0.4768231},
{0.0237483,0.7937787,0.4873992},
{0.0236009,0.7993040,0.4986046},
{0.0231891,0.8052551,0.5093905},
{0.0186015,0.8171015,0.5115494},
{0.0212833,0.8214319,0.5250925},
{0.0250268,0.8254434,0.5387712},
{0.0274607,0.8296607,0.5520771},
{0.0304250,0.8347044,0.5636329},
{0.0308476,0.8395711,0.5748912},
{0.0333637,0.8444397,0.5856493},
{0.0339061,0.8493155,0.5963810},
{0.0364177,0.8541522,0.6066784},
{0.0380818,0.8591265,0.6163905},
{0.0400631,0.8634249,0.6266543},
{0.0359655,0.8643180,0.6415944},
{0.0521398,0.8676109,0.6509146},
{0.0525840,0.8729623,0.6584180},
{0.0536339,0.8770930,0.6665810},
{0.0541772,0.8804887,0.6755142},
{0.0561387,0.8841310,0.6837054},
{0.0572730,0.8881305,0.6913448},
{0.0595947,0.8911872,0.6994583},
{0.0608149,0.8952525,0.7064725},
{0.0640573,0.8993560,0.7124145},
{0.0641547,0.9039196,0.7178710},
{0.0654574,0.9072604,0.7238541},
{0.0673448,0.9111132,0.7285530},
{0.0681924,0.9143614,0.7337112},
{0.0693095,0.9177801,0.7382045},
{0.0730594,0.9204580,0.7428416},
{0.0750293,0.9221609,0.7481469},
{0.0769974,0.9239113,0.7527313},
{0.0788683,0.9248250,0.7578334},
{0.0820627,0.9260855,0.7611570},
{0.0826167,0.9266040,0.7649321},
{0.0848821,0.9267240,0.7688752},
{0.0858995,0.9265881,0.7722375},
{0.0875183,0.9256362,0.7765144},
{0.0894215,0.9255163,0.7791822},
{0.0900143,0.9253944,0.7821491},
{0.0906635,0.9246045,0.7849279},
{0.0909171,0.9241690,0.7871378},
{0.0939855,0.9237381,0.7888366},
{0.0935796,0.9233220,0.7903912}
};
outPWrWam = {
{0.2006294,0.3771539,-0.1463286},
{0.1998838,0.3767891,-0.1457106},
{0.1990475,0.3765113,-0.1453205},
{0.1978514,0.3761370,-0.1449952},
{0.1966880,0.3760037,-0.1446405},
{0.1955239,0.3762878,-0.1432899},
{0.1942402,0.3767741,-0.1423997},
{0.1932138,0.3775164,-0.1406915},
{0.1932269,0.3785101,-0.1360669},
{0.1922417,0.3795158,-0.1332772},
{0.1917557,0.3808060,-0.1291719},
{0.1914967,0.3822203,-0.1247587},
{0.1912980,0.3840146,-0.1198646},
{0.1908548,0.3860526,-0.1146117},
{0.1913830,0.3879398,-0.1089561},
{0.1922959,0.3902398,-0.1023565},
{0.1922572,0.3927967,-0.0956340},
{0.1915814,0.3956617,-0.0889950},
{0.1901480,0.3985324,-0.0825459},
{0.1886665,0.4012571,-0.0756999},
{0.1870096,0.4040069,-0.0692153},
{0.1859693,0.4064838,-0.0618880},
{0.1849325,0.4090140,-0.0552994},
{0.1843140,0.4113145,-0.0487123},
{0.1832828,0.4141180,-0.0418123},
{0.1822849,0.4169086,-0.0344928},
{0.1778476,0.4214456,-0.0270872},
{0.1717524,0.4267655,-0.0163772},
{0.1675852,0.4303556,-0.0056059},
{0.1631820,0.4345262,0.0054038},
{0.1593159,0.4384271,0.0171024},
{0.1554488,0.4423636,0.0296404},
{0.1506907,0.4467572,0.0416032},
{0.1460143,0.4512275,0.0530997},
{0.1413967,0.4556206,0.0651820},
{0.1360526,0.4600256,0.0778482},
{0.1315057,0.4639070,0.0900729},
{0.1259835,0.4682368,0.1018203},
{0.1211037,0.4720220,0.1142911},
{0.1147682,0.4765727,0.1269518},
{0.1110182,0.4807416,0.1382234},
{0.1103524,0.4857601,0.1448233},
{0.1060051,0.4903969,0.1564117},
{0.1017501,0.4948821,0.1682953},
{0.0987011,0.4995009,0.1808133},
{0.0939150,0.5041530,0.1932795},
{0.0900972,0.5085479,0.2050066},
{0.0851603,0.5132214,0.2174043},
{0.0807687,0.5178078,0.2294265},
{0.0754018,0.5225318,0.2419146},
{0.0700798,0.5271788,0.2544240},
{0.0647178,0.5314737,0.2670652},
{0.0593071,0.5355318,0.2796205},
{0.0551343,0.5396583,0.2921290},
{0.0506774,0.5433465,0.3052969},
{0.0471548,0.5470662,0.3183279},
{0.0431657,0.5503963,0.3322853},
{0.0389825,0.5541498,0.3459994},
{0.0320713,0.5622544,0.3538423},
{0.0304643,0.5654478,0.3689266},
{0.0293910,0.5682770,0.3843484},
{0.0273107,0.5715764,0.3991311},
{0.0258306,0.5754786,0.4126995},
{0.0225123,0.5794010,0.4257535},
{0.0203017,0.5832864,0.4385837},
{0.0166299,0.5872296,0.4514240},
{0.0142011,0.5912588,0.4638727},
{0.0109819,0.5955640,0.4756766},
{0.0079378,0.5994521,0.4877790},
{0.0008419,0.6006789,0.5028112},
{0.0080357,0.6045170,0.5136688},
{0.0042153,0.6096675,0.5230063},
{0.0008983,0.6138689,0.5326704},
{-0.0029652,0.6174362,0.5430826},
{-0.0058095,0.6212908,0.5530247},
{-0.0093299,0.6255011,0.5625433},
{-0.0116434,0.6287923,0.5726746},
{-0.0148977,0.6330823,0.5818354},
{-0.0161639,0.6372831,0.5904211},
{-0.0194572,0.6419243,0.5980064},
{-0.0215531,0.6455150,0.6058774},
{-0.0227586,0.6494699,0.6126902},
{-0.0244600,0.6528075,0.6196713},
{-0.0257647,0.6563925,0.6257883},
{-0.0249986,0.6595401,0.6319072},
{-0.0255130,0.6619161,0.6378568},
{-0.0256446,0.6640466,0.6434841},
{-0.0257708,0.6656587,0.6488220},
{-0.0247018,0.6676037,0.6525822},
{-0.0249415,0.6685460,0.6561327},
{-0.0241255,0.6693994,0.6597816},
{-0.0236325,0.6697539,0.6625154},
{-0.0232665,0.6697625,0.6658103},
{-0.0222953,0.6703088,0.6678787},
{-0.0226966,0.6710409,0.6698970},
{-0.0228175,0.6710610,0.6716241},
{-0.0234134,0.6714409,0.6728703},
{-0.0216831,0.6719908,0.6737536},
{-0.0226057,0.6723306,0.6741831}
};
outPEeWam = {
{0.2170784,0.3398244,-0.1903279},
{0.2164288,0.3392391,-0.1894858},
{0.2156384,0.3387609,-0.1889054},
{0.2144447,0.3381245,-0.1883508},
{0.2133812,0.3376971,-0.1876980},
{0.2124190,0.3377526,-0.1860637},
{0.2113751,0.3379170,-0.1847850},
{0.2107207,0.3383300,-0.1826193},
{0.2108847,0.3391751,-0.1777917},
{0.2101093,0.3398479,-0.1745956},
{0.2098123,0.3409199,-0.1701970},
{0.2097411,0.3421206,-0.1654914},
{0.2097328,0.3437647,-0.1603628},
{0.2094736,0.3456397,-0.1548627},
{0.2101038,0.3473523,-0.1489834},
{0.2112133,0.3494992,-0.1421351},
{0.2113755,0.3518511,-0.1351049},
{0.2109604,0.3544600,-0.1280702},
{0.2096059,0.3570708,-0.1213058},
{0.2080081,0.3595308,-0.1142332},
{0.2061542,0.3620411,-0.1075865},
{0.2046799,0.3643472,-0.1002863},
{0.2031664,0.3666563,-0.0936835},
{0.2019035,0.3687205,-0.0871357},
{0.2002844,0.3713238,-0.0802779},
{0.1986437,0.3739493,-0.0730530},
{0.1939889,0.3783638,-0.0656025},
{0.1883349,0.3835124,-0.0545110},
{0.1843062,0.3869713,-0.0435297},
{0.1800255,0.3909477,-0.0322421},
{0.1761939,0.3946978,-0.0203526},
{0.1722233,0.3984621,-0.0076594},
{0.1675251,0.4027097,0.0045030},
{0.1627074,0.4070250,0.0161203},
{0.1579785,0.4113081,0.0282842},
{0.1523535,0.4156883,0.0408551},
{0.1473673,0.4194674,0.0530118},
{0.1414517,0.4237658,0.0646308},
{0.1360252,0.4275597,0.0768684},
{0.1294349,0.4322073,0.0893140},
{0.1251367,0.4363008,0.1004652},
{0.1236850,0.4407562,0.1074484},
{0.1188922,0.4452922,0.1190021},
{0.1141565,0.4496575,0.1308679},
{0.1104728,0.4541515,0.1433319},
{0.1051912,0.4586122,0.1558779},
{0.1007007,0.4627436,0.1677302},
{0.0952697,0.4671182,0.1803598},
{0.0902158,0.4713452,0.1926573},
{0.0842664,0.4757089,0.2054587},
{0.0783675,0.4799424,0.2183680},
{0.0724328,0.4838518,0.2313913},
{0.0663225,0.4874776,0.2443844},
{0.0614230,0.4911495,0.2573821},
{0.0561847,0.4944300,0.2709916},
{0.0518361,0.4977237,0.2845137},
{0.0470787,0.5006147,0.2990214},
{0.0421412,0.5039287,0.3133211},
{0.0347653,0.5112850,0.3223009},
{0.0323006,0.5142509,0.3376934},
{0.0302638,0.5168437,0.3534638},
{0.0272807,0.5199596,0.3685420},
{0.0249117,0.5236335,0.3825128},
{0.0208452,0.5273670,0.3959259},
{0.0176892,0.5310557,0.4091705},
{0.0131746,0.5348124,0.4224326},
{0.0097578,0.5386801,0.4353116},
{0.0055620,0.5428515,0.4475338},
{0.0015128,0.5466575,0.4600040},
{-0.0061828,0.5479511,0.4750546},
{-0.0007851,0.5518982,0.4862196},
{-0.0054584,0.5570086,0.4959240},
{-0.0096488,0.5612241,0.5058883},
{-0.0143937,0.5648257,0.5165962},
{-0.0181991,0.5687228,0.5268885},
{-0.0226505,0.5729752,0.5367830},
{-0.0258910,0.5763134,0.5473179},
{-0.0300402,0.5806483,0.5569079},
{-0.0322082,0.5848686,0.5660225},
{-0.0361796,0.5895253,0.5740334},
{-0.0389552,0.5931659,0.5822821},
{-0.0407793,0.5971413,0.5895177},
{-0.0429905,0.6004967,0.5968634},
{-0.0447795,0.6041149,0.6033051},
{-0.0446102,0.6073565,0.6097203},
{-0.0456215,0.6098672,0.6157988},
{-0.0461730,0.6120737,0.6216346},
{-0.0466986,0.6138254,0.6270198},
{-0.0460547,0.6159073,0.6308673},
{-0.0464531,0.6169344,0.6343728},
{-0.0459270,0.6179345,0.6379629},
{-0.0455389,0.6183871,0.6405710},
{-0.0454235,0.6185878,0.6436695},
{-0.0446387,0.6192673,0.6456180},
{-0.0452387,0.6201702,0.6474466},
{-0.0455136,0.6203523,0.6489633},
{-0.0462795,0.6208953,0.6500168},
{-0.0448168,0.6216414,0.6507370},
{-0.0458427,0.6221324,0.6509415}
};
outThetasWam = {
{-0.1158496,-0.2494568,-0.0474730,1.2057666,0.0000000,0.0000000,0.0000000},
{-0.1147501,-0.2519346,-0.0475739,1.2070694,0.0000000,0.0000000,0.0000000},
{-0.1136078,-0.2544860,-0.0476542,1.2092547,0.0000000,0.0000000,0.0000000},
{-0.1126843,-0.2577024,-0.0481949,1.2115541,0.0000000,0.0000000,0.0000000},
{-0.1113500,-0.2615049,-0.0486997,1.2155735,0.0000000,0.0000000,0.0000000},
{-0.1092408,-0.2647742,-0.0483702,1.2207495,0.0000000,0.0000000,0.0000000},
{-0.1069642,-0.2691286,-0.0484169,1.2271541,0.0000000,0.0000000,0.0000000},
{-0.1042144,-0.2738180,-0.0483447,1.2361982,0.0000000,0.0000000,0.0000000},
{-0.1008371,-0.2764620,-0.0465608,1.2447726,0.0000000,0.0000000,0.0000000},
{-0.0984564,-0.2813438,-0.0466176,1.2550061,0.0000000,0.0000000,0.0000000},
{-0.0959758,-0.2848869,-0.0459274,1.2656575,0.0000000,0.0000000,0.0000000},
{-0.1092565,-0.2572046,-0.0566796,1.2767832,0.0000000,0.0000000,0.0000000},
{-0.1075282,-0.2605678,-0.0553508,1.2891612,0.0000000,0.0000000,0.0000000},
{-0.1058488,-0.2641651,-0.0540457,1.3024526,0.0000000,0.0000000,0.0000000},
{-0.1040886,-0.2685330,-0.0523490,1.3175960,0.0000000,0.0000000,0.0000000},
{-0.1020572,-0.2719445,-0.0501681,1.3339050,0.0000000,0.0000000,0.0000000},
{-0.1002775,-0.2763232,-0.0485197,1.3514882,0.0000000,0.0000000,0.0000000},
{-0.0984159,-0.2803298,-0.0470581,1.3687631,0.0000000,0.0000000,0.0000000},
{-0.0971172,-0.2856790,-0.0460498,1.3846811,0.0000000,0.0000000,0.0000000},
{-0.0959586,-0.2914327,-0.0448068,1.3982720,0.0000000,0.0000000,0.0000000},
{-0.0951190,-0.2973649,-0.0437888,1.4101856,0.0000000,0.0000000,0.0000000},
{-0.0777923,-0.3285671,-0.0363258,1.4201309,0.0000000,0.0000000,0.0000000},
{-0.0783816,-0.3349911,-0.0374065,1.4301427,0.0000000,0.0000000,0.0000000},
{-0.0793342,-0.3416001,-0.0387462,1.4390944,0.0000000,0.0000000,0.0000000},
{-0.0806726,-0.3480265,-0.0404936,1.4495978,0.0000000,0.0000000,0.0000000},
{-0.0822526,-0.3537376,-0.0423087,1.4599617,0.0000000,0.0000000,0.0000000},
{-0.0839028,-0.3589221,-0.0446828,1.4707385,0.0000000,0.0000000,0.0000000},
{-0.0820486,-0.3623030,-0.0430934,1.4823164,0.0000000,0.0000000,0.0000000},
{-0.0805520,-0.3642077,-0.0413478,1.4897986,0.0000000,0.0000000,0.0000000},
{-0.0792137,-0.3675140,-0.0398455,1.4997715,0.0000000,0.0000000,0.0000000},
{-0.0772886,-0.3689531,-0.0370586,1.5078020,0.0000000,0.0000000,0.0000000},
{-0.0756259,-0.3709337,-0.0344147,1.5161689,0.0000000,0.0000000,0.0000000},
{-0.0740435,-0.3725590,-0.0318885,1.5249189,0.0000000,0.0000000,0.0000000},
{-0.0731054,-0.3751861,-0.0302268,1.5332201,0.0000000,0.0000000,0.0000000},
{-0.0719135,-0.3763683,-0.0279967,1.5397327,0.0000000,0.0000000,0.0000000},
{-0.0711261,-0.3771877,-0.0261686,1.5461905,0.0000000,0.0000000,0.0000000},
{-0.0706988,-0.3795373,-0.0251040,1.5519567,0.0000000,0.0000000,0.0000000},
{-0.0703631,-0.3807841,-0.0241575,1.5567489,0.0000000,0.0000000,0.0000000},
{-0.0701424,-0.3813363,-0.0232966,1.5602261,0.0000000,0.0000000,0.0000000},
{-0.0699058,-0.3809659,-0.0224787,1.5658219,0.0000000,0.0000000,0.0000000},
{-0.0695557,-0.3829474,-0.0215729,1.5718445,0.0000000,0.0000000,0.0000000},
{-0.0678176,-0.3901783,-0.0186108,1.5777883,0.0000000,0.0000000,0.0000000},
{-0.0670357,-0.3922863,-0.0170143,1.5846183,0.0000000,0.0000000,0.0000000},
{-0.0662026,-0.3946326,-0.0153578,1.5912184,0.0000000,0.0000000,0.0000000},
{-0.0657359,-0.3980848,-0.0143972,1.5991983,0.0000000,0.0000000,0.0000000},
{-0.0646006,-0.4013331,-0.0123166,1.6055391,0.0000000,0.0000000,0.0000000},
{-0.0640950,-0.4067987,-0.0114885,1.6109222,0.0000000,0.0000000,0.0000000},
{-0.0626877,-0.4119606,-0.0090839,1.6172950,0.0000000,0.0000000,0.0000000},
{-0.0618915,-0.4194226,-0.0078826,1.6227877,0.0000000,0.0000000,0.0000000},
{-0.0607005,-0.4266209,-0.0059822,1.6281535,0.0000000,0.0000000,0.0000000},
{-0.0596407,-0.4355195,-0.0043971,1.6337268,0.0000000,0.0000000,0.0000000},
{-0.0585556,-0.4440938,-0.0027495,1.6383646,0.0000000,0.0000000,0.0000000},
{-0.0580164,-0.4548385,-0.0021345,1.6411310,0.0000000,0.0000000,0.0000000},
{-0.0567117,-0.4659337,-0.0001874,1.6446302,0.0000000,0.0000000,0.0000000},
{-0.0557825,-0.4773604,0.0010422,1.6467185,0.0000000,0.0000000,0.0000000},
{-0.0546575,-0.4901758,0.0025159,1.6488994,0.0000000,0.0000000,0.0000000},
{-0.0535011,-0.5039720,0.0040106,1.6510943,0.0000000,0.0000000,0.0000000},
{-0.0522589,-0.5185754,0.0056497,1.6534181,0.0000000,0.0000000,0.0000000},
{-0.0519307,-0.5409210,0.0061555,1.6567272,0.0000000,0.0000000,0.0000000},
{-0.0504427,-0.5525069,0.0084702,1.6607914,0.0000000,0.0000000,0.0000000},
{-0.0498684,-0.5668276,0.0094037,1.6635221,0.0000000,0.0000000,0.0000000},
{-0.0473025,-0.5826421,0.0116167,1.6661054,0.0000000,0.0000000,0.0000000},
{-0.0452953,-0.6035374,0.0124802,1.6686032,0.0000000,0.0000000,0.0000000},
{-0.0453184,-0.6144283,0.0133744,1.6700647,0.0000000,0.0000000,0.0000000},
{-0.0424052,-0.6330524,0.0157552,1.6698836,0.0000000,0.0000000,0.0000000},
{-0.0419755,-0.6435122,0.0174956,1.6692765,0.0000000,0.0000000,0.0000000},
{-0.0402552,-0.6559848,0.0198244,1.6674002,0.0000000,0.0000000,0.0000000},
{-0.0384850,-0.6674384,0.0219260,1.6644946,0.0000000,0.0000000,0.0000000},
{-0.0366143,-0.6788503,0.0234489,1.6614833,0.0000000,0.0000000,0.0000000},
{-0.0378388,-0.6848222,0.0233818,1.6586635,0.0000000,0.0000000,0.0000000},
{-0.0356923,-0.7062629,0.0233703,1.6555327,0.0000000,0.0000000,0.0000000},
{-0.0339096,-0.7154879,0.0248728,1.6521564,0.0000000,0.0000000,0.0000000},
{-0.0334404,-0.7238381,0.0260954,1.6475641,0.0000000,0.0000000,0.0000000},
{-0.0324568,-0.7319367,0.0270672,1.6425192,0.0000000,0.0000000,0.0000000},
{-0.0315487,-0.7403808,0.0282970,1.6366261,0.0000000,0.0000000,0.0000000},
{-0.0302104,-0.7484358,0.0295916,1.6306949,0.0000000,0.0000000,0.0000000},
{-0.0290619,-0.7562986,0.0310485,1.6247948,0.0000000,0.0000000,0.0000000},
{-0.0270985,-0.7643223,0.0325382,1.6193697,0.0000000,0.0000000,0.0000000},
{-0.0252143,-0.7719655,0.0346519,1.6137023,0.0000000,0.0000000,0.0000000},
{-0.0228817,-0.7785011,0.0362809,1.6100718,0.0000000,0.0000000,0.0000000},
{-0.0209789,-0.7849556,0.0375945,1.6065341,0.0000000,0.0000000,0.0000000},
{-0.0187402,-0.7912531,0.0392382,1.6038819,0.0000000,0.0000000,0.0000000},
{-0.0170592,-0.7962812,0.0406801,1.6017133,0.0000000,0.0000000,0.0000000},
{-0.0150441,-0.8018029,0.0418606,1.6003685,0.0000000,0.0000000,0.0000000},
{-0.0134535,-0.8083792,0.0426796,1.5987314,0.0000000,0.0000000,0.0000000},
{-0.0123213,-0.8140263,0.0426161,1.5973524,0.0000000,0.0000000,0.0000000},
{-0.0111591,-0.8184620,0.0431677,1.5959752,0.0000000,0.0000000,0.0000000},
{-0.0106713,-0.8229052,0.0427619,1.5948705,0.0000000,0.0000000,0.0000000},
{-0.0097150,-0.8274463,0.0425497,1.5932500,0.0000000,0.0000000,0.0000000},
{-0.0092779,-0.8300809,0.0419721,1.5936638,0.0000000,0.0000000,0.0000000},
{-0.0086381,-0.8343598,0.0410710,1.5938483,0.0000000,0.0000000,0.0000000},
{-0.0087960,-0.8364686,0.0400890,1.5945917,0.0000000,0.0000000,0.0000000},
{-0.0092536,-0.8394682,0.0384346,1.5937979,0.0000000,0.0000000,0.0000000},
{-0.0094753,-0.8419119,0.0373512,1.5935442,0.0000000,0.0000000,0.0000000},
{-0.0099953,-0.8439542,0.0358291,1.5923257,0.0000000,0.0000000,0.0000000},
{-0.0106909,-0.8452996,0.0342605,1.5909187,0.0000000,0.0000000,0.0000000},
{-0.0111469,-0.8465974,0.0327746,1.5890088,0.0000000,0.0000000,0.0000000},
{-0.0118643,-0.8489934,0.0312846,1.5872231,0.0000000,0.0000000,0.0000000},
{-0.0125508,-0.8494753,0.0297113,1.5853125,0.0000000,0.0000000,0.0000000}
};
xyzEulersBase = {
{0.3558404,-2.5601623,1.1443466},
{0.3500867,-2.5605557,1.1441920},
{0.3441622,-2.5591244,1.1433376},
{0.3373688,-2.5574123,1.1433781},
{0.3294798,-2.5558872,1.1439309},
{0.3215400,-2.5540199,1.1427001},
{0.3116682,-2.5522101,1.1426215},
{0.3007842,-2.5501178,1.1429747},
{0.2906168,-2.5417914,1.1361984},
{0.2796017,-2.5360309,1.1359595},
{0.2700036,-2.5283778,1.1335190},
{0.2426289,-2.4917690,1.1470149},
{0.2334125,-2.4824418,1.1432105},
{0.2244615,-2.4725130,1.1399661},
{0.2156739,-2.4599679,1.1361108},
{0.2048812,-2.4463954,1.1300893},
{0.1957098,-2.4333875,1.1274868},
{0.1852145,-2.4212489,1.1253850},
{0.1791397,-2.4099257,1.1264413},
{0.1742426,-2.3980899,1.1265292},
{0.1717069,-2.3873672,1.1277606},
{0.1859402,-2.3986800,1.1153423},
{0.1848076,-2.3864645,1.1184859},
{0.1848398,-2.3728622,1.1223630},
{0.1872534,-2.3592169,1.1290922},
{0.1915231,-2.3444617,1.1367359},
{0.1978032,-2.3370512,1.1489557},
{0.1915524,-2.3345530,1.1485230},
{0.1860079,-2.3294984,1.1453362},
{0.1808140,-2.3232528,1.1445428},
{0.1732785,-2.3147317,1.1378126},
{0.1664853,-2.3042713,1.1316557},
{0.1601669,-2.2962280,1.1266739},
{0.1562660,-2.2868026,1.1240827},
{0.1513399,-2.2780136,1.1186340},
{0.1486953,-2.2664322,1.1126608},
{0.1469565,-2.2546480,1.1095261},
{0.1459334,-2.2437190,1.1057787},
{0.1452568,-2.2308146,1.1005391},
{0.1453560,-2.2201100,1.0959199},
{0.1438324,-2.2059547,1.0922689},
{0.1337159,-2.1915444,1.0883811},
{0.1303439,-2.1782747,1.0834519},
{0.1265109,-2.1648608,1.0783547},
{0.1247886,-2.1489064,1.0758223},
{0.1192410,-2.1362790,1.0703707},
{0.1173494,-2.1244372,1.0713245},
{0.1110712,-2.1137608,1.0676594},
{0.1089596,-2.1040284,1.0706738},
{0.1049850,-2.0953183,1.0714267},
{0.1029131,-2.0884498,1.0760417},
{0.1007383,-2.0822907,1.0799275},
{0.1027864,-2.0785159,1.0902444},
{0.1009163,-2.0734659,1.0957902},
{0.1017284,-2.0695503,1.1036699},
{0.1025127,-2.0661690,1.1118568},
{0.1036892,-2.0647763,1.1212367},
{0.1048582,-2.0642979,1.1308273},
{0.1113530,-2.0760064,1.1572171},
{0.1117189,-2.0688755,1.1596592},
{0.1179622,-2.0646272,1.1698770},
{0.1166963,-2.0623276,1.1690553},
{0.1215105,-2.0659932,1.1769349},
{0.1274689,-2.0632028,1.1872650},
{0.1267588,-2.0657766,1.1878616},
{0.1306283,-2.0627819,1.1958595},
{0.1364097,-2.0606074,1.2034173},
{0.1405909,-2.0585253,1.2093741},
{0.1400711,-2.0557629,1.2107291},
{0.1479190,-2.0549990,1.2173374},
{0.1345543,-2.0483379,1.2062516},
{0.1352147,-2.0463079,1.2086116},
{0.1425795,-2.0446779,1.2163082},
{0.1448371,-2.0427952,1.2194402},
{0.1500642,-2.0408298,1.2253940},
{0.1531934,-2.0388303,1.2296756},
{0.1594417,-2.0367675,1.2368004},
{0.1606296,-2.0345704,1.2397315},
{0.1683518,-2.0323224,1.2489254},
{0.1684548,-2.0304005,1.2511238},
{0.1692038,-2.0283246,1.2535297},
{0.1707835,-2.0262284,1.2570422},
{0.1744358,-2.0243971,1.2620484},
{0.1735556,-2.0224675,1.2629561},
{0.1734225,-2.0199610,1.2641557},
{0.1679206,-2.0179033,1.2597430},
{0.1675609,-2.0161264,1.2603561},
{0.1632278,-2.0144063,1.2564891},
{0.1573889,-2.0127449,1.2515880},
{0.1505887,-2.0119374,1.2453227},
{0.1405791,-2.0105909,1.2360730},
{0.1342190,-2.0099838,1.2296784},
{0.1245916,-2.0091697,1.2197908},
{0.1182171,-2.0084484,1.2132950},
{0.1097479,-2.0080623,1.2044888},
{0.1016845,-2.0079951,1.1959296},
{0.0926932,-2.0080742,1.1866888},
{0.0865944,-2.0074176,1.1799628},
{0.0780024,-2.0079084,1.1709140}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.463388e+02
Final                            2.276059e+00
Change                           2.440627e+02

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0137
    Line search gradient evaluation    0.0071
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0142

Postprocessor                          0.0000
Total                                  0.0143

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.375078e-11 <= 1.000000e-10)

*) 
fitErrUA0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa0 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr0 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe0 = {
{-0.0354113,-0.0782404,0.0772527}
};
rMatsBase0 = {
{-0.3456707,0.7608346,-0.5492198},
{0.7742601,0.5619283,0.2911320},
{0.5301255,-0.3246032,-0.7833261}
};
outThetasWam0 = {
{-0.1158496,-0.2494568,-0.0474730,1.2057666,-0.7959598,1.1480220,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.576039e+02
Final                            5.172611e-04
Change                           2.576034e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0196

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.892520e-11 <= 1.000000e-10)

*) 
fitErrUA1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr1 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe1 = {
{0.0022760,-0.0019143,-0.0021909}
};
rMatsBase1 = {
{-0.3458777,0.7609778,-0.5488910},
{0.7772576,0.5600688,0.2866942},
{0.5255847,-0.3274686,-0.7851911}
};
outThetasWam1 = {
{-0.1147501,-0.2519346,-0.0475739,1.2070694,-0.8775891,-1.5070310,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.570360e+02
Final                            2.774687e-04
Change                           2.570358e+02

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0201
    Line search gradient evaluation    0.0110
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0209

Postprocessor                          0.0000
Total                                  0.0209

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.217715e-11 <= 1.000000e-10)

*) 
fitErrUA2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa2 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr2 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe2 = {
{0.0017858,-0.0016006,-0.0018507}
};
rMatsBase2 = {
{-0.3462018,0.7599663,-0.5500869},
{0.7797133,0.5591527,0.2817720},
{0.5217198,-0.3313601,-0.7861354}
};
outThetasWam2 = {
{-0.1136078,-0.2544860,-0.0476542,1.2092547,-0.8674977,-1.4970420,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.567176e+02
Final                            3.419785e-04
Change                           2.567173e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0196

Postprocessor                          0.0000
Total                                  0.0197

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 9.431056e-11 <= 1.000000e-10)

*) 
fitErrUA3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr3 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe3 = {
{0.0023168,-0.0019245,-0.0020841}
};
rMatsBase3 = {
{-0.3457800,0.7591221,-0.5515159},
{0.7830660,0.5572874,0.2761129},
{0.5169563,-0.3363990,-0.7871416}
};
outThetasWam3 = {
{-0.1126843,-0.2577024,-0.0481949,1.2115541,-0.8587070,-1.5010590,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.552738e+02
Final                            1.386759e-04
Change                           2.552737e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0188
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0195

Postprocessor                          0.0000
Total                                  0.0195

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.371403e-11 <= 1.000000e-10)

*) 
fitErrUA4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa4 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr4 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe4 = {
{0.0018779,-0.0016977,-0.0018989}
};
rMatsBase4 = {
{-0.3450117,0.7585466,-0.5527874},
{0.7872560,0.5545556,0.2696221},
{0.5110723,-0.3421624,-0.7884986}
};
outThetasWam4 = {
{-0.1113500,-0.2615049,-0.0486997,1.2155735,-0.8612436,-1.4926161,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.535944e+02
Final                            3.794139e-05
Change                           2.535943e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0196

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.441069e-11 <= 1.000000e-10)

*) 
fitErrUA5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr5 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe5 = {
{0.0008468,-0.0011841,-0.0015640}
};
rMatsBase5 = {
{-0.3455160,0.7571810,-0.5543425},
{0.7904051,0.5532421,0.2630266},
{0.5058443,-0.3472752,-0.7896337}
};
outThetasWam5 = {
{-0.1092408,-0.2647742,-0.0483702,1.2207495,-0.8743685,-1.4775046,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.528625e+02
Final                            1.822389e-05
Change                           2.528625e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0195

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.645528e-11 <= 1.000000e-10)

*) 
fitErrUA6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa6 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr6 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe6 = {
{0.0011400,-0.0014010,-0.0017462}
};
rMatsBase6 = {
{-0.3451583,0.7562400,-0.5558479},
{0.7951253,0.5502693,0.2549107},
{0.4986396,-0.3539842,-0.7912356}
};
outThetasWam6 = {
{-0.1069642,-0.2691286,-0.0484169,1.2271541,-0.8732530,-1.4800033,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.502784e+02
Final                            2.212724e-04
Change                           2.502782e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0188
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0195

Postprocessor                          0.0000
Total                                  0.0195

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.319789e-11 <= 1.000000e-10)

*) 
fitErrUA7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr7 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe7 = {
{-0.0003290,-0.0003764,-0.0008052}
};
rMatsBase7 = {
{-0.3444079,0.7553020,-0.5575860},
{0.8004845,0.5465698,0.2459388},
{0.4905178,-0.3616357,-0.7928505}
};
outThetasWam7 = {
{-0.1042144,-0.2738180,-0.0483447,1.2361982,-0.8848582,-1.4512953,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.491857e+02
Final                            1.449949e-04
Change                           2.491856e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0191
    Line search gradient evaluation    0.0105
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0198

Postprocessor                          0.0000
Total                                  0.0199

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.293144e-11 <= 1.000000e-10)

*) 
fitErrUA8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr8 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe8 = {
{-0.0015574,0.0001125,-0.0006424}
};
rMatsBase8 = {
{-0.3475513,0.7487137,-0.5644784},
{0.8009017,0.5501015,0.2365265},
{0.4876111,-0.3698867,-0.7908346}
};
outThetasWam8 = {
{-0.1008371,-0.2764620,-0.0465608,1.2447726,-0.8975727,-1.4357660,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.481313e+02
Final                            9.094551e-04
Change                           2.481304e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0196

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.172396e-11 <= 1.000000e-10)

*) 
fitErrUA9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr9 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe9 = {
{-0.0012857,0.0004373,0.0000190}
};
rMatsBase9 = {
{-0.3463546,0.7456691,-0.5692241},
{0.8055419,0.5473743,0.2269000},
{0.4807709,-0.3799460,-0.7902534}
};
outThetasWam9 = {
{-0.0984564,-0.2813438,-0.0466176,1.2550061,-0.8839786,-1.4240911,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.458361e+02
Final                            1.595645e-03
Change                           2.458345e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0188
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0195

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.564360e-11 <= 1.000000e-10)

*) 
fitErrUA10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrEl10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrLa10 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrWr10 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe10 = {
{-0.0028277,0.0014154,0.0008493}
};
rMatsBase10 = {
{-0.3463183,0.7408535,-0.5754996},
{0.8080811,0.5471942,0.2181364},
{0.4765171,-0.3895057,-0.7881731}
};
outThetasWam10 = {
{-0.0959758,-0.2848869,-0.0459274,1.2656575,-0.8940759,-1.3945202,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.759491e+02
Final                            1.651934e-02
Change                           1.759326e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           6

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0195
    Line search gradient evaluation    0.0110
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0202

Postprocessor                          0.0000
Total                                  0.0202

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 9.576340e-11 <= 1.000000e-10)

*) 
fitErrUA11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr11 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe11 = {
{-0.0270498,0.0097960,0.0220399}
};
rMatsBase11 = {
{-0.3274017,0.7257599,-0.6050460},
{0.8250654,0.5316724,0.1912890},
{0.4605162,-0.4365742,-0.7728698}
};
outThetasWam11 = {
{-0.1092565,-0.2572046,-0.0566796,1.2767832,-1.1594569,-0.8889485,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.437216e+02
Final                            3.060527e-03
Change                           2.437185e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0189
    Line search gradient evaluation    0.0104
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0195

Postprocessor                          0.0000
Total                                  0.0196

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.136336e-11 <= 1.000000e-10)

*) 
fitErrUA12 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl12 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa12 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr12 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe12 = {
{-0.0042775,0.0024173,0.0016351}
};
rMatsBase12 = {
{-0.3278060,0.7193423,-0.6124458},
{0.8265516,0.5323348,0.1828446},
{0.4575541,-0.4462805,-0.7690761}
};
outThetasWam12 = {
{-0.1075282,-0.2605678,-0.0553508,1.2891612,-0.8955098,-1.3689815,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.428452e+02
Final                            4.092144e-03
Change                           2.428411e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0169
    Line search gradient evaluation    0.0091
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0175

Postprocessor                          0.0000
Total                                  0.0176

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 7.805001e-11 <= 1.000000e-10)

*) 
fitErrUA13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr13 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe13 = {
{-0.0048295,0.0028700,0.0020101}
};
rMatsBase13 = {
{-0.3275823,0.7127145,-0.6202644},
{0.8281687,0.5325922,0.1745913},
{0.4547817,-0.4564905,-0.7647156}
};
outThetasWam13 = {
{-0.1058488,-0.2641651,-0.0540457,1.3024526,-0.8914767,-1.3572042,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.420604e+02
Final                            5.083199e-03
Change                           2.420553e+02

Minimizer iterations                       15
Successful steps                           15
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0222
    Line search gradient evaluation    0.0123
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0231

Postprocessor                          0.0000
Total                                  0.0231

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.708323e-11 <= 1.000000e-10)

*) 
fitErrUA14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr14 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe14 = {
{-0.0052979,0.0031275,0.0020384}
};
rMatsBase14 = {
{-0.3270248,0.7043328,-0.6300556},
{0.8292068,0.5336649,0.1661862},
{0.4532890,-0.4680994,-0.7585592}
};
outThetasWam14 = {
{-0.1040886,-0.2685330,-0.0523490,1.3175960,-0.8903229,-1.3503549,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.400466e+02
Final                            7.214195e-03
Change                           2.400393e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           6

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0196
    Line search gradient evaluation    0.0111
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0203

Postprocessor                          0.0000
Total                                  0.0204

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.410250e-11 <= 1.000000e-10)

*) 
fitErrUA15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr15 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe15 = {
{-0.0069913,0.0042823,0.0029062}
};
rMatsBase15 = {
{-0.3275817,0.6945521,-0.6405370},
{0.8299430,0.5355232,0.1562355},
{0.4515361,-0.4804292,-0.7518663}
};
outThetasWam15 = {
{-0.1020572,-0.2719445,-0.0501681,1.3339050,-0.8945657,-1.3244268,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.386731e+02
Final                            9.908571e-03
Change                           2.386632e+02

Minimizer iterations                       18
Successful steps                           18
Unsuccessful steps                          0
Line search steps                           8

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0262
    Line search gradient evaluation    0.0144
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0272

Postprocessor                          0.0000
Total                                  0.0272

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.623235e-11 <= 1.000000e-10)

*) 
fitErrUA16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr16 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe16 = {
{-0.0074507,0.0048351,0.0034661}
};
rMatsBase16 = {
{-0.3257865,0.6861121,-0.6504716},
{0.8318356,0.5350085,0.1477005},
{0.4493469,-0.4929666,-0.7450311}
};
outThetasWam16 = {
{-0.1002775,-0.2763232,-0.0485197,1.3514882,-0.8849937,-1.3094887,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.372034e+02
Final                            1.114178e-02
Change                           2.371922e+02

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0209
    Line search gradient evaluation    0.0117
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0217

Postprocessor                          0.0000
Total                                  0.0218

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.475265e-11 <= 1.000000e-10)

*) 
fitErrUA17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr17 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe17 = {
{-0.0079008,0.0053177,0.0038799}
};
rMatsBase17 = {
{-0.3238021,0.6782501,-0.6596431},
{0.8346627,0.5330865,0.1384088},
{0.4455226,-0.5057624,-0.7387246}
};
outThetasWam17 = {
{-0.0984159,-0.2803298,-0.0470581,1.3687631,-0.8765836,-1.2960565,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.381361e+02
Final                            1.035916e-02
Change                           2.381258e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           6

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0196
    Line search gradient evaluation    0.0111
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0203

Postprocessor                          0.0000
Total                                  0.0203

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.754774e-11 <= 1.000000e-10)

*) 
fitErrUA18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa18 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr18 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe18 = {
{-0.0064375,0.0046888,0.0033438}
};
rMatsBase18 = {
{-0.3198540,0.6718045,-0.6681109},
{0.8372645,0.5304817,0.1325793},
{0.4434880,-0.5169795,-0.7321548}
};
outThetasWam18 = {
{-0.0971172,-0.2856790,-0.0460498,1.3846811,-0.8474079,-1.3177876,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.395124e+02
Final                            7.001547e-03
Change                           2.395054e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0163
    Line search gradient evaluation    0.0085
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0169

Postprocessor                          0.0000
Total                                  0.0170

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 9.395151e-11 <= 1.000000e-10)

*) 
fitErrUA19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa19 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr19 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe19 = {
{-0.0046473,0.0035344,0.0021618}
};
rMatsBase19 = {
{-0.3163740,0.6646457,-0.6768704},
{0.8388200,0.5292411,0.1276123},
{0.4430447,-0.5273992,-0.7249562}
};
outThetasWam19 = {
{-0.0959586,-0.2914327,-0.0448068,1.3982720,-0.8177500,-1.3561602,0.0000000}
};
(* 
W1104 07:49:54.785661  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.786347  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.787016  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.787684  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.788353  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.789026  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.789695  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.790374  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.791041  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.791725  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.792402  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.793081  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.793745  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.803109  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.803783  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.804447  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.805126  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.805800  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.806466  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.807129  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.807798  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.813784  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.814502  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.815197  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.815871  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.816534  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.817204  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.817869  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.818536  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.819198  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.819916  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.820585  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.821252  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.821923  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.827888  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.828569  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.829243  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.829910  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.830605  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.831311  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.831990  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.832656  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.833326  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.833994  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.834658  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.835340  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.836014  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.842133  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.842813  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.843478  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.844143  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.844808  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.845468  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.846136  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.846801  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.847472  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.848141  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.848811  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.849488  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.850150  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.856091  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.856758  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.857425  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.858098  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.858767  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.859429  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.860095  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.860757  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.861426  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.862092  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.862769  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.863457  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:54.864212  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.393143e+02
Final                            2.653761e+00
Change                           2.366606e+02

Minimizer iterations                       16
Successful steps                           16
Unsuccessful steps                          0
Line search steps                         182

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1336
    Line search gradient evaluation    0.1230
  Linear solver                        0.0002
  Line search polynomial minimization  0.0021
Minimizer                              0.1372

Postprocessor                          0.0000
Total                                  0.1372

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr20 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe20 = {
{0.0059295,-0.0068742,-0.0040399}
};
rMatsBase20 = {
{-0.3124259,0.6584395,-0.6847244},
{0.8400148,0.5280798,0.1245264},
{0.4435822,-0.5362734,-0.7180848}
};
outThetasWam20 = {
{-0.0951190,-0.2973649,-0.0437888,1.4101856,-0.7012687,-1.6000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.882641e+02
Final                            3.763761e+01
Change                           2.506264e+02

Minimizer iterations                      501
Successful steps                          501
Unsuccessful steps                          0
Line search steps                         999

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0163
    Line search cost evaluation        0.0000
  Jacobian evaluation                  1.3028
    Line search gradient evaluation    0.9747
  Linear solver                        0.0041
  Line search polynomial minimization  0.0074
Minimizer                              1.3386

Postprocessor                          0.0000
Total                                  1.3387

Termination:                   NO_CONVERGENCE (Maximum number of iterations reached. Number of iterations: 500.)

*) 
fitErrUA21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr21 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe21 = {
{-0.0007660,-0.0050423,-0.0084182}
};
rMatsBase21 = {
{-0.3239650,0.6614235,-0.6764359},
{0.8275742,0.5445934,0.1361575},
{0.4584404,-0.5156907,-0.7238063}
};
outThetasWam21 = {
{-0.0777923,-0.3285671,-0.0363258,1.4201309,-3.9704116,1.5911307,0.0000000}
};
(* 
W1104 07:49:56.285807  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.286494  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.287166  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.287838  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.288502  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.289177  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.289846  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.290518  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.291186  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.297204  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.297876  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.298542  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.299211  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.299883  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.300549  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.301218  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.301894  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.302558  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.303222  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.303886  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.304565  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.305249  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.310577  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.311239  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.311894  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.312562  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.313237  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.313901  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.314564  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.315227  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.315893  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.316568  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.317241  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.317955  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.318619  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.325250  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.325922  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.326587  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.327270  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.327936  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.328616  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.329285  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.329955  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.330619  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.331287  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.331954  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.341864  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.342553  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.343226  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.343890  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.344565  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.345238  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.357751  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.358417  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.353011e+02
Final                            2.182210e+00
Change                           2.331189e+02

Minimizer iterations                       75
Successful steps                           67
Unsuccessful steps                          8
Line search steps                         254

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0024
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2464
    Line search gradient evaluation    0.2025
  Linear solver                        0.0007
  Line search polynomial minimization  0.0022
Minimizer                              0.2530

Postprocessor                          0.0000
Total                                  0.2530

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr22 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe22 = {
{0.0063129,-0.0071878,-0.0035650}
};
rMatsBase22 = {
{-0.3182489,0.6549574,-0.6853820},
{0.8290805,0.5428817,0.1338092},
{0.4597207,-0.5256522,-0.7157839}
};
outThetasWam22 = {
{-0.0783816,-0.3349911,-0.0374065,1.4301427,-0.6754306,-1.6000000,0.0000000}
};
(* 
W1104 07:49:56.520610  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.521296  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.521965  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.522631  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.531963  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.532635  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.533318  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.533991  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.534662  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.535328  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.535992  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.536656  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.544023  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.544695  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.545372  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.546043  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.546708  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.547371  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.548038  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.548702  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.549371  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.550041  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.550706  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.556694  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.557365  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.558037  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.558703  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.559367  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.560034  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.560698  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.561364  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.562091  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.562762  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.563416  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.564095  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.575297  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.575969  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.576638  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.577316  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.339686e+02
Final                            1.474751e+00
Change                           2.324938e+02

Minimizer iterations                       78
Successful steps                           69
Unsuccessful steps                          9
Line search steps                         248

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0025
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2429
    Line search gradient evaluation    0.1993
  Linear solver                        0.0006
  Line search polynomial minimization  0.0020
Minimizer                              0.2493

Postprocessor                          0.0000
Total                                  0.2494

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr23 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe23 = {
{0.0058267,-0.0072349,-0.0040831}
};
rMatsBase23 = {
{-0.3116361,0.6477249,-0.6952232},
{0.8303802,0.5413100,0.1321065},
{0.4618999,-0.5361305,-0.7065497}
};
outThetasWam23 = {
{-0.0793342,-0.3416001,-0.0387462,1.4390944,-0.6802130,-1.6000000,0.0000000}
};
(* 
W1104 07:49:56.778582  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.779222  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.779850  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.780475  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.781117  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.781744  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.792929  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.793596  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.794247  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.794889  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.803380  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.804023  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.804659  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.805300  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.805955  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.806663  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.807320  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:56.831416  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.297224e+02
Final                            2.676057e+00
Change                           2.270463e+02

Minimizer iterations                       75
Successful steps                           69
Unsuccessful steps                          6
Line search steps                         232

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0023
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2141
    Line search gradient evaluation    0.1728
  Linear solver                        0.0006
  Line search polynomial minimization  0.0015
Minimizer                              0.2196

Postprocessor                          0.0000
Total                                  0.2197

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr24 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe24 = {
{0.0066543,-0.0076611,-0.0033499}
};
rMatsBase24 = {
{-0.3031867,0.6411710,-0.7049664},
{0.8321201,0.5386497,0.1320330},
{0.4643856,-0.5465860,-0.6968426}
};
outThetasWam24 = {
{-0.0806726,-0.3480265,-0.0404936,1.4495978,-0.6516324,-1.6000000,0.0000000}
};
(* 
W1104 07:49:57.009975  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.010612  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.011301  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.011926  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.012550  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.021126  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.021761  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.022435  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.023078  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.023717  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.024384  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.025112  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.271113e+02
Final                            2.910853e+00
Change                           2.242004e+02

Minimizer iterations                       73
Successful steps                           67
Unsuccessful steps                          6
Line search steps                         229

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0022
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2091
    Line search gradient evaluation    0.1696
  Linear solver                        0.0006
  Line search polynomial minimization  0.0014
Minimizer                              0.2144

Postprocessor                          0.0000
Total                                  0.2145

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa25 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr25 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe25 = {
{0.0070370,-0.0079440,-0.0029494}
};
rMatsBase25 = {
{-0.2938700,0.6339627,-0.7153543},
{0.8334089,0.5364115,0.1330124},
{0.4680492,-0.5570943,-0.6859854}
};
outThetasWam25 = {
{-0.0822526,-0.3537376,-0.0423087,1.4599617,-0.6314248,-1.6000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.244089e+02
Final                            2.112232e-02
Change                           2.243878e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0178
    Line search gradient evaluation    0.0098
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0185

Postprocessor                          0.0000
Total                                  0.0185

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.499157e-11 <= 1.000000e-10)

*) 
fitErrUA26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa26 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr26 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe26 = {
{-0.0071106,0.0070944,0.0066218}
};
rMatsBase26 = {
{-0.2839230,0.6326524,-0.7205128},
{0.8365733,0.5306363,0.1362723},
{0.4685433,-0.5640709,-0.6799200}
};
outThetasWam26 = {
{-0.0839028,-0.3589221,-0.0446828,1.4707385,-0.7744207,-1.2484549,0.0000000}
};
(* 
W1104 07:49:57.231918  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.232561  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.244371  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.245012  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.245615  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.255689  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.256311  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.256975  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.257601  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.268065  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.268697  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.269335  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.269968  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.271369e+02
Final                            2.815651e+00
Change                           2.243212e+02

Minimizer iterations                       75
Successful steps                           69
Unsuccessful steps                          6
Line search steps                         226

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0022
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2112
    Line search gradient evaluation    0.1703
  Linear solver                        0.0006
  Line search polynomial minimization  0.0014
Minimizer                              0.2166

Postprocessor                          0.0000
Total                                  0.2166

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr27 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe27 = {
{0.0053765,-0.0073921,-0.0042604}
};
rMatsBase27 = {
{-0.2834582,0.6308857,-0.7222428},
{0.8391226,0.5277638,0.1316765},
{0.4642464,-0.5687255,-0.6789894}
};
outThetasWam27 = {
{-0.0820486,-0.3623030,-0.0430934,1.4823164,-0.6509760,-1.6000000,0.0000000}
};
(* 
W1104 07:49:57.437397  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.438026  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.438673  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.446652  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.450801  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.451468  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.462215  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.462879  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.463546  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.464210  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.473104  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.473789  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.474503  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.475165  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.475823  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.476469  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.485325  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.485973  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.486601  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.487222  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.487845  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.488476  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.500012  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.500684  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.282194e+02
Final                            1.096771e+00
Change                           2.271227e+02

Minimizer iterations                       87
Successful steps                           80
Unsuccessful steps                          7
Line search steps                         230

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0025
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2257
    Line search gradient evaluation    0.1782
  Linear solver                        0.0007
  Line search polynomial minimization  0.0016
Minimizer                              0.2318

Postprocessor                          0.0000
Total                                  0.2319

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA28 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrEl28 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrLa28 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr28 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe28 = {
{0.0044677,-0.0071081,-0.0049578}
};
rMatsBase28 = {
{-0.2839568,0.6266459,-0.7257296},
{0.8397415,0.5278693,0.1272331},
{0.4628204,-0.5732965,-0.6761127}
};
outThetasWam28 = {
{-0.0805520,-0.3642077,-0.0413478,1.4897986,-0.6554978,-1.6000000,0.0000000}
};
(* 
W1104 07:49:57.679579  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.680275  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.680912  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.681536  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.692126  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.692775  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.693403  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.694038  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.694671  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.703181  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.703840  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.704488  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.705139  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.705788  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.706434  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.707087  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.717774  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.718438  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.719135  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.252696e+02
Final                            1.697998e+00
Change                           2.235716e+02

Minimizer iterations                       86
Successful steps                           80
Unsuccessful steps                          6
Line search steps                         231

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0026
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2270
    Line search gradient evaluation    0.1780
  Linear solver                        0.0007
  Line search polynomial minimization  0.0015
Minimizer                              0.2330

Postprocessor                          0.0000
Total                                  0.2331

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr29 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe29 = {
{0.0047104,-0.0072573,-0.0046801}
};
rMatsBase29 = {
{-0.2825743,0.6222812,-0.7300122},
{0.8413988,0.5262538,0.1229022},
{0.4606514,-0.5795024,-0.6722925}
};
outThetasWam29 = {
{-0.0792137,-0.3675140,-0.0398455,1.4997715,-0.6374781,-1.6000000,0.0000000}
};
(* 
W1104 07:49:57.900987  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.901643  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.902338  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.903009  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.914819  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.915450  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.916085  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.925354  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.926028  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.926693  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.927353  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.928017  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.928685  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.929350  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.937099  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.937762  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.938431  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.939095  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.939764  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.940424  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.941076  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.941740  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.949908  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.952360  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.952996  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.953629  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.954270  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:57.965026  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.257549e+02
Final                            8.261776e-01
Change                           2.249288e+02

Minimizer iterations                       80
Successful steps                           74
Unsuccessful steps                          6
Line search steps                         226

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0024
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2187
    Line search gradient evaluation    0.1745
  Linear solver                        0.0006
  Line search polynomial minimization  0.0016
Minimizer                              0.2246

Postprocessor                          0.0000
Total                                  0.2247

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr30 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe30 = {
{0.0037360,-0.0069130,-0.0054832}
};
rMatsBase30 = {
{-0.2841356,0.6146964,-0.7358093},
{0.8408953,0.5284535,0.1167560},
{0.4606104,-0.5855641,-0.6670478}
};
outThetasWam30 = {
{-0.0772886,-0.3689531,-0.0370586,1.5078020,-0.6527785,-1.6000000,0.0000000}
};
(* 
W1104 07:49:58.138589  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.139271  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.139914  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.140548  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.141192  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.152953  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.153584  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.154224  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.163676  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.164345  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.165033  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.165702  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.166364  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.175258  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.175938  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.176602  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.177263  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.177909  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.178578  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.190595  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.237935e+02
Final                            6.728759e-01
Change                           2.231206e+02

Minimizer iterations                       82
Successful steps                           75
Unsuccessful steps                          7
Line search steps                         229

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0024
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2203
    Line search gradient evaluation    0.1755
  Linear solver                        0.0006
  Line search polynomial minimization  0.0015
Minimizer                              0.2261

Postprocessor                          0.0000
Total                                  0.2262

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr31 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe31 = {
{0.0037268,-0.0070528,-0.0056202}
};
rMatsBase31 = {
{-0.2846267,0.6059354,-0.7428526},
{0.8402637,0.5307063,0.1109403},
{0.4614592,-0.5926155,-0.6601987}
};
outThetasWam31 = {
{-0.0756259,-0.3709337,-0.0344147,1.5161689,-0.6440079,-1.6000000,0.0000000}
};
(* 
W1104 07:49:58.366524  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.367156  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.379398  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.380023  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.390486  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.391119  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.391743  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.392366  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.215023e+02
Final                            9.979353e-01
Change                           2.205044e+02

Minimizer iterations                       82
Successful steps                           76
Unsuccessful steps                          6
Line search steps                         227

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0024
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2196
    Line search gradient evaluation    0.1748
  Linear solver                        0.0006
  Line search polynomial minimization  0.0013
Minimizer                              0.2251

Postprocessor                          0.0000
Total                                  0.2251

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA32 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl32 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa32 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr32 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe32 = {
{0.0038881,-0.0071279,-0.0053774}
};
rMatsBase32 = {
{-0.2850653,0.5990951,-0.7482131},
{0.8401596,0.5319172,0.1058103},
{0.4613779,-0.5984556,-0.6549667}
};
outThetasWam32 = {
{-0.0740435,-0.3725590,-0.0318885,1.5249189,-0.6318358,-1.6000000,0.0000000}
};
(* 
W1104 07:49:58.579712  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.580386  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.581030  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.581670  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.592728  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.593353  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.593971  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.594599  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.604303  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.604990  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.605651  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.606312  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.606971  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.607631  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.615890  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.616552  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.617218  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.617879  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.618530  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.619179  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.619837  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.629900  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.630584  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.631253  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.631958  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.199827e+02
Final                            6.450180e-01
Change                           2.193377e+02

Minimizer iterations                       94
Successful steps                           88
Unsuccessful steps                          6
Line search steps                         231

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0027
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2346
    Line search gradient evaluation    0.1825
  Linear solver                        0.0007
  Line search polynomial minimization  0.0016
Minimizer                              0.2411

Postprocessor                          0.0000
Total                                  0.2411

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr33 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe33 = {
{0.0039610,-0.0072661,-0.0053819}
};
rMatsBase33 = {
{-0.2835575,0.5919677,-0.7544331},
{0.8401598,0.5326316,0.1021524},
{0.4623059,-0.6048783,-0.6483792}
};
outThetasWam33 = {
{-0.0731054,-0.3751861,-0.0302268,1.5332201,-0.6267642,-1.6000000,0.0000000}
};
(* 
W1104 07:49:58.804152  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.804811  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.805460  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.806118  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.816072  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.816709  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.817355  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.817996  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.818635  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.819276  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.829082  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.829761  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.830408  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.831061  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.831708  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.832360  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.839792  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.840454  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.841141  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.841815  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.842480  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.843142  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.843806  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.844462  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.845125  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.845788  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.851210  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.851873  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.852536  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.853188  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.853843  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.854522  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.855159  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.855796  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.856453  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.857300  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.857951  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.858608  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.868902  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.869529  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.870151  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:58.870780  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.194178e+02
Final                            5.325413e-02
Change                           2.193646e+02

Minimizer iterations                       81
Successful steps                           73
Unsuccessful steps                          8
Line search steps                         224

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0024
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2150
    Line search gradient evaluation    0.1717
  Linear solver                        0.0006
  Line search polynomial minimization  0.0019
Minimizer                              0.2212

Postprocessor                          0.0000
Total                                  0.2213

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr34 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe34 = {
{0.0033437,-0.0069514,-0.0057586}
};
rMatsBase34 = {
{-0.2838706,0.5844269,-0.7601728},
{0.8391505,0.5350061,0.0979538},
{0.4639439,-0.6100932,-0.6422946}
};
outThetasWam34 = {
{-0.0719135,-0.3763683,-0.0279967,1.5397327,-0.6260965,-1.6000000,0.0000000}
};
(* 
W1104 07:49:59.041332  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.042003  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.042642  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.052634  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.053284  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.053918  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.054558  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.055210  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.055858  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.065235  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.065861  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.066493  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.067122  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.067749  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.068367  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.076145  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.076766  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.077383  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.077996  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.078625  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.079257  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.079921  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.080550  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.092263  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.092934  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.174974e+02
Final                            2.586853e-01
Change                           2.172387e+02

Minimizer iterations                       80
Successful steps                           74
Unsuccessful steps                          6
Line search steps                         224

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0023
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2160
    Line search gradient evaluation    0.1725
  Linear solver                        0.0007
  Line search polynomial minimization  0.0016
Minimizer                              0.2219

Postprocessor                          0.0000
Total                                  0.2219

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr35 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe35 = {
{0.0035742,-0.0070585,-0.0054277}
};
rMatsBase35 = {
{-0.2834435,0.5747859,-0.7676463},
{0.8366838,0.5393940,0.0949441},
{0.4686364,-0.6153659,-0.6338018}
};
outThetasWam35 = {
{-0.0711261,-0.3771877,-0.0261686,1.5461905,-0.6144604,-1.6000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.164093e+02
Final                            6.700078e-03
Change                           2.164026e+02

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0127
    Line search gradient evaluation    0.0061
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0132

Postprocessor                          0.0000
Total                                  0.0133

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 8.391421e-11 <= 1.000000e-10)

*) 
fitErrUA36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr36 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe36 = {
{0.0031683,-0.0063134,-0.0049821}
};
rMatsBase36 = {
{-0.2811979,0.5657543,-0.7751451},
{0.8353171,0.5419291,0.0925109},
{0.4724121,-0.6214780,-0.6249735}
};
outThetasWam36 = {
{-0.0706988,-0.3795373,-0.0251040,1.5519567,-0.6084817,-1.5820260,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.146422e+02
Final                            7.270938e-03
Change                           2.146349e+02

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0111
    Line search gradient evaluation    0.0053
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0116

Postprocessor                          0.0000
Total                                  0.0116

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.121503e-11 <= 1.000000e-10)

*) 
fitErrUA37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr37 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe37 = {
{0.0030598,-0.0061210,-0.0047468}
};
rMatsBase37 = {
{-0.2795002,0.5570910,-0.7820034},
{0.8333184,0.5453127,0.0906340},
{0.4769278,-0.6263256,-0.6166491}
};
outThetasWam37 = {
{-0.0703631,-0.3807841,-0.0241575,1.5567489,-0.5967774,-1.5784312,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.136690e+02
Final                            5.563712e-03
Change                           2.136634e+02

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0112
    Line search gradient evaluation    0.0053
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0117

Postprocessor                          0.0000
Total                                  0.0117

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.507594e-11 <= 1.000000e-10)

*) 
fitErrUA38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr38 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe38 = {
{0.0026167,-0.0051219,-0.0039875}
};
rMatsBase38 = {
{-0.2778194,0.5465770,-0.7899810},
{0.8302513,0.5502786,0.0887486},
{0.4832176,-0.6312267,-0.6066743}
};
outThetasWam38 = {
{-0.0701424,-0.3813363,-0.0232966,1.5602261,-0.5899039,-1.5546727,0.0000000}
};
(* 
W1104 07:49:59.299522  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.309443  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.311311  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.311947  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.312572  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.321794  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.322470  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.323220  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.323891  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.324534  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.325212  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.325831  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.333786  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.334403  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.335017  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.335680  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.336344  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.336977  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.337592  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.338210  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.348425  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.349107  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.349764  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.350422  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots
W1104 07:49:59.351078  4339 polynomial.cc:204] Trying to extract roots from a constant polynomial in FindPolynomialRoots

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.108711e+02
Final                            2.481395e-01
Change                           2.106230e+02

Minimizer iterations                       83
Successful steps                           77
Unsuccessful steps                          6
Line search steps                         203

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0025
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2104
    Line search gradient evaluation    0.1635
  Linear solver                        0.0007
  Line search polynomial minimization  0.0016
Minimizer                              0.2166

Postprocessor                          0.0000
Total                                  0.2166

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa39 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr39 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe39 = {
{0.0037164,-0.0074106,-0.0052089}
};
rMatsBase39 = {
{-0.2764586,0.5377360,-0.7964990},
{0.8272207,0.5550098,0.0875789},
{0.4891591,-0.6346685,-0.5982636}
};
outThetasWam39 = {
{-0.0699058,-0.3809659,-0.0224787,1.5658219,-0.5755345,-1.6000000,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.111135e+02
Final                            7.407912e-03
Change                           2.111061e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0104
    Line search gradient evaluation    0.0049
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0109

Postprocessor                          0.0000
Total                                  0.0109

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.869260e-11 <= 1.000000e-10)

*) 
fitErrUA40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr40 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe40 = {
{0.0030501,-0.0064547,-0.0049979}
};
rMatsBase40 = {
{-0.2732007,0.5266614,-0.8049777},
{0.8253770,0.5581403,0.0850426},
{0.4940791,-0.6411764,-0.5871785}
};
outThetasWam40 = {
{-0.0695557,-0.3829474,-0.0215729,1.5718445,-0.5843212,-1.5812588,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.137733e+02
Final                            7.465593e-01
Change                           2.130267e+02

Minimizer iterations                      501
Successful steps                          501
Unsuccessful steps                          0
Line search steps                         504

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0144
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.8753
    Line search gradient evaluation    0.5828
  Linear solver                        0.0036
  Line search polynomial minimization  0.0017
Minimizer                              0.9013

Postprocessor                          0.0000
Total                                  0.9013

Termination:                   NO_CONVERGENCE (Maximum number of iterations reached. Number of iterations: 500.)

*) 
fitErrUA41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr41 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe41 = {
{-0.0025078,0.0020901,-0.0009216}
};
rMatsBase41 = {
{-0.2698363,0.5152649,-0.8134436},
{0.8276586,0.5558491,0.0775435},
{0.4921073,-0.6523295,-0.5764517}
};
outThetasWam41 = {
{-0.0678176,-0.3901783,-0.0186108,1.5777883,-0.6500014,-1.4077195,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.053232e+02
Final                            5.759249e-03
Change                           2.053174e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0105
    Line search gradient evaluation    0.0049
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0109

Postprocessor                          0.0000
Total                                  0.0110

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.497203e-11 <= 1.000000e-10)

*) 
fitErrUA42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr42 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe42 = {
{0.0023297,-0.0056610,-0.0047418}
};
rMatsBase42 = {
{-0.2672943,0.5043461,-0.8210900},
{0.8261088,0.5586056,0.0741896},
{0.4960827,-0.6584792,-0.5659569}
};
outThetasWam42 = {
{-0.0670357,-0.3922863,-0.0170143,1.5846183,-0.5886301,-1.5646163,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.042643e+02
Final                            4.388889e-03
Change                           2.042599e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0099
    Line search gradient evaluation    0.0046
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0103

Postprocessor                          0.0000
Total                                  0.0104

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.290967e-11 <= 1.000000e-10)

*) 
fitErrUA43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa43 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr43 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe43 = {
{0.0020447,-0.0050872,-0.0043949}
};
rMatsBase43 = {
{-0.2646303,0.4932268,-0.8286725},
{0.8247067,0.5611338,0.0706237},
{0.4998297,-0.6647226,-0.5552605}
};
outThetasWam43 = {
{-0.0662026,-0.3946326,-0.0153578,1.5912184,-0.5926119,-1.5499722,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.008786e+02
Final                            5.603109e-03
Change                           2.008730e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0099
    Line search gradient evaluation    0.0047
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0104

Postprocessor                          0.0000
Total                                  0.0104

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.552092e-11 <= 1.000000e-10)

*) 
fitErrUA44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa44 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr44 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe44 = {
{0.0025159,-0.0062560,-0.0049425}
};
rMatsBase44 = {
{-0.2595648,0.4808587,-0.8374969},
{0.8236239,0.5630435,0.0680129},
{0.5042518,-0.6721286,-0.5421930}
};
outThetasWam44 = {
{-0.0657359,-0.3980848,-0.0143972,1.5991983,-0.5855202,-1.5708586,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          2.010663e+02
Final                            1.377705e-03
Change                           2.010650e+02

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0112
    Line search gradient evaluation    0.0052
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0116

Postprocessor                          0.0000
Total                                  0.0117

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.471845e-11 <= 1.000000e-10)

*) 
fitErrUA45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr45 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe45 = {
{0.0011209,-0.0034008,-0.0034737}
};
rMatsBase45 = {
{-0.2570875,0.4701199,-0.8443301},
{0.8229572,0.5645163,0.0637408},
{0.5066039,-0.6784605,-0.5320186}
};
outThetasWam45 = {
{-0.0646006,-0.4013331,-0.0123166,1.6055391,-0.5940001,-1.5149036,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.977953e+02
Final                            1.375263e-05
Change                           1.977953e+02

Minimizer iterations                       16
Successful steps                           16
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0192
    Line search gradient evaluation    0.0093
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0200

Postprocessor                          0.0000
Total                                  0.0201

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 8.121070e-11 <= 1.000000e-10)

*) 
fitErrUA46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr46 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe46 = {
{0.0008463,-0.0023755,-0.0023073}
};
rMatsBase46 = {
{-0.2518323,0.4615552,-0.8506158},
{0.8240984,0.5630918,0.0615593},
{0.5073878,-0.6854885,-0.5221716}
};
outThetasWam46 = {
{-0.0640950,-0.4067987,-0.0114885,1.6109222,-0.5827103,-1.4887924,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.957193e+02
Final                            3.455095e-06
Change                           1.957193e+02

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0117
    Line search gradient evaluation    0.0056
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0122

Postprocessor                          0.0000
Total                                  0.0122

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.945500e-11 <= 1.000000e-10)

*) 
fitErrUA47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr47 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe47 = {
{0.0002376,-0.0017948,-0.0025870}
};
rMatsBase47 = {
{-0.2491290,0.4526469,-0.8561808},
{0.8249166,0.5623458,0.0572699},
{0.5073927,-0.6920101,-0.5134926}
};
outThetasWam47 = {
{-0.0626877,-0.4119606,-0.0090839,1.6172950,-0.5876894,-1.4835159,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.920432e+02
Final                            6.845971e-04
Change                           1.920425e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0154
    Line search gradient evaluation    0.0073
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0161

Postprocessor                          0.0000
Total                                  0.0161

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.900613e-11 <= 1.000000e-10)

*) 
fitErrUA48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr48 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe48 = {
{0.0001721,-0.0012095,-0.0017198}
};
rMatsBase48 = {
{-0.2437559,0.4460623,-0.8611686},
{0.8274131,0.5588668,0.0552767},
{0.5059354,-0.6990682,-0.5053049}
};
outThetasWam48 = {
{-0.0618915,-0.4194226,-0.0078826,1.6227877,-0.5792171,-1.4635599,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.895281e+02
Final                            1.010688e-03
Change                           1.895271e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0105
    Line search gradient evaluation    0.0049
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0109

Postprocessor                          0.0000
Total                                  0.0110

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.043610e-11 <= 1.000000e-10)

*) 
fitErrUA49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr49 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe49 = {
{-0.0002338,-0.0006087,-0.0015777}
};
rMatsBase49 = {
{-0.2398189,0.4396440,-0.8655635},
{0.8296153,0.5558635,0.0524799},
{0.5042076,-0.7054991,-0.4980419}
};
outThetasWam49 = {
{-0.0607005,-0.4266209,-0.0059822,1.6281535,-0.5837897,-1.4531833,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.848276e+02
Final                            1.690375e-03
Change                           1.848259e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0103
    Line search gradient evaluation    0.0048
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0107

Postprocessor                          0.0000
Total                                  0.0107

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.951506e-12 <= 1.000000e-10)

*) 
fitErrUA50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr50 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe50 = {
{-0.0000932,-0.0008598,-0.0016303}
};
rMatsBase50 = {
{-0.2349590,0.4355035,-0.8689827},
{0.8330411,0.5508705,0.0508359},
{0.5008362,-0.7119540,-0.4922242}
};
outThetasWam50 = {
{-0.0596407,-0.4355195,-0.0043971,1.6337268,-0.5699894,-1.4595449,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.813956e+02
Final                            2.275339e-03
Change                           1.813933e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0104
    Line search gradient evaluation    0.0050
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0109

Postprocessor                          0.0000
Total                                  0.0109

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.846879e-11 <= 1.000000e-10)

*) 
fitErrUA51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr51 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe51 = {
{-0.0003020,-0.0003278,-0.0012331}
};
rMatsBase51 = {
{-0.2307375,0.4316848,-0.8720140},
{0.8361129,0.5463442,0.0492261},
{0.4976699,-0.7177439,-0.4869993}
};
outThetasWam51 = {
{-0.0585556,-0.4440938,-0.0027495,1.6383646,-0.5662065,-1.4475047,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.777763e+02
Final                            6.737600e-03
Change                           1.777695e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0106
    Line search gradient evaluation    0.0050
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0111

Postprocessor                          0.0000
Total                                  0.0111

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 9.263346e-11 <= 1.000000e-10)

*) 
fitErrUA52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr52 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe52 = {
{-0.0004906,0.0006555,-0.0000824}
};
rMatsBase52 = {
{-0.2247485,0.4311203,-0.8738555},
{0.8406117,0.5393361,0.0498853},
{0.4928084,-0.7233615,-0.4836197}
};
outThetasWam52 = {
{-0.0580164,-0.4548385,-0.0021345,1.6411310,-0.5584833,-1.4180171,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.748108e+02
Final                            6.848741e-03
Change                           1.748039e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0102
    Line search gradient evaluation    0.0048
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0107

Postprocessor                          0.0000
Total                                  0.0107

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.268674e-11 <= 1.000000e-10)

*) 
fitErrUA53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEl53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr53 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe53 = {
{-0.0007446,0.0007275,-0.0005693}
};
rMatsBase53 = {
{-0.2203330,0.4284301,-0.8762996},
{0.8443898,0.5335261,0.0485356},
{0.4883229,-0.7292445,-0.4793155}
};
outThetasWam53 = {
{-0.0567117,-0.4659337,-0.0001874,1.6446302,-0.5666486,-1.4191076,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.701551e+02
Final                            8.000477e-03
Change                           1.701471e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           1

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0104
    Line search gradient evaluation    0.0049
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0108

Postprocessor                          0.0000
Total                                  0.0109

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.960477e-11 <= 1.000000e-10)

*) 
fitErrUA54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr54 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe54 = {
{-0.0005678,0.0007505,-0.0001712}
};
rMatsBase54 = {
{-0.2154035,0.4270861,-0.8781793},
{0.8480894,0.5276217,0.0485761},
{0.4840926,-0.7343111,-0.4758587}
};
outThetasWam54 = {
{-0.0557825,-0.4773604,0.0010422,1.6467185,-0.5578283,-1.4176667,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.644021e+02
Final                            8.859230e-03
Change                           1.643933e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0103
    Line search gradient evaluation    0.0049
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0107

Postprocessor                          0.0000
Total                                  0.0107

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 8.902568e-11 <= 1.000000e-10)

*) 
fitErrUA55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr55 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe55 = {
{-0.0004265,0.0003295,-0.0005062}
};
rMatsBase55 = {
{-0.2105832,0.4261707,-0.8797916},
{0.8519322,0.5213877,0.0486451},
{0.4794436,-0.7392790,-0.4728640}
};
outThetasWam55 = {
{-0.0546575,-0.4901758,0.0025159,1.6488994,-0.5427344,-1.4312101,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.597427e+02
Final                            9.001721e-03
Change                           1.597337e+02

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           0

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0002
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0100
    Line search gradient evaluation    0.0047
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0104

Postprocessor                          0.0000
Total                                  0.0105

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.341327e-11 <= 1.000000e-10)

*) 
fitErrUA56 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr56 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe56 = {
{-0.0002374,-0.0002131,-0.0007935}
};
rMatsBase56 = {
{-0.2060438,0.4270232,-0.8804528},
{0.8561991,0.5143101,0.0490745},
{0.4737817,-0.7437314,-0.4715873}
};
outThetasWam56 = {
{-0.0535011,-0.5039720,0.0040106,1.6510943,-0.5402012,-1.4390710,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.546969e+02
Final                            8.837905e-03
Change                           1.546881e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0142
    Line search gradient evaluation    0.0067
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0148

Postprocessor                          0.0000
Total                                  0.0148

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.684430e-11 <= 1.000000e-10)

*) 
fitErrUA57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa57 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr57 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe57 = {
{-0.0000903,-0.0007661,-0.0011196}
};
rMatsBase57 = {
{-0.2017596,0.4285985,-0.8806795},
{0.8605360,0.5069709,0.0495817},
{0.4677296,-0.7478528,-0.4711106}
};
outThetasWam57 = {
{-0.0522589,-0.5185754,0.0056497,1.6534181,-0.5358827,-1.4471086,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.464308e+02
Final                            2.404193e-01
Change                           1.461904e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0147
    Line search gradient evaluation    0.0077
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0153

Postprocessor                          0.0000
Total                                  0.0153

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.254464e-11 <= 1.000000e-10)

*) 
fitErrUA58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa58 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr58 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe58 = {
{-0.0168290,0.0237722,0.0176427}
};
rMatsBase58 = {
{-0.1945109,0.4431851,-0.8750728},
{0.8709370,0.4884425,0.0537826},
{0.4512584,-0.7516720,-0.4809937}
};
outThetasWam58 = {
{-0.0519307,-0.5409210,0.0061555,1.6567272,-0.6733866,-0.8662667,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.438147e+02
Final                            1.977899e-01
Change                           1.436169e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0158
    Line search gradient evaluation    0.0085
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0165

Postprocessor                          0.0000
Total                                  0.0165

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.147260e-11 <= 1.000000e-10)

*) 
fitErrUA59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa59 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr59 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe59 = {
{-0.0184697,0.0254248,0.0178076}
};
rMatsBase59 = {
{-0.1909293,0.4379276,-0.8785018},
{0.8718100,0.4869400,0.0532615},
{0.4511023,-0.7557175,-0.4747607}
};
outThetasWam59 = {
{-0.0504427,-0.5525069,0.0084702,1.6607914,-0.7207813,-0.8408366,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.377622e+02
Final                            2.319613e-01
Change                           1.375303e+02

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0137
    Line search gradient evaluation    0.0070
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0142

Postprocessor                          0.0000
Total                                  0.0142

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 7.230128e-11 <= 1.000000e-10)

*) 
fitErrUA60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa60 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr60 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe60 = {
{-0.0193787,0.0269273,0.0196862}
};
rMatsBase60 = {
{-0.1849866,0.4364154,-0.8805235},
{0.8738620,0.4829631,0.0557848},
{0.4496057,-0.7591365,-0.4707085}
};
outThetasWam60 = {
{-0.0498684,-0.5668276,0.0094037,1.6635221,-0.7184765,-0.7979892,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.367208e+02
Final                            2.469691e-01
Change                           1.364738e+02

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           2

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0139
    Line search gradient evaluation    0.0072
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0145

Postprocessor                          0.0000
Total                                  0.0145

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 8.100187e-11 <= 1.000000e-10)

*) 
fitErrUA61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa61 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr61 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe61 = {
{-0.0199625,0.0277006,0.0197155}
};
rMatsBase61 = {
{-0.1845528,0.4343984,-0.8816112},
{0.8739845,0.4828367,0.0549530},
{0.4495457,-0.7603728,-0.4687664}
};
outThetasWam61 = {
{-0.0473025,-0.5826421,0.0116167,1.6661054,-0.7553460,-0.7857890,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.306260e+02
Final                            2.959255e-01
Change                           1.303301e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0154
    Line search gradient evaluation    0.0083
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0159

Postprocessor                          0.0000
Total                                  0.0160

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.290790e-11 <= 1.000000e-10)

*) 
fitErrUA62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa62 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr62 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe62 = {
{-0.0215424,0.0294148,0.0218988}
};
rMatsBase62 = {
{-0.1823632,0.4388204,-0.8798752},
{0.8756972,0.4794128,0.0576004},
{0.4470996,-0.7600000,-0.4717011}
};
outThetasWam62 = {
{-0.0452953,-0.6035374,0.0124802,1.6686032,-0.7829050,-0.7343765,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.283702e+02
Final                            2.479660e-01
Change                           1.281222e+02

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           2

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0135
    Line search gradient evaluation    0.0069
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0140

Postprocessor                          0.0000
Total                                  0.0140

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.893153e-11 <= 1.000000e-10)

*) 
fitErrUA63 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl63 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa63 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr63 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe63 = {
{-0.0215081,0.0300245,0.0219867}
};
rMatsBase63 = {
{-0.1769011,0.4384023,-0.8811977},
{0.8779071,0.4750446,0.0600976},
{0.4449551,-0.7629785,-0.4689124}
};
outThetasWam63 = {
{-0.0453184,-0.6144283,0.0133744,1.6700647,-0.7965566,-0.7300590,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.264885e+02
Final                            3.022854e-01
Change                           1.261862e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0157
    Line search gradient evaluation    0.0084
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0162

Postprocessor                          0.0000
Total                                  0.0162

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.119194e-11 <= 1.000000e-10)

*) 
fitErrUA64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr64 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe64 = {
{-0.0221725,0.0310960,0.0224844}
};
rMatsBase64 = {
{-0.1774864,0.4406100,-0.8799781},
{0.8785634,0.4738356,0.0600511},
{0.4434241,-0.7624583,-0.4712031}
};
outThetasWam64 = {
{-0.0424052,-0.6330524,0.0157552,1.6698836,-0.8297894,-0.7114350,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.223643e+02
Final                            2.689527e-01
Change                           1.220954e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0169
    Line search gradient evaluation    0.0091
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0176

Postprocessor                          0.0000
Total                                  0.0176

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.333422e-11 <= 1.000000e-10)

*) 
fitErrUA65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa65 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr65 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe65 = {
{-0.0225218,0.0321562,0.0231839}
};
rMatsBase65 = {
{-0.1729909,0.4395612,-0.8813967},
{0.8805585,0.4699262,0.0615305},
{0.4412378,-0.7654771,-0.4683524}
};
outThetasWam65 = {
{-0.0419755,-0.6435122,0.0174956,1.6692765,-0.8427823,-0.6930944,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.194614e+02
Final                            2.907408e-01
Change                           1.191707e+02

Minimizer iterations                       13
Successful steps                           13
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0186
    Line search gradient evaluation    0.0098
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0193

Postprocessor                          0.0000
Total                                  0.0193

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.419576e-12 <= 1.000000e-10)

*) 
fitErrUA66 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl66 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa66 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr66 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe66 = {
{-0.0230158,0.0330453,0.0237319}
};
rMatsBase66 = {
{-0.1689751,0.4390663,-0.8824218},
{0.8815027,0.4678248,0.0639764},
{0.4409087,-0.7670467,-0.4660889}
};
outThetasWam66 = {
{-0.0402552,-0.6559848,0.0198244,1.6674002,-0.8704017,-0.6738271,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.160450e+02
Final                            2.960780e-01
Change                           1.157489e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0172
    Line search gradient evaluation    0.0093
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0179

Postprocessor                          0.0000
Total                                  0.0179

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.482104e-11 <= 1.000000e-10)

*) 
fitErrUA67 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl67 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa67 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr67 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe67 = {
{-0.0234058,0.0339244,0.0244725}
};
rMatsBase67 = {
{-0.1657067,0.4383456,-0.8833994},
{0.8823932,0.4659078,0.0656670},
{0.4403675,-0.7686241,-0.4639972}
};
outThetasWam67 = {
{-0.0384850,-0.6674384,0.0219260,1.6644946,-0.8978049,-0.6541222,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.110113e+02
Final                            3.113278e-01
Change                           1.106999e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           5

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0174
    Line search gradient evaluation    0.0094
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0182

Postprocessor                          0.0000
Total                                  0.0182

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.385026e-11 <= 1.000000e-10)

*) 
fitErrUA68 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl68 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa68 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr68 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe68 = {
{-0.0244473,0.0352260,0.0257712}
};
rMatsBase68 = {
{-0.1642521,0.4362842,-0.8846905},
{0.8831884,0.4644805,0.0650849},
{0.4393170,-0.7706581,-0.4616131}
};
outThetasWam68 = {
{-0.0366143,-0.6788503,0.0234489,1.6614833,-0.9362978,-0.6205872,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.108005e+02
Final                            2.791760e-01
Change                           1.105213e+02

Minimizer iterations                       12
Successful steps                           12
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0171
    Line search gradient evaluation    0.0092
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0179

Postprocessor                          0.0000
Total                                  0.0179

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.847500e-11 <= 1.000000e-10)

*) 
fitErrUA69 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl69 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa69 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr69 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe69 = {
{-0.0239586,0.0350684,0.0258634}
};
rMatsBase69 = {
{-0.1611315,0.4367260,-0.8850464},
{0.8827855,0.4647398,0.0686059},
{0.4412782,-0.7702515,-0.4604196}
};
outThetasWam69 = {
{-0.0378388,-0.6848222,0.0233818,1.6586635,-0.9557624,-0.6265031,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          9.998486e+01
Final                            4.022972e-01
Change                           9.958256e+01

Minimizer iterations                       16
Successful steps                           16
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0231
    Line search gradient evaluation    0.0124
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0240

Postprocessor                          0.0000
Total                                  0.0240

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.695977e-11 <= 1.000000e-10)

*) 
fitErrUA70 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl70 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa70 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr70 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe70 = {
{-0.0278838,0.0379556,0.0292694}
};
rMatsBase70 = {
{-0.1638574,0.4293953,-0.8881275},
{0.8833647,0.4646133,0.0616544},
{0.4391100,-0.7744379,-0.4554430}
};
outThetasWam70 = {
{-0.0356923,-0.7062629,0.0233703,1.6555327,-1.1045639,-0.5469249,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.036436e+02
Final                            3.260306e-01
Change                           1.033175e+02

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0004
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0217
    Line search gradient evaluation    0.0125
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0227

Postprocessor                          0.0000
Total                                  0.0227

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.911538e-11 <= 1.000000e-10)

*) 
fitErrUA71 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl71 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa71 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr71 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe71 = {
{-0.0261745,0.0376341,0.0275433}
};
rMatsBase71 = {
{-0.1622045,0.4280940,-0.8890586},
{0.8841253,0.4631567,0.0617119},
{0.4381920,-0.7760293,-0.4536148}
};
outThetasWam71 = {
{-0.0339096,-0.7154879,0.0248728,1.6521564,-1.1092396,-0.5861865,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.028087e+02
Final                            3.255528e-01
Change                           1.024832e+02

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0001

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0215
    Line search gradient evaluation    0.0123
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0224

Postprocessor                          0.0000
Total                                  0.0225

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.967493e-11 <= 1.000000e-10)

*) 
fitErrUA72 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl72 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa72 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr72 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe72 = {
{-0.0260457,0.0379764,0.0277403}
};
rMatsBase72 = {
{-0.1584016,0.4279701,-0.8898037},
{0.8844199,0.4621651,0.0648450},
{0.4389879,-0.7766885,-0.4517129}
};
outThetasWam72 = {
{-0.0334404,-0.7238381,0.0260954,1.6475641,-1.1538820,-0.5916161,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          1.001788e+02
Final                            3.331112e-01
Change                           9.984569e+01

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           7

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0226
    Line search gradient evaluation    0.0131
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0236

Postprocessor                          0.0000
Total                                  0.0236

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.150102e-11 <= 1.000000e-10)

*) 
fitErrUA73 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl73 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa73 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr73 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrEe73 = {
{-0.0264884,0.0386794,0.0284326}
};
rMatsBase73 = {
{-0.1564836,0.4268904,-0.8906612},
{0.8848326,0.4612645,0.0656227},
{0.4388441,-0.7778172,-0.4499069}
};
outThetasWam73 = {
{-0.0324568,-0.7319367,0.0270672,1.6425192,-1.2039902,-0.5831088,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          9.804039e+01
Final                            3.428570e-01
Change                           9.769753e+01

Minimizer iterations                       14
Successful steps                           14
Unsuccessful steps                          0
Line search steps                           8

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0233
    Line search gradient evaluation    0.0140
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0242

Postprocessor                          0.0000
Total                                  0.0243

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.132339e-11 <= 1.000000e-10)

*) 
fitErrUA74 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl74 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrLa74 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr74 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe74 = {
{-0.0268509,0.0393294,0.0288188}
};
rMatsBase74 = {
{-0.1533462,0.4261666,-0.8915531},
{0.8852363,0.4601867,0.0677117},
{0.4391374,-0.7788519,-0.4478260}
};
outThetasWam74 = {
{-0.0315487,-0.7403808,0.0282970,1.6366261,-1.2569681,-0.5816496,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          9.478187e+01
Final                            3.501524e-01
Change                           9.443172e+01

Minimizer iterations                       16
Successful steps                           16
Unsuccessful steps                          0
Line search steps                          12

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0281
    Line search gradient evaluation    0.0176
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0292

Postprocessor                          0.0000
Total                                  0.0293

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.715694e-11 <= 1.000000e-10)

*) 
fitErrUA75 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl75 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa75 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr75 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe75 = {
{-0.0274610,0.0401682,0.0294603}
};
rMatsBase75 = {
{-0.1509234,0.4251384,-0.8924570},
{0.8857843,0.4589630,0.0688405},
{0.4388715,-0.7801348,-0.4458492}
};
outThetasWam75 = {
{-0.0302104,-0.7484358,0.0295916,1.6306949,-1.3089848,-0.5723611,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          9.152416e+01
Final                            3.584482e-01
Change                           9.116571e+01

Minimizer iterations                       16
Successful steps                           16
Unsuccessful steps                          0
Line search steps                          11

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0271
    Line search gradient evaluation    0.0165
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0282

Postprocessor                          0.0000
Total                                  0.0282

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.646505e-11 <= 1.000000e-10)

*) 
fitErrUA76 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl76 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa76 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr76 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe76 = {
{-0.0281363,0.0410650,0.0300305}
};
rMatsBase76 = {
{-0.1472868,0.4244628,-0.8933857},
{0.8862588,0.4576648,0.0713325},
{0.4391491,-0.7812646,-0.4435918}
};
outThetasWam76 = {
{-0.0290619,-0.7562986,0.0310485,1.6247948,-1.3632651,-0.5658964,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          8.716286e+01
Final                            3.707523e-01
Change                           8.679211e+01

Minimizer iterations                       15
Successful steps                           15
Unsuccessful steps                          0
Line search steps                          10

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0252
    Line search gradient evaluation    0.0150
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0262

Postprocessor                          0.0000
Total                                  0.0262

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.076916e-11 <= 1.000000e-10)

*) 
fitErrUA77 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl77 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa77 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr77 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe77 = {
{-0.0291027,0.0420804,0.0309371}
};
rMatsBase77 = {
{-0.1454036,0.4230354,-0.8943706},
{0.8870257,0.4561433,0.0715453},
{0.4382274,-0.7829267,-0.4415682}
};
outThetasWam77 = {
{-0.0270985,-0.7643223,0.0325382,1.6193697,-1.4278920,-0.5532754,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          8.419073e+01
Final                            3.767910e-01
Change                           8.381394e+01

Minimizer iterations                       15
Successful steps                           15
Unsuccessful steps                          0
Line search steps                          10

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0258
    Line search gradient evaluation    0.0158
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0268

Postprocessor                          0.0000
Total                                  0.0269

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.538947e-11 <= 1.000000e-10)

*) 
fitErrUA78 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl78 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa78 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr78 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe78 = {
{-0.0295975,0.0428976,0.0312376}
};
rMatsBase78 = {
{-0.1408718,0.4224460,-0.8953740},
{0.8877738,0.4541918,0.0746159},
{0.4381927,-0.7843782,-0.4390193}
};
outThetasWam78 = {
{-0.0252143,-0.7719655,0.0346519,1.6137023,-1.4764976,-0.5517736,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          7.998862e+01
Final                            3.781775e-01
Change                           7.961045e+01

Minimizer iterations                       17
Successful steps                           17
Unsuccessful steps                          0
Line search steps                          12

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0290
    Line search gradient evaluation    0.0178
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0301

Postprocessor                          0.0000
Total                                  0.0302

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 9.610091e-11 <= 1.000000e-10)

*) 
fitErrUA79 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl79 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa79 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr79 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEe79 = {
{-0.0305731,0.0437534,0.0321293}
};
rMatsBase79 = {
{-0.1394017,0.4211202,-0.8962282},
{0.8886801,0.4524559,0.0743725},
{0.4368235,-0.7860925,-0.4373143}
};
outThetasWam79 = {
{-0.0228817,-0.7785011,0.0362809,1.6100718,-1.5458212,-0.5465465,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          7.711101e+01
Final                            3.841097e-01
Change                           7.672690e+01

Minimizer iterations                       17
Successful steps                           17
Unsuccessful steps                          0
Line search steps                          11

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0281
    Line search gradient evaluation    0.0169
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0292

Postprocessor                          0.0000
Total                                  0.0292

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 3.481659e-11 <= 1.000000e-10)

*) 
fitErrUA80 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl80 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa80 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr80 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe80 = {
{-0.0310470,0.0443383,0.0326750}
};
rMatsBase80 = {
{-0.1378075,0.4196858,-0.8971471},
{0.8893919,0.4510530,0.0743866},
{0.4358798,-0.7876643,-0.4354236}
};
outThetasWam80 = {
{-0.0209789,-0.7849556,0.0375945,1.6065341,-1.5966345,-0.5472225,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          7.472011e+01
Final                            3.866708e-01
Change                           7.433344e+01

Minimizer iterations                       17
Successful steps                           17
Unsuccessful steps                          0
Line search steps                          12

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0005
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0289
    Line search gradient evaluation    0.0176
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0299

Postprocessor                          0.0000
Total                                  0.0299

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 8.908785e-11 <= 1.000000e-10)

*) 
fitErrUA81 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl81 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa81 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr81 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe81 = {
{-0.0315759,0.0447636,0.0329172}
};
rMatsBase81 = {
{-0.1357517,0.4183776,-0.8980711},
{0.8902369,0.4493217,0.0747545},
{0.4347984,-0.7893480,-0.4334514}
};
outThetasWam81 = {
{-0.0187402,-0.7912531,0.0392382,1.6038819,-1.6485996,-0.5559401,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          7.328711e+01
Final                            3.808606e-01
Change                           7.290625e+01

Minimizer iterations                       18
Successful steps                           18
Unsuccessful steps                          0
Line search steps                          11

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0301
    Line search gradient evaluation    0.0183
  Linear solver                        0.0001
  Line search polynomial minimization  0.0001
Minimizer                              0.0311

Postprocessor                          0.0000
Total                                  0.0311

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 4.057199e-12 <= 1.000000e-10)

*) 
fitErrUA82 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl82 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa82 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr82 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe82 = {
{-0.0316160,0.0450221,0.0330096}
};
rMatsBase82 = {
{-0.1331556,0.4174844,-0.8988751},
{0.8908533,0.4478801,0.0760516},
{0.4343386,-0.7906391,-0.4315550}
};
outThetasWam82 = {
{-0.0170592,-0.7962812,0.0406801,1.6017133,-1.6767444,-0.5637749,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.989157e+01
Final                            3.905278e-01
Change                           6.950104e+01

Minimizer iterations                       19
Successful steps                           19
Unsuccessful steps                          0
Line search steps                          13

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0320
    Line search gradient evaluation    0.0196
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0331

Postprocessor                          0.0000
Total                                  0.0332

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.919620e-11 <= 1.000000e-10)

*) 
fitErrUA83 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEl83 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa83 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr83 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe83 = {
{-0.0324295,0.0456635,0.0337447}
};
rMatsBase83 = {
{-0.1322508,0.4159514,-0.8997190},
{0.8915966,0.4465138,0.0753721},
{0.4330880,-0.7922183,-0.4299126}
};
outThetasWam83 = {
{-0.0150441,-0.8018029,0.0418606,1.6003685,-1.7326147,-0.5653896,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.692840e+01
Final                            4.035949e-01
Change                           6.652481e+01

Minimizer iterations                       20
Successful steps                           20
Unsuccessful steps                          0
Line search steps                          14

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0341
    Line search gradient evaluation    0.0210
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0352

Postprocessor                          0.0000
Total                                  0.0353

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 5.057998e-11 <= 1.000000e-10)

*) 
fitErrUA84 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl84 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa84 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr84 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrEe84 = {
{-0.0330494,0.0462215,0.0343940}
};
rMatsBase84 = {
{-0.1310706,0.4139585,-0.9008101},
{0.8921323,0.4455179,0.0749254},
{0.4323430,-0.7938213,-0.4277000}
};
outThetasWam84 = {
{-0.0134535,-0.8083792,0.0426796,1.5987314,-1.7864217,-0.5736505,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.481270e+01
Final                            4.044497e-01
Change                           6.440826e+01

Minimizer iterations                       20
Successful steps                           20
Unsuccessful steps                          0
Line search steps                          14

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0341
    Line search gradient evaluation    0.0208
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0353

Postprocessor                          0.0000
Total                                  0.0353

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 2.226130e-11 <= 1.000000e-10)

*) 
fitErrUA85 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl85 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa85 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr85 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe85 = {
{-0.0333409,0.0468023,0.0350686}
};
rMatsBase85 = {
{-0.1323284,0.4116106,-0.9017017},
{0.8924965,0.4452284,0.0722612},
{0.4312066,-0.7952034,-0.4262774}
};
outThetasWam85 = {
{-0.0123213,-0.8140263,0.0426161,1.5973524,-1.8227725,-0.5755193,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.490315e+01
Final                            3.983308e-01
Change                           6.450482e+01

Minimizer iterations                       20
Successful steps                           20
Unsuccessful steps                          0
Line search steps                          14

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0343
    Line search gradient evaluation    0.0211
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0354

Postprocessor                          0.0000
Total                                  0.0355

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.668444e-12 <= 1.000000e-10)

*) 
fitErrUA86 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl86 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrLa86 = {
{-0.0000000,0.0000000,0.0000000}
};
fitErrWr86 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe86 = {
{-0.0331847,0.0470152,0.0348176}
};
rMatsBase86 = {
{-0.1315863,0.4101653,-0.9024685},
{0.8928851,0.4445167,0.0718406},
{0.4306288,-0.7963475,-0.4247228}
};
outThetasWam86 = {
{-0.0111591,-0.8184620,0.0431677,1.5959752,-1.8336459,-0.5889486,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.307630e+01
Final                            4.025114e-01
Change                           6.267379e+01

Minimizer iterations                       20
Successful steps                           20
Unsuccessful steps                          0
Line search steps                          13

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0006
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0340
    Line search gradient evaluation    0.0209
  Linear solver                        0.0002
  Line search polynomial minimization  0.0001
Minimizer                              0.0351

Postprocessor                          0.0000
Total                                  0.0352

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.364687e-11 <= 1.000000e-10)

*) 
fitErrUA87 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl87 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrLa87 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrWr87 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe87 = {
{-0.0335377,0.0473798,0.0354147}
};
rMatsBase87 = {
{-0.1326914,0.4081765,-0.9032081},
{0.8929933,0.4446329,0.0697472},
{0.4300652,-0.7973039,-0.4234978}
};
outThetasWam87 = {
{-0.0106713,-0.8229052,0.0427619,1.5948705,-1.8671738,-0.5940085,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.210546e+01
Final                            8.859778e+00
Change                           5.324569e+01

Minimizer iterations                      134
Successful steps                          134
Unsuccessful steps                          0
Line search steps                          64

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0045
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2119
    Line search gradient evaluation    0.1235
  Linear solver                        0.0012
  Line search polynomial minimization  0.0005
Minimizer                              0.2201

Postprocessor                          0.0000
Total                                  0.2201

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA88 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrEl88 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrLa88 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrWr88 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe88 = {
{-0.0222127,0.0463178,0.0421128}
};
rMatsBase88 = {
{-0.1342192,0.4060959,-0.9039200},
{0.8932870,0.4444595,0.0670379},
{0.4289796,-0.7984622,-0.4224152}
};
outThetasWam88 = {
{-0.0097150,-0.8274463,0.0425497,1.5932500,-4.7600000,0.4300346,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.257324e+01
Final                            9.724677e+00
Change                           5.284856e+01

Minimizer iterations                      120
Successful steps                          119
Unsuccessful steps                          1
Line search steps                          54

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0040
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1878
    Line search gradient evaluation    0.1094
  Linear solver                        0.0011
  Line search polynomial minimization  0.0004
Minimizer                              0.1953

Postprocessor                          0.0000
Total                                  0.1953

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA89 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEl89 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa89 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr89 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe89 = {
{-0.0216294,0.0463984,0.0417111}
};
rMatsBase89 = {
{-0.1365274,0.4045553,-0.9042650},
{0.8933988,0.4446747,0.0640544},
{0.4280173,-0.7991241,-0.4221395}
};
outThetasWam89 = {
{-0.0092779,-0.8300809,0.0419721,1.5936638,-4.7600000,0.4474297,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.097436e+01
Final                            1.094408e+01
Change                           5.003029e+01

Minimizer iterations                      104
Successful steps                          103
Unsuccessful steps                          1
Line search steps                          90

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0035
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1913
    Line search gradient evaluation    0.1235
  Linear solver                        0.0009
  Line search polynomial minimization  0.0006
Minimizer                              0.1980

Postprocessor                          0.0000
Total                                  0.1980

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA90 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEl90 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrLa90 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr90 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe90 = {
{-0.0205918,0.0463352,0.0430811}
};
rMatsBase90 = {
{-0.1398634,0.4021248,-0.9048391},
{0.8935345,0.4450138,0.0596551},
{0.4266547,-0.8001614,-0.4215536}
};
outThetasWam90 = {
{-0.0086381,-0.8343598,0.0410710,1.5938483,-4.7600000,0.4302058,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.370201e+01
Final                            1.085128e+01
Change                           5.285073e+01

Minimizer iterations                      119
Successful steps                          119
Unsuccessful steps                          0
Line search steps                          64

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0039
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1916
    Line search gradient evaluation    0.1136
  Linear solver                        0.0011
  Line search polynomial minimization  0.0005
Minimizer                              0.1989

Postprocessor                          0.0000
Total                                  0.1989

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA91 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrEl91 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrLa91 = {
{-0.0000000,-0.0000000,0.0000000}
};
fitErrWr91 = {
{0.0000000,-0.0000000,0.0000000}
};
fitErrEe91 = {
{-0.0200884,0.0460898,0.0422806}
};
rMatsBase91 = {
{-0.1422482,0.4007044,-0.9050975},
{0.8933871,0.4456703,0.0568993},
{0.4261748,-0.8005086,-0.4213799}
};
outThetasWam91 = {
{-0.0087960,-0.8364686,0.0400890,1.5945917,-4.7600000,0.4554319,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.384960e+01
Final                            1.131384e+01
Change                           5.253576e+01

Minimizer iterations                      115
Successful steps                          115
Unsuccessful steps                          0
Line search steps                          66

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1873
    Line search gradient evaluation    0.1120
  Linear solver                        0.0010
  Line search polynomial minimization  0.0005
Minimizer                              0.1944

Postprocessor                          0.0000
Total                                  0.1945

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA92 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl92 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa92 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrWr92 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe92 = {
{-0.0193265,0.0458318,0.0428588}
};
rMatsBase92 = {
{-0.1459498,0.3985864,-0.9054433},
{0.8930598,0.4468353,0.0527483},
{0.4256088,-0.8009164,-0.4211770}
};
outThetasWam92 = {
{-0.0092536,-0.8394682,0.0384346,1.5937979,-4.7600000,0.4534451,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.537036e+01
Final                            1.169912e+01
Change                           5.367124e+01

Minimizer iterations                      119
Successful steps                          116
Unsuccessful steps                          3
Line search steps                          64

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0039
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1912
    Line search gradient evaluation    0.1154
  Linear solver                        0.0011
  Line search polynomial minimization  0.0005
Minimizer                              0.1985

Postprocessor                          0.0000
Total                                  0.1985

Termination:                      CONVERGENCE (Parameter tolerance reached. Relative step_norm: 0.000000e+00 <= 1.000000e-100.)

*) 
fitErrUA93 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl93 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa93 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrWr93 = {
{0.0000000,0.0000000,-0.0000000}
};
fitErrEe93 = {
{-0.0187353,0.0456393,0.0426256}
};
rMatsBase93 = {
{-0.1483072,0.3970180,-0.9057492},
{0.8928539,0.4475639,0.0499854},
{0.4252258,-0.8012885,-0.4208560}
};
outThetasWam93 = {
{-0.0094753,-0.8419119,0.0373512,1.5935442,-4.7600000,0.4663518,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.637076e+01
Final                            1.171471e+01
Change                           5.465605e+01

Minimizer iterations                      119
Successful steps                          118
Unsuccessful steps                          1
Line search steps                          78

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0038
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.1991
    Line search gradient evaluation    0.1220
  Linear solver                        0.0010
  Line search polynomial minimization  0.0005
Minimizer                              0.2061

Postprocessor                          0.0000
Total                                  0.2061

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA94 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEl94 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrLa94 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrWr94 = {
{0.0000000,0.0000000,0.0000000}
};
fitErrEe94 = {
{-0.0183128,0.0454709,0.0426053}
};
rMatsBase94 = {
{-0.1516723,0.3953700,-0.9059128},
{0.8925005,0.4486553,0.0463811},
{0.4247803,-0.8014930,-0.4209166}
};
outThetasWam94 = {
{-0.0099953,-0.8439542,0.0358291,1.5923257,-4.7600000,0.4728329,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.758437e+01
Final                            1.593625e-05
Change                           6.758435e+01

Minimizer iterations                       10
Successful steps                           10
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0143
    Line search gradient evaluation    0.0078
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0149

Postprocessor                          0.0000
Total                                  0.0149

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 7.615775e-11 <= 1.000000e-10)

*) 
fitErrUA95 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl95 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa95 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr95 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEe95 = {
{0.0002987,-0.0008905,0.0000088}
};
rMatsBase95 = {
{-0.1550285,0.3940007,-0.9059413},
{0.8920781,0.4498326,0.0429794},
{0.4244559,-0.8015073,-0.4212163}
};
outThetasWam95 = {
{-0.0106909,-0.8452996,0.0342605,1.5909187,-0.8509049,-1.4887962,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.872561e+01
Final                            2.756065e-05
Change                           6.872559e+01

Minimizer iterations                       11
Successful steps                           11
Unsuccessful steps                          0
Line search steps                           4

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0150
    Line search gradient evaluation    0.0078
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0156

Postprocessor                          0.0000
Total                                  0.0157

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 6.472156e-11 <= 1.000000e-10)

*) 
fitErrUA96 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl96 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa96 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr96 = {
{-0.0000000,0.0000000,-0.0000000}
};
fitErrEe96 = {
{0.0003647,-0.0008889,0.0000534}
};
rMatsBase96 = {
{-0.1586896,0.3926178,-0.9059078},
{0.8917314,0.4508644,0.0391970},
{0.4238310,-0.8016063,-0.4216571}
};
outThetasWam96 = {
{-0.0111469,-0.8465974,0.0327746,1.5890088,-0.8589616,-1.4897067,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          6.869402e+01
Final                            1.267745e+01
Change                           5.601657e+01

Minimizer iterations                      129
Successful steps                          125
Unsuccessful steps                          4
Line search steps                         168

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0042
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.2648
    Line search gradient evaluation    0.1832
  Linear solver                        0.0011
  Line search polynomial minimization  0.0009
Minimizer                              0.2729

Postprocessor                          0.0000
Total                                  0.2730

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA97 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl97 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa97 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr97 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe97 = {
{-0.0169309,0.0450411,0.0429685}
};
rMatsBase97 = {
{-0.1611001,0.3909915,-0.9061856},
{0.8912707,0.4519943,0.0365733},
{0.4238906,-0.8017648,-0.4212956}
};
outThetasWam97 = {
{-0.0118643,-0.8489934,0.0312846,1.5872231,-4.7600000,0.4856612,0.0000000}
};
(* 

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                            1                        1
Parameters                                  3                        3
Residual blocks                             1                        1
Residual                                    3                        3

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                        1

Cost:
Initial                          7.083383e+01
Final                            6.726586e-06
Change                           7.083382e+01

Minimizer iterations                        9
Successful steps                            9
Unsuccessful steps                          0
Line search steps                           3

Time (in seconds):
Preprocessor                           0.0000

  Residual evaluation                  0.0003
    Line search cost evaluation        0.0000
  Jacobian evaluation                  0.0124
    Line search gradient evaluation    0.0066
  Linear solver                        0.0001
  Line search polynomial minimization  0.0000
Minimizer                              0.0129

Postprocessor                          0.0000
Total                                  0.0130

Termination:                      CONVERGENCE (Gradient tolerance reached. Gradient max norm: 1.391376e-11 <= 1.000000e-10)

*) 
fitErrUA98 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl98 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa98 = {
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr98 = {
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe98 = {
{0.0004213,-0.0005288,0.0001760}
};
rMatsBase98 = {
{-0.1648046,0.3899274,-0.9059780},
{0.8908220,0.4531534,0.0329869},
{0.4234095,-0.8016287,-0.4220377}
};
outThetasWam98 = {
{-0.0125508,-0.8494753,0.0297113,1.5853125,-0.8735327,-1.4888753,0.0000000}
};
fitErrUA Mean = 0.0000000
fitErrEl Mean = 0.0000000
fitErrLa Mean = 0.0000000
fitErrWr Mean = 0.0000000
fitErrEe Mean = 0.0266238
fitErrUA = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr = {
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe = {
{-0.0354113,-0.0782404,0.0772527},
{0.0022760,-0.0019143,-0.0021909},
{0.0017858,-0.0016006,-0.0018507},
{0.0023168,-0.0019245,-0.0020841},
{0.0018779,-0.0016977,-0.0018989},
{0.0008468,-0.0011841,-0.0015640},
{0.0011400,-0.0014010,-0.0017462},
{-0.0003290,-0.0003764,-0.0008052},
{-0.0015574,0.0001125,-0.0006424},
{-0.0012857,0.0004373,0.0000190},
{-0.0028277,0.0014154,0.0008493},
{-0.0270498,0.0097960,0.0220399},
{-0.0042775,0.0024173,0.0016351},
{-0.0048295,0.0028700,0.0020101},
{-0.0052979,0.0031275,0.0020384},
{-0.0069913,0.0042823,0.0029062},
{-0.0074507,0.0048351,0.0034661},
{-0.0079008,0.0053177,0.0038799},
{-0.0064375,0.0046888,0.0033438},
{-0.0046473,0.0035344,0.0021618},
{0.0059295,-0.0068742,-0.0040399},
{-0.0007660,-0.0050423,-0.0084182},
{0.0063129,-0.0071878,-0.0035650},
{0.0058267,-0.0072349,-0.0040831},
{0.0066543,-0.0076611,-0.0033499},
{0.0070370,-0.0079440,-0.0029494},
{-0.0071106,0.0070944,0.0066218},
{0.0053765,-0.0073921,-0.0042604},
{0.0044677,-0.0071081,-0.0049578},
{0.0047104,-0.0072573,-0.0046801},
{0.0037360,-0.0069130,-0.0054832},
{0.0037268,-0.0070528,-0.0056202},
{0.0038881,-0.0071279,-0.0053774},
{0.0039610,-0.0072661,-0.0053819},
{0.0033437,-0.0069514,-0.0057586},
{0.0035742,-0.0070585,-0.0054277},
{0.0031683,-0.0063134,-0.0049821},
{0.0030598,-0.0061210,-0.0047468},
{0.0026167,-0.0051219,-0.0039875},
{0.0037164,-0.0074106,-0.0052089},
{0.0030501,-0.0064547,-0.0049979},
{-0.0025078,0.0020901,-0.0009216},
{0.0023297,-0.0056610,-0.0047418},
{0.0020447,-0.0050872,-0.0043949},
{0.0025159,-0.0062560,-0.0049425},
{0.0011209,-0.0034008,-0.0034737},
{0.0008463,-0.0023755,-0.0023073},
{0.0002376,-0.0017948,-0.0025870},
{0.0001721,-0.0012095,-0.0017198},
{-0.0002338,-0.0006087,-0.0015777},
{-0.0000932,-0.0008598,-0.0016303},
{-0.0003020,-0.0003278,-0.0012331},
{-0.0004906,0.0006555,-0.0000824},
{-0.0007446,0.0007275,-0.0005693},
{-0.0005678,0.0007505,-0.0001712},
{-0.0004265,0.0003295,-0.0005062},
{-0.0002374,-0.0002131,-0.0007935},
{-0.0000903,-0.0007661,-0.0011196},
{-0.0168290,0.0237722,0.0176427},
{-0.0184697,0.0254248,0.0178076},
{-0.0193787,0.0269273,0.0196862},
{-0.0199625,0.0277006,0.0197155},
{-0.0215424,0.0294148,0.0218988},
{-0.0215081,0.0300245,0.0219867},
{-0.0221725,0.0310960,0.0224844},
{-0.0225218,0.0321562,0.0231839},
{-0.0230158,0.0330453,0.0237319},
{-0.0234058,0.0339244,0.0244725},
{-0.0244473,0.0352260,0.0257712},
{-0.0239586,0.0350684,0.0258634},
{-0.0278838,0.0379556,0.0292694},
{-0.0261745,0.0376341,0.0275433},
{-0.0260457,0.0379764,0.0277403},
{-0.0264884,0.0386794,0.0284326},
{-0.0268509,0.0393294,0.0288188},
{-0.0274610,0.0401682,0.0294603},
{-0.0281363,0.0410650,0.0300305},
{-0.0291027,0.0420804,0.0309371},
{-0.0295975,0.0428976,0.0312376},
{-0.0305731,0.0437534,0.0321293},
{-0.0310470,0.0443383,0.0326750},
{-0.0315759,0.0447636,0.0329172},
{-0.0316160,0.0450221,0.0330096},
{-0.0324295,0.0456635,0.0337447},
{-0.0330494,0.0462215,0.0343940},
{-0.0333409,0.0468023,0.0350686},
{-0.0331847,0.0470152,0.0348176},
{-0.0335377,0.0473798,0.0354147},
{-0.0222127,0.0463178,0.0421128},
{-0.0216294,0.0463984,0.0417111},
{-0.0205918,0.0463352,0.0430811},
{-0.0200884,0.0460898,0.0422806},
{-0.0193265,0.0458318,0.0428588},
{-0.0187353,0.0456393,0.0426256},
{-0.0183128,0.0454709,0.0426053},
{0.0002987,-0.0008905,0.0000088},
{0.0003647,-0.0008889,0.0000534},
{-0.0169309,0.0450411,0.0429685},
{0.0004213,-0.0005288,0.0001760}
};
outShoToUaVsWam = {
{-0.3938006,-0.3705459,-0.1005826},
{-0.3948034,-0.3695158,-0.1004407},
{-0.3965285,-0.3677113,-0.1002672},
{-0.3986010,-0.3656589,-0.0995528},
{-0.4008618,-0.3634268,-0.0986446},
{-0.4031109,-0.3609329,-0.0986362},
{-0.4057808,-0.3580799,-0.0980850},
{-0.4087193,-0.3549036,-0.0974265},
{-0.4132201,-0.3492220,-0.0989604},
{-0.4174501,-0.3444710,-0.0978528},
{-0.4218082,-0.3392198,-0.0975082},
{-0.4263963,-0.3334321,-0.0975150},
{-0.4310397,-0.3275073,-0.0971788},
{-0.4358662,-0.3212874,-0.0964109},
{-0.4416850,-0.3136535,-0.0950574},
{-0.4474944,-0.3054195,-0.0946977},
{-0.4532002,-0.2974845,-0.0928035},
{-0.4584396,-0.2898569,-0.0911925},
{-0.4635210,-0.2827381,-0.0877920},
{-0.4686856,-0.2751933,-0.0842762},
{-0.4733612,-0.2683002,-0.0802754},
{-0.4783310,-0.2605870,-0.0761178},
{-0.4831411,-0.2531332,-0.0706980},
{-0.4881207,-0.2450988,-0.0645352},
{-0.4927746,-0.2374525,-0.0573541},
{-0.4972569,-0.2297068,-0.0497027},
{-0.4997187,-0.2257840,-0.0424598},
{-0.5012567,-0.2224015,-0.0421815},
{-0.5029948,-0.2184163,-0.0423147},
{-0.5052108,-0.2134711,-0.0411352},
{-0.5075882,-0.2076244,-0.0417898},
{-0.5103565,-0.2007825,-0.0415042},
{-0.5124847,-0.1952932,-0.0414727},
{-0.5148997,-0.1891908,-0.0398136},
{-0.5169122,-0.1836955,-0.0394684},
{-0.5192234,-0.1773355,-0.0381993},
{-0.5216915,-0.1704997,-0.0356060},
{-0.5237280,-0.1645819,-0.0334928},
{-0.5258802,-0.1580303,-0.0312483},
{-0.5274619,-0.1530063,-0.0295465},
{-0.5298342,-0.1452045,-0.0262948},
{-0.5329823,-0.1338259,-0.0228132},
{-0.5349841,-0.1260421,-0.0201338},
{-0.5369075,-0.1180206,-0.0173615},
{-0.5390034,-0.1086829,-0.0127832},
{-0.5406667,-0.1003838,-0.0101288},
{-0.5422026,-0.0921184,-0.0055269},
{-0.5435738,-0.0837882,-0.0026563},
{-0.5447842,-0.0755357,0.0021186},
{-0.5458055,-0.0675378,0.0059163},
{-0.5466322,-0.0598818,0.0103620},
{-0.5472868,-0.0526381,0.0143655},
{-0.5477156,-0.0460775,0.0196072},
{-0.5481531,-0.0380902,0.0240271},
{-0.5483779,-0.0308073,0.0288552},
{-0.5484755,-0.0230339,0.0338248},
{-0.5484200,-0.0157156,0.0385819},
{-0.5482365,-0.0083667,0.0432060},
{-0.5478261,-0.0035395,0.0487237},
{-0.5473764,0.0057523,0.0533481},
{-0.5465684,0.0143150,0.0596492},
{-0.5458023,0.0234429,0.0636422},
{-0.5447164,0.0315075,0.0692196},
{-0.5436785,0.0378249,0.0740471},
{-0.5425595,0.0459562,0.0775708},
{-0.5413816,0.0524758,0.0815611},
{-0.5399672,0.0594291,0.0860442},
{-0.5385914,0.0660170,0.0897831},
{-0.5371885,0.0733353,0.0924688},
{-0.5361828,0.0756162,0.0963857},
{-0.5333047,0.0906650,0.0993274},
{-0.5318825,0.0964464,0.1014848},
{-0.5303394,0.1007534,0.1053038},
{-0.5289036,0.1055950,0.1077530},
{-0.5272594,0.1104041,0.1109435},
{-0.5256876,0.1153232,0.1133717},
{-0.5239787,0.1199174,0.1164738},
{-0.5223545,0.1252361,0.1181598},
{-0.5205191,0.1299528,0.1211288},
{-0.5191435,0.1346218,0.1219302},
{-0.5176840,0.1391566,0.1230396},
{-0.5161961,0.1436733,0.1240949},
{-0.5148727,0.1471792,0.1254768},
{-0.5135712,0.1513312,0.1258710},
{-0.5118884,0.1560741,0.1269297},
{-0.5105895,0.1603382,0.1268463},
{-0.5093995,0.1636073,0.1274549},
{-0.5082990,0.1668771,0.1276093},
{-0.5072239,0.1703884,0.1272465},
{-0.5067115,0.1725196,0.1264138},
{-0.5058123,0.1759202,0.1253236},
{-0.5053918,0.1775194,0.1247639},
{-0.5047947,0.1797456,0.1239914},
{-0.5042510,0.1815420,0.1235858},
{-0.5038935,0.1830550,0.1228097},
{-0.5037330,0.1840350,0.1220008},
{-0.5036258,0.1850764,0.1208627},
{-0.5030495,0.1866735,0.1208067},
{-0.5031806,0.1870841,0.1196195}
};
outShoToElVsWam = {
{-0.3682806,-0.3889318,-0.1327647},
{-0.3692298,-0.3881410,-0.1324421},
{-0.3709565,-0.3866038,-0.1321129},
{-0.3730600,-0.3848772,-0.1312279},
{-0.3753416,-0.3830394,-0.1300941},
{-0.3775805,-0.3809189,-0.1298413},
{-0.3802513,-0.3785487,-0.1289762},
{-0.3831919,-0.3759235,-0.1279472},
{-0.3878099,-0.3707036,-0.1292567},
{-0.3921930,-0.3665612,-0.1278378},
{-0.3967395,-0.3618412,-0.1272543},
{-0.4015362,-0.3565950,-0.1270185},
{-0.4064430,-0.3511801,-0.1264977},
{-0.4115777,-0.3454937,-0.1255506},
{-0.4178311,-0.3384564,-0.1240541},
{-0.4240594,-0.3308200,-0.1235182},
{-0.4302448,-0.3235222,-0.1214407},
{-0.4359208,-0.3165422,-0.1195790},
{-0.4415301,-0.3100249,-0.1160203},
{-0.4472785,-0.3030361,-0.1124102},
{-0.4525412,-0.2966286,-0.1083650},
{-0.4581957,-0.2893147,-0.1043010},
{-0.4637323,-0.2822860,-0.0989543},
{-0.4695229,-0.2746669,-0.0929050},
{-0.4750186,-0.2674191,-0.0858449},
{-0.4803843,-0.2600335,-0.0783488},
{-0.4834471,-0.2564031,-0.0711427},
{-0.4851328,-0.2533545,-0.0705880},
{-0.4870721,-0.2496109,-0.0705700},
{-0.4896055,-0.2449950,-0.0692015},
{-0.4922849,-0.2394150,-0.0697212},
{-0.4954736,-0.2328596,-0.0693352},
{-0.4979206,-0.2276300,-0.0691714},
{-0.5007873,-0.2217842,-0.0674453},
{-0.5031556,-0.2164789,-0.0670547},
{-0.5059485,-0.2102415,-0.0658755},
{-0.5089890,-0.2035725,-0.0633519},
{-0.5115237,-0.1977493,-0.0613493},
{-0.5142335,-0.1912422,-0.0592899},
{-0.5162471,-0.1862185,-0.0577631},
{-0.5192907,-0.1785476,-0.0546156},
{-0.5232875,-0.1676563,-0.0508581},
{-0.5259229,-0.1600164,-0.0482165},
{-0.5284980,-0.1521434,-0.0454669},
{-0.5314239,-0.1429613,-0.0409354},
{-0.5337420,-0.1348454,-0.0382258},
{-0.5360246,-0.1268019,-0.0335249},
{-0.5380530,-0.1187220,-0.0304799},
{-0.5400088,-0.1107515,-0.0254866},
{-0.5417102,-0.1030301,-0.0214430},
{-0.5432224,-0.0956881,-0.0166803},
{-0.5445175,-0.0887277,-0.0123716},
{-0.5455981,-0.0824731,-0.0067724},
{-0.5467411,-0.0748018,-0.0019588},
{-0.5476484,-0.0677923,0.0032316},
{-0.5484658,-0.0603014,0.0086032},
{-0.5490865,-0.0532760,0.0138074},
{-0.5495739,-0.0462182,0.0189061},
{-0.5496593,-0.0419331,0.0253234},
{-0.5500350,-0.0327588,0.0302219},
{-0.5500695,-0.0243175,0.0368397},
{-0.5500940,-0.0152629,0.0410935},
{-0.5497818,-0.0073102,0.0470265},
{-0.5493653,-0.0010855,0.0521692},
{-0.5489415,0.0069639,0.0560331},
{-0.5483620,0.0133957,0.0603710},
{-0.5475965,0.0202815,0.0652052},
{-0.5468154,0.0268160,0.0692734},
{-0.5460240,0.0341216,0.0722395},
{-0.5453364,0.0364622,0.0761823},
{-0.5436504,0.0516889,0.0793567},
{-0.5427103,0.0574645,0.0817827},
{-0.5416107,0.0617872,0.0858206},
{-0.5406061,0.0666561,0.0884705},
{-0.5394158,0.0714880,0.0918972},
{-0.5382753,0.0764238,0.0945730},
{-0.5369972,0.0810310,0.0979436},
{-0.5358023,0.0863622,0.0999121},
{-0.5343917,0.0910621,0.1032384},
{-0.5333641,0.0957250,0.1043287},
{-0.5322582,0.1002768,0.1056917},
{-0.5311169,0.1047944,0.1070420},
{-0.5300800,0.1082997,0.1086802},
{-0.5290815,0.1124722,0.1093058},
{-0.5277731,0.1172779,0.1105733},
{-0.5267859,0.1216362,0.1105726},
{-0.5258503,0.1249524,0.1113253},
{-0.5250008,0.1283197,0.1115043},
{-0.5241746,0.1319194,0.1111900},
{-0.5237977,0.1341236,0.1103262},
{-0.5231219,0.1376431,0.1091917},
{-0.5228103,0.1393290,0.1085439},
{-0.5223670,0.1416927,0.1076148},
{-0.5219515,0.1435889,0.1071160},
{-0.5216918,0.1452157,0.1061844},
{-0.5215880,0.1462988,0.1052027},
{-0.5215288,0.1474367,0.1038998},
{-0.5210783,0.1491572,0.1037043},
{-0.5212079,0.1496536,0.1023285}
};
outShoToLaVsWam = {
{-0.4074878,-0.4106883,-0.1289637},
{-0.4085167,-0.4097701,-0.1287376},
{-0.4103476,-0.4080617,-0.1285219},
{-0.4125703,-0.4061284,-0.1277173},
{-0.4149677,-0.4040967,-0.1267230},
{-0.4173176,-0.4018049,-0.1267206},
{-0.4201118,-0.3992369,-0.1261243},
{-0.4231610,-0.3964480,-0.1254537},
{-0.4279762,-0.3908911,-0.1272237},
{-0.4325032,-0.3864910,-0.1261357},
{-0.4371881,-0.3815174,-0.1259272},
{-0.4421305,-0.3759927,-0.1261047},
{-0.4471565,-0.3703411,-0.1259869},
{-0.4524029,-0.3644221,-0.1254305},
{-0.4587922,-0.3570875,-0.1243198},
{-0.4651499,-0.3491499,-0.1242861},
{-0.4714307,-0.3416142,-0.1226217},
{-0.4771852,-0.3344207,-0.1211924},
{-0.4828689,-0.3277093,-0.1178558},
{-0.4887312,-0.3204379,-0.1143734},
{-0.4941018,-0.3137676,-0.1103563},
{-0.4999108,-0.3060820,-0.1062281},
{-0.5055926,-0.2987055,-0.1007203},
{-0.5115565,-0.2906638,-0.0944139},
{-0.5171875,-0.2830814,-0.0870585},
{-0.5226855,-0.2753580,-0.0792219},
{-0.5257541,-0.2717254,-0.0717341},
{-0.5274091,-0.2687447,-0.0715156},
{-0.5293796,-0.2648988,-0.0717347},
{-0.5319442,-0.2601797,-0.0705669},
{-0.5346958,-0.2543675,-0.0713752},
{-0.5379803,-0.2475113,-0.0712064},
{-0.5404749,-0.2421087,-0.0712907},
{-0.5434159,-0.2360280,-0.0696625},
{-0.5458553,-0.2304830,-0.0694256},
{-0.5487442,-0.2239368,-0.0683191},
{-0.5519046,-0.2168969,-0.0657419},
{-0.5545414,-0.2107479,-0.0636980},
{-0.5573808,-0.2038201,-0.0615501},
{-0.5594583,-0.1985719,-0.0600401},
{-0.5626297,-0.1904629,-0.0567967},
{-0.5668263,-0.1788419,-0.0529207},
{-0.5695649,-0.1707975,-0.0502518},
{-0.5722459,-0.1624945,-0.0474610},
{-0.5752911,-0.1528234,-0.0427803},
{-0.5777111,-0.1442507,-0.0400300},
{-0.5801031,-0.1357241,-0.0350999},
{-0.5822226,-0.1271937,-0.0319903},
{-0.5842737,-0.1187534,-0.0267481},
{-0.5860589,-0.1105815,-0.0225281},
{-0.5876439,-0.1028296,-0.0175348},
{-0.5890064,-0.0954613,-0.0130041},
{-0.5901516,-0.0887915,-0.0070260},
{-0.5913637,-0.0806178,-0.0019152},
{-0.5923311,-0.0731109,0.0036421},
{-0.5932035,-0.0650880,0.0093943},
{-0.5938662,-0.0575704,0.0149667},
{-0.5943869,-0.0500242,0.0204237},
{-0.5944734,-0.0455168,0.0272869},
{-0.5948780,-0.0357512,0.0324906},
{-0.5949208,-0.0267284,0.0395871},
{-0.5949563,-0.0170370,0.0441311},
{-0.5946312,-0.0085352,0.0504957},
{-0.5941927,-0.0018622,0.0560295},
{-0.5937464,0.0068482,0.0602181},
{-0.5931286,0.0138260,0.0649284},
{-0.5923055,0.0213453,0.0702023},
{-0.5914581,0.0285260,0.0746681},
{-0.5905953,0.0365458,0.0779421},
{-0.5898399,0.0391891,0.0822651},
{-0.5880035,0.0557816,0.0857641},
{-0.5869639,0.0621614,0.0884573},
{-0.5857387,0.0670180,0.0929168},
{-0.5846074,0.0724831,0.0958822},
{-0.5832614,0.0779416,0.0997019},
{-0.5819626,0.0835138,0.1027069},
{-0.5805084,0.0887293,0.1064592},
{-0.5791430,0.0947092,0.1086823},
{-0.5775355,0.1000167,0.1123724},
{-0.5763651,0.1052037,0.1136060},
{-0.5751079,0.1102659,0.1151323},
{-0.5738216,0.1152569,0.1166256},
{-0.5726559,0.1191341,0.1184223},
{-0.5715412,0.1236994,0.1191101},
{-0.5700822,0.1289590,0.1204975},
{-0.5689767,0.1337225,0.1205152},
{-0.5679294,0.1373610,0.1213440},
{-0.5669789,0.1410412,0.1215543},
{-0.5660449,0.1449931,0.1212379},
{-0.5656357,0.1473572,0.1202986},
{-0.5648946,0.1511505,0.1190709},
{-0.5645633,0.1529405,0.1183630},
{-0.5640616,0.1555201,0.1173802},
{-0.5636004,0.1575752,0.1168503},
{-0.5632930,0.1593748,0.1158722},
{-0.5631534,0.1605939,0.1148446},
{-0.5630537,0.1618913,0.1134780},
{-0.5625274,0.1638122,0.1133062},
{-0.5626346,0.1644156,0.1118635}
};
outShoToWrVsWam = {
{-0.3252429,-0.5973360,-0.3489601},
{-0.3257916,-0.5975198,-0.3476133},
{-0.3273932,-0.5968138,-0.3464467},
{-0.3296034,-0.5961909,-0.3444955},
{-0.3315020,-0.5956295,-0.3420104},
{-0.3328423,-0.5944807,-0.3405896},
{-0.3344372,-0.5935228,-0.3380508},
{-0.3356265,-0.5923799,-0.3350925},
{-0.3396872,-0.5875663,-0.3358476},
{-0.3431652,-0.5848307,-0.3327273},
{-0.3469054,-0.5809480,-0.3310527},
{-0.3509086,-0.5764912,-0.3297684},
{-0.3549826,-0.5715907,-0.3284779},
{-0.3593088,-0.5664862,-0.3266856},
{-0.3651883,-0.5600251,-0.3244563},
{-0.3705629,-0.5528533,-0.3231787},
{-0.3758391,-0.5463423,-0.3199759},
{-0.3802899,-0.5404293,-0.3165683},
{-0.3855792,-0.5350169,-0.3116554},
{-0.3920230,-0.5290695,-0.3070398},
{-0.3983788,-0.5235968,-0.3022126},
{-0.4063578,-0.5167647,-0.2982194},
{-0.4144229,-0.5104944,-0.2926409},
{-0.4236090,-0.5036339,-0.2865310},
{-0.4321793,-0.4970525,-0.2793864},
{-0.4408916,-0.4901543,-0.2720231},
{-0.4450476,-0.4871340,-0.2643103},
{-0.4444967,-0.4850105,-0.2621845},
{-0.4457747,-0.4818203,-0.2613535},
{-0.4477270,-0.4780725,-0.2587960},
{-0.4503058,-0.4730142,-0.2586502},
{-0.4541081,-0.4670188,-0.2577054},
{-0.4563028,-0.4623459,-0.2567918},
{-0.4599504,-0.4570406,-0.2545596},
{-0.4629460,-0.4520456,-0.2539143},
{-0.4672400,-0.4456234,-0.2532843},
{-0.4725965,-0.4390951,-0.2510477},
{-0.4772001,-0.4331029,-0.2496458},
{-0.4827729,-0.4261312,-0.2486635},
{-0.4861251,-0.4203990,-0.2482288},
{-0.4920374,-0.4126673,-0.2455875},
{-0.5001630,-0.4038617,-0.2397953},
{-0.5051293,-0.3963213,-0.2373001},
{-0.5102136,-0.3886177,-0.2345980},
{-0.5164327,-0.3795706,-0.2301874},
{-0.5213301,-0.3719546,-0.2270383},
{-0.5270856,-0.3647455,-0.2214821},
{-0.5316756,-0.3577095,-0.2172130},
{-0.5370382,-0.3510666,-0.2105942},
{-0.5417355,-0.3446959,-0.2048078},
{-0.5462054,-0.3390114,-0.1978151},
{-0.5504314,-0.3335711,-0.1913737},
{-0.5550744,-0.3290623,-0.1832063},
{-0.5599204,-0.3231619,-0.1756497},
{-0.5647942,-0.3176932,-0.1678841},
{-0.5697971,-0.3118005,-0.1596769},
{-0.5743013,-0.3064782,-0.1513526},
{-0.5785935,-0.3011295,-0.1429675},
{-0.5810036,-0.3003639,-0.1304202},
{-0.5856970,-0.2917354,-0.1236754},
{-0.5905567,-0.2838948,-0.1148357},
{-0.5951062,-0.2751213,-0.1088149},
{-0.5992256,-0.2677610,-0.1004377},
{-0.6025280,-0.2620322,-0.0931082},
{-0.6068084,-0.2543052,-0.0868476},
{-0.6104048,-0.2482599,-0.0800286},
{-0.6145222,-0.2415482,-0.0726033},
{-0.6185580,-0.2350365,-0.0660457},
{-0.6227205,-0.2274269,-0.0609332},
{-0.6249635,-0.2244499,-0.0565181},
{-0.6321076,-0.2073123,-0.0514817},
{-0.6353326,-0.2011334,-0.0469544},
{-0.6384743,-0.1962061,-0.0409937},
{-0.6417497,-0.1905694,-0.0365494},
{-0.6452096,-0.1848986,-0.0309789},
{-0.6485655,-0.1791156,-0.0260946},
{-0.6517465,-0.1736655,-0.0203244},
{-0.6548556,-0.1674609,-0.0159549},
{-0.6577567,-0.1620561,-0.0096210},
{-0.6599771,-0.1567915,-0.0062587},
{-0.6621184,-0.1514795,-0.0028444},
{-0.6639249,-0.1463863,0.0007628},
{-0.6653082,-0.1424198,0.0043825},
{-0.6666154,-0.1376882,0.0066939},
{-0.6681402,-0.1319590,0.0095631},
{-0.6695190,-0.1265223,0.0102251},
{-0.6705715,-0.1225037,0.0120968},
{-0.6716180,-0.1181251,0.0125429},
{-0.6728094,-0.1134888,0.0126631},
{-0.6731940,-0.1107008,0.0114992},
{-0.6739021,-0.1061741,0.0099773},
{-0.6740952,-0.1038937,0.0086409},
{-0.6748464,-0.1003536,0.0066761},
{-0.6753172,-0.0976323,0.0055468},
{-0.6760039,-0.0949787,0.0036201},
{-0.6766344,-0.0929496,0.0015407},
{-0.6773842,-0.0908368,-0.0007894},
{-0.6781960,-0.0879351,-0.0017769},
{-0.6788198,-0.0865758,-0.0043445}
};
outShoToEeVsWam = {
{-0.3010580,-0.5700695,-0.3966217},
{-0.3396178,-0.6465950,-0.3159831},
{-0.3419460,-0.6460620,-0.3154172},
{-0.3450846,-0.6450778,-0.3133443},
{-0.3471054,-0.6445881,-0.3110331},
{-0.3479034,-0.6438117,-0.3099364},
{-0.3501288,-0.6425190,-0.3071776},
{-0.3506931,-0.6421282,-0.3051240},
{-0.3545205,-0.6377256,-0.3064535},
{-0.3591210,-0.6350936,-0.3041083},
{-0.3623183,-0.6320125,-0.3035781},
{-0.3431384,-0.6356778,-0.3237215},
{-0.3709975,-0.6231637,-0.3023294},
{-0.3758288,-0.6182750,-0.3012887},
{-0.3822370,-0.6118694,-0.2995261},
{-0.3874730,-0.6053414,-0.2995347},
{-0.3934356,-0.5990624,-0.2973718},
{-0.3985212,-0.5933060,-0.2948502},
{-0.4062047,-0.5869220,-0.2897361},
{-0.4155087,-0.5793654,-0.2842637},
{-0.4330303,-0.5632245,-0.2734217},
{-0.4351011,-0.5578356,-0.2652496},
{-0.4507818,-0.5490984,-0.2645738},
{-0.4599860,-0.5419001,-0.2580282},
{-0.4699445,-0.5345297,-0.2516511},
{-0.4796203,-0.5269609,-0.2447217},
{-0.4698573,-0.5387918,-0.2465353},
{-0.4824429,-0.5219710,-0.2340065},
{-0.4837966,-0.5186937,-0.2331633},
{-0.4867932,-0.5144386,-0.2313855},
{-0.4891209,-0.5093768,-0.2308807},
{-0.4937089,-0.5029167,-0.2304451},
{-0.4967377,-0.4978119,-0.2301988},
{-0.5008674,-0.4921453,-0.2282260},
{-0.5041861,-0.4868950,-0.2277462},
{-0.5092191,-0.4800265,-0.2277074},
{-0.5147988,-0.4738563,-0.2263370},
{-0.5200272,-0.4675309,-0.2255511},
{-0.5257570,-0.4611572,-0.2257389},
{-0.5304661,-0.4529819,-0.2243076},
{-0.5360538,-0.4458890,-0.2219470},
{-0.5392832,-0.4448427,-0.2200427},
{-0.5496014,-0.4290225,-0.2137871},
{-0.5546408,-0.4216302,-0.2114376},
{-0.5616681,-0.4109856,-0.2063788},
{-0.5658598,-0.4055490,-0.2049356},
{-0.5719505,-0.3986260,-0.2005235},
{-0.5766224,-0.3913637,-0.1960664},
{-0.5822870,-0.3847452,-0.1901419},
{-0.5869620,-0.3783165,-0.1842112},
{-0.5922544,-0.3713951,-0.1770595},
{-0.5966785,-0.3657806,-0.1707884},
{-0.6013493,-0.3617285,-0.1634187},
{-0.6061834,-0.3552399,-0.1548955},
{-0.6115535,-0.3488946,-0.1469070},
{-0.6174441,-0.3412291,-0.1381430},
{-0.6222757,-0.3347100,-0.1289601},
{-0.6269275,-0.3280907,-0.1197959},
{-0.6125969,-0.3510908,-0.1250691},
{-0.6156562,-0.3433710,-0.1176579},
{-0.6199194,-0.3360171,-0.1102424},
{-0.6236583,-0.3276134,-0.1033965},
{-0.6260364,-0.3212729,-0.0962348},
{-0.6292663,-0.3155232,-0.0882322},
{-0.6327406,-0.3081585,-0.0816185},
{-0.6360386,-0.3022618,-0.0748610},
{-0.6395049,-0.2958383,-0.0672699},
{-0.6429369,-0.2895965,-0.0606721},
{-0.6460004,-0.2825285,-0.0562564},
{-0.6481203,-0.2795338,-0.0510843},
{-0.6511460,-0.2641316,-0.0484639},
{-0.6554592,-0.2573606,-0.0411734},
{-0.6578707,-0.2525689,-0.0341369},
{-0.6601841,-0.2472312,-0.0295057},
{-0.6626712,-0.2417934,-0.0233579},
{-0.6650853,-0.2362882,-0.0184532},
{-0.6672477,-0.2311077,-0.0125720},
{-0.6691534,-0.2252615,-0.0085609},
{-0.6712408,-0.2200101,-0.0019063},
{-0.6720184,-0.2150870,0.0012673},
{-0.6732232,-0.2099487,0.0047738},
{-0.6738673,-0.2049963,0.0088884},
{-0.6746631,-0.2010502,0.0130406},
{-0.6747282,-0.1965297,0.0151707},
{-0.6750142,-0.1909494,0.0181002},
{-0.6758158,-0.1856158,0.0184897},
{-0.6765683,-0.1815195,0.0211059},
{-0.6769146,-0.1772408,0.0213342},
{-0.6889307,-0.1712234,0.0152735},
{-0.6892620,-0.1683983,0.0150786},
{-0.6906330,-0.1637384,0.0125133},
{-0.6905952,-0.1614504,0.0125101},
{-0.6917227,-0.1578216,0.0102281},
{-0.6922348,-0.1550464,0.0097211},
{-0.6931020,-0.1523260,0.0079724},
{-0.7121621,-0.1039078,0.0486331},
{-0.7127050,-0.1019710,0.0464172},
{-0.6959127,-0.1450831,0.0027201},
{-0.7137689,-0.0981964,0.0430214}
};
outPUaWam = {
{0.1320717,0.6039440,0.1020489},
{0.1308719,0.6047931,0.1014619},
{0.1299123,0.6056138,0.1008590},
{0.1288537,0.6066690,0.0999475},
{0.1273283,0.6082064,0.0987253},
{0.1252554,0.6098357,0.0986635},
{0.1228965,0.6122171,0.0975661},
{0.1201210,0.6149927,0.0969744},
{0.1196940,0.6168544,0.1008202},
{0.1179567,0.6198755,0.1015973},
{0.1168530,0.6225343,0.1043727},
{0.1160089,0.6252794,0.1074947},
{0.1152410,0.6280980,0.1114346},
{0.1142973,0.6312513,0.1156630},
{0.1148863,0.6343114,0.1204428},
{0.1153644,0.6376736,0.1261245},
{0.1148961,0.6416544,0.1315384},
{0.1134316,0.6462341,0.1363808},
{0.1122062,0.6508111,0.1413175},
{0.1120039,0.6551334,0.1470637},
{0.1120272,0.6593035,0.1527219},
{0.1139962,0.6626614,0.1602136},
{0.1162142,0.6663752,0.1666435},
{0.1198024,0.6698496,0.1732836},
{0.1226875,0.6737180,0.1802200},
{0.1259196,0.6773561,0.1878277},
{0.1231765,0.6827956,0.1947633},
{0.1149924,0.6893745,0.2036258},
{0.1103651,0.6937596,0.2134329},
{0.1056982,0.6991277,0.2230645},
{0.1020336,0.7038170,0.2339629},
{0.0992004,0.7086000,0.2458415},
{0.0945088,0.7138098,0.2569223},
{0.0910650,0.7190774,0.2678456},
{0.0874305,0.7239707,0.2796279},
{0.0840692,0.7283134,0.2929332},
{0.0824106,0.7325024,0.3055146},
{0.0794556,0.7367578,0.3179733},
{0.0779964,0.7401228,0.3317063},
{0.0734314,0.7439653,0.3456341},
{0.0732215,0.7482044,0.3575161},
{0.0775330,0.7557959,0.3618054},
{0.0761503,0.7606762,0.3735780},
{0.0750562,0.7654792,0.3855319},
{0.0761304,0.7703885,0.3982175},
{0.0745783,0.7757239,0.4101890},
{0.0749803,0.7811751,0.4209618},
{0.0732620,0.7871427,0.4319611},
{0.0730227,0.7933387,0.4421393},
{0.0713318,0.7996898,0.4526387},
{0.0696530,0.8063085,0.4626011},
{0.0678624,0.8124067,0.4728043},
{0.0666658,0.8185166,0.4824340},
{0.0669016,0.8247300,0.4918059},
{0.0670937,0.8302324,0.5020363},
{0.0684764,0.8358328,0.5118297},
{0.0690471,0.8411588,0.5222198},
{0.0693395,0.8469125,0.5321728},
{0.0652488,0.8590787,0.5329862},
{0.0687849,0.8629355,0.5459500},
{0.0733792,0.8664868,0.5588333},
{0.0766147,0.8701406,0.5715882},
{0.0803398,0.8747471,0.5823567},
{0.0813618,0.8792581,0.5929088},
{0.0845506,0.8835477,0.6030020},
{0.0856530,0.8879653,0.6130136},
{0.0887560,0.8922360,0.6225202},
{0.0909485,0.8966175,0.6315055},
{0.0934699,0.9002143,0.6411810},
{0.0896226,0.9007450,0.6557151},
{0.1068386,0.9024943,0.6644779},
{0.1076655,0.9072473,0.6714455},
{0.1090333,0.9108284,0.6789680},
{0.1098810,0.9136006,0.6873851},
{0.1121407,0.9165936,0.6949470},
{0.1135480,0.9199398,0.7020095},
{0.1161244,0.9223752,0.7094728},
{0.1176034,0.9257793,0.7159500},
{0.1210738,0.9292920,0.7211709},
{0.1213763,0.9333376,0.7261953},
{0.1228814,0.9361512,0.7317614},
{0.1249702,0.9395296,0.7360223},
{0.1259756,0.9424065,0.7407657},
{0.1272795,0.9454119,0.7449654},
{0.1312532,0.9475731,0.7492738},
{0.1334164,0.9487766,0.7544781},
{0.1355273,0.9501576,0.7588422},
{0.1375482,0.9506610,0.7638884},
{0.1408837,0.9514808,0.7671656},
{0.1415410,0.9517663,0.7710473},
{0.1439643,0.9514938,0.7751279},
{0.1450710,0.9511670,0.7786384},
{0.1467852,0.9498617,0.7831256},
{0.1487709,0.9494831,0.7859177},
{0.1494138,0.9490746,0.7890866},
{0.1500839,0.9480456,0.7920842},
{0.1503450,0.9473541,0.7945224},
{0.1534635,0.9465993,0.7963371},
{0.1530335,0.9459905,0.7981471}
};
outPElWam = {
{0.1575917,0.5855581,0.0698668},
{0.1564456,0.5861679,0.0694606},
{0.1554843,0.5867214,0.0690133},
{0.1543947,0.5874507,0.0682724},
{0.1528484,0.5885938,0.0672758},
{0.1507858,0.5898497,0.0674584},
{0.1484261,0.5917483,0.0666749},
{0.1456484,0.5939728,0.0664537},
{0.1451041,0.5953728,0.0705239},
{0.1432138,0.5977853,0.0716123},
{0.1419216,0.5999128,0.0746265},
{0.1408691,0.6021165,0.0779912},
{0.1398377,0.6044252,0.0821156},
{0.1385859,0.6070450,0.0865233},
{0.1387401,0.6095085,0.0914460},
{0.1387994,0.6122731,0.0973040},
{0.1378516,0.6156168,0.1029012},
{0.1359505,0.6195488,0.1079942},
{0.1341971,0.6235244,0.1130892},
{0.1334109,0.6272906,0.1189298},
{0.1328473,0.6309750,0.1246323},
{0.1341314,0.6339338,0.1320304},
{0.1356231,0.6372224,0.1383873},
{0.1384002,0.6402815,0.1449137},
{0.1404435,0.6437514,0.1517292},
{0.1427922,0.6470294,0.1591815},
{0.1394481,0.6521764,0.1660804},
{0.1311163,0.6584215,0.1752193},
{0.1262878,0.6625650,0.1851775},
{0.1213035,0.6676037,0.1949982},
{0.1173369,0.6720263,0.2060315},
{0.1140834,0.6765229,0.2180106},
{0.1090729,0.6814730,0.2292236},
{0.1051774,0.6864840,0.2402139},
{0.1011870,0.6911873,0.2520416},
{0.0973441,0.6954074,0.2652569},
{0.0951132,0.6994296,0.2777687},
{0.0916599,0.7035904,0.2901169},
{0.0896430,0.7069110,0.3036647},
{0.0846462,0.7107531,0.3174175},
{0.0837649,0.7148613,0.3291952},
{0.0872279,0.7219656,0.3337605},
{0.0852115,0.7267018,0.3454953},
{0.0834657,0.7313564,0.3574264},
{0.0837099,0.7361101,0.3700653},
{0.0815031,0.7412622,0.3820920},
{0.0811583,0.7464916,0.3929638},
{0.0787828,0.7522089,0.4041375},
{0.0777981,0.7581229,0.4145341},
{0.0754271,0.7641975,0.4252795},
{0.0730629,0.7705022,0.4355589},
{0.0706317,0.7763171,0.4460673},
{0.0687833,0.7821211,0.4560545},
{0.0683136,0.7880185,0.4658199},
{0.0678232,0.7932473,0.4764126},
{0.0684860,0.7985653,0.4866080},
{0.0683805,0.8035985,0.4974453},
{0.0680021,0.8090611,0.5078730},
{0.0634156,0.8206851,0.5095860},
{0.0661263,0.8244243,0.5228238},
{0.0698781,0.8278543,0.5360237},
{0.0723230,0.8314348,0.5490395},
{0.0752744,0.8359294,0.5601637},
{0.0756750,0.8403478,0.5710309},
{0.0781685,0.8445554,0.5814644},
{0.0786727,0.8488852,0.5918235},
{0.0811267,0.8530884,0.6016813},
{0.0827245,0.8574165,0.6109957},
{0.0846344,0.8610007,0.6209518},
{0.0804690,0.8615910,0.6355117},
{0.0964929,0.8635182,0.6445072},
{0.0968376,0.8682654,0.6517434},
{0.0977620,0.8718622,0.6594848},
{0.0981785,0.8746617,0.6681025},
{0.0999843,0.8776775,0.6759008},
{0.1009602,0.8810405,0.6832109},
{0.1031058,0.8834888,0.6909426},
{0.1041555,0.8869055,0.6977023},
{0.1072011,0.8904014,0.7032805},
{0.1071557,0.8944408,0.7085938},
{0.1083071,0.8972713,0.7144135},
{0.1100495,0.9006506,0.7189694},
{0.1107683,0.9035271,0.7239691},
{0.1117692,0.9065529,0.7284002},
{0.1153685,0.9087770,0.7329174},
{0.1172201,0.9100746,0.7382044},
{0.1190765,0.9115027,0.7427126},
{0.1208464,0.9121035,0.7477834},
{0.1239330,0.9130118,0.7511091},
{0.1244548,0.9133704,0.7549597},
{0.1266547,0.9132167,0.7589960},
{0.1276524,0.9129766,0.7624184},
{0.1292129,0.9118088,0.7667490},
{0.1310704,0.9115300,0.7694479},
{0.1316155,0.9112352,0.7724613},
{0.1322289,0.9103094,0.7752861},
{0.1324420,0.9097144,0.7775596},
{0.1354347,0.9090831,0.7792347},
{0.1350062,0.9085601,0.7808562}
};
outPLaWam = {
{0.1183845,0.5638016,0.0736678},
{0.1171587,0.5645388,0.0731651},
{0.1160932,0.5652634,0.0726043},
{0.1148845,0.5661995,0.0717830},
{0.1132223,0.5675365,0.0706469},
{0.1110487,0.5689637,0.0705791},
{0.1085656,0.5710601,0.0695268},
{0.1056793,0.5734483,0.0689472},
{0.1049378,0.5751853,0.0725569},
{0.1029037,0.5778555,0.0733144},
{0.1014730,0.5802366,0.0759536},
{0.1002748,0.5827188,0.0789051},
{0.0991242,0.5852642,0.0826264},
{0.0977607,0.5881166,0.0866434},
{0.0977790,0.5908774,0.0911804},
{0.0977089,0.5939432,0.0965361},
{0.0966657,0.5975247,0.1017202},
{0.0946860,0.6016703,0.1063809},
{0.0928583,0.6058400,0.1112537},
{0.0919583,0.6098888,0.1169665},
{0.0912866,0.6138360,0.1226410},
{0.0924164,0.6171665,0.1301033},
{0.0937628,0.6208030,0.1366213},
{0.0963666,0.6242846,0.1434049},
{0.0982746,0.6280890,0.1505156},
{0.1004910,0.6317049,0.1583084},
{0.0971411,0.6368542,0.1654889},
{0.0888400,0.6430313,0.1742917},
{0.0839803,0.6472771,0.1840129},
{0.0789648,0.6524191,0.1936328},
{0.0749259,0.6570739,0.2043774},
{0.0715766,0.6618712,0.2161394},
{0.0665186,0.6669943,0.2271042},
{0.0625488,0.6722401,0.2379968},
{0.0584874,0.6771831,0.2496707},
{0.0545484,0.6817121,0.2628134},
{0.0521976,0.6861051,0.2753787},
{0.0486422,0.6905918,0.2877681},
{0.0464957,0.6943330,0.3014046},
{0.0414350,0.6983998,0.3151404},
{0.0404259,0.7029460,0.3270141},
{0.0436891,0.7107799,0.3316979},
{0.0415695,0.7159207,0.3434600},
{0.0397178,0.7210054,0.3554323},
{0.0398427,0.7262480,0.3682204},
{0.0375340,0.7318569,0.3802878},
{0.0370798,0.7375694,0.3913888},
{0.0346133,0.7437371,0.4026271},
{0.0335332,0.7501210,0.4132726},
{0.0310784,0.7566462,0.4241944},
{0.0286414,0.7633607,0.4347043},
{0.0261429,0.7695836,0.4454347},
{0.0242298,0.7758026,0.4558008},
{0.0236910,0.7822024,0.4658635},
{0.0231405,0.7879287,0.4768231},
{0.0237483,0.7937787,0.4873992},
{0.0236009,0.7993040,0.4986046},
{0.0231891,0.8052551,0.5093905},
{0.0186015,0.8171015,0.5115494},
{0.0212833,0.8214319,0.5250925},
{0.0250268,0.8254434,0.5387712},
{0.0274607,0.8296607,0.5520771},
{0.0304250,0.8347044,0.5636329},
{0.0308476,0.8395711,0.5748912},
{0.0333637,0.8444397,0.5856493},
{0.0339061,0.8493155,0.5963810},
{0.0364177,0.8541522,0.6066784},
{0.0380818,0.8591265,0.6163905},
{0.0400631,0.8634249,0.6266543},
{0.0359655,0.8643180,0.6415944},
{0.0521398,0.8676109,0.6509146},
{0.0525840,0.8729623,0.6584180},
{0.0536339,0.8770930,0.6665810},
{0.0541772,0.8804887,0.6755142},
{0.0561387,0.8841310,0.6837054},
{0.0572730,0.8881305,0.6913448},
{0.0595947,0.8911872,0.6994583},
{0.0608149,0.8952525,0.7064725},
{0.0640573,0.8993560,0.7124145},
{0.0641547,0.9039196,0.7178710},
{0.0654574,0.9072604,0.7238541},
{0.0673448,0.9111132,0.7285530},
{0.0681924,0.9143614,0.7337112},
{0.0693095,0.9177801,0.7382045},
{0.0730594,0.9204580,0.7428416},
{0.0750293,0.9221609,0.7481469},
{0.0769974,0.9239113,0.7527313},
{0.0788683,0.9248250,0.7578334},
{0.0820627,0.9260855,0.7611570},
{0.0826167,0.9266040,0.7649321},
{0.0848821,0.9267240,0.7688752},
{0.0858995,0.9265881,0.7722375},
{0.0875183,0.9256362,0.7765144},
{0.0894215,0.9255163,0.7791822},
{0.0900143,0.9253944,0.7821491},
{0.0906635,0.9246045,0.7849279},
{0.0909171,0.9241690,0.7871378},
{0.0939855,0.9237381,0.7888366},
{0.0935796,0.9233220,0.7903912}
};
outPWrWam = {
{0.2006294,0.3771539,-0.1463286},
{0.1998838,0.3767891,-0.1457106},
{0.1990475,0.3765113,-0.1453205},
{0.1978514,0.3761370,-0.1449952},
{0.1966880,0.3760037,-0.1446405},
{0.1955239,0.3762878,-0.1432899},
{0.1942402,0.3767741,-0.1423997},
{0.1932138,0.3775164,-0.1406915},
{0.1932269,0.3785101,-0.1360669},
{0.1922417,0.3795158,-0.1332772},
{0.1917557,0.3808060,-0.1291719},
{0.1914967,0.3822203,-0.1247587},
{0.1912980,0.3840146,-0.1198646},
{0.1908548,0.3860526,-0.1146117},
{0.1913830,0.3879398,-0.1089561},
{0.1922959,0.3902398,-0.1023565},
{0.1922572,0.3927967,-0.0956340},
{0.1915814,0.3956617,-0.0889950},
{0.1901480,0.3985324,-0.0825459},
{0.1886665,0.4012571,-0.0756999},
{0.1870096,0.4040069,-0.0692153},
{0.1859693,0.4064838,-0.0618880},
{0.1849325,0.4090140,-0.0552994},
{0.1843140,0.4113145,-0.0487123},
{0.1832828,0.4141180,-0.0418123},
{0.1822849,0.4169086,-0.0344928},
{0.1778476,0.4214456,-0.0270872},
{0.1717524,0.4267655,-0.0163772},
{0.1675852,0.4303556,-0.0056059},
{0.1631820,0.4345262,0.0054038},
{0.1593159,0.4384271,0.0171024},
{0.1554488,0.4423636,0.0296404},
{0.1506907,0.4467572,0.0416032},
{0.1460143,0.4512275,0.0530997},
{0.1413967,0.4556206,0.0651820},
{0.1360526,0.4600256,0.0778482},
{0.1315057,0.4639070,0.0900729},
{0.1259835,0.4682368,0.1018203},
{0.1211037,0.4720220,0.1142911},
{0.1147682,0.4765727,0.1269518},
{0.1110182,0.4807416,0.1382234},
{0.1103524,0.4857601,0.1448233},
{0.1060051,0.4903969,0.1564117},
{0.1017501,0.4948821,0.1682953},
{0.0987011,0.4995009,0.1808133},
{0.0939150,0.5041530,0.1932795},
{0.0900972,0.5085479,0.2050066},
{0.0851603,0.5132214,0.2174043},
{0.0807687,0.5178078,0.2294265},
{0.0754018,0.5225318,0.2419146},
{0.0700798,0.5271788,0.2544240},
{0.0647178,0.5314737,0.2670652},
{0.0593071,0.5355318,0.2796205},
{0.0551343,0.5396583,0.2921290},
{0.0506774,0.5433465,0.3052969},
{0.0471548,0.5470662,0.3183279},
{0.0431657,0.5503963,0.3322853},
{0.0389825,0.5541498,0.3459994},
{0.0320713,0.5622544,0.3538423},
{0.0304643,0.5654478,0.3689266},
{0.0293910,0.5682770,0.3843484},
{0.0273107,0.5715764,0.3991311},
{0.0258306,0.5754786,0.4126995},
{0.0225123,0.5794010,0.4257535},
{0.0203017,0.5832864,0.4385837},
{0.0166299,0.5872296,0.4514240},
{0.0142011,0.5912588,0.4638727},
{0.0109819,0.5955640,0.4756766},
{0.0079378,0.5994521,0.4877790},
{0.0008419,0.6006789,0.5028112},
{0.0080357,0.6045170,0.5136688},
{0.0042153,0.6096675,0.5230063},
{0.0008983,0.6138689,0.5326704},
{-0.0029652,0.6174362,0.5430826},
{-0.0058095,0.6212908,0.5530247},
{-0.0093299,0.6255011,0.5625433},
{-0.0116434,0.6287923,0.5726746},
{-0.0148977,0.6330823,0.5818354},
{-0.0161639,0.6372831,0.5904211},
{-0.0194572,0.6419243,0.5980064},
{-0.0215531,0.6455150,0.6058774},
{-0.0227586,0.6494699,0.6126902},
{-0.0244600,0.6528075,0.6196713},
{-0.0257647,0.6563925,0.6257883},
{-0.0249986,0.6595401,0.6319072},
{-0.0255130,0.6619161,0.6378568},
{-0.0256446,0.6640466,0.6434841},
{-0.0257708,0.6656587,0.6488220},
{-0.0247018,0.6676037,0.6525822},
{-0.0249415,0.6685460,0.6561327},
{-0.0241255,0.6693994,0.6597816},
{-0.0236325,0.6697539,0.6625154},
{-0.0232665,0.6697625,0.6658103},
{-0.0222953,0.6703088,0.6678787},
{-0.0226966,0.6710409,0.6698970},
{-0.0228175,0.6710610,0.6716241},
{-0.0234134,0.6714409,0.6728703},
{-0.0216831,0.6719908,0.6737536},
{-0.0226057,0.6723306,0.6741831}
};
outPEeWam = {
{0.2248143,0.4044204,-0.1939903},
{0.1860576,0.3277139,-0.1140805},
{0.1844948,0.3272631,-0.1142909},
{0.1823701,0.3272501,-0.1138440},
{0.1810847,0.3270451,-0.1136633},
{0.1804628,0.3269569,-0.1126366},
{0.1785486,0.3277780,-0.1115265},
{0.1781473,0.3277681,-0.1107231},
{0.1783935,0.3283508,-0.1066729},
{0.1762859,0.3292529,-0.1046582},
{0.1763429,0.3297415,-0.1016972},
{0.1992669,0.3230337,-0.1187118},
{0.1752832,0.3324416,-0.0937160},
{0.1743348,0.3342637,-0.0892148},
{0.1743343,0.3360955,-0.0840260},
{0.1753858,0.3377517,-0.0787125},
{0.1746607,0.3400765,-0.0730299},
{0.1733501,0.3427850,-0.0672770},
{0.1695225,0.3466273,-0.0606266},
{0.1651808,0.3509613,-0.0529238},
{0.1523582,0.3643791,-0.0404244},
{0.1572261,0.3654129,-0.0289182},
{0.1485735,0.3704101,-0.0272323},
{0.1479371,0.3730483,-0.0202094},
{0.1455176,0.3766408,-0.0140770},
{0.1435562,0.3801020,-0.0071914},
{0.1530379,0.3697878,-0.0093123},
{0.1338062,0.3898050,0.0118009},
{0.1295633,0.3934823,0.0225843},
{0.1241158,0.3981601,0.0328143},
{0.1205008,0.4020645,0.0448720},
{0.1158481,0.4064658,0.0569007},
{0.1102558,0.4112912,0.0681962},
{0.1050972,0.4161229,0.0794333},
{0.1001566,0.4207712,0.0913501},
{0.0940735,0.4256224,0.1034250},
{0.0893033,0.4291458,0.1147836},
{0.0831564,0.4338088,0.1259151},
{0.0781195,0.4369959,0.1372157},
{0.0704272,0.4439897,0.1508730},
{0.0670019,0.4475199,0.1618639},
{0.0712321,0.4447791,0.1645759},
{0.0615330,0.4576957,0.1799247},
{0.0573229,0.4618696,0.1914557},
{0.0534657,0.4680858,0.2046219},
{0.0493853,0.4705587,0.2153822},
{0.0452324,0.4746675,0.2259652},
{0.0402134,0.4795672,0.2385510},
{0.0355199,0.4841292,0.2498788},
{0.0301753,0.4889111,0.2625112},
{0.0240309,0.4947952,0.2751796},
{0.0184707,0.4992643,0.2876504},
{0.0130321,0.5028656,0.2994081},
{0.0088713,0.5075803,0.3128833},
{0.0039180,0.5121451,0.3262740},
{-0.0004923,0.5176376,0.3398619},
{-0.0048086,0.5221644,0.3546778},
{-0.0093515,0.5271886,0.3691709},
{0.0004780,0.5115274,0.3591934},
{0.0005051,0.5138122,0.3749440},
{0.0000283,0.5161547,0.3889416},
{-0.0012414,0.5190844,0.4045495},
{-0.0009802,0.5219668,0.4169024},
{-0.0042260,0.5259100,0.4306295},
{-0.0056306,0.5294331,0.4438128},
{-0.0090039,0.5332277,0.4565916},
{-0.0107817,0.5369687,0.4692061},
{-0.0133970,0.5410040,0.4810503},
{-0.0153420,0.5443506,0.4924559},
{-0.0223149,0.5455950,0.5082451},
{-0.0110028,0.5476977,0.5166866},
{-0.0159113,0.5534403,0.5287873},
{-0.0184980,0.5575061,0.5395272},
{-0.0213996,0.5607744,0.5501264},
{-0.0232711,0.5643961,0.5606456},
{-0.0258497,0.5683285,0.5701847},
{-0.0271446,0.5713501,0.5804270},
{-0.0291955,0.5752818,0.5892293},
{-0.0296480,0.5793292,0.5981358},
{-0.0314986,0.5836288,0.6055324},
{-0.0326579,0.5870458,0.6134956},
{-0.0327010,0.5908600,0.6208158},
{-0.0338149,0.5941771,0.6283295},
{-0.0338775,0.5975509,0.6342651},
{-0.0318727,0.6005497,0.6404443},
{-0.0318099,0.6028226,0.6461215},
{-0.0316415,0.6050307,0.6524932},
{-0.0310674,0.6065430,0.6576133},
{-0.0408231,0.6098690,0.6551926},
{-0.0410095,0.6108484,0.6597121},
{-0.0408564,0.6118352,0.6623176},
{-0.0401324,0.6121972,0.6663846},
{-0.0401429,0.6122945,0.6693623},
{-0.0392129,0.6128947,0.6720530},
{-0.0397947,0.6136936,0.6742493},
{-0.0583452,0.6601028,0.7187165},
{-0.0587343,0.6603067,0.7200769},
{-0.0393998,0.6148428,0.6782505},
{-0.0575548,0.6607101,0.7215490}
};
outThetasWam = {
{-0.1158496,-0.2494568,-0.0474730,1.2057666,-0.7959598,1.1480220,0.0000000},
{-0.1147501,-0.2519346,-0.0475739,1.2070694,-0.8775891,-1.5070310,0.0000000},
{-0.1136078,-0.2544860,-0.0476542,1.2092547,-0.8674977,-1.4970420,0.0000000},
{-0.1126843,-0.2577024,-0.0481949,1.2115541,-0.8587070,-1.5010590,0.0000000},
{-0.1113500,-0.2615049,-0.0486997,1.2155735,-0.8612436,-1.4926161,0.0000000},
{-0.1092408,-0.2647742,-0.0483702,1.2207495,-0.8743685,-1.4775046,0.0000000},
{-0.1069642,-0.2691286,-0.0484169,1.2271541,-0.8732530,-1.4800033,0.0000000},
{-0.1042144,-0.2738180,-0.0483447,1.2361982,-0.8848582,-1.4512953,0.0000000},
{-0.1008371,-0.2764620,-0.0465608,1.2447726,-0.8975727,-1.4357660,0.0000000},
{-0.0984564,-0.2813438,-0.0466176,1.2550061,-0.8839786,-1.4240911,0.0000000},
{-0.0959758,-0.2848869,-0.0459274,1.2656575,-0.8940759,-1.3945202,0.0000000},
{-0.1092565,-0.2572046,-0.0566796,1.2767832,-1.1594569,-0.8889485,0.0000000},
{-0.1075282,-0.2605678,-0.0553508,1.2891612,-0.8955098,-1.3689815,0.0000000},
{-0.1058488,-0.2641651,-0.0540457,1.3024526,-0.8914767,-1.3572042,0.0000000},
{-0.1040886,-0.2685330,-0.0523490,1.3175960,-0.8903229,-1.3503549,0.0000000},
{-0.1020572,-0.2719445,-0.0501681,1.3339050,-0.8945657,-1.3244268,0.0000000},
{-0.1002775,-0.2763232,-0.0485197,1.3514882,-0.8849937,-1.3094887,0.0000000},
{-0.0984159,-0.2803298,-0.0470581,1.3687631,-0.8765836,-1.2960565,0.0000000},
{-0.0971172,-0.2856790,-0.0460498,1.3846811,-0.8474079,-1.3177876,0.0000000},
{-0.0959586,-0.2914327,-0.0448068,1.3982720,-0.8177500,-1.3561602,0.0000000},
{-0.0951190,-0.2973649,-0.0437888,1.4101856,-0.7012687,-1.6000000,0.0000000},
{-0.0777923,-0.3285671,-0.0363258,1.4201309,-3.9704116,1.5911307,0.0000000},
{-0.0783816,-0.3349911,-0.0374065,1.4301427,-0.6754306,-1.6000000,0.0000000},
{-0.0793342,-0.3416001,-0.0387462,1.4390944,-0.6802130,-1.6000000,0.0000000},
{-0.0806726,-0.3480265,-0.0404936,1.4495978,-0.6516324,-1.6000000,0.0000000},
{-0.0822526,-0.3537376,-0.0423087,1.4599617,-0.6314248,-1.6000000,0.0000000},
{-0.0839028,-0.3589221,-0.0446828,1.4707385,-0.7744207,-1.2484549,0.0000000},
{-0.0820486,-0.3623030,-0.0430934,1.4823164,-0.6509760,-1.6000000,0.0000000},
{-0.0805520,-0.3642077,-0.0413478,1.4897986,-0.6554978,-1.6000000,0.0000000},
{-0.0792137,-0.3675140,-0.0398455,1.4997715,-0.6374781,-1.6000000,0.0000000},
{-0.0772886,-0.3689531,-0.0370586,1.5078020,-0.6527785,-1.6000000,0.0000000},
{-0.0756259,-0.3709337,-0.0344147,1.5161689,-0.6440079,-1.6000000,0.0000000},
{-0.0740435,-0.3725590,-0.0318885,1.5249189,-0.6318358,-1.6000000,0.0000000},
{-0.0731054,-0.3751861,-0.0302268,1.5332201,-0.6267642,-1.6000000,0.0000000},
{-0.0719135,-0.3763683,-0.0279967,1.5397327,-0.6260965,-1.6000000,0.0000000},
{-0.0711261,-0.3771877,-0.0261686,1.5461905,-0.6144604,-1.6000000,0.0000000},
{-0.0706988,-0.3795373,-0.0251040,1.5519567,-0.6084817,-1.5820260,0.0000000},
{-0.0703631,-0.3807841,-0.0241575,1.5567489,-0.5967774,-1.5784312,0.0000000},
{-0.0701424,-0.3813363,-0.0232966,1.5602261,-0.5899039,-1.5546727,0.0000000},
{-0.0699058,-0.3809659,-0.0224787,1.5658219,-0.5755345,-1.6000000,0.0000000},
{-0.0695557,-0.3829474,-0.0215729,1.5718445,-0.5843212,-1.5812588,0.0000000},
{-0.0678176,-0.3901783,-0.0186108,1.5777883,-0.6500014,-1.4077195,0.0000000},
{-0.0670357,-0.3922863,-0.0170143,1.5846183,-0.5886301,-1.5646163,0.0000000},
{-0.0662026,-0.3946326,-0.0153578,1.5912184,-0.5926119,-1.5499722,0.0000000},
{-0.0657359,-0.3980848,-0.0143972,1.5991983,-0.5855202,-1.5708586,0.0000000},
{-0.0646006,-0.4013331,-0.0123166,1.6055391,-0.5940001,-1.5149036,0.0000000},
{-0.0640950,-0.4067987,-0.0114885,1.6109222,-0.5827103,-1.4887924,0.0000000},
{-0.0626877,-0.4119606,-0.0090839,1.6172950,-0.5876894,-1.4835159,0.0000000},
{-0.0618915,-0.4194226,-0.0078826,1.6227877,-0.5792171,-1.4635599,0.0000000},
{-0.0607005,-0.4266209,-0.0059822,1.6281535,-0.5837897,-1.4531833,0.0000000},
{-0.0596407,-0.4355195,-0.0043971,1.6337268,-0.5699894,-1.4595449,0.0000000},
{-0.0585556,-0.4440938,-0.0027495,1.6383646,-0.5662065,-1.4475047,0.0000000},
{-0.0580164,-0.4548385,-0.0021345,1.6411310,-0.5584833,-1.4180171,0.0000000},
{-0.0567117,-0.4659337,-0.0001874,1.6446302,-0.5666486,-1.4191076,0.0000000},
{-0.0557825,-0.4773604,0.0010422,1.6467185,-0.5578283,-1.4176667,0.0000000},
{-0.0546575,-0.4901758,0.0025159,1.6488994,-0.5427344,-1.4312101,0.0000000},
{-0.0535011,-0.5039720,0.0040106,1.6510943,-0.5402012,-1.4390710,0.0000000},
{-0.0522589,-0.5185754,0.0056497,1.6534181,-0.5358827,-1.4471086,0.0000000},
{-0.0519307,-0.5409210,0.0061555,1.6567272,-0.6733866,-0.8662667,0.0000000},
{-0.0504427,-0.5525069,0.0084702,1.6607914,-0.7207813,-0.8408366,0.0000000},
{-0.0498684,-0.5668276,0.0094037,1.6635221,-0.7184765,-0.7979892,0.0000000},
{-0.0473025,-0.5826421,0.0116167,1.6661054,-0.7553460,-0.7857890,0.0000000},
{-0.0452953,-0.6035374,0.0124802,1.6686032,-0.7829050,-0.7343765,0.0000000},
{-0.0453184,-0.6144283,0.0133744,1.6700647,-0.7965566,-0.7300590,0.0000000},
{-0.0424052,-0.6330524,0.0157552,1.6698836,-0.8297894,-0.7114350,0.0000000},
{-0.0419755,-0.6435122,0.0174956,1.6692765,-0.8427823,-0.6930944,0.0000000},
{-0.0402552,-0.6559848,0.0198244,1.6674002,-0.8704017,-0.6738271,0.0000000},
{-0.0384850,-0.6674384,0.0219260,1.6644946,-0.8978049,-0.6541222,0.0000000},
{-0.0366143,-0.6788503,0.0234489,1.6614833,-0.9362978,-0.6205872,0.0000000},
{-0.0378388,-0.6848222,0.0233818,1.6586635,-0.9557624,-0.6265031,0.0000000},
{-0.0356923,-0.7062629,0.0233703,1.6555327,-1.1045639,-0.5469249,0.0000000},
{-0.0339096,-0.7154879,0.0248728,1.6521564,-1.1092396,-0.5861865,0.0000000},
{-0.0334404,-0.7238381,0.0260954,1.6475641,-1.1538820,-0.5916161,0.0000000},
{-0.0324568,-0.7319367,0.0270672,1.6425192,-1.2039902,-0.5831088,0.0000000},
{-0.0315487,-0.7403808,0.0282970,1.6366261,-1.2569681,-0.5816496,0.0000000},
{-0.0302104,-0.7484358,0.0295916,1.6306949,-1.3089848,-0.5723611,0.0000000},
{-0.0290619,-0.7562986,0.0310485,1.6247948,-1.3632651,-0.5658964,0.0000000},
{-0.0270985,-0.7643223,0.0325382,1.6193697,-1.4278920,-0.5532754,0.0000000},
{-0.0252143,-0.7719655,0.0346519,1.6137023,-1.4764976,-0.5517736,0.0000000},
{-0.0228817,-0.7785011,0.0362809,1.6100718,-1.5458212,-0.5465465,0.0000000},
{-0.0209789,-0.7849556,0.0375945,1.6065341,-1.5966345,-0.5472225,0.0000000},
{-0.0187402,-0.7912531,0.0392382,1.6038819,-1.6485996,-0.5559401,0.0000000},
{-0.0170592,-0.7962812,0.0406801,1.6017133,-1.6767444,-0.5637749,0.0000000},
{-0.0150441,-0.8018029,0.0418606,1.6003685,-1.7326147,-0.5653896,0.0000000},
{-0.0134535,-0.8083792,0.0426796,1.5987314,-1.7864217,-0.5736505,0.0000000},
{-0.0123213,-0.8140263,0.0426161,1.5973524,-1.8227725,-0.5755193,0.0000000},
{-0.0111591,-0.8184620,0.0431677,1.5959752,-1.8336459,-0.5889486,0.0000000},
{-0.0106713,-0.8229052,0.0427619,1.5948705,-1.8671738,-0.5940085,0.0000000},
{-0.0097150,-0.8274463,0.0425497,1.5932500,-4.7600000,0.4300346,0.0000000},
{-0.0092779,-0.8300809,0.0419721,1.5936638,-4.7600000,0.4474297,0.0000000},
{-0.0086381,-0.8343598,0.0410710,1.5938483,-4.7600000,0.4302058,0.0000000},
{-0.0087960,-0.8364686,0.0400890,1.5945917,-4.7600000,0.4554319,0.0000000},
{-0.0092536,-0.8394682,0.0384346,1.5937979,-4.7600000,0.4534451,0.0000000},
{-0.0094753,-0.8419119,0.0373512,1.5935442,-4.7600000,0.4663518,0.0000000},
{-0.0099953,-0.8439542,0.0358291,1.5923257,-4.7600000,0.4728329,0.0000000},
{-0.0106909,-0.8452996,0.0342605,1.5909187,-0.8509049,-1.4887962,0.0000000},
{-0.0111469,-0.8465974,0.0327746,1.5890088,-0.8589616,-1.4897067,0.0000000},
{-0.0118643,-0.8489934,0.0312846,1.5872231,-4.7600000,0.4856612,0.0000000},
{-0.0125508,-0.8494753,0.0297113,1.5853125,-0.8735327,-1.4888753,0.0000000}
};
(* 
iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  1.215466e+04    0.00e+00    6.00e+00   0.00e+00   0.00e+00  1.00e+04        0    6.43e-02    6.44e-02
   1  8.195790e+03    3.96e+03    6.00e+00   1.39e+01   6.52e-01  1.03e+04        0    1.34e-01    1.98e-01
   2  6.706663e+03    1.49e+03    5.99e+00   3.27e+00   5.36e-01  1.03e+04        0    1.95e-01    4.89e-01
   3  6.538368e+03    1.68e+02    5.99e+00   2.32e+00   4.15e-01  1.02e+04        0    1.93e-01    6.82e-01
   4  6.446612e+03    9.18e+01    5.99e+00   6.57e-01   3.40e-01  9.92e+03        0    2.58e-01    9.40e-01
   5  6.408612e+03    3.80e+01    5.98e+00   2.93e+00   2.87e-01  9.21e+03        0    1.93e-01    1.13e+00
   6  6.308774e+03    9.98e+01    5.98e+00   8.28e-01   2.52e-01  8.21e+03        0    2.57e-01    1.39e+00
   7  6.230446e+03    7.83e+01    5.98e+00   6.06e-01   2.25e-01  7.03e+03        0    2.55e-01    1.65e+00
   8  6.171277e+03    5.92e+01    5.98e+00   5.21e-01   2.03e-01  5.82e+03        0    2.38e-01    1.88e+00
   9  6.120791e+03    5.05e+01    5.98e+00   4.77e-01   1.85e-01  4.66e+03        0    2.31e-01    2.11e+00
  10  6.098282e+03    2.25e+01    5.98e+00   5.02e-01   1.70e-01  3.62e+03        0    2.39e-01    2.35e+00
  11  6.058159e+03    4.01e+01    5.97e+00   5.14e-01   1.58e-01  2.74e+03        0    2.30e-01    2.58e+00
  12  6.038891e+03    1.93e+01    5.97e+00   5.38e-01   1.47e-01  2.02e+03        0    2.33e-01    2.82e+00
  13  5.979642e+03    5.92e+01    5.97e+00   4.51e-01   1.38e-01  1.47e+03        0    2.31e-01    3.05e+00
  14  5.931790e+03    4.79e+01    5.97e+00   4.33e-01   1.31e-01  1.05e+03        0    2.29e-01    3.28e+00
  15  5.890859e+03    4.09e+01    5.97e+00   4.27e-01   1.24e-01  7.33e+02        0    2.36e-01    3.51e+00
  16  5.846411e+03    4.44e+01    5.97e+00   4.09e-01   1.18e-01  5.07e+02        0    2.35e-01    3.75e+00
  17  5.803133e+03    4.33e+01    5.97e+00   3.90e-01   1.12e-01  3.46e+02        0    2.38e-01    3.99e+00
  18  5.764756e+03    3.84e+01    5.97e+00   3.88e-01   1.08e-01  2.33e+02        0    2.34e-01    4.22e+00
  19  5.721026e+03    4.37e+01    5.97e+00   3.83e-01   1.03e-01  1.56e+02        0    2.36e-01    4.45e+00
  20  5.666015e+03    5.50e+01    5.97e+00   3.90e-01   9.97e-02  1.03e+02        0    2.36e-01    4.69e+00
  21  5.600069e+03    6.59e+01    5.97e+00   1.38e+00   9.66e-02  6.74e+01        0    1.78e-01    4.87e+00
  22  5.381914e+03    2.18e+02    5.97e+00   1.33e+00   9.59e-02  4.41e+01        0    1.78e-01    5.05e+00
  23  5.225420e+03    1.56e+02    5.97e+00   1.44e+00   9.46e-02  2.88e+01        0    1.75e-01    5.22e+00
  24  5.060177e+03    1.65e+02    5.96e+00   1.32e+00   9.36e-02  1.87e+01        0    1.75e-01    5.40e+00
  25  4.741645e+03    3.19e+02    5.96e+00   1.32e+00   1.32e-01  1.34e+01        0    1.75e-01    5.57e+00
  26  4.593461e+03    1.48e+02    5.96e+00   1.24e+00   9.40e-02  8.71e+00        0    1.78e-01    5.75e+00
  27  4.300116e+03    2.93e+02    5.96e+00   1.29e+00   1.40e-01  6.34e+00        0    1.80e-01    5.93e+00
  28  4.106355e+03    1.94e+02    5.96e+00   1.26e+00   1.04e-01  4.23e+00        0    1.75e-01    6.11e+00
  29  3.930793e+03    1.76e+02    5.96e+00   1.16e+00   1.02e-01  2.81e+00        0    1.77e-01    6.28e+00
  30  3.725066e+03    2.06e+02    5.96e+00   1.15e+00   1.28e-01  1.99e+00        0    1.79e-01    6.46e+00
  31  3.636627e+03    8.84e+01    5.89e+00   2.90e+00   9.56e-02  1.30e+00        0    1.20e-01    6.58e+00
  32  3.249015e+03    3.88e+02    4.72e+00   3.24e+00   2.77e-01  1.20e+00        0    1.18e-01    6.70e+00
  33  3.068198e+03    1.81e+02    4.66e+00   1.05e+00   1.74e-01  9.38e-01        0    1.79e-01    6.88e+00
  34  2.922442e+03    1.46e+02    4.56e+00   1.34e+00   1.78e-01  7.39e-01        0    1.77e-01    7.05e+00
  35  2.849156e+03    7.33e+01    4.56e+00   9.09e-01   1.13e-01  5.06e-01        0    1.76e-01    7.23e+00
  36  2.719322e+03    1.30e+02    5.49e+00   1.28e+00   2.68e-01  4.60e-01        0    1.19e-01    7.35e+00
  37  2.666713e+03    5.26e+01    4.56e+00   5.37e-01   1.11e-01  3.13e-01        0    1.80e-01    7.53e+00
  38  2.624710e+03    4.20e+01    4.56e+00   5.05e-01   1.58e-01  2.37e-01        0    1.30e-01    7.66e+00
  39  2.603083e+03    2.16e+01    4.51e+00   7.04e-01   1.01e-01  1.57e-01        0    1.30e-01    7.79e+00
  40  2.576376e+03    2.67e+01    4.38e+00   4.86e-01   1.57e-01  1.19e-01        0    1.30e-01    7.92e+00
  41  2.559325e+03    1.71e+01    4.38e+00   2.51e-01   1.44e-01  8.74e-02        0    1.30e-01    8.05e+00
  42  2.553069e+03    6.26e+00    4.38e+00   7.58e-02   1.01e-01  5.80e-02        0    1.30e-01    8.18e+00
  43  2.549341e+03    3.73e+00    4.38e+00   2.02e-02   1.01e-01  3.85e-02        0    1.30e-01    8.31e+00
  44  2.547060e+03    2.28e+00    4.33e+00   7.25e-03   1.01e-01  2.55e-02        0    1.29e-01    8.44e+00
  45  2.545601e+03    1.46e+00    4.29e+00   4.77e-03   1.01e-01  1.69e-02        0    1.29e-01    8.57e+00
  46  2.544651e+03    9.50e-01    4.27e+00   3.16e-03   1.01e-01  1.12e-02        0    1.29e-01    8.70e+00
  47  2.544030e+03    6.22e-01    4.26e+00   2.09e-03   1.01e-01  7.45e-03        0    1.30e-01    8.83e+00
  48  2.543620e+03    4.09e-01    4.25e+00   1.39e-03   1.01e-01  4.94e-03        0    1.29e-01    8.96e+00
  49  2.543351e+03    2.70e-01    4.24e+00   9.21e-04   1.01e-01  3.28e-03        0    1.29e-01    9.09e+00
  50  2.543172e+03    1.78e-01    4.23e+00   6.11e-04   1.01e-01  2.17e-03        0    1.29e-01    9.21e+00
  51  2.543054e+03    1.18e-01    4.23e+00   4.05e-04   1.01e-01  1.44e-03        0    1.30e-01    9.34e+00
  52  2.542976e+03    7.81e-02    4.23e+00   2.69e-04   1.01e-01  9.57e-04        0    1.29e-01    9.47e+00
  53  2.542924e+03    5.18e-02    4.23e+00   1.78e-04   1.01e-01  6.35e-04        0    1.29e-01    9.60e+00
  54  2.542890e+03    3.43e-02    4.23e+00   1.18e-04   1.01e-01  4.21e-04        0    1.20e-01    9.72e+00
  55  2.542867e+03    2.28e-02    4.23e+00   7.85e-05   1.01e-01  2.79e-04        0    1.21e-01    9.84e+00
  56  2.542852e+03    1.51e-02    4.23e+00   5.20e-05   1.01e-01  1.85e-04        0    1.18e-01    9.96e+00
  57  2.542842e+03    1.00e-02    4.23e+00   3.45e-05   1.01e-01  1.23e-04        0    1.17e-01    1.01e+01
  58  2.542836e+03    6.64e-03    4.23e+00   2.29e-05   1.01e-01  8.15e-05        0    1.18e-01    1.02e+01
  59  2.542831e+03    4.40e-03    4.23e+00   1.52e-05   1.01e-01  5.41e-05        0    1.21e-01    1.03e+01
  60  2.542828e+03    2.92e-03    4.23e+00   1.01e-05   1.01e-01  3.59e-05        0    1.19e-01    1.04e+01
  61  2.542826e+03    1.94e-03    4.23e+00   6.68e-06   1.01e-01  2.38e-05        0    1.19e-01    1.06e+01
  62  2.542825e+03    1.28e-03    4.23e+00   4.43e-06   1.01e-01  1.58e-05        0    1.21e-01    1.07e+01
  63  2.542824e+03    8.52e-04    4.23e+00   2.94e-06   1.01e-01  1.05e-05        0    1.19e-01    1.08e+01
  64  2.542824e+03    5.65e-04    4.23e+00   1.95e-06   1.01e-01  6.94e-06        0    1.21e-01    1.09e+01
  65  2.542823e+03    3.75e-04    4.23e+00   1.29e-06   1.01e-01  4.61e-06        0    1.18e-01    1.10e+01
  66  2.542823e+03    2.49e-04    4.23e+00   8.59e-07   1.01e-01  3.06e-06        0    1.17e-01    1.12e+01
  67  2.542823e+03    1.65e-04    4.23e+00   5.70e-07   1.01e-01  2.03e-06        0    1.17e-01    1.13e+01
  68  2.542823e+03    1.09e-04    4.23e+00   3.78e-07   1.01e-01  1.34e-06        0    1.18e-01    1.14e+01
  69  2.542823e+03    7.26e-05    4.23e+00   2.51e-07   1.01e-01  8.92e-07        0    1.22e-01    1.15e+01
  70  2.542823e+03    4.82e-05    4.23e+00   1.66e-07   1.01e-01  5.92e-07        0    1.22e-01    1.16e+01
  71  2.542823e+03    3.19e-05    4.23e+00   1.10e-07   1.01e-01  3.92e-07        0    1.21e-01    1.18e+01
  72  2.542823e+03    2.12e-05    4.23e+00   7.31e-08   1.01e-01  2.60e-07        0    1.21e-01    1.19e+01
  73  2.542823e+03    1.41e-05    4.23e+00   4.85e-08   1.01e-01  1.73e-07        0    1.21e-01    1.20e+01
  74  2.542823e+03    9.32e-06    4.23e+00   3.22e-08   1.01e-01  1.15e-07        0    1.19e-01    1.21e+01
  75  2.542823e+03    6.18e-06    4.23e+00   2.14e-08   1.01e-01  7.60e-08        0    1.18e-01    1.22e+01
  76  2.542823e+03    4.10e-06    4.23e+00   1.42e-08   1.01e-01  5.04e-08        0    1.21e-01    1.24e+01
  77  2.542823e+03    2.72e-06    4.23e+00   9.39e-09   1.01e-01  3.34e-08        0    1.21e-01    1.25e+01
  78  2.542823e+03    1.81e-06    4.23e+00   6.23e-09   1.01e-01  2.22e-08        0    1.19e-01    1.26e+01
  79  2.542823e+03    1.20e-06    4.23e+00   4.13e-09   1.01e-01  1.47e-08        0    1.20e-01    1.27e+01
  80  2.542823e+03    7.94e-07    4.23e+00   2.74e-09   1.01e-01  9.76e-09        0    1.20e-01    1.28e+01
  81  2.542823e+03    5.27e-07    4.23e+00   1.82e-09   1.01e-01  6.47e-09        0    1.22e-01    1.30e+01
  82  2.542823e+03    3.50e-07    4.23e+00   1.21e-09   1.01e-01  4.29e-09        0    1.19e-01    1.31e+01
  83  2.542823e+03    2.32e-07    4.23e+00   8.00e-10   1.01e-01  2.85e-09        0    1.18e-01    1.32e+01
  84  2.542823e+03    1.54e-07    4.23e+00   5.31e-10   1.01e-01  1.89e-09        0    1.17e-01    1.33e+01
  85  2.542823e+03    1.02e-07    4.23e+00   3.52e-10   1.01e-01  1.25e-09        0    1.18e-01    1.34e+01
  86  2.542823e+03    6.77e-08    4.23e+00   2.34e-10   1.01e-01  8.31e-10        0    1.18e-01    1.35e+01
  87  2.542823e+03    4.49e-08    4.23e+00   1.55e-10   1.01e-01  5.51e-10        0    1.17e-01    1.37e+01
  88  2.542823e+03    2.98e-08    4.23e+00   1.03e-10   1.01e-01  3.66e-10        0    1.17e-01    1.38e+01
  89  2.542823e+03    1.98e-08    4.23e+00   6.82e-11   1.01e-01  2.43e-10        0    1.30e-01    1.39e+01
  90  2.542823e+03    1.31e-08    4.23e+00   4.52e-11   1.01e-01  1.61e-10        0    1.32e-01    1.40e+01
  91  2.542823e+03    8.70e-09    4.23e+00   3.00e-11   1.01e-01  1.07e-10        0    1.30e-01    1.42e+01
  92  2.542823e+03    5.77e-09    4.23e+00   1.99e-11   1.01e-01  7.08e-11        0    1.30e-01    1.43e+01
  93  2.542823e+03    3.82e-09    4.23e+00   1.32e-11   1.01e-01  4.70e-11        0    1.30e-01    1.44e+01
  94  2.542823e+03    2.54e-09    4.23e+00   8.76e-12   1.01e-01  3.12e-11        0    1.30e-01    1.46e+01
  95  2.542823e+03    1.68e-09    4.23e+00   5.81e-12   1.01e-01  2.07e-11        0    1.30e-01    1.47e+01
  96  2.542823e+03    1.11e-09    4.23e+00   3.85e-12   1.01e-01  1.37e-11        0    1.30e-01    1.48e+01
  97  2.542823e+03    7.44e-10    4.23e+00   2.56e-12   1.01e-01  9.10e-12        0    1.30e-01    1.50e+01
  98  2.542823e+03    4.93e-10    4.23e+00   1.70e-12   1.01e-01  6.03e-12        0    1.31e-01    1.51e+01
  99  2.542823e+03    3.31e-10    4.23e+00   1.12e-12   1.01e-01  4.00e-12        0    1.29e-01    1.52e+01
 100  2.542823e+03    2.19e-10    4.23e+00   7.46e-13   1.01e-01  2.66e-12        0    1.30e-01    1.53e+01
 101  2.542823e+03    1.45e-10    4.23e+00   4.95e-13   1.01e-01  1.76e-12        0    1.30e-01    1.55e+01
 102  2.542823e+03    9.46e-11    4.23e+00   3.28e-13   1.01e-01  1.17e-12        0    1.32e-01    1.56e+01
 103  2.542823e+03    6.23e-11    4.23e+00   2.18e-13   1.01e-01  7.75e-13        0    1.30e-01    1.57e+01
 104  2.542823e+03    4.32e-11    4.23e+00   1.44e-13   1.01e-01  5.14e-13        0    1.31e-01    1.59e+01
 105  2.542823e+03    2.91e-11    4.23e+00   9.59e-14   1.01e-01  3.41e-13        0    1.31e-01    1.60e+01
 106  2.542823e+03    2.14e-11    4.23e+00   6.36e-14   1.01e-01  2.26e-13        0    1.30e-01    1.61e+01
 107  2.542823e+03    1.18e-11    4.23e+00   4.22e-14   1.01e-01  1.50e-13        0    1.30e-01    1.63e+01
 108  2.542823e+03    9.09e-12    4.23e+00   2.80e-14   1.01e-01  9.96e-14        0    1.30e-01    1.64e+01
 109  2.542823e+03    6.37e-12    4.23e+00   1.86e-14   1.01e-01  6.60e-14        0    1.30e-01    1.65e+01
 110  2.542823e+03    6.37e-12    4.23e+00   1.23e-14   1.01e-01  4.38e-14        0    1.30e-01    1.66e+01
 111  2.542823e+03    1.36e-12    4.23e+00   8.25e-15   1.01e-01  2.91e-14        0    1.30e-01    1.68e+01
 112  2.542823e+03    1.36e-12    4.23e+00   5.41e-15   1.01e-01  1.93e-14        0    1.30e-01    1.69e+01
 113  2.542823e+03    2.27e-12    4.23e+00   3.56e-15   1.12e-01  1.31e-14        0    1.30e-01    1.70e+01
 114  2.542823e+03    2.73e-12    4.23e+00   2.43e-15   1.31e-01  9.38e-15        0    1.30e-01    1.72e+01
 115  2.542823e+03    9.09e-13    4.23e+00   1.80e-15   1.01e-01  6.22e-15        0    1.30e-01    1.73e+01

Solver Summary (v 1.12.0-eigen-(3.2.92)-lapack-suitesparse-(4.4.6)-cxsparse-(3.1.4)-openmp)

                                     Original                  Reduced
Parameter blocks                           99                       99
Parameters                                297                      297
Residual blocks                            99                       99
Residual                                  297                      297

Minimizer                        TRUST_REGION

Sparse linear algebra library    SUITE_SPARSE
Trust region strategy     LEVENBERG_MARQUARDT

                                        Given                     Used
Linear solver                    SPARSE_SCHUR             SPARSE_SCHUR
Threads                                     1                        1
Linear solver threads                       1                        1
Linear solver ordering              AUTOMATIC                       99

Cost:
Initial                          1.215466e+04
Final                            2.542823e+03
Change                           9.611835e+03

Minimizer iterations                      116
Successful steps                          116
Unsuccessful steps                          0
Line search steps                          50

Time (in seconds):
Preprocessor                           0.0002

  Residual evaluation                  0.2532
    Line search cost evaluation        0.0000
  Jacobian evaluation                 16.9885
    Line search gradient evaluation    9.9604
  Linear solver                        0.0136
  Line search polynomial minimization  0.0007
Minimizer                             17.3613

Postprocessor                          0.0000
Total                                 17.3614

Termination:                      CONVERGENCE (Function tolerance reached. |cost_change|/cost: 0.000000e+00 <= 1.000000e-100)

*) 
fitErrUA Mean = 0.0000000
fitErrEl Mean = 0.0000000
fitErrLa Mean = 0.0000000
fitErrWr Mean = 0.0000000
fitErrEe Mean = 0.0532520
fitErrUA = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrEl = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrLa = {
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000}
};
fitErrWr = {
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,-0.0000000},
{0.0000000,0.0000000,0.0000000},
{-0.0000000,-0.0000000,-0.0000000},
{-0.0000000,0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000},
{0.0000000,-0.0000000,-0.0000000}
};
fitErrEe = {
{-0.0354113,-0.0782404,0.0772527},
{0.0287529,-0.0775657,0.0650675},
{0.0272650,-0.0774794,0.0650711},
{0.0265831,-0.0774857,0.0652419},
{0.0256759,-0.0773220,0.0656362},
{0.0247751,-0.0771998,0.0660724},
{0.0239534,-0.0770435,0.0666415},
{0.0225489,-0.0766735,0.0673127},
{0.0208877,-0.0769112,0.0673343},
{0.0225575,-0.0739761,0.0664902},
{0.0233170,-0.0717458,0.0655357},
{0.0240861,-0.0692546,0.0644850},
{0.0243515,-0.0672905,0.0635334},
{0.0247127,-0.0650564,0.0623048},
{0.0252170,-0.0626985,0.0607653},
{0.0249266,-0.0601125,0.0593232},
{0.0250736,-0.0574726,0.0576296},
{0.0252585,-0.0545503,0.0557664},
{0.0255179,-0.0517572,0.0538047},
{0.0255957,-0.0489551,0.0515542},
{0.0260143,-0.0465067,0.0493262},
{0.0251467,-0.0468845,0.0492930},
{0.0255550,-0.0447521,0.0470288},
{0.0259577,-0.0426460,0.0443872},
{0.0260696,-0.0407275,0.0420189},
{0.0260189,-0.0390344,0.0397407},
{0.0259872,-0.0381095,0.0387168},
{0.0253255,-0.0367511,0.0377148},
{0.0243731,-0.0356331,0.0364510},
{0.0236275,-0.0341205,0.0348804},
{0.0229456,-0.0327918,0.0333870},
{0.0221986,-0.0314061,0.0313505},
{0.0214953,-0.0301319,0.0299235},
{0.0210634,-0.0289233,0.0282259},
{0.0200899,-0.0277488,0.0267438},
{0.0195944,-0.0271303,0.0256882},
{0.0189376,-0.0261551,0.0238134},
{0.0182107,-0.0254448,0.0225747},
{0.0176427,-0.0250013,0.0212627},
{0.0174680,-0.0251751,0.0210898},
{0.0169994,-0.0241997,0.0193172},
{0.0146585,-0.0181137,0.0184663},
{0.0129519,-0.0147034,0.0209789},
{0.0108631,-0.0109286,0.0239277},
{0.0072792,-0.0058819,0.0283304},
{0.0018317,-0.0000511,0.0323563},
{-0.0095303,0.0087224,0.0383366},
{-0.0120771,0.0118452,0.0358342},
{-0.0125972,0.0138669,0.0316952},
{-0.0147301,0.0164964,0.0281048},
{-0.0169645,0.0189585,0.0239852},
{-0.0191450,0.0208375,0.0197398},
{-0.0216098,0.0222638,0.0150720},
{-0.0242024,0.0232150,0.0100589},
{-0.0260536,0.0239086,0.0069319},
{-0.0276111,0.0249275,0.0048287},
{-0.0284199,0.0252055,0.0034353},
{-0.0289574,0.0255553,0.0025069},
{-0.0293798,0.0259076,0.0019475},
{-0.0293519,0.0263852,0.0021520},
{-0.0294072,0.0271721,0.0022823},
{-0.0288137,0.0271986,0.0025750},
{-0.0280824,0.0275099,0.0031711},
{-0.0278704,0.0279426,0.0035836},
{-0.0271455,0.0281576,0.0038727},
{-0.0270251,0.0287940,0.0040797},
{-0.0265285,0.0290136,0.0043038},
{-0.0259687,0.0292313,0.0046004},
{-0.0254820,0.0295964,0.0048029},
{-0.0246822,0.0293114,0.0055367},
{-0.0235494,0.0298529,0.0062027},
{-0.0226819,0.0297430,0.0067582},
{-0.0216130,0.0296083,0.0076030},
{-0.0207785,0.0296554,0.0081325},
{-0.0198516,0.0296814,0.0087015},
{-0.0191492,0.0298435,0.0090185},
{-0.0184578,0.0300772,0.0093582},
{-0.0178315,0.0303148,0.0095733},
{-0.0171957,0.0305486,0.0097957},
{-0.0164927,0.0306952,0.0101384},
{-0.0157853,0.0307613,0.0104689},
{-0.0150150,0.0307026,0.0108274},
{-0.0144001,0.0306630,0.0111056},
{-0.0138180,0.0308213,0.0114016},
{-0.0130470,0.0309399,0.0118313},
{-0.0135258,0.0328401,0.0136461},
{-0.0183631,0.0379480,0.0179093},
{-0.0215163,0.0407071,0.0207576},
{-0.0239891,0.0426525,0.0230269},
{-0.0256056,0.0436434,0.0244313},
{-0.0255846,0.0446796,0.0272750},
{-0.0242225,0.0447252,0.0291343},
{-0.0227095,0.0449717,0.0318002},
{-0.0213728,0.0450555,0.0339003},
{-0.0203361,0.0451156,0.0357920},
{-0.0010915,0.0027489,-0.0000320},
{-0.0006814,0.0018246,0.0000003},
{-0.0176648,0.0450021,0.0403840},
{-0.0000000,0.0000000,-0.0000000}
};
outShoToUaVsWam = {
{-0.3938006,-0.3705459,-0.1005826},
{-0.3948034,-0.3695158,-0.1004407},
{-0.3965285,-0.3677113,-0.1002672},
{-0.3986010,-0.3656589,-0.0995528},
{-0.4008618,-0.3634268,-0.0986446},
{-0.4031109,-0.3609329,-0.0986362},
{-0.4057808,-0.3580799,-0.0980850},
{-0.4087193,-0.3549036,-0.0974265},
{-0.4132201,-0.3492220,-0.0989604},
{-0.4174501,-0.3444710,-0.0978528},
{-0.4218082,-0.3392198,-0.0975082},
{-0.4263963,-0.3334321,-0.0975150},
{-0.4310397,-0.3275073,-0.0971788},
{-0.4358662,-0.3212874,-0.0964109},
{-0.4416850,-0.3136535,-0.0950574},
{-0.4474944,-0.3054195,-0.0946977},
{-0.4532002,-0.2974845,-0.0928035},
{-0.4584396,-0.2898569,-0.0911925},
{-0.4635210,-0.2827381,-0.0877920},
{-0.4686856,-0.2751933,-0.0842762},
{-0.4733612,-0.2683002,-0.0802754},
{-0.4783310,-0.2605870,-0.0761178},
{-0.4831411,-0.2531332,-0.0706980},
{-0.4881207,-0.2450988,-0.0645352},
{-0.4927746,-0.2374525,-0.0573541},
{-0.4972569,-0.2297068,-0.0497027},
{-0.4997187,-0.2257840,-0.0424598},
{-0.5012567,-0.2224015,-0.0421815},
{-0.5029948,-0.2184163,-0.0423147},
{-0.5052108,-0.2134711,-0.0411352},
{-0.5075882,-0.2076244,-0.0417898},
{-0.5103565,-0.2007825,-0.0415042},
{-0.5124847,-0.1952932,-0.0414727},
{-0.5148997,-0.1891908,-0.0398136},
{-0.5169122,-0.1836955,-0.0394684},
{-0.5192234,-0.1773355,-0.0381993},
{-0.5216915,-0.1704997,-0.0356060},
{-0.5237280,-0.1645819,-0.0334928},
{-0.5258802,-0.1580303,-0.0312483},
{-0.5274619,-0.1530063,-0.0295465},
{-0.5298342,-0.1452045,-0.0262948},
{-0.5329823,-0.1338259,-0.0228132},
{-0.5349841,-0.1260421,-0.0201338},
{-0.5369075,-0.1180206,-0.0173615},
{-0.5390034,-0.1086829,-0.0127832},
{-0.5406667,-0.1003838,-0.0101288},
{-0.5422026,-0.0921184,-0.0055269},
{-0.5435738,-0.0837882,-0.0026563},
{-0.5447842,-0.0755357,0.0021186},
{-0.5458055,-0.0675378,0.0059163},
{-0.5466322,-0.0598818,0.0103620},
{-0.5472868,-0.0526381,0.0143655},
{-0.5477156,-0.0460775,0.0196072},
{-0.5481531,-0.0380902,0.0240271},
{-0.5483779,-0.0308073,0.0288552},
{-0.5484755,-0.0230339,0.0338248},
{-0.5484200,-0.0157156,0.0385819},
{-0.5482365,-0.0083667,0.0432060},
{-0.5478261,-0.0035395,0.0487237},
{-0.5473764,0.0057523,0.0533481},
{-0.5465684,0.0143150,0.0596492},
{-0.5458023,0.0234429,0.0636422},
{-0.5447164,0.0315075,0.0692196},
{-0.5436785,0.0378249,0.0740471},
{-0.5425595,0.0459562,0.0775708},
{-0.5413816,0.0524758,0.0815611},
{-0.5399672,0.0594291,0.0860442},
{-0.5385914,0.0660170,0.0897831},
{-0.5371885,0.0733353,0.0924688},
{-0.5361828,0.0756162,0.0963857},
{-0.5333047,0.0906650,0.0993274},
{-0.5318825,0.0964464,0.1014848},
{-0.5303394,0.1007534,0.1053038},
{-0.5289036,0.1055950,0.1077530},
{-0.5272594,0.1104041,0.1109435},
{-0.5256876,0.1153232,0.1133717},
{-0.5239787,0.1199174,0.1164738},
{-0.5223545,0.1252361,0.1181598},
{-0.5205191,0.1299528,0.1211288},
{-0.5191435,0.1346218,0.1219302},
{-0.5176840,0.1391566,0.1230396},
{-0.5161961,0.1436733,0.1240949},
{-0.5148727,0.1471792,0.1254768},
{-0.5135712,0.1513312,0.1258710},
{-0.5118884,0.1560741,0.1269297},
{-0.5105895,0.1603382,0.1268463},
{-0.5093995,0.1636073,0.1274549},
{-0.5082990,0.1668771,0.1276093},
{-0.5072239,0.1703884,0.1272465},
{-0.5067115,0.1725196,0.1264138},
{-0.5058123,0.1759202,0.1253236},
{-0.5053918,0.1775194,0.1247639},
{-0.5047947,0.1797456,0.1239914},
{-0.5042510,0.1815420,0.1235858},
{-0.5038935,0.1830550,0.1228097},
{-0.5037330,0.1840350,0.1220008},
{-0.5036258,0.1850764,0.1208627},
{-0.5030495,0.1866735,0.1208067},
{-0.5031806,0.1870841,0.1196195}
};
outShoToElVsWam = {
{-0.3682806,-0.3889318,-0.1327647},
{-0.3692298,-0.3881410,-0.1324421},
{-0.3709565,-0.3866038,-0.1321129},
{-0.3730600,-0.3848772,-0.1312279},
{-0.3753416,-0.3830394,-0.1300941},
{-0.3775805,-0.3809189,-0.1298413},
{-0.3802513,-0.3785487,-0.1289762},
{-0.3831919,-0.3759235,-0.1279472},
{-0.3878099,-0.3707036,-0.1292567},
{-0.3921930,-0.3665612,-0.1278378},
{-0.3967395,-0.3618412,-0.1272543},
{-0.4015362,-0.3565950,-0.1270185},
{-0.4064430,-0.3511801,-0.1264977},
{-0.4115777,-0.3454937,-0.1255506},
{-0.4178311,-0.3384564,-0.1240541},
{-0.4240594,-0.3308200,-0.1235182},
{-0.4302448,-0.3235222,-0.1214407},
{-0.4359208,-0.3165422,-0.1195790},
{-0.4415301,-0.3100249,-0.1160203},
{-0.4472785,-0.3030361,-0.1124102},
{-0.4525412,-0.2966286,-0.1083650},
{-0.4581957,-0.2893147,-0.1043010},
{-0.4637323,-0.2822860,-0.0989543},
{-0.4695229,-0.2746669,-0.0929050},
{-0.4750186,-0.2674191,-0.0858449},
{-0.4803843,-0.2600335,-0.0783488},
{-0.4834471,-0.2564031,-0.0711427},
{-0.4851328,-0.2533545,-0.0705880},
{-0.4870721,-0.2496109,-0.0705700},
{-0.4896055,-0.2449950,-0.0692015},
{-0.4922849,-0.2394150,-0.0697212},
{-0.4954736,-0.2328596,-0.0693352},
{-0.4979206,-0.2276300,-0.0691714},
{-0.5007873,-0.2217842,-0.0674453},
{-0.5031556,-0.2164789,-0.0670547},
{-0.5059485,-0.2102415,-0.0658755},
{-0.5089890,-0.2035725,-0.0633519},
{-0.5115237,-0.1977493,-0.0613493},
{-0.5142335,-0.1912422,-0.0592899},
{-0.5162471,-0.1862185,-0.0577631},
{-0.5192907,-0.1785476,-0.0546156},
{-0.5232875,-0.1676563,-0.0508581},
{-0.5259229,-0.1600164,-0.0482165},
{-0.5284980,-0.1521434,-0.0454669},
{-0.5314239,-0.1429613,-0.0409354},
{-0.5337420,-0.1348454,-0.0382258},
{-0.5360246,-0.1268019,-0.0335249},
{-0.5380530,-0.1187220,-0.0304799},
{-0.5400088,-0.1107515,-0.0254866},
{-0.5417102,-0.1030301,-0.0214430},
{-0.5432224,-0.0956881,-0.0166803},
{-0.5445175,-0.0887277,-0.0123716},
{-0.5455981,-0.0824731,-0.0067724},
{-0.5467411,-0.0748018,-0.0019588},
{-0.5476484,-0.0677923,0.0032316},
{-0.5484658,-0.0603014,0.0086032},
{-0.5490865,-0.0532760,0.0138074},
{-0.5495739,-0.0462182,0.0189061},
{-0.5496593,-0.0419331,0.0253234},
{-0.5500350,-0.0327588,0.0302219},
{-0.5500695,-0.0243175,0.0368397},
{-0.5500940,-0.0152629,0.0410935},
{-0.5497818,-0.0073102,0.0470265},
{-0.5493653,-0.0010855,0.0521692},
{-0.5489415,0.0069639,0.0560331},
{-0.5483620,0.0133957,0.0603710},
{-0.5475965,0.0202815,0.0652052},
{-0.5468154,0.0268160,0.0692734},
{-0.5460240,0.0341216,0.0722395},
{-0.5453364,0.0364622,0.0761823},
{-0.5436504,0.0516889,0.0793567},
{-0.5427103,0.0574645,0.0817827},
{-0.5416107,0.0617872,0.0858206},
{-0.5406061,0.0666561,0.0884705},
{-0.5394158,0.0714880,0.0918972},
{-0.5382753,0.0764238,0.0945730},
{-0.5369972,0.0810310,0.0979436},
{-0.5358023,0.0863622,0.0999121},
{-0.5343917,0.0910621,0.1032384},
{-0.5333641,0.0957250,0.1043287},
{-0.5322582,0.1002768,0.1056917},
{-0.5311169,0.1047944,0.1070420},
{-0.5300800,0.1082997,0.1086802},
{-0.5290815,0.1124722,0.1093058},
{-0.5277731,0.1172779,0.1105733},
{-0.5267859,0.1216362,0.1105726},
{-0.5258503,0.1249524,0.1113253},
{-0.5250008,0.1283197,0.1115043},
{-0.5241746,0.1319194,0.1111900},
{-0.5237977,0.1341236,0.1103262},
{-0.5231219,0.1376431,0.1091917},
{-0.5228103,0.1393290,0.1085439},
{-0.5223670,0.1416927,0.1076148},
{-0.5219515,0.1435889,0.1071160},
{-0.5216918,0.1452157,0.1061844},
{-0.5215880,0.1462988,0.1052027},
{-0.5215288,0.1474367,0.1038998},
{-0.5210783,0.1491572,0.1037043},
{-0.5212079,0.1496536,0.1023285}
};
outShoToLaVsWam = {
{-0.4074878,-0.4106883,-0.1289637},
{-0.4085167,-0.4097701,-0.1287376},
{-0.4103476,-0.4080617,-0.1285219},
{-0.4125703,-0.4061284,-0.1277173},
{-0.4149677,-0.4040967,-0.1267230},
{-0.4173176,-0.4018049,-0.1267206},
{-0.4201118,-0.3992369,-0.1261243},
{-0.4231610,-0.3964480,-0.1254537},
{-0.4279762,-0.3908911,-0.1272237},
{-0.4325032,-0.3864910,-0.1261357},
{-0.4371881,-0.3815174,-0.1259272},
{-0.4421305,-0.3759927,-0.1261047},
{-0.4471565,-0.3703411,-0.1259869},
{-0.4524029,-0.3644221,-0.1254305},
{-0.4587922,-0.3570875,-0.1243198},
{-0.4651499,-0.3491499,-0.1242861},
{-0.4714307,-0.3416142,-0.1226217},
{-0.4771852,-0.3344207,-0.1211924},
{-0.4828689,-0.3277093,-0.1178558},
{-0.4887312,-0.3204379,-0.1143734},
{-0.4941018,-0.3137676,-0.1103563},
{-0.4999108,-0.3060820,-0.1062281},
{-0.5055926,-0.2987055,-0.1007203},
{-0.5115565,-0.2906638,-0.0944139},
{-0.5171875,-0.2830814,-0.0870585},
{-0.5226855,-0.2753580,-0.0792219},
{-0.5257541,-0.2717254,-0.0717341},
{-0.5274091,-0.2687447,-0.0715156},
{-0.5293796,-0.2648988,-0.0717347},
{-0.5319442,-0.2601797,-0.0705669},
{-0.5346958,-0.2543675,-0.0713752},
{-0.5379803,-0.2475113,-0.0712064},
{-0.5404749,-0.2421087,-0.0712907},
{-0.5434159,-0.2360280,-0.0696625},
{-0.5458553,-0.2304830,-0.0694256},
{-0.5487442,-0.2239368,-0.0683191},
{-0.5519046,-0.2168969,-0.0657419},
{-0.5545414,-0.2107479,-0.0636980},
{-0.5573808,-0.2038201,-0.0615501},
{-0.5594583,-0.1985719,-0.0600401},
{-0.5626297,-0.1904629,-0.0567967},
{-0.5668263,-0.1788419,-0.0529207},
{-0.5695649,-0.1707975,-0.0502518},
{-0.5722459,-0.1624945,-0.0474610},
{-0.5752911,-0.1528234,-0.0427803},
{-0.5777111,-0.1442507,-0.0400300},
{-0.5801031,-0.1357241,-0.0350999},
{-0.5822226,-0.1271937,-0.0319903},
{-0.5842737,-0.1187534,-0.0267481},
{-0.5860589,-0.1105815,-0.0225281},
{-0.5876439,-0.1028296,-0.0175348},
{-0.5890064,-0.0954613,-0.0130041},
{-0.5901516,-0.0887915,-0.0070260},
{-0.5913637,-0.0806178,-0.0019152},
{-0.5923311,-0.0731109,0.0036421},
{-0.5932035,-0.0650880,0.0093943},
{-0.5938662,-0.0575704,0.0149667},
{-0.5943869,-0.0500242,0.0204237},
{-0.5944734,-0.0455168,0.0272869},
{-0.5948780,-0.0357512,0.0324906},
{-0.5949208,-0.0267284,0.0395871},
{-0.5949563,-0.0170370,0.0441311},
{-0.5946312,-0.0085352,0.0504957},
{-0.5941927,-0.0018622,0.0560295},
{-0.5937464,0.0068482,0.0602181},
{-0.5931286,0.0138260,0.0649284},
{-0.5923055,0.0213453,0.0702023},
{-0.5914581,0.0285260,0.0746681},
{-0.5905953,0.0365458,0.0779421},
{-0.5898399,0.0391891,0.0822651},
{-0.5880035,0.0557816,0.0857641},
{-0.5869639,0.0621614,0.0884573},
{-0.5857387,0.0670180,0.0929168},
{-0.5846074,0.0724831,0.0958822},
{-0.5832614,0.0779416,0.0997019},
{-0.5819626,0.0835138,0.1027069},
{-0.5805084,0.0887293,0.1064592},
{-0.5791430,0.0947092,0.1086823},
{-0.5775355,0.1000167,0.1123724},
{-0.5763651,0.1052037,0.1136060},
{-0.5751079,0.1102659,0.1151323},
{-0.5738216,0.1152569,0.1166256},
{-0.5726559,0.1191341,0.1184223},
{-0.5715412,0.1236994,0.1191101},
{-0.5700822,0.1289590,0.1204975},
{-0.5689767,0.1337225,0.1205152},
{-0.5679294,0.1373610,0.1213440},
{-0.5669789,0.1410412,0.1215543},
{-0.5660449,0.1449931,0.1212379},
{-0.5656357,0.1473572,0.1202986},
{-0.5648946,0.1511505,0.1190709},
{-0.5645633,0.1529405,0.1183630},
{-0.5640616,0.1555201,0.1173802},
{-0.5636004,0.1575752,0.1168503},
{-0.5632930,0.1593748,0.1158722},
{-0.5631534,0.1605939,0.1148446},
{-0.5630537,0.1618913,0.1134780},
{-0.5625274,0.1638122,0.1133062},
{-0.5626346,0.1644156,0.1118635}
};
outShoToWrVsWam = {
{-0.3252429,-0.5973360,-0.3489601},
{-0.3257916,-0.5975198,-0.3476133},
{-0.3273932,-0.5968138,-0.3464467},
{-0.3296034,-0.5961909,-0.3444955},
{-0.3315020,-0.5956295,-0.3420104},
{-0.3328423,-0.5944807,-0.3405896},
{-0.3344372,-0.5935228,-0.3380508},
{-0.3356265,-0.5923799,-0.3350925},
{-0.3396872,-0.5875663,-0.3358476},
{-0.3431652,-0.5848307,-0.3327273},
{-0.3469054,-0.5809480,-0.3310527},
{-0.3509086,-0.5764912,-0.3297684},
{-0.3549826,-0.5715907,-0.3284779},
{-0.3593088,-0.5664862,-0.3266856},
{-0.3651883,-0.5600251,-0.3244563},
{-0.3705629,-0.5528533,-0.3231787},
{-0.3758391,-0.5463423,-0.3199759},
{-0.3802899,-0.5404293,-0.3165683},
{-0.3855792,-0.5350169,-0.3116554},
{-0.3920230,-0.5290695,-0.3070398},
{-0.3983788,-0.5235968,-0.3022126},
{-0.4063578,-0.5167647,-0.2982194},
{-0.4144229,-0.5104944,-0.2926409},
{-0.4236090,-0.5036339,-0.2865310},
{-0.4321793,-0.4970525,-0.2793864},
{-0.4408916,-0.4901543,-0.2720231},
{-0.4450476,-0.4871340,-0.2643103},
{-0.4444967,-0.4850105,-0.2621845},
{-0.4457747,-0.4818203,-0.2613535},
{-0.4477270,-0.4780725,-0.2587960},
{-0.4503058,-0.4730142,-0.2586502},
{-0.4541081,-0.4670188,-0.2577054},
{-0.4563028,-0.4623459,-0.2567918},
{-0.4599504,-0.4570406,-0.2545596},
{-0.4629460,-0.4520456,-0.2539143},
{-0.4672400,-0.4456234,-0.2532843},
{-0.4725965,-0.4390951,-0.2510477},
{-0.4772001,-0.4331029,-0.2496458},
{-0.4827729,-0.4261312,-0.2486635},
{-0.4861251,-0.4203990,-0.2482288},
{-0.4920374,-0.4126673,-0.2455875},
{-0.5001630,-0.4038617,-0.2397953},
{-0.5051293,-0.3963213,-0.2373001},
{-0.5102136,-0.3886177,-0.2345980},
{-0.5164327,-0.3795706,-0.2301874},
{-0.5213301,-0.3719546,-0.2270383},
{-0.5270856,-0.3647455,-0.2214821},
{-0.5316756,-0.3577095,-0.2172130},
{-0.5370382,-0.3510666,-0.2105942},
{-0.5417355,-0.3446959,-0.2048078},
{-0.5462054,-0.3390114,-0.1978151},
{-0.5504314,-0.3335711,-0.1913737},
{-0.5550744,-0.3290623,-0.1832063},
{-0.5599204,-0.3231619,-0.1756497},
{-0.5647942,-0.3176932,-0.1678841},
{-0.5697971,-0.3118005,-0.1596769},
{-0.5743013,-0.3064782,-0.1513526},
{-0.5785935,-0.3011295,-0.1429675},
{-0.5810036,-0.3003639,-0.1304202},
{-0.5856970,-0.2917354,-0.1236754},
{-0.5905567,-0.2838948,-0.1148357},
{-0.5951062,-0.2751213,-0.1088149},
{-0.5992256,-0.2677610,-0.1004377},
{-0.6025280,-0.2620322,-0.0931082},
{-0.6068084,-0.2543052,-0.0868476},
{-0.6104048,-0.2482599,-0.0800286},
{-0.6145222,-0.2415482,-0.0726033},
{-0.6185580,-0.2350365,-0.0660457},
{-0.6227205,-0.2274269,-0.0609332},
{-0.6249635,-0.2244499,-0.0565181},
{-0.6321076,-0.2073123,-0.0514817},
{-0.6353326,-0.2011334,-0.0469544},
{-0.6384743,-0.1962061,-0.0409937},
{-0.6417497,-0.1905694,-0.0365494},
{-0.6452096,-0.1848986,-0.0309789},
{-0.6485655,-0.1791156,-0.0260946},
{-0.6517465,-0.1736655,-0.0203244},
{-0.6548556,-0.1674609,-0.0159549},
{-0.6577567,-0.1620561,-0.0096210},
{-0.6599771,-0.1567915,-0.0062587},
{-0.6621184,-0.1514795,-0.0028444},
{-0.6639249,-0.1463863,0.0007628},
{-0.6653082,-0.1424198,0.0043825},
{-0.6666154,-0.1376882,0.0066939},
{-0.6681402,-0.1319590,0.0095631},
{-0.6695190,-0.1265223,0.0102251},
{-0.6705715,-0.1225037,0.0120968},
{-0.6716180,-0.1181251,0.0125429},
{-0.6728094,-0.1134888,0.0126631},
{-0.6731940,-0.1107008,0.0114992},
{-0.6739021,-0.1061741,0.0099773},
{-0.6740952,-0.1038937,0.0086409},
{-0.6748464,-0.1003536,0.0066761},
{-0.6753172,-0.0976323,0.0055468},
{-0.6760039,-0.0949787,0.0036201},
{-0.6766344,-0.0929496,0.0015407},
{-0.6773842,-0.0908368,-0.0007894},
{-0.6781960,-0.0879351,-0.0017769},
{-0.6788198,-0.0865758,-0.0043445}
};
outShoToEeVsWam = {
{-0.3010580,-0.5700695,-0.3966217},
{-0.3660946,-0.5709436,-0.3832415},
{-0.3674252,-0.5701833,-0.3823390},
{-0.3693509,-0.5695166,-0.3806703},
{-0.3709034,-0.5689638,-0.3785682},
{-0.3718317,-0.5677960,-0.3775728},
{-0.3729422,-0.5668765,-0.3755653},
{-0.3735709,-0.5658311,-0.3732419},
{-0.3769657,-0.5607019,-0.3744302},
{-0.3829642,-0.5606802,-0.3705796},
{-0.3884629,-0.5588514,-0.3682644},
{-0.3942744,-0.5566272,-0.3661667},
{-0.3996266,-0.5534559,-0.3642277},
{-0.4053710,-0.5503486,-0.3615833},
{-0.4127519,-0.5460434,-0.3582530},
{-0.4193909,-0.5409467,-0.3559517},
{-0.4259599,-0.5367547,-0.3515352},
{-0.4316804,-0.5334380,-0.3467367},
{-0.4381602,-0.5304760,-0.3401970},
{-0.4457516,-0.5268759,-0.3336561},
{-0.4531151,-0.5235921,-0.3267878},
{-0.4610137,-0.5159933,-0.3229608},
{-0.4700238,-0.5115341,-0.3151676},
{-0.4801170,-0.5064890,-0.3064984},
{-0.4893597,-0.5014633,-0.2970199},
{-0.4986022,-0.4958706,-0.2874118},
{-0.5029551,-0.4935879,-0.2786304},
{-0.5023919,-0.4926120,-0.2759816},
{-0.5037020,-0.4901687,-0.2745720},
{-0.5057104,-0.4875754,-0.2709460},
{-0.5083305,-0.4834980,-0.2697509},
{-0.5121807,-0.4785634,-0.2674157},
{-0.5143448,-0.4748079,-0.2654997},
{-0.5179698,-0.4704880,-0.2618338},
{-0.5209323,-0.4660976,-0.2602486},
{-0.5252394,-0.4599547,-0.2588233},
{-0.5305682,-0.4540146,-0.2551326},
{-0.5351781,-0.4482071,-0.2528725},
{-0.5407830,-0.4412778,-0.2509892},
{-0.5442178,-0.4352174,-0.2506062},
{-0.5500031,-0.4281439,-0.2462621},
{-0.5564496,-0.4246389,-0.2394307},
{-0.5602237,-0.4199801,-0.2395078},
{-0.5634592,-0.4157888,-0.2397602},
{-0.5664314,-0.4113597,-0.2396518},
{-0.5665706,-0.4088986,-0.2407657},
{-0.5615740,-0.4097238,-0.2411674},
{-0.5643077,-0.4050037,-0.2344876},
{-0.5695177,-0.3998215,-0.2235569},
{-0.5724657,-0.3954216,-0.2138937},
{-0.5753831,-0.3912134,-0.2026750},
{-0.5778355,-0.3869459,-0.1917613},
{-0.5802302,-0.3833368,-0.1785730},
{-0.5827255,-0.3777274,-0.1655237},
{-0.5860677,-0.3720526,-0.1540101},
{-0.5902596,-0.3658271,-0.1434779},
{-0.5940931,-0.3601286,-0.1331889},
{-0.5980604,-0.3544121,-0.1234224},
{-0.6000461,-0.3532263,-0.1093739},
{-0.6047740,-0.3443315,-0.1020023},
{-0.6098909,-0.3362619,-0.0928386},
{-0.6148072,-0.3271114,-0.0862561},
{-0.6194964,-0.3193680,-0.0775070},
{-0.6229040,-0.3134414,-0.0698292},
{-0.6277676,-0.3052200,-0.0630067},
{-0.6315353,-0.2988997,-0.0557568},
{-0.6359922,-0.2918065,-0.0478419},
{-0.6403740,-0.2849034,-0.0408000},
{-0.6449657,-0.2768989,-0.0352880},
{-0.6473967,-0.2737769,-0.0307576},
{-0.6554804,-0.2560289,-0.0253972},
{-0.6589518,-0.2494695,-0.0203884},
{-0.6623034,-0.2442008,-0.0139996},
{-0.6658941,-0.2382072,-0.0092056},
{-0.6696705,-0.2321454,-0.0032407},
{-0.6733971,-0.2259635,0.0019887},
{-0.6769262,-0.2201200,0.0081002},
{-0.6804246,-0.2134958,0.0128029},
{-0.6836426,-0.2076611,0.0195356},
{-0.6860987,-0.2020288,0.0232582},
{-0.6884850,-0.1963718,0.0269800},
{-0.6904282,-0.1909353,0.0309782},
{-0.6918791,-0.1866912,0.0349445},
{-0.6933397,-0.1816875,0.0375139},
{-0.6950167,-0.1756678,0.0406629},
{-0.6956310,-0.1716536,0.0399123},
{-0.6913900,-0.1724524,0.0380142},
{-0.6889360,-0.1705680,0.0359914},
{-0.6871542,-0.1675581,0.0343594},
{-0.6852858,-0.1656433,0.0323584},
{-0.6856403,-0.1620828,0.0283194},
{-0.6864611,-0.1600858,0.0256563},
{-0.6883397,-0.1569616,0.0212866},
{-0.6895973,-0.1544626,0.0184464},
{-0.6910788,-0.1519706,0.0147857},
{-0.7107719,-0.1075471,0.0486739},
{-0.7116589,-0.1046845,0.0464703},
{-0.6951789,-0.1450441,0.0053046},
{-0.7133475,-0.0987251,0.0431974}
};
outPUaWam = {
{0.1320717,0.6039440,0.1020489},
{0.1308719,0.6047931,0.1014619},
{0.1299123,0.6056138,0.1008590},
{0.1288537,0.6066690,0.0999475},
{0.1273283,0.6082064,0.0987253},
{0.1252554,0.6098357,0.0986635},
{0.1228965,0.6122171,0.0975661},
{0.1201210,0.6149927,0.0969744},
{0.1196940,0.6168544,0.1008202},
{0.1179567,0.6198755,0.1015973},
{0.1168530,0.6225343,0.1043727},
{0.1160089,0.6252794,0.1074947},
{0.1152410,0.6280980,0.1114346},
{0.1142973,0.6312513,0.1156630},
{0.1148863,0.6343114,0.1204428},
{0.1153644,0.6376736,0.1261245},
{0.1148961,0.6416544,0.1315384},
{0.1134316,0.6462341,0.1363808},
{0.1122062,0.6508111,0.1413175},
{0.1120039,0.6551334,0.1470637},
{0.1120272,0.6593035,0.1527219},
{0.1139962,0.6626614,0.1602136},
{0.1162142,0.6663752,0.1666435},
{0.1198024,0.6698496,0.1732836},
{0.1226875,0.6737180,0.1802200},
{0.1259196,0.6773561,0.1878277},
{0.1231765,0.6827956,0.1947633},
{0.1149924,0.6893745,0.2036258},
{0.1103651,0.6937596,0.2134329},
{0.1056982,0.6991277,0.2230645},
{0.1020336,0.7038170,0.2339629},
{0.0992004,0.7086000,0.2458415},
{0.0945088,0.7138098,0.2569223},
{0.0910650,0.7190774,0.2678456},
{0.0874305,0.7239707,0.2796279},
{0.0840692,0.7283134,0.2929332},
{0.0824106,0.7325024,0.3055146},
{0.0794556,0.7367578,0.3179733},
{0.0779964,0.7401228,0.3317063},
{0.0734314,0.7439653,0.3456341},
{0.0732215,0.7482044,0.3575161},
{0.0775330,0.7557959,0.3618054},
{0.0761503,0.7606762,0.3735780},
{0.0750562,0.7654792,0.3855319},
{0.0761304,0.7703885,0.3982175},
{0.0745783,0.7757239,0.4101890},
{0.0749803,0.7811751,0.4209618},
{0.0732620,0.7871427,0.4319611},
{0.0730227,0.7933387,0.4421393},
{0.0713318,0.7996898,0.4526387},
{0.0696530,0.8063085,0.4626011},
{0.0678624,0.8124067,0.4728043},
{0.0666658,0.8185166,0.4824340},
{0.0669016,0.8247300,0.4918059},
{0.0670937,0.8302324,0.5020363},
{0.0684764,0.8358328,0.5118297},
{0.0690471,0.8411588,0.5222198},
{0.0693395,0.8469125,0.5321728},
{0.0652488,0.8590787,0.5329862},
{0.0687849,0.8629355,0.5459500},
{0.0733792,0.8664868,0.5588333},
{0.0766147,0.8701406,0.5715882},
{0.0803398,0.8747471,0.5823567},
{0.0813618,0.8792581,0.5929088},
{0.0845506,0.8835477,0.6030020},
{0.0856530,0.8879653,0.6130136},
{0.0887560,0.8922360,0.6225202},
{0.0909485,0.8966175,0.6315055},
{0.0934699,0.9002143,0.6411810},
{0.0896226,0.9007450,0.6557151},
{0.1068386,0.9024943,0.6644779},
{0.1076655,0.9072473,0.6714455},
{0.1090333,0.9108284,0.6789680},
{0.1098810,0.9136006,0.6873851},
{0.1121407,0.9165936,0.6949470},
{0.1135480,0.9199398,0.7020095},
{0.1161244,0.9223752,0.7094728},
{0.1176034,0.9257793,0.7159500},
{0.1210738,0.9292920,0.7211709},
{0.1213763,0.9333376,0.7261953},
{0.1228814,0.9361512,0.7317614},
{0.1249702,0.9395296,0.7360223},
{0.1259756,0.9424065,0.7407657},
{0.1272795,0.9454119,0.7449654},
{0.1312532,0.9475731,0.7492738},
{0.1334164,0.9487766,0.7544781},
{0.1355273,0.9501576,0.7588422},
{0.1375482,0.9506610,0.7638884},
{0.1408837,0.9514808,0.7671656},
{0.1415410,0.9517663,0.7710473},
{0.1439643,0.9514938,0.7751279},
{0.1450710,0.9511670,0.7786384},
{0.1467852,0.9498617,0.7831256},
{0.1487709,0.9494831,0.7859177},
{0.1494138,0.9490746,0.7890866},
{0.1500839,0.9480456,0.7920842},
{0.1503450,0.9473541,0.7945224},
{0.1534635,0.9465993,0.7963371},
{0.1530335,0.9459905,0.7981471}
};
outPElWam = {
{0.1575917,0.5855581,0.0698668},
{0.1564456,0.5861679,0.0694606},
{0.1554843,0.5867214,0.0690133},
{0.1543947,0.5874507,0.0682724},
{0.1528484,0.5885938,0.0672758},
{0.1507858,0.5898497,0.0674584},
{0.1484261,0.5917483,0.0666749},
{0.1456484,0.5939728,0.0664537},
{0.1451041,0.5953728,0.0705239},
{0.1432138,0.5977853,0.0716123},
{0.1419216,0.5999128,0.0746265},
{0.1408691,0.6021165,0.0779912},
{0.1398377,0.6044252,0.0821156},
{0.1385859,0.6070450,0.0865233},
{0.1387401,0.6095085,0.0914460},
{0.1387994,0.6122731,0.0973040},
{0.1378516,0.6156168,0.1029012},
{0.1359505,0.6195488,0.1079942},
{0.1341971,0.6235244,0.1130892},
{0.1334109,0.6272906,0.1189298},
{0.1328473,0.6309750,0.1246323},
{0.1341314,0.6339338,0.1320304},
{0.1356231,0.6372224,0.1383873},
{0.1384002,0.6402815,0.1449137},
{0.1404435,0.6437514,0.1517292},
{0.1427922,0.6470294,0.1591815},
{0.1394481,0.6521764,0.1660804},
{0.1311163,0.6584215,0.1752193},
{0.1262878,0.6625650,0.1851775},
{0.1213035,0.6676037,0.1949982},
{0.1173369,0.6720263,0.2060315},
{0.1140834,0.6765229,0.2180106},
{0.1090729,0.6814730,0.2292236},
{0.1051774,0.6864840,0.2402139},
{0.1011870,0.6911873,0.2520416},
{0.0973441,0.6954074,0.2652569},
{0.0951132,0.6994296,0.2777687},
{0.0916599,0.7035904,0.2901169},
{0.0896430,0.7069110,0.3036647},
{0.0846462,0.7107531,0.3174175},
{0.0837649,0.7148613,0.3291952},
{0.0872279,0.7219656,0.3337605},
{0.0852115,0.7267018,0.3454953},
{0.0834657,0.7313564,0.3574264},
{0.0837099,0.7361101,0.3700653},
{0.0815031,0.7412622,0.3820920},
{0.0811583,0.7464916,0.3929638},
{0.0787828,0.7522089,0.4041375},
{0.0777981,0.7581229,0.4145341},
{0.0754271,0.7641975,0.4252795},
{0.0730629,0.7705022,0.4355589},
{0.0706317,0.7763171,0.4460673},
{0.0687833,0.7821211,0.4560545},
{0.0683136,0.7880185,0.4658199},
{0.0678232,0.7932473,0.4764126},
{0.0684860,0.7985653,0.4866080},
{0.0683805,0.8035985,0.4974453},
{0.0680021,0.8090611,0.5078730},
{0.0634156,0.8206851,0.5095860},
{0.0661263,0.8244243,0.5228238},
{0.0698781,0.8278543,0.5360237},
{0.0723230,0.8314348,0.5490395},
{0.0752744,0.8359294,0.5601637},
{0.0756750,0.8403478,0.5710309},
{0.0781685,0.8445554,0.5814644},
{0.0786727,0.8488852,0.5918235},
{0.0811267,0.8530884,0.6016813},
{0.0827245,0.8574165,0.6109957},
{0.0846344,0.8610007,0.6209518},
{0.0804690,0.8615910,0.6355117},
{0.0964929,0.8635182,0.6445072},
{0.0968376,0.8682654,0.6517434},
{0.0977620,0.8718622,0.6594848},
{0.0981785,0.8746617,0.6681025},
{0.0999843,0.8776775,0.6759008},
{0.1009602,0.8810405,0.6832109},
{0.1031058,0.8834888,0.6909426},
{0.1041555,0.8869055,0.6977023},
{0.1072011,0.8904014,0.7032805},
{0.1071557,0.8944408,0.7085938},
{0.1083071,0.8972713,0.7144135},
{0.1100495,0.9006506,0.7189694},
{0.1107683,0.9035271,0.7239691},
{0.1117692,0.9065529,0.7284002},
{0.1153685,0.9087770,0.7329174},
{0.1172201,0.9100746,0.7382044},
{0.1190765,0.9115027,0.7427126},
{0.1208464,0.9121035,0.7477834},
{0.1239330,0.9130118,0.7511091},
{0.1244548,0.9133704,0.7549597},
{0.1266547,0.9132167,0.7589960},
{0.1276524,0.9129766,0.7624184},
{0.1292129,0.9118088,0.7667490},
{0.1310704,0.9115300,0.7694479},
{0.1316155,0.9112352,0.7724613},
{0.1322289,0.9103094,0.7752861},
{0.1324420,0.9097144,0.7775596},
{0.1354347,0.9090831,0.7792347},
{0.1350062,0.9085601,0.7808562}
};
outPLaWam = {
{0.1183845,0.5638016,0.0736678},
{0.1171587,0.5645388,0.0731651},
{0.1160932,0.5652634,0.0726043},
{0.1148845,0.5661995,0.0717830},
{0.1132223,0.5675365,0.0706469},
{0.1110487,0.5689637,0.0705791},
{0.1085656,0.5710601,0.0695268},
{0.1056793,0.5734483,0.0689472},
{0.1049378,0.5751853,0.0725569},
{0.1029037,0.5778555,0.0733144},
{0.1014730,0.5802366,0.0759536},
{0.1002748,0.5827188,0.0789051},
{0.0991242,0.5852642,0.0826264},
{0.0977607,0.5881166,0.0866434},
{0.0977790,0.5908774,0.0911804},
{0.0977089,0.5939432,0.0965361},
{0.0966657,0.5975247,0.1017202},
{0.0946860,0.6016703,0.1063809},
{0.0928583,0.6058400,0.1112537},
{0.0919583,0.6098888,0.1169665},
{0.0912866,0.6138360,0.1226410},
{0.0924164,0.6171665,0.1301033},
{0.0937628,0.6208030,0.1366213},
{0.0963666,0.6242846,0.1434049},
{0.0982746,0.6280890,0.1505156},
{0.1004910,0.6317049,0.1583084},
{0.0971411,0.6368542,0.1654889},
{0.0888400,0.6430313,0.1742917},
{0.0839803,0.6472771,0.1840129},
{0.0789648,0.6524191,0.1936328},
{0.0749259,0.6570739,0.2043774},
{0.0715766,0.6618712,0.2161394},
{0.0665186,0.6669943,0.2271042},
{0.0625488,0.6722401,0.2379968},
{0.0584874,0.6771831,0.2496707},
{0.0545484,0.6817121,0.2628134},
{0.0521976,0.6861051,0.2753787},
{0.0486422,0.6905918,0.2877681},
{0.0464957,0.6943330,0.3014046},
{0.0414350,0.6983998,0.3151404},
{0.0404259,0.7029460,0.3270141},
{0.0436891,0.7107799,0.3316979},
{0.0415695,0.7159207,0.3434600},
{0.0397178,0.7210054,0.3554323},
{0.0398427,0.7262480,0.3682204},
{0.0375340,0.7318569,0.3802878},
{0.0370798,0.7375694,0.3913888},
{0.0346133,0.7437371,0.4026271},
{0.0335332,0.7501210,0.4132726},
{0.0310784,0.7566462,0.4241944},
{0.0286414,0.7633607,0.4347043},
{0.0261429,0.7695836,0.4454347},
{0.0242298,0.7758026,0.4558008},
{0.0236910,0.7822024,0.4658635},
{0.0231405,0.7879287,0.4768231},
{0.0237483,0.7937787,0.4873992},
{0.0236009,0.7993040,0.4986046},
{0.0231891,0.8052551,0.5093905},
{0.0186015,0.8171015,0.5115494},
{0.0212833,0.8214319,0.5250925},
{0.0250268,0.8254434,0.5387712},
{0.0274607,0.8296607,0.5520771},
{0.0304250,0.8347044,0.5636329},
{0.0308476,0.8395711,0.5748912},
{0.0333637,0.8444397,0.5856493},
{0.0339061,0.8493155,0.5963810},
{0.0364177,0.8541522,0.6066784},
{0.0380818,0.8591265,0.6163905},
{0.0400631,0.8634249,0.6266543},
{0.0359655,0.8643180,0.6415944},
{0.0521398,0.8676109,0.6509146},
{0.0525840,0.8729623,0.6584180},
{0.0536339,0.8770930,0.6665810},
{0.0541772,0.8804887,0.6755142},
{0.0561387,0.8841310,0.6837054},
{0.0572730,0.8881305,0.6913448},
{0.0595947,0.8911872,0.6994583},
{0.0608149,0.8952525,0.7064725},
{0.0640573,0.8993560,0.7124145},
{0.0641547,0.9039196,0.7178710},
{0.0654574,0.9072604,0.7238541},
{0.0673448,0.9111132,0.7285530},
{0.0681924,0.9143614,0.7337112},
{0.0693095,0.9177801,0.7382045},
{0.0730594,0.9204580,0.7428416},
{0.0750293,0.9221609,0.7481469},
{0.0769974,0.9239113,0.7527313},
{0.0788683,0.9248250,0.7578334},
{0.0820627,0.9260855,0.7611570},
{0.0826167,0.9266040,0.7649321},
{0.0848821,0.9267240,0.7688752},
{0.0858995,0.9265881,0.7722375},
{0.0875183,0.9256362,0.7765144},
{0.0894215,0.9255163,0.7791822},
{0.0900143,0.9253944,0.7821491},
{0.0906635,0.9246045,0.7849279},
{0.0909171,0.9241690,0.7871378},
{0.0939855,0.9237381,0.7888366},
{0.0935796,0.9233220,0.7903912}
};
outPWrWam = {
{0.2006294,0.3771539,-0.1463286},
{0.1998838,0.3767891,-0.1457106},
{0.1990475,0.3765113,-0.1453205},
{0.1978514,0.3761370,-0.1449952},
{0.1966880,0.3760037,-0.1446405},
{0.1955239,0.3762878,-0.1432899},
{0.1942402,0.3767741,-0.1423997},
{0.1932138,0.3775164,-0.1406915},
{0.1932269,0.3785101,-0.1360669},
{0.1922417,0.3795158,-0.1332772},
{0.1917557,0.3808060,-0.1291719},
{0.1914967,0.3822203,-0.1247587},
{0.1912980,0.3840146,-0.1198646},
{0.1908548,0.3860526,-0.1146117},
{0.1913830,0.3879398,-0.1089561},
{0.1922959,0.3902398,-0.1023565},
{0.1922572,0.3927967,-0.0956340},
{0.1915814,0.3956617,-0.0889950},
{0.1901480,0.3985324,-0.0825459},
{0.1886665,0.4012571,-0.0756999},
{0.1870096,0.4040069,-0.0692153},
{0.1859693,0.4064838,-0.0618880},
{0.1849325,0.4090140,-0.0552994},
{0.1843140,0.4113145,-0.0487123},
{0.1832828,0.4141180,-0.0418123},
{0.1822849,0.4169086,-0.0344928},
{0.1778476,0.4214456,-0.0270872},
{0.1717524,0.4267655,-0.0163772},
{0.1675852,0.4303556,-0.0056059},
{0.1631820,0.4345262,0.0054038},
{0.1593159,0.4384271,0.0171024},
{0.1554488,0.4423636,0.0296404},
{0.1506907,0.4467572,0.0416032},
{0.1460143,0.4512275,0.0530997},
{0.1413967,0.4556206,0.0651820},
{0.1360526,0.4600256,0.0778482},
{0.1315057,0.4639070,0.0900729},
{0.1259835,0.4682368,0.1018203},
{0.1211037,0.4720220,0.1142911},
{0.1147682,0.4765727,0.1269518},
{0.1110182,0.4807416,0.1382234},
{0.1103524,0.4857601,0.1448233},
{0.1060051,0.4903969,0.1564117},
{0.1017501,0.4948821,0.1682953},
{0.0987011,0.4995009,0.1808133},
{0.0939150,0.5041530,0.1932795},
{0.0900972,0.5085479,0.2050066},
{0.0851603,0.5132214,0.2174043},
{0.0807687,0.5178078,0.2294265},
{0.0754018,0.5225318,0.2419146},
{0.0700798,0.5271788,0.2544240},
{0.0647178,0.5314737,0.2670652},
{0.0593071,0.5355318,0.2796205},
{0.0551343,0.5396583,0.2921290},
{0.0506774,0.5433465,0.3052969},
{0.0471548,0.5470662,0.3183279},
{0.0431657,0.5503963,0.3322853},
{0.0389825,0.5541498,0.3459994},
{0.0320713,0.5622544,0.3538423},
{0.0304643,0.5654478,0.3689266},
{0.0293910,0.5682770,0.3843484},
{0.0273107,0.5715764,0.3991311},
{0.0258306,0.5754786,0.4126995},
{0.0225123,0.5794010,0.4257535},
{0.0203017,0.5832864,0.4385837},
{0.0166299,0.5872296,0.4514240},
{0.0142011,0.5912588,0.4638727},
{0.0109819,0.5955640,0.4756766},
{0.0079378,0.5994521,0.4877790},
{0.0008419,0.6006789,0.5028112},
{0.0080357,0.6045170,0.5136688},
{0.0042153,0.6096675,0.5230063},
{0.0008983,0.6138689,0.5326704},
{-0.0029652,0.6174362,0.5430826},
{-0.0058095,0.6212908,0.5530247},
{-0.0093299,0.6255011,0.5625433},
{-0.0116434,0.6287923,0.5726746},
{-0.0148977,0.6330823,0.5818354},
{-0.0161639,0.6372831,0.5904211},
{-0.0194572,0.6419243,0.5980064},
{-0.0215531,0.6455150,0.6058774},
{-0.0227586,0.6494699,0.6126902},
{-0.0244600,0.6528075,0.6196713},
{-0.0257647,0.6563925,0.6257883},
{-0.0249986,0.6595401,0.6319072},
{-0.0255130,0.6619161,0.6378568},
{-0.0256446,0.6640466,0.6434841},
{-0.0257708,0.6656587,0.6488220},
{-0.0247018,0.6676037,0.6525822},
{-0.0249415,0.6685460,0.6561327},
{-0.0241255,0.6693994,0.6597816},
{-0.0236325,0.6697539,0.6625154},
{-0.0232665,0.6697625,0.6658103},
{-0.0222953,0.6703088,0.6678787},
{-0.0226966,0.6710409,0.6698970},
{-0.0228175,0.6710610,0.6716241},
{-0.0234134,0.6714409,0.6728703},
{-0.0216831,0.6719908,0.6737536},
{-0.0226057,0.6723306,0.6741831}
};
outPEeWam = {
{0.2248143,0.4044204,-0.1939903},
{0.1595808,0.4033653,-0.1813388},
{0.1590156,0.4031419,-0.1812127},
{0.1581038,0.4028113,-0.1811700},
{0.1572867,0.4026694,-0.1811983},
{0.1565345,0.4029725,-0.1802730},
{0.1557352,0.4034205,-0.1799142},
{0.1552694,0.4040652,-0.1788410},
{0.1559484,0.4053745,-0.1746495},
{0.1524427,0.4036663,-0.1711295},
{0.1501982,0.4029026,-0.1663836},
{0.1481309,0.4020843,-0.1611570},
{0.1466541,0.4021494,-0.1556144},
{0.1447926,0.4021901,-0.1495095},
{0.1438194,0.4019215,-0.1427529},
{0.1434679,0.4021464,-0.1351295},
{0.1421365,0.4023842,-0.1271933},
{0.1401908,0.4026530,-0.1191635},
{0.1375670,0.4030733,-0.1110875},
{0.1349379,0.4034508,-0.1023162},
{0.1322734,0.4040115,-0.0937905},
{0.1313134,0.4072551,-0.0866294},
{0.1293315,0.4079744,-0.0778261},
{0.1278061,0.4084594,-0.0686797},
{0.1261024,0.4097072,-0.0594458},
{0.1245743,0.4111923,-0.0498815},
{0.1199401,0.4149917,-0.0414073},
{0.1138572,0.4191639,-0.0301743},
{0.1096579,0.4220073,-0.0188244},
{0.1051986,0.4250233,-0.0067463},
{0.1012912,0.4279434,0.0060018},
{0.0973762,0.4308190,0.0199301},
{0.0926487,0.4342952,0.0328952},
{0.0879949,0.4377801,0.0458255},
{0.0834103,0.4415685,0.0588477},
{0.0780532,0.4456942,0.0723091},
{0.0735339,0.4489875,0.0859880},
{0.0680054,0.4531326,0.0985936},
{0.0630936,0.4568753,0.1119655},
{0.0566755,0.4617543,0.1245743},
{0.0530526,0.4652650,0.1375488},
{0.0540658,0.4649829,0.1451880},
{0.0509107,0.4667382,0.1542040},
{0.0485045,0.4677111,0.1631331},
{0.0487024,0.4677117,0.1713490},
{0.0486745,0.4672090,0.1795522},
{0.0556089,0.4635696,0.1853213},
{0.0525282,0.4659272,0.2001297},
{0.0482892,0.4690528,0.2164638},
{0.0446716,0.4718060,0.2328287},
{0.0409021,0.4749769,0.2495641},
{0.0373138,0.4780990,0.2666776},
{0.0341513,0.4812573,0.2842538},
{0.0323292,0.4850929,0.3022550},
{0.0294038,0.4889870,0.3191709},
{0.0266922,0.4930396,0.3345270},
{0.0233740,0.4967459,0.3504490},
{0.0195156,0.5008672,0.3655444},
{0.0130288,0.5093920,0.3748886},
{0.0113873,0.5128517,0.3905996},
{0.0100568,0.5159099,0.4063455},
{0.0076097,0.5195863,0.4216899},
{0.0055598,0.5238717,0.4356302},
{0.0021362,0.5279919,0.4490326},
{-0.0006576,0.5323715,0.4624246},
{-0.0045006,0.5365899,0.4756958},
{-0.0072690,0.5410004,0.4886342},
{-0.0108341,0.5456970,0.5009224},
{-0.0143073,0.5499801,0.5134243},
{-0.0215913,0.5513520,0.5285718},
{-0.0153371,0.5558004,0.5397533},
{-0.0194039,0.5613314,0.5495724},
{-0.0229307,0.5658742,0.5596645},
{-0.0271095,0.5697984,0.5704264},
{-0.0302704,0.5740441,0.5807629},
{-0.0341615,0.5786532,0.5906265},
{-0.0368232,0.5823379,0.6010993},
{-0.0404667,0.5870474,0.6105932},
{-0.0420498,0.5916782,0.6195777},
{-0.0455789,0.5966870,0.6275232},
{-0.0479196,0.6006227,0.6357018},
{-0.0492619,0.6049210,0.6429056},
{-0.0510308,0.6085361,0.6502334},
{-0.0524890,0.6123932,0.6566083},
{-0.0518751,0.6158312,0.6630069},
{-0.0516250,0.6167848,0.6675440},
{-0.0464632,0.6140979,0.6694015},
{-0.0430888,0.6132158,0.6722704},
{-0.0390466,0.6135343,0.6742785},
{-0.0370333,0.6136035,0.6769919},
{-0.0358637,0.6134907,0.6781237},
{-0.0359983,0.6135618,0.6795309},
{-0.0367599,0.6131545,0.6804208},
{-0.0365754,0.6134785,0.6807783},
{-0.0377715,0.6140490,0.6810626},
{-0.0569550,0.6564635,0.7187573},
{-0.0576882,0.6575932,0.7201301},
{-0.0386659,0.6148818,0.6808350},
{-0.0571334,0.6601813,0.7217250}
};
outThetasWam = {
{-0.1158496,-0.2494568,-0.0474730,1.2057666,-0.7959598,1.1480220,0.0000000},
{-0.1147501,-0.2519346,-0.0475739,1.2070694,1.2400000,-1.6000000,0.0000000},
{-0.1136078,-0.2544860,-0.0476542,1.2092547,1.2400000,-1.6000000,0.0000000},
{-0.1126843,-0.2577024,-0.0481949,1.2115541,1.2400000,-1.6000000,0.0000000},
{-0.1113500,-0.2615049,-0.0486997,1.2155735,1.2400000,-1.6000000,0.0000000},
{-0.1092408,-0.2647742,-0.0483702,1.2207495,1.2400000,-1.6000000,0.0000000},
{-0.1069642,-0.2691286,-0.0484169,1.2271541,1.2400000,-1.6000000,0.0000000},
{-0.1042144,-0.2738180,-0.0483447,1.2361982,1.2400000,-1.6000000,0.0000000},
{-0.1008371,-0.2764620,-0.0465608,1.2447726,1.2400000,-1.6000000,0.0000000},
{-0.0984564,-0.2813438,-0.0466176,1.2550061,1.1677457,-1.6000000,0.0000000},
{-0.0959758,-0.2848869,-0.0459274,1.2656575,1.1113616,-1.6000000,0.0000000},
{-0.1092565,-0.2572046,-0.0566796,1.2767832,-2.0911466,1.6000000,0.0000000},
{-0.1075282,-0.2605678,-0.0553508,1.2891612,1.0027819,-1.6000000,0.0000000},
{-0.1058488,-0.2641651,-0.0540457,1.3024526,0.9495558,-1.6000000,0.0000000},
{-0.1040886,-0.2685330,-0.0523490,1.3175960,0.8909284,-1.6000000,0.0000000},
{-0.1020572,-0.2719445,-0.0501681,1.3339050,0.8340623,-1.6000000,0.0000000},
{-0.1002775,-0.2763232,-0.0485197,1.3514882,0.7750156,-1.6000000,0.0000000},
{-0.0984159,-0.2803298,-0.0470581,1.3687631,0.7113759,-1.6000000,0.0000000},
{-0.0971172,-0.2856790,-0.0460498,1.3846811,0.6517097,-1.6000000,0.0000000},
{-0.0959586,-0.2914327,-0.0448068,1.3982720,0.5908713,-1.6000000,0.0000000},
{-0.0951190,-0.2973649,-0.0437888,1.4101856,0.5335454,-1.6000000,0.0000000},
{-0.0777923,-0.3285671,-0.0363258,1.4201309,-2.6015144,1.6000000,0.0000000},
{-0.0783816,-0.3349911,-0.0374065,1.4301427,0.4875998,-1.6000000,0.0000000},
{-0.0793342,-0.3416001,-0.0387462,1.4390944,0.4318868,-1.6000000,0.0000000},
{-0.0806726,-0.3480265,-0.0404936,1.4495978,0.3845734,-1.6000000,0.0000000},
{-0.0822526,-0.3537376,-0.0423087,1.4599617,0.3423102,-1.6000000,0.0000000},
{-0.0839028,-0.3589221,-0.0446828,1.4707385,0.3253673,-1.6000000,0.0000000},
{-0.0820486,-0.3623030,-0.0430934,1.4823164,0.3011606,-1.6000000,0.0000000},
{-0.0805520,-0.3642077,-0.0413478,1.4897986,0.2799461,-1.6000000,0.0000000},
{-0.0792137,-0.3675140,-0.0398455,1.4997715,0.2486821,-1.6000000,0.0000000},
{-0.0772886,-0.3689531,-0.0370586,1.5078020,0.2162294,-1.6000000,0.0000000},
{-0.0756259,-0.3709337,-0.0344147,1.5161689,0.1788517,-1.6000000,0.0000000},
{-0.0740435,-0.3725590,-0.0318885,1.5249189,0.1492906,-1.6000000,0.0000000},
{-0.0731054,-0.3751861,-0.0302268,1.5332201,0.1152108,-1.6000000,0.0000000},
{-0.0719135,-0.3763683,-0.0279967,1.5397327,0.0905029,-1.6000000,0.0000000},
{-0.0711261,-0.3771877,-0.0261686,1.5461905,0.0716215,-1.6000000,0.0000000},
{-0.0706988,-0.3795373,-0.0251040,1.5519567,0.0421858,-1.6000000,0.0000000},
{-0.0703631,-0.3807841,-0.0241575,1.5567489,0.0252011,-1.6000000,0.0000000},
{-0.0701424,-0.3813363,-0.0232966,1.5602261,0.0086838,-1.6000000,0.0000000},
{-0.0699058,-0.3809659,-0.0224787,1.5658219,0.0094792,-1.6000000,0.0000000},
{-0.0695557,-0.3829474,-0.0215729,1.5718445,-0.0242703,-1.6000000,0.0000000},
{-0.0678176,-0.3901783,-0.0186108,1.5777883,-0.1042786,-1.5232844,0.0000000},
{-0.0670357,-0.3922863,-0.0170143,1.5846183,-0.1086256,-1.4483505,0.0000000},
{-0.0662026,-0.3946326,-0.0153578,1.5912184,-0.1168471,-1.3576808,0.0000000},
{-0.0657359,-0.3980848,-0.0143972,1.5991983,-0.1230610,-1.2286640,0.0000000},
{-0.0646006,-0.4013331,-0.0123166,1.6055391,-0.1427632,-1.0834736,0.0000000},
{-0.0640950,-0.4067987,-0.0114885,1.6109222,-0.2026051,-0.8304721,0.0000000},
{-0.0626877,-0.4119606,-0.0090839,1.6172950,-0.2902740,-0.8068297,0.0000000},
{-0.0618915,-0.4194226,-0.0078826,1.6227877,-0.3834710,-0.8279190,0.0000000},
{-0.0607005,-0.4266209,-0.0059822,1.6281535,-0.4895300,-0.8283436,0.0000000},
{-0.0596407,-0.4355195,-0.0043971,1.6337268,-0.5896297,-0.8413504,0.0000000},
{-0.0585556,-0.4440938,-0.0027495,1.6383646,-0.6911838,-0.8616692,0.0000000},
{-0.0580164,-0.4548385,-0.0021345,1.6411310,-0.7987812,-0.8891089,0.0000000},
{-0.0567117,-0.4659337,-0.0001874,1.6446302,-0.9059818,-0.9301934,0.0000000},
{-0.0557825,-0.4773604,0.0010422,1.6467185,-0.9725117,-0.9595637,0.0000000},
{-0.0546575,-0.4901758,0.0025159,1.6488994,-1.0106217,-0.9743102,0.0000000},
{-0.0535011,-0.5039720,0.0040106,1.6510943,-1.0407603,-0.9853830,0.0000000},
{-0.0522589,-0.5185754,0.0056497,1.6534181,-1.0592808,-0.9898547,0.0000000},
{-0.0519307,-0.5409210,0.0061555,1.6567272,-4.2109326,0.9886862,0.0000000},
{-0.0504427,-0.5525069,0.0084702,1.6607914,-4.2218955,0.9881649,0.0000000},
{-0.0498684,-0.5668276,0.0094037,1.6635221,-1.0824952,-0.9827118,0.0000000},
{-0.0473025,-0.5826421,0.0116167,1.6661054,-1.0875143,-0.9837340,0.0000000},
{-0.0452953,-0.6035374,0.0124802,1.6686032,-1.0829060,-0.9810975,0.0000000},
{-0.0453184,-0.6144283,0.0133744,1.6700647,-1.0857951,-0.9768679,0.0000000},
{-0.0424052,-0.6330524,0.0157552,1.6698836,-1.0852320,-0.9774713,0.0000000},
{-0.0419755,-0.6435122,0.0174956,1.6692765,-1.0889705,-0.9738165,0.0000000},
{-0.0402552,-0.6559848,0.0198244,1.6674002,-1.0904569,-0.9714729,0.0000000},
{-0.0384850,-0.6674384,0.0219260,1.6644946,-1.0924738,-0.9695656,0.0000000},
{-0.0366143,-0.6788503,0.0234489,1.6614833,-1.0953052,-0.9675057,0.0000000},
{-0.0378388,-0.6848222,0.0233818,1.6586635,-1.0938054,-0.9671739,0.0000000},
{-0.0356923,-0.7062629,0.0233703,1.6555327,-1.1007553,-0.9637570,0.0000000},
{-0.0339096,-0.7154879,0.0248728,1.6521564,-1.1051547,-0.9634978,0.0000000},
{-0.0334404,-0.7238381,0.0260954,1.6475641,-1.1068321,-0.9632618,0.0000000},
{-0.0324568,-0.7319367,0.0270672,1.6425192,-1.1087982,-0.9622795,0.0000000},
{-0.0315487,-0.7403808,0.0282970,1.6366261,-1.1100524,-0.9609866,0.0000000},
{-0.0302104,-0.7484358,0.0295916,1.6306949,-1.1108176,-0.9588497,0.0000000},
{-0.0290619,-0.7562986,0.0310485,1.6247948,-1.1104301,-0.9561946,0.0000000},
{-0.0270985,-0.7643223,0.0325382,1.6193697,-1.1114195,-0.9533913,0.0000000},
{-0.0252143,-0.7719655,0.0346519,1.6137023,-4.2524867,0.9499168,0.0000000},
{-0.0228817,-0.7785011,0.0362809,1.6100718,-1.1135333,-0.9481057,0.0000000},
{-0.0209789,-0.7849556,0.0375945,1.6065341,-1.1155921,-0.9461950,0.0000000},
{-0.0187402,-0.7912531,0.0392382,1.6038819,-1.1190577,-0.9450168,0.0000000},
{-0.0170592,-0.7962812,0.0406801,1.6017133,-1.1217584,-0.9441407,0.0000000},
{-0.0150441,-0.8018029,0.0418606,1.6003685,-1.1245447,-0.9426925,0.0000000},
{-0.0134535,-0.8083792,0.0426796,1.5987314,-1.1281378,-0.9418108,0.0000000},
{-0.0123213,-0.8140263,0.0426161,1.5973524,-1.1587613,-0.9065530,0.0000000},
{-0.0111591,-0.8184620,0.0431677,1.5959752,-1.3062930,-0.8195911,0.0000000},
{-0.0106713,-0.8229052,0.0427619,1.5948705,-1.4139030,-0.7759639,0.0000000},
{-0.0097150,-0.8274463,0.0425497,1.5932500,-4.6517357,0.7515149,0.0000000},
{-0.0092779,-0.8300809,0.0419721,1.5936638,-4.7195708,0.7468107,0.0000000},
{-0.0086381,-0.8343598,0.0410710,1.5938483,-4.7600000,0.7087447,0.0000000},
{-0.0087960,-0.8364686,0.0400890,1.5945917,-4.7600000,0.6867536,0.0000000},
{-0.0092536,-0.8394682,0.0384346,1.5937979,-4.7600000,0.6470199,0.0000000},
{-0.0094753,-0.8419119,0.0373512,1.5935442,-4.7600000,0.6187304,0.0000000},
{-0.0099953,-0.8439542,0.0358291,1.5923257,-4.7600000,0.5915058,0.0000000},
{-0.0106909,-0.8452996,0.0342605,1.5909187,-0.9003060,-1.4463256,0.0000000},
{-0.0111469,-0.8465974,0.0327746,1.5890088,-0.8961918,-1.4584428,0.0000000},
{-0.0118643,-0.8489934,0.0312846,1.5872231,-4.7600000,0.5304477,0.0000000},
{-0.0125508,-0.8494753,0.0297113,1.5853125,-0.8846680,-1.4853459,0.0000000}
};
